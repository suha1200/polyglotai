المحتويات

تمهيد السلسلة
شكر وتقدير
 -١أيتها املرآة على الحائط
 -٢الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي
 -٣كل ما له علاقة بالبشر
 -٤أهي ٍّ
حقا مجرد آلات؟
 -٥التكنولوجيا
 -٦لا َ
تنس )علم( البيانات
 -٧الخصوصية وغريها من القضايا
ُ
لامسئولية الآلات والقرارات غري ا ُملبررة
-٨
 -٩التحيز ومعنى الحياة
 -١٠السياسات املقترحة
 -١١التحديات التي تُواجه صانعي السياسات
 -١٢تحد ِّي ُّ
تغري املناخ :حول الأولويات وحقبة التأثري البشري
مسرد املصطلحات
ملاحظات
قراءات إضافية
املراجع
إلى أرنو

تمهيد السلسلة

تُقد ِّم »سلسلة املعارف الأساسية« التي تَنشرها مؤسسة »إم آي تي بريس« ُكتبًا موجز ًة
وشكل أنيق ،وحج ٍم صغري يُلائم الجيب ،تُناقِ ش املوضوعات التي
بلُغة جَ زلة سهلة الفهم،
ٍ
تُثري الاهتمام في الوقت الحالي .و َّملا كانت ُكتب هذه السلسلة من تأليف مُف ِّكرين بارزين،
ً
ٍ
إضافة
موضوعات تتنو َّع بني املجالات الثقافية والتاريخية،
فإنها تُقد ِّم آراء الخبراء بشأن
إلى العِ لمية والتقنية.
إشباع َلحظي للمعلومات ،أضحى لدى الجميع
في ِظل ما يَشيع في هذا العصر من
ٍ
ٍ
بسرعة وسهولة ،وأصبح من
القدر ُة على الوصول إلى الآراء والأفكار والشروح السطحية
ً
بمكان أن يَحظى املرء باملعرفة الأساسية التي تُ ِّ
صادقا للعا َلم؛ وما
يسر َفهمً ا
الصعوبة
ٍ
تفعله كتب هذه السلسلة هو أنها تُ ِّ
حقق ذلك الغرض .وك ُّل كتاب من هذه الكتب ا ُمل َ
ختصرة
ُيسرة للوصول إلى الأفكار ا ُمل َّ
ً
وسيلة م َّ
عقدة ،من خلال تبسيط املواد ا ُمل ِّ
تخصصة
يُقد ِّم للقارئ
ٍ
لغري ا ُمل ِّ
طريقة مُمكنة.
وشرح املوضوعات املهمة بأبسط
ختصنيْ َ ،
بروس تيدور
أستاذ الهندسة البيولوجية وعلوم الكمبيوتر
»معهد ماساتشوستس للتكنولوجيا«

شكر وتقدير

لا يعتمد هذا الكتاب على عملي الخاص في موضوع أخلاقيات الذكاء الاصطناعي فحسب،
بل يعكس املعرفة والخبرة في هذا املجال بأكملِه .وسيكون من ا ُملستحيل إدراج جميع
الأشخاص الذين ناقشتُهم وتع َّل ُ
مت منهم على مدار السنوات املاضية ،لكن املجتمعات
ذات الصلة والسريعة النمو التي أعرفها تضم باحثني في مجال الذكاء الاصطناعي مثل
جوانا بريسون ولوك ستيلز ،وزملائي الفلاسفة في مجال التكنولوجيا مثل شانون فالور
ولوتشيانو فلوريدي ،وأكاديميني يسعَ ون إلى الابتكار املسئول في هولندا واململكة املتحدة،
مثل بريند ستال في جامعة دي مونتفورت ،وبعض الأشخاص الذين ا ْلتَ ُ
قيت بهم في فيينا،
مثل روبرت ترابل ،وسارة سبيكرمان ،وولفجانج )بيل( برايس ،وزملائي الأعضاء في
عني بالذكاء
الهيئات الاستشارية ذات التوج ُّ هات السياسية ،فريق الخبراء الرفيع املستوى ا َمل ِّ
الاصطناعي )املفوضية الأوروبية( واملجلس النمساوي للروبوتات والذكاء الاصطناعي ،ومن
ِضمنهم على سبيل املثال لا الحصر راجا شاتيلا ،وفريجينيا ديج نوم ،وجريوين فان دين
هوفن ،وسابني كوسيجي ،وماتياس شوتز .أو ُّد ً
أيضا أن أشكر بحرارة زاكاري ستورمز
للمساعدة في التدقيق اللغوي للكتاب وتنسيقه ،ولينا ستاركل وإيزابيل والتر على دعمهما
في البحث عن الأدبيات.

الفصل الأول

أيتها المرآة على الحائط

الضجة واملخاوف التي يُثريها الذكاء الاصطناعي :أيتها املرآة على الحائط:
مَ ن الأذكى في العا َلم؟
عندما أُعلنت النتائج ،اغرورقت عينا اللاعب لي سيدول بالدموع . َّ
حقق »ألفا جو« ،وهو
برنامج ذكاء اصطناعي ط َّو َرتْه شركة »ديب مايند« التابعة إلى جوجل ،فو ًزا ١-٤في
لعبة »جو« )لعبة »جو« هي لعبة استراتيجية قديمة ظهرت في الصني ويُشارك فيها
لاعبان اثنان( .تاريخ الحدث :مارس .٢٠١٦قبل عقدَين من الزمان ،خسر لاعب الشطرنج
جاري كاسباروف الحاصل على لقب »جراند ماستر« )الأستاذ الكبري( أمام الآلة »ديب
بلو« ،والآن فاز برنامج كمبيوتر على بطل العالم لثماني عشرة مرة؛ لي سيدول ،في لعبة
م َّ
ُعقدة كان يُن َ
ِ
حدسهم
ظر إليها على أنها لعبة لا يمكن أن يلعبها إلا البشر ،باستخدام
وتفكريهم الاستراتيجي .الأدهى من ذلك أن الكمبيوتر لم ُ
يفز باتباع القواعد ا ُملعطاة له
من قِ بَل ا ُملبرمجني ،وإنما عن طريق تع ُّلم الآلة القائم على امللايني من مباريات »جو«
السابقة وعلى اللعب ض َّد نفسه .في مثل هذه الحالة ،يُعِ د املبرمجون مجموعات البيانات
وي ِ
ُنشئون الخوارزميات ،ولكن لا يُمكنهم معرفة التح ُّركات التي سيأتي بها البرنامج.
فالذكاء الاصطناعي يتع َّلم من تلقاء نفسه .وبعد عددٍ من التح ُّركات غري املعتادة واملفاجئة،
اض ُ
ط َّر بطل العالم لي إلى الانسحاب ).(Borowiec 2016
إنه إنجاز رائع َّ
حق َقه الذكاء الاصطناعي .ولكنه ،مع ذلك ،يُثري املخاوف في قلوبنا .إننا
مُعجبون بجمال الحركات ،ولكننا ً
أيضا حزانى ،وربما حتى خائفون .نأمُل في أن تساعدنا
حلول
أنظمة الذكاء الاصطناعي الأكثر ذكاءً في إحداث ثورة في الرعاية الصحية أو في إيجاد
ٍ

أخلاقيات الذكاء الاصطناعي

لجميع أنواع املشكلات املجتمعية ،ولكن يُراودنا القلق من أن تسيطر الآلات على زمام
أمورنا .فهل تستطيع الآلات أن تتفو َّق علينا وتتح َّكم فينا؟ هل لا يزال الذكاء الاصطناعي
مجرد أداة ،أم إنه سيُصبح رويدًا رويدًا سيدنا لا محالة؟ تُذ ِّكرنا هذه املخاوف بكلمات
»هال« كمبيوتر الذكاء الاصطناعي في فيلم الخيال العلمي الذي أخرجه ستانلي كوبريك:
» :٢٠٠١ملحمة الفضاء« ) :٢٠٠١سبيس أوديسي( ،حني قال ردٍّا على الأمر البشري »افتح
أبواب املركبة الصغرية«» :أخشى أنني لا أستطيع أن أفعل ذلك يا ديف «.وإذا لم ي ُكن هناك
خوف ،فقد يكون هناك شعور بالحزن أو خيبة الأمل .لقد أطاح داروين وفرويد بإيماننا
بتمي ُّزنا ،وبإحساسنا بالتفو ُّق ،وأطاحا بأوهام السيطرة التي يعيش فيها البشر؛ والآن جاء
ً
ضربة أخرى إلى صورة البشر عن ذواتهم .إذا كانت الآلة
دور الذكاء الاصطناعي ليُوج ِّ ه
تستطيع القيام بذلك ،فماذا َّ
تبقى لنا؟ ماذا نحن؟ هل نحن مج َّرد آلات؟ هل نحن آلات
رديئة ،بها الكثري من العيوب والأخطاء؟ وماذا سيحدُث لنا؟ هل سنُصبح عبيدًا للآلات؟ أو
ما هو أسوأ ،مجرد مصدر للطاقة ،كما في فيلم »املصفوفة« )ذا ماتريكس(؟
التأثري الحقيقي والواسع النطاق للذكاء الاصطناعي
ولكن إنجازات الذكاء الاصطناعي لا تقتصر على الألعاب أو عا َلم الخيال العلمي .فالذكاء
الاصطناعي يحدث الآن وهو م ِّ
ُتوغل في كل ما حولنا ،وغالبًا ما يكون مُضم َّ نًا على نحو
غري مرئي في أدواتنا اليومية وبكونه جزءًا من الأنظمة التكنولوجية َّ
املعقدة )Boddington
 .(2017ونظ ًرا إلى النمو الهائل لقدرة الكمبيوتر ،وإتاحة البيانات )الضخمة( بسبب
وسائل التواصل الاجتماعي والاستخدام الهائل ملليارات الهواتف الذكية ،وشبكات املحمول
السريعة ،أح َر َز الذكاء الاصطناعي ،وخاصة تع ُّلم الآلة ،تقد ُّمً ا كبريًا .وقد م َّك َن هذا
الخوارزميات من ِّ
تولي العديد من أنشطتنا ،بما في ذلك التخطيط والكلام والتع ُّرف على
ٍ
تطبيقات في العديد من املجالات ،بما
الوجوه واتخاذ القرار .يمتلك الذكاء الاصطناعي
في ذلك النقل والتسويق والرعاية الصحية والتمويل والتأمني والأمن والجيش والعلوم
والتعليم والعمل املكتبي واملساعدة الشخصية )مثل جوجل دوبلكس 1والترفيه والفنون
)مثل استرجاع املوسيقى وتأليفها( والزراعة ،وبالطبع التصنيع.
تت ُّم عمليات إنشاء الذكاء الاصطناعي واستخدامه لدى شركات تكنولوجيا املعلومات
والإنترنت .على سبيل املثال ،لطاملا استخدمت جوجل الذكاءَ الاصطناعي في مُح ِّرك البحث
الخاص بها .كما يستخدم فيسبوك الذكاء الاصطناعي في الإعلانات املستهدفة وإشارات
أيتها املرآة على الحائط

الصور .كذلك تستخدم مايكروسوفت وأ ِبل الذكاء الاصطناعي في تشغيل مساعدَيهما
الرقميني .لكن الذكاء الاصطناعي لا يقتصر على قطاع تكنولوجيا املعلومات بمعناه الضي ِّق.
فهناك ،على سبيل املثال ،الكثري من ُ
الخطط امللموسة ،والتجارب في مجال السيارات الذاتية
القيادة .فهذه التقنية تعتمد ً
أيضا على الذكاء الاصطناعي .كما تستخدِم الطائرات دون
طيار الذكاءَ الاصطناعي ،مثلها مثل الأسلحة الذاتية التشغيل التي يمكن أن تقتُل دون
 ُّ
تدخ ٍل بشري .بل إن الذكاء الاصطناعي قد استُخدِم بالفعل في اتخاذ القرار في املحاكم.
ففي الولايات املتحدة ،على سبيل املثال ،استُخدم نظام »كومباس« للتنب ُّؤ بالذين يُحتمَ ل أن
يُعاودوا ارتكاب الجرائم .يدخل الذكاء الاصطناعي ً
نعتبرها عمومً ا
أيضا في املجالات التي ِ
أكثر شخصية أو حميمية .على سبيل املثال ،يمكن للآلات الآن قراءة وجوهنا ،ليس فقط
للتع ُّرف علينا ،ولكن ً
أيضا لقراءة انفعالاتنا واسترداد جميع املعلومات املرتبطة بنا.
الذكاء الاصطناعي يحدث الآن وهو م ِّ
نحو غري
ُتوغل في ك ِّل ما حولنا ،وغالبًا ما يكون مُضم َّ نًا على ٍ
مرئي في أدواتنا اليومية.

الحاجة إلى مناقشة املشكلات الأخلاقية واملجتمعية
يمكن أن يكون للذكاء الاصطناعي العديد من الفوائد .ويمكن استخدامه لتحسني الخدمات
العامة والتجارية .على سبيل املثال ،يُعد التع ُّرف على الصور شيئًا مفيدًا في الطب؛ إذ ربما
أمراض مثل السرطان ومرض ألزهايمر .ولكن مثل هذه التطبيقات
يساعد في تشخيص
ٍ
ُ
ُ
ً
ظهر أيضا كيف تثري التقنيات الجديدة تخو ُّفات أخلاقية.
اليومية للذكاء الاصطناعي ت ِ
ٍ
أسئلة حول أخلاقيات الذكاء الاصطناعي.
واسمحوا لي أن أُقد ِّم بعض الأمثلة على
هل يجب أن تحتوي السيارات الذاتية القيادة على قيو ٍد أخلاقية مضم َّ نة؟ وإذا كان
الأمر كذلك ،فما نوع هذه القيود وكيف ينبغي تحديدها؟ على سبيل املثال ،إذا واجهت
ً
 َّ
بطفل أو تصطدم
يتعني عليها فيه الاختيار بني أن تصطدم
موقفا
سيارة ذاتية القيادة
ٍ
بجدار لإنقاذ حياة الطفل ،ولكن مع احتمال قتل را ِكبها ،فماذا تختار؟ وهل ينبغي ترخيص
ٍ
الأسلحة الفت َّاكة الذاتية التشغيل من الأساس؟ كم عدد القرارات التي نُريد تفويضها إلى
الذكاء الاصطناعي ،وما َ
القدْر الذي نُفو ِّضه منها؟ ومَ ن سيكون املسئول عندما يحدُث خطأ
ما؟ في إحدى القضاياَ ،
وض َع القضاة ثقتهم في خوارزمية »كومباس« أكثر من ثِقتهم في
أخلاقيات الذكاء الاصطناعي

الاتفاقات التي َّ
توصل إليها الدفاع والادعاء 2 .فهل سنعتمد كثريًا على الذكاء الاصطناعي؟
تُعد خوارزمية »كومباس« ً
أيضا مُثرية للجدل إلى ح ٍّد كبري؛ نظ ًرا إلى أن الأبحاث أظهرت
أن الأشخاص الذين تنب َّأَت الخوارزمية بأنهم سيُعيدون ارتكاب الجرائم ولكنهم لم يفعلوا
كانت النسبة الكبرى منهم ِمن السود ) .(Fry 2018وبالتالي يمكن للذكاء الاصطناعي أن
يُع ِّزز التحي ُّز والتمييز غري العادل .ويمكن أن تنشأ مشكلات مُماثلة مع الخوارزميات التي
ٍ
بقرارات بشأن طلبات الرهن العقاري وطلبات التقد ُّم للوظائف .أو فلنُفكر فيما
تُوصي
يُسمى بالشرطة التنب ُّؤية :تُستخدَم الخوارزميات للتنبؤ باملكان ا ُملحتمَ ل لارتكاب الجرائم
)على سبيل املثال ،أي منطقة في املدينة( ومَ ن قد يرتكِبها ،ولكن قد تكون النتيجة أن
ٍ
بدرجة أكبر
تُستهدَف مجموعات اجتماعية واقتصادية أو عِ رقية مُعي َّنة للمراقبة الشرطية
من غريهم من املجموعات .وقد جَ َرت الاستعانة بالفعل بالشرطة التنب ُّؤية في الولايات
املتحدة ،وكما يُظهر تقرير حديث ملنظمة »ألجوريذم ووتش« ) ،(٢٠١٩فقد استُعني
بها ً
أيضا في أوروبا 3 .وغالبًا ما تُستخدَم تقنية التع ُّرف على الوجوه القائمة على الذكاء
الاصطناعي لأغراض ا ُملراقبة ،ومِن ثَم يمكن أن تُش ِّكل انتها ًكا لخصوصية الأفراد .كما
بشكل أو َ
بآخر التنبؤ بامليول الجنسية لدى الأفراد .الأمر لا يتط َّلب أي معلومات
يُمكنها
ٍ
من هاتفك أو أي بيانات بيومترية )بيانات املقاييس الحيوية( .وتقوم الآلة بعملها عن بُعد.
ومِن ثَم فإننا باستخدام الكامريات املوجودة في الشوارع والأماكن العامة الأخرى ،يمكن
التع ُّرف علينا و»قراءتنا« ،بما في ذلك التعرف على حالتنا املزاجية .وعن طريق تحليل
بياناتنا ،يمكن التنبؤ بصح َّ تنا العقلية والجسدية؛ دون عِ لمنا بذلك .ويمكن لأصحاب العمل
استخدام التكنولوجيا ُملراقبة أدائنا .ويمكن للخوارزميات النشطة على وسائل التواصل
الاجتماعي أن تنشر خطاب الكراهية أو املعلومات الخطأ؛ على سبيل املثال ،يمكن أن تظهر
ُ
وتنشر محتوًى سياسيٍّا .إحدى الحالات
أشخاص حقيقي ِّني
الروبوتات السياسية في هيئة
ٍ
املعروفة هي برنامج الدردشة الآلي من مايكروسوفت لعام ٢٠١٦ا ُملسمى »تاي« ا ُملصم َّ م
لإجراء محادثات مَ ِرحة على تويتر ،ولكن عندما أصبح أكثر ذكاءً ،بدأ في نشر تغريدات
ٍ
ِ
دلالات عنصرية .يمكن لبعض خوارزميات الذكاء الاصطناعي إنشاء خطابات فيديو
تحمل
بشكل مُض ِّلل خطابًا لباراك أوباما.
كاذبة ،مثل الفيديو الذي جرى إنشاؤه ليُشبه
ٍ
غالبًا ما تكون النوايا طيبة .ولكن هذه املشكلات الأخلاقية عاد ًة ما تكون نتائج غري
مقصودة للتكنولوجيا :فمعظم هذه التأثريات ،مثل التحي ُّز أو خطاب الكراهية ،لم يقصدها
مطورو التكنولوجيا أو مُستخدموها .علاو ًة على ذلك ،هناك سؤال مهم يجب طرحه دائمً ا:
أيتها املرآة على الحائط

من أجل مَ ن يتم التحسني؟ من أجل الحكومة أم من أجل املواطنني؟ من أجل الشرطة أم من
أجل مَ ن تستهدفهم الشرطة؟ من أجل بائع التجزئة أم من أجل الزبون؟ من أجل القضاة
أم من أجل ا ُملتهمني؟ كما تظهر الأسئلة املتعلقة بالسلطة والهيمنة ،كالحال على سبيل
املثال عندما يقتصر تشكيل التكنولوجيا على عددٍ قليل من الشركات الضخمة )Nemitz
 .(2018فمَ ن الذي يُشكل مُستقبل الذكاء الاصطناعي؟
يُلقي هذا السؤال الضوء على الأهمية الاجتماعية والسياسية للذكاء الاصطناعي .تتع َّلق
 ُّ
بالتغري التكنولوجي وتأثريه على حياة الأفراد ،ولكنها تتعلق
أخلاقي َّات الذكاء الاصطناعي
ً
أيضا بالتحولات التي تحدُث في املجتمع وفي الاقتصاد .وتد ُّل قضايا التحي ُّز والتمييز بالفعل
ُغري ً
أيضا الاقتصاد ،وبالتالي ربما ي ِّ
على أن الذكاء الاصطناعي مُرت ِبط باملجتمع .ولكنه ي ِّ
ُغري
ً
ووفقا ملكافي وبرينجولفسون ) ،(٢٠١٤فقد دخلنا عصر الآلة
الهيكل الاجتماعي ملجتمعاتنا.
الثاني ،الذي لا تكون فيه الآلات مُكملة للبشر فحسب ،كما في الثورة الصناعية ،ولكنها أيضاً
بدائل للبشر .ونظ ًرا إلى أن املِ هن والأعمال من جميع الأنواع ستتأثر بالذكاء الاصطناعي،
 َّ
يتغري مجتمعنا ُّ
 َّ
تغريًا جذريٍّا مع دخول التقنيات التي وَصفت في يو ٍم
املتوقع أن
فمن
من الأيام في روايات الخيال العلمي حي َّز العالم الحقيقي )McAfee and Brynjolfsson
 .(2017فما هو مستقبل العمل؟ وما نوع الحياة التي سنعيشها نحن عندما يتولى الذكاء
الاصطناعي القيام بالوظائف؟ ومَ ن »نحن«؟ ومَ ن الذي سيستفيد من هذا التحو ُّل ومن
سيخسر؟
هذا الكتاب
استنادًا إلى الإنجازات ا ُملذهلة التي تم تحقيقها ،فهناك الكثري من الضجة ا ُملثارة حول الذكاء
ٍ
مجموعة واسعة من مجالات املعرفة
الاصطناعي .ويُستخدَم الذكاء الاصطناعي بالفعل في
واملمارسات البشرية .وقد أثارت الأولى تكه ُّ ٍ
نات جامحة حول مستقبل التكنولوجيا ،كما
ً
ٍ
ً
إحساسا
فلسفية مهم َّ ة حول معنى أن تكون إنسانًا .بينما خلقت الثانية
مناقشات
أثارت
بالإلحاح من جانب الأخلاقيني وصانعي السياسات لضمان أن تُفيدنا هذه التكنولوجيا ً
بدلا
من أن تخلق أمام الأفراد واملجتمعات تحديات لا يُمكنهم التغ ُّلب عليها .وتُعد هذه املخاوف
ً
عملية وإلحاحً ا.
الأخرية أكثر
أخلاقيات الذكاء الاصطناعي

 ُّ
ريه على حياة الأفراد ،ولكنها تتعلق
تتعلق أخلاقيات الذكاء الاصطناعي
بالتغري التكنولوجي وتأث ِ
ً
أيضا بالتحو ُّلات التي تحدث في املجتمع وفي الاقتصاد.

يتناول هذا الكتاب ،الذي كتبَه فيلسوف أكاديمي لدَيه ً
أيضا خبرة في تقديم املشورة
من أجل وضع السياسات ،كِلا الجانبَني؛ فهو يتعامل مع الأخلاقيات على هذه املستويات
كافة .ويهدف إلى إعطاء القارئ نظر ًة عامة جيدة على املشكلات الأخلاقية التي يُثريها الذكاء
الاصطناعي ،بدءًا من السرديات املؤثرة حول مستقبل الذكاء الاصطناعي والأسئلة الفلسفية
ً
وانطلاقا إلى القضايا الأخلاقية ا ُملتعلقة باملسئولية والتحي ُّز
حول طبيعة الإنسان ومُستقبله،
وكيفية التعامُل مع املسائل العملية الواقعية التي أثارتها التكنولوجيا عن طريق وضع
السياسات؛ لا سيما إذا كان ذلك قبل فوات الأوان.
لكن ماذا سيحدُث إذا »فات الأوان«؟ بعض السيناريوهات متشائمة ومتفائلة في الوقت
نفسه .اسمحوا لي أن أبدأ ببعض الأحلام والكوابيس حول مستقبل التكنولوجيا ،والسرديات
املؤثرة التي تبدو ،ولو للوهلة الأولى على الأقل ،ذات ِص ٍلة بتقييم الفوائد واملخاطر ا ُملحتمَ لة
للذكاء الاصطناعي.
الفصل الثاني

الذكاء الفائق والوحوش ونهاية العالم
بالذكاء الاصطناعي

الذكاء الفائق وتجاوز الإنسانية
أد َّت الضجة ا ُملحيطة بالذكاء الاصطناعي إلى ظهور جميع أنواع التكه ُّ نات حول مستقبل
الذكاء الاصطناعي ومستقبل ما سيكون عليه الإنسان .إن إحدى الأفكار الشائعة ،والتي
تتك َّرر كثريًا في وسائل الإعلام وفي النقاشات العامة حول الذكاء الاصطناعي ،بل ينشرها
ً
أيضا خبراء التكنولوجيا املؤث ِّرون الذين يُطو ِّرون تقنية الذكاء الاصطناعي مثل إيلون
وبشكل أكثر عمومية ،فكرة أن الآلات
ماسك وراي كورزوايل ،هي فكرة الذكاء الفائق،
ٍ
ستُسيطر علينا ،وتستع ِبدنا وليس العكس .بالنسبة إلى البعض ،هذا حلم؛ وبالنسبة إلى
الكثريين ،هذا كابوس .وهناك مَ ن ي َرون أنه حلم وكابوس في الوقت نفسه.
فكرة الذكاء الفائق هي أن الآلات ستتفو َّق على الذكاء البشري .وهي غالبًا ما ترتبط
ً
ووفقا لنيك بوستروم )،(٢٠١٤
بفكرة انفجار الذكاء الاصطناعي والتف ُّرد التكنولوجي.
مأزق يُماثل ذلك الذي وقعت فيه الغوريلا ،التي يعتمد مصريها اليوم علينا
سنقع في
ٍ
َ
طريقني على الأقل لبلوغ الذكاء الفائق وما يُسم َّ ى أحيانًا بانفجار
بشكل كامل .إنه يرى
ٍ
الذكاء الاصطناعي .أحدهما أن الذكاء الاصطناعي سوف يُطو ِّر تحسينًا ذاتيٍّا تكراريٍّا؛
ٍ
نسخة م َّ
ُحسنة من نفسه ،والتي بدورها تُصم ِّ م
إذ يستطيع الذكاء الاصطناعي تصميم
ً
نسخة أكثر ذكاءً من نفسها ،وهكذا دواليك .أما الطريق َ
الآخر فهو محاكاة الدماغ بالكامل
أو تحميله :دماغ بيولوجي يُمكِن مسحه ضوئيٍّا ُ
إنتاجه في
وصنع نموذج له ،ثم إعادة
ِ
ٍ
مكونات برمجية ذكي َّة ومِن خلالها .يتم بعد ذلك توصيل هذه ا ُملحاكاة للدماغ البيولوجي

أخلاقيات الذكاء الاصطناعي

انفجار في الذكاء غري البشري .حتى
بجسم إنسان آلي .وستؤدي مثل هذه التطو ُّرات إلى
ٍ
ً
فريقا ما يُمكِنه إنشاء ذكاء اصطناعي يُصبح
إن ماكس تجمارك ) (٢٠١٧يتخيل أن
في منتهى القوة بحيث يستطيع إدارة الكوكب .ويكتب يوفال هراري عن عا َل ٍم لم يعُ د
فيه البشر يسيطرون ،ولكنهم يعبدون البيانات ويثقون في قدرة الخوارزميات على اتخاذ
قراراتهم .وبعد انهيار ك ِّل أوهام الإنسانيني واملؤسسات الليبرالية ،لن يبقى للبشر إلا أن
يحلموا بالاندماج في ُّ
تدفق البيانات .يسري الذكاء الاصطناعي في مساره الخاص» ،الذهاب
إنسان أن يتبعه« )Harari
إنسان من قبل؛ وإلى حيث لا يمكن لأي
إلى حيث لم يذهب أي
ٍ
ٍ
.(2015, 393
طا ً
ترتبط فكرة انفجار الذكاء الاصطناعي ارتبا ً
وثيقا بفكرة »التف ُّرد التكنولوجي«:
لحظة في تاريخ البشرية سيُحدِث فيها التقد ُّم التكنولوجي الهائل تغيريًا دراماتيكيٍّا بحيث
لا نعود نستوعِب ما يحدث و»تنتهي الشئون الإنسانية كما نفهمها اليوم« )Shanahan
 .(2015, xvفي عام ،١٩٦٥تكه َّ َن عالم الرياضيات البريطاني إيرفينج جون جود
بآلة فائقة الذكاء تُصم ِّ م ٍ
آلات أفضل؛ وفي التسعينيات ،رأى مؤلف الخيال العلمي وعالم
الكمبيوتر فرينور فينج أن هذا سيعني نهاية عصر الإنسان .وقد اقترح رائد علم الكمبيوتر
جون فون نيومان بالفعل الفكرة في خمسينيات القرن العشرين .وتبن َّى راي كورزوايل
 َّ
جنب مع أجهزة
وتوقع أن الذكاء الاصطناعي ،جنبًا إلى
) (٢٠٠٥مصطلح »التف ُّرد«
ٍ
ٍ
نقطة يكون فيها
الكمبيوتر وعلم الوراثة وتكنولوجيا النانو وعلم الروبوتات ،سيؤدي إلى
ذكاءُ الآلة أقوى من ك ِّل الذكاء البشري مُجتمعً ا ،ويندمج عندها الذكاء البشري وذكاء الآلة
في النهاية .وسوف يتجاوز البشر حدود أجسامهم البيولوجية .وكما جاء في عنوان كتابه:
»التف ُّرد قريب« .وهو يعتقد أن هذا سيحدث حوالي عام .٢٠٤٥
ليس لهذه القصة بالضرورة نهاية سعيدة :ففي رأي بوستروم وتجمارك وآخرين،
ثم َّ ة »مخاطر وجودية« مُرتبطة بالذكاء الفائق .وقد تكون نتيجة هذه التطو ُّرات أن الذكاء
 َّ
ويتولى زمام الأمور ويُهد ِّد حياة الإنسان الذكية .وسواء
الاصطناعي الفائق سوف يُسيطر
أكان هذا الكيان واعيًا أم لا ،وبصورة أعم مهما كانت حالته أو كيفية نشوئه ،فإن القلق
هنا يتع َّلق بما سيفعله هذا الكيان )أو ما لا يفعله( .قد لا يهت ُّم الذكاء الاصطناعي بأهدافنا
البشرية .ونظ ًرا لعدم امتلاكِه جسدًا بيولوجيٍّا ،فإنه لن يفهم حتى املعاناة البشرية .ويُقدم
ً
تجربة فكرية لذكاءٍ اصطناعي يُحد َّد له هدف م َّ
ُعني وهو تصنيع مشابك الورق
بوستروم
بأكبر ك ٍّم مُمكِن ،فما كان منه إلا أن حو َّل كوكب الأرض والبشر الذين يعيشون عليه إلى
الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي

موارد لإنتاج مشابك الورق .إذَن التحد ِّي الذي يُواجهنا اليوم هو التأ ُّكد من أننا نبني
ٍ
بطريقة ما مشكلة السيطرة هذه؛ بمعنى أنه يفعل ما نريد ويأخذ
ذكاءً اصطناعيٍّا لا يُثري
ٍ
بطريقة ما من قدرات الذكاء
حقوقنا في الاعتبار .على سبيل املثال ،هل يجب أن نح َّد
الاصطناعي؟ وكيف يُمكننا احتواء الذكاء الاصطناعي؟
ثم َّ ة أفكار أخرى مترابطة وذات صلة؛ ألا وهي الأفكار املتع ِّلقة بتجاوز الإنسانية.
في ضوء الذكاء الفائق والإحباط من الضعف البشري و»الأخطاء« ،يجادل أنصار تجاوز
بحاجة إلى تعزيز الإنسان :جعله أكثر ذكاءً ،وأقل عُ ً
ٍ
رضة
الإنسانية مثل بوستروم بأننا
للمرض ،وأطوَل عم ًرا ،وربما حتى خالدًا ،مما يؤدي إلى ما يُسم ِّ يه هاراري »الإنسان الإله«:
ترقية البشر إلى آلهة .وكما قال فرانسيس بيكون في »دحض الفلسفات« :البشر »آلهة
فانية« ) .(Bacon 1964, 106ملاذا لا نُحاول تحقيق الخلود؟ ولكن حتى لو لم نستطع
تحقيق ذلك ،فإن الآلة البشريةً ،
ٍ
بحاجة إلى ترقية .فنحن
وفقا ُملناصري تجاوُز الإنسانية،
إذا لم نفعل ذلك ،فسيُخاطر البشر بأن يظلوا »الجزء ا ُملتخلف غري الكفء بشكل متزايد«
ٍ
بحاجة إلى إعادة
من الذكاء الاصطناعي ) .(Armstrong 2014, 23إن البيولوجيا البشرية
تصميم ،ولذا يتساءل بعض مؤيدي تجاوز الإنسانية ،ملاذا لا نتخ َّلص تمامً ا من الأجزاء
ٍ
كائنات ذكية غري عضوية؟
البيولوجية ونُصم ِّ م
على الرغم من أن معظم الفلاسفة والعلماء الذين يُرو ِّجون لهذه الأفكار يحرصون
على تمييز آرائهم عن الخيال العلمي والدين ،فإن العديد من الباحثني ي ِّ
ُفسرون أفكارهم
بهذه املصطلحات بالضبط .بادئ ذي بدء ،ليس من الواضح مدى ارتباط أفكارهم
بالتطو ُّرات التكنولوجية الحالية وعلوم الذكاء الاصطناعي ،وما إذا كان هناك فرصة
حقيقية للوصول إلى الذكاء الفائق في ا ُملستقبل القريب ،هذا إن أمكن الوصول إليه من
الأساس .إذ يرفض البعض تمامً ا إمكانية الوصول إليه )انظر الفصل التالي( ،وحتى هؤلاء
الذين على استعدادٍ لقبول إمكانية الوصول إليه من حيث املبدأ ،مثل العالِمة مارجريت
بودن ،فإنهم لا يعتقدون أنه من ا ُملرج َّ ح الوصول إليه عمليٍّا .إن فكرة الذكاء الفائق
تفترض أننا سنُطو ِّر »الذكاء الاصطناعي العام« ،أو الذكاء الذي يكافئ الذكاء البشري
ِ
أو يتفو َّق عليه ،وهناك العديد من العقبات التي يجب التغ ُّلب عليها قبل تحقيق ذلك.
وترى بودن ) (٢٠١٦أن الذكاء الاصطناعي ليس واعدًا كما َّ
تقرير
يتوقع الكثريون .وفي
ٍ
صادر عن البيت الأبيض عام ،٢٠١٦تم التأكيد على اتفاق خبراء القطاع الخاص على
 َّ
يتحقق على الأقل قبل عقود .كما يرفض العديد من
أن الذكاء الاصطناعي العام لن
أخلاقيات الذكاء الاصطناعي

الباحثني في مجال الذكاء الاصطناعي الرؤى ا ُملظلمة املتشائمة التي يُرو ِّج لها بوستروم
 ُّ
بشكل إيجابي ،كمساع ٍد أو زميل.
ويحضون على استخدام الذكاء الاصطناعي
وآخرون،
ٍ
ولكن املسألة لا تتعلق بما سيحدث فعليٍّا في املستقبل .بل يوجَ د شيء َ
آخر يُثري القلق وهو
أن هذه املناقشة حول تأثريات الذكاء الاصطناعي في املستقبل )البعيد( تُشت ِّت الانتباه عن
املخاطر الحقيقية واملوجودة حاليٍّا للأنظمة التي تم نشرها فعليٍّا )Crawford and Calo
ً
ذكية
 .(2016يبدو أن هناك خط ًرا حقيقيٍّا أنه في املستقبل القريب ،لن تكون الأنظمة
بشكل غري ٍ
كاف ،ومع ذلك
بما فيه الكفاية وأننا سنفهم آثارها الأخلاقية والاجتماعية
ٍ
ً
فرط على الذكاء ،بوصفه ِسمة رئيسية
سنستخدِمها على
نطاق واسع .كما أن التركيز ا ُمل ِ
ٍ
ً
وهدفا نهائيٍّا وحيدًا ،هو ً
أيضا أمر مشكوك فيه ).(Boddington 2017
للإنسانية،
مع ذلك ،تستمر الأفكار مثل الذكاء الفائق في التأثري على املناقشة العامة .ومن
ا ُملحتمل أن تؤث ِّر ً
أيضا على تطو ُّر التكنولوجيا .على سبيل املثال ،لا يُعتبر راي كورزوايل
من دُعاة املستقبلية فحسب .بل إنه يشغل منصب مدير الهندسة في شركة جوجل منذ عام
 .٢٠١٢كما يبدو أن إيلون ماسك ،الرئيس التنفيذي لشركة تيسلا وشركة سبيس إكس،
وهو شخصية عامة معروفة جدٍّا ،يؤيد سيناريوهات الذكاء الفائق واملخاطر الوجودية
)سيناريوهات الهلاك؟( التي وضعها بوستروم وكورزوايل .وقد حذ َّر مرا ًرا من خطورة
َ
واعتبرَه تهديدًا وجوديٍّا وزعم أننا لا يُمكننا التح ُّكم في الشيطان
الذكاء الاصطناعي،
) .(Dowd 2017ويعتقد ماسك أن البشر سينقرضون على الأرجح ،ما لم يُدمَ ج الذكاء
البشري والذكاء الآلي أو نتم َّكن من الهروب إلى املريخ.
ً
ً
ربما تكون هذه الأفكار مؤثرة للغاية لأنها ُّ
عميقة تتع َّلق بالبشر
وآمالا
تمس مخاوف
َ
ُ
ْ
والآلات داخل وع ِينا الجمعي .وسواء َق ِبلنا هذه الأفكار املحد َّدة أو رفضناها ،فإن هناك
ِص ٍ
لات واضحة بالسرديات الخيالية في الثقافة البشرية والتاريخ التي تُحاول أن تفهم
الإنسان وعلاقته بالآلات .ويجدُر بنا أن ن ُ ِّ
وضح هذه السرديات لكي نفهم بعض هذه
وبشكل عام ،فإنه من ا ُملهم أن
نحو أفضل ونضعها في سياقها الصحيح.
ٍ
الأفكار على ٍ
ندمج بحث السرديات في أخلاقيات الذكاء الاصطناعي ،على سبيل املثال ،لكي نفهم
الأسباب التي تجعل بعض السرديات مُنتشرة ،ومَ ن أنشأها ،ومَ ن الذي يستفيد منها
) .(Royal Society 2018كما يمكن أن يُساعدنا في إنشاء سردي َّات جديدة حول مستقبل
الذكاء الاصطناعي.
الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي

وحش فرانكنشتاين الجديد
ِمن السبل التي يُمكننا اتخاذها لتجاوُز الضجة املثارة أن نف ِّكر في بعض السرديات
ذات الصلة من تاريخ الثقافة البشرية التي تُشكل املناقشة العامة الحالية حول الذكاء
الاصطناعي .فليست هذه هي املرة الأولى التي يتساءل فيها الناس عن مُستقبل البشرية
ومُستقبل التكنولوجيا .ومهما كانت بعض الأفكار املتعلقة بالذكاء الاصطناعي تبدو
غريبة ،فإننا يُمكننا استكشاف ِصلتها بأفكار وسرديات أكثر شهرة توجَ د في وعينا
بشكل أدق ،في الوعي الجماعي للغرب.
الجمعي ،أو
ٍ
ً
أولا ،هناك تاريخ طويل للتفكري في البشر والآلات أو املخلوقات الاصطناعية في
الثقافات الغربية وغري الغربية على ح ٍّد سواء .يُمكن العثور على فكرة إنشاء كائنات
حية من مادة غري حية في قصص الخلق في الثقافات السومرية والصينية واليهودية
واملسيحية والإسلامية .فقد كانت لدى الإغريق فكرة إنشاء َ
بشر اصطناعيني ،وخاصة
النساء الاصطناعيات .على سبيل املثال ،في الإلياذة ،يُقال إن هيفايستوس يقوم على
خدمته َخدَم مصنوعون من الذهب يُشبهون النساء .وفي أسطورة بيجماليون الشهرية،
يقع النح َّ ات في حُ ب تمثال امرأة صنَعَ ه من العاج .ويتمن َّى أن تدب َّ فيه الروح ويُصبح
امرأة حقيقية ،فتُ ِّ
حقق له الإلهة أفروديت أُمنيته :فتصبح شفتاها دافئتَني وجسدُها ناعمً ا.
ويُمكننا بسهولة هنا ملاحظة ِّ
الصلة بني ذلك وبني الروبوتات الجنسية املعاصرة.
هذه السردي َّات لا تأتي فقط من الأساطري :ففي كتابه »الأوتوماتا« ،قد َّم عالِم
َ
اكتشفت في البحر،
الرياضيات واملهندس الإغريقي هريون السكندري )ولد عام (١٠أداة
ظري إغريقي يعتمد على آلية م َّ
وهي آلية »أنتيكيثريا« ،التي تُحدد أنها كمبيوتر تنا ُ
ُعقدة
من التروس وا ُملسن َّنات .ولكن القصص الخيالية التي تجعل الآلات تُش ِبه البشر تسلُب
بشكل خاص .فلنأخذ ،على سبيل املثال ،أسطورة الجوليم :وحش مصنوع من
ألبابنا
ٍ
َ
َ
نواج ُه نسخة
الطني صنعَ ه حاخام في القرن السادس عشر ،ثم فق َد السيطرة عليه .هنا
ِ
مُب ِّكرة من مشكلة التح ُّكم .ويمكن تفسري أسطورة بروميثيوس بهذه الطريقة ً
أيضا؛ إذ
يسرق النار من الآلهة ويُعطيها إلى البشر ،لكنه ي َ
ُعاقب بعد ذلك .وعقوبته الأبدية هي أن
يُربط بصخر ٍة بينما يأكل النسر ك ِبدَه ك َّل يوم .وقد كان الدرس القديم من هذه الأسطورة
هو التحذير من الغطرسة :فهذه القدرات ليست مُقد َّرة للبشر.
ومع ذلك ،في رواية ماري شيلي »فرانكنشتاين« — التي تحمل العنوان الفرعي
الدال »بروميثيوس الحديث« — يُصبح إنشاء حياة ذكية من مادة غري حي َّة مشروعً ا
أخلاقيات الذكاء الاصطناعي

علميٍّا حديثًا .حيث ينشئ العالم فيكتور فرانكنشتاين كائنًا شبيهً ا بالإنسان من أجزاء
الجثث ،لكنه يفقد السيطرة عليه .ومع أن الحاخام استطاع أن يُسيطر على الجوليم في
النهاية ،فإن الأمر ليس كذلك في هذه الحالة .ويمكن اعتبار فرانكنشتاين رواية رومانسية
تُحذ ِّر من التكنولوجيا الحديثة ،ولكنها تستند إلى العلم في زمنِها .على سبيل املثال ،يلعب
استخدام الكهرباء — وهي تقنية جديدة جدٍّا في ذلك الوقت — دو ًرا مهمٍّ ا؛ إذ تُستخدَم
لإحياء الجثة .كما أنها تُشري إلى املغناطيسية وعِلم التشريح .في ذلك الوقت ،كان املف ِّكرون
والكت َّاب يناقشون طبيعة الحياة وأصلها .ما قوة الحياة؟ لقد تأثرت ماري شيلي بعلوم
ري
عصرها .وتُظهر القصة كيف كان الرومانسيون في القرن التاسع عشر مفتونني في كث ٍ
ظ ً
فضلا عن أملهم في أن يُح ِّررنا ِّ
الشعر والأدب من الجوانب الأكثر ُ
ً
لمة
من الأحيان بالعلم،
في الحداثة ) .(Coeckelbergh 2017يجب َّألا نعتبر هذه الرواية بالضرورة ضد العلم
والتكنولوجيا؛ إذ يبدو أن الرسالة الرئيسية التي تحرص على توصيلها هي أن العلماء
ينبغي أن يتحملوا مسئولية اختراعاتهم .يهرب الوحش ،ولكنه يفعل ذلك لأن صانعه
يرفضه .يجب أن نتذ َّكر هذا الدرس فيما يتع َّلق بأخلاقيات الذكاء الاصطناعي .ومع ذلك،
تؤ ِّكد الرواية بوضوح خطر التكنولوجيا التي تخرج عن السيطرة ،وعلى وجه الخصوص
خطر البشر الاصطناعيني الذين يُصيبهم الجنون .تعود هذه املخاوف للظهور على السطح
في القلق ا ُملعاصر من أن يخرج الذكاء الاصطناعي عن السيطرة.
في رواية ماري شيلي »فرانكنشتاين« — التي تحمل العنوان الفرعي الدال »بروميثيوس الحديث« —
يُصبح إنشاء حياة ذكية من مادة غري حية مشروعً ا علميٍّا حديثًا.

وعلاو ًة على ذلك ،كما هو الحال في رواية »فرانكنشتاين« وأسطورة »الجوليم« ،تظهر
سردية املنافسة :فاملخلوقات الاصطناعية تتنافس مع الإنسان .وتستم ُّر هذه السردية في
تشكيل خيالنا العلمي حول الذكاء الاصطناعي ،ولكنها ً
أيضا تؤث ِّر على تفكرينا ا ُملعاصر
ُ
فلنأخذ مسرحية »روبوتات روسوم
في التكنولوجيا مثل الذكاء الاصطناعي والروبوتات.
العاملية« التي كتبت عام ً ١٩٢٠
مثالا ،وهي تتناول قصة الروبوتات العبيد التي تتم َّرد
على سيدها وتثور عليه ،أو فيلم » :٢٠٠١سبيس أوديسي« ) :٢٠٠١أوديسة الفضاء(
الذي أنتج عام ١٩٦٨والذي ذكرناه من قب ُل ،ويتحد َّث عن ذكاء اصطناعي يبدأ في قتل
طاقم املركبة الفضائية لتحقيق مهم َّ ته ،أو فيلم »إكس ماكينا« الذي أنتج عام ٢٠١٥
الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي

ويروي قصة روبوت الذكاء الاصطناعي »أفا« التي تنقلب على صانعها .كما يندرج تحت
سردية الآلات التي تتم َّرد علينا مجموعة أفلام »ا ُملدم ِّ ر« )ترمينيتور( .وقد وصف كاتب
الخيال العلمي أيزاك أسيموف هذا الخوف ب »عقدة فرانكنشتاين« :الخوف من الروبوتات.
ويرتبط هذا ً
 َّ
يتعني على العلماء وا ُملستثمرين
أيضا بالذكاء الاصطناعي اليوم .وهو أمر
التعامُل معه .فبعضهم يُحاربون هذا الخوف؛ وبعضهم يساعد في خلقه والحفاظ عليه.
أشرت بالفعل إلى مثال »ماسك« .وثم َّ ة مثال َ
ُ
آخر على شخصية مؤثرة ساهمت في
وقد
نشر الخوف من الذكاء الاصطناعي وهو عالم الفيزياء ستيفن هوكينج ،الذي صر َّ ح في
عام ٢٠١٧بأن خلق الذكاء الاصطناعي يمكن أن يكون أسوأ حد ٍَث في تاريخ حضارتنا
) .(Kharpal 2017إن »عقدة فرانكنشتاين« منتشرة وعميقة الجذور في الثقافة والحضارة
الغربية.
التسامي ونهاية العالم بسبب الذكاء الاصطناعي
ثمة مقدمات لأفكار مثل »تجاوز الإنسانية« و»التف ُّرد التكنولوجي« في تاريخ التفكري
الديني والفلسفي الغربي أو على الأقل توجَ د أفكار مشابهة لها ،ولا سيما في التقاليد
اليهودية املسيحية وفي الفكر الأفلاطوني .وعلى عكس ما يعتقده الكثريون ،فإن الدين
والتكنولوجيا كانا دائمً ا مُتراب َ
طني في تاريخ الثقافة الغربية .ودعوني أحصر نقاشي هنا في
التسامي ونهاية العالم.
في الدين اللاهوتي ،يقصد بالت َّسامي أن الإله »فوق« العالم املادي والجسدي ومُستقل
عنه ،وهي فكرة مُناقضة لفكرة أنه موجود في العا َلم وأنه جزء منه )الحلولية( .في التقليد
اليهودي املسيحي الأحادي اللاهوتي ،يُرى الله على أنه يتسامى فوق خلقه .ويُمكن في
الوقت نفسه ً
أيضا أن يُرى على أنه مُتغلغل في كل مخلوقاتِه وفي كل الكائنات )أي إنه
 َّ
يتجلى من خلال
يح ُّل فيها( ،وعلى سبيل املثال ،في اللاهوت الكاثوليكي ،يُفهم الله كما
ابنه )املسيح( والروح القدس .ويبدو أن سرديات الذكاء الاصطناعي التي تتجلى فيها
ً
انفصالا أو فجوة بني الخالق
»عقدة فرانكنشتاين« تؤكد فكرة التسامي بمعنى أن هناك
واملخلوق )بني الإنسان الإله والذكاء الاصطناعي( ،دون إعطاء الكثري من الأمل في إمكانية
تجاوز هذه الفجوة.
أخلاقيات الذكاء الاصطناعي
على عكس ما يعتقده الكثريون ،فإن الدين والتكنولوجيا كانا دائمً ا مُتراب َ
طني في تاريخ الثقافة
الغربية.

أيضا أن يُشري إلى تجاوز الحدود ،أو تخ ِّ
التسامي يمكن ً
طي شيءٍ ما .في التاريخ
ري من الأحيان شك َل السمو فوق
الديني والفلسفي الغربي ،اتخذت هذه الفكرة في كث ٍ
 ِّ
املتوسط في
العالم املادي والجسدي وتجاوُز حدوده .على سبيل املثال ،في منطقة البحر
القرن الثاني امليلادي ،كانت الغنوصية تنظر إلى املاد َّة جميعها باعتبارها شرٍّا ،وتهدف إلى
تحرير الشعلة الإلهية من الجسد البشري .وفي ٍ
وقت أسبَق ،رأى أفلاطون الجسد سجنًا
للروح .وعلى عكس الجسد ،كان ينظر إلى الروح على أنها خالدة .وفي امليتافيزيقا الخاصة
به ،مي َّز أفلاطون بني الأشكال ،التي هي أبدية ،والأشياء املوجودة في العالم ،التي تتغري؛
فالأولى تتسامى فوق الأخرية وتتجاوزها .وهناك أفكار في مبدأ تجاوز الإنسانية تُذ ِّكرنا
بهذا .فهي تُحافظ على هدف التسامي بمعنى تجاوز القيود البشرية ،وليس هذا فحسب،
بل إن الطرق الخاصة التي يُفترض أن يحدث بها هذا التسامي تستحضر أفلاطون
والغنوصية :لتحقيق الخلود ،يجب التسامي فوق الجسد البيولوجي عن طريق تحميل
ٍ
بشكل أكثر عمومية ،عندما يَستخدِم الذكاء الاصطناعي
أدوات اصطناعية وتطويرها.
ٍ
أشكال أكثر نقاءً من العا َلم
والعلوم والتكنولوجيا ذات الصلة الرياضيات لاستخلاص
ٍ
 َّ
يتحقق بواسطة وسائل
املادي الفوضوي ،يمكن تفسري ذلك على أنه برنامج أفلاطوني
تكنولوجية .ومن هنا َّ
يتبني أن خوارزمية الذكاء الاصطناعي هي آلة أفلاطونية تستخلِص
ً
شكلا )أو نموذجً ا( من عا َلم الظواهر )البيانات(.
التسامي يمكن ً
أيضا أن يعني تجاوز الحالة الإنسانية .في التقليد املسيحي ،يمكن
أن يأخذ هذا شكل محاولة رأب الفجوة بني الله والبشر من خلال تحويل البشر إلى آلهة،
ربما عن طريق استعادة تشابُههم مع الآلهة وكمالهم الأصلي ) .(Noble 1997ولكن
َسعْ ي مؤيدي تجاوز الإنسانية للخلود ليس جديدًا ،بل يمكن تتب ُّعه إلى العصور القديمة.
إذ يُمكننا أن نجده في امليثولوجيا امليزوبوتامية )الأساطري التي تأتي من منطقة ما بني
النه َرين( :تحكي لنا قصة »ملحمة جلجامش« ،وهي واحدة من أقدم القصص املكتوبة عن
البشرية ،عن ملك أوروك )جلجامش( ،الذي يبحث عن الخلود بعد وفاة صديقه إنكيدو.
ولكنه يفشل في العثور عليه :ومع ذلك ،ينجح في الحصول على ٍ
نبتة يُقال إنها تُعيد
الشباب ،ولكن تسرقها أفعى ،وفي النهاية ، َّ
يتعني عليه أن يتع َّلم الدرس بأن عليه مواجهة
الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي

حقيقة موتِه هو شخصيٍّا؛ إذ إن سعيه إلى الخلود بلا جدوى .على م ِّر التاريخ ،كان الناس
ٍ
علاجات مضاد َّة للشيخوخة .ومِن
يبحثون عن إكسري الحياة .واليوم ،تبحث العلوم عن
هذا املنطلق ،فإن سعي مؤيدي مبدأ تجاوز الإنسانية إلى الخلود أو إلى إطالة العمر ليس
جديدًا أو غريبًا؛ بل هو واحد من أقدم أحلام البشرية وأهداف العلم ا ُملعاصر .وفي أيدي
مؤيدي تجاوز الإنسانية ،يُصبح الذكاء الاصطناعي هو أداة التجاوز التي تَعِ دنا بالخلود.
من املفاهيم القديمة الأخرى التي تساعدنا على وضع أفكار تجاوز الإنسانية في
سياقها ،ولا سيما فكرة التف ُّرد التكنولوجي ،مفهوم نهاية العالم )أبوكاليبس( والأخروية.
ومصطلح »أبوكاليبس« عند الإغريق القدماء ،الذي يلعب ً
أيضا دو ًرا في الفكر اليهودي
واملسيحي ،يُشري إلى كشف الحجاب .وفي الوقت الحاضر ،يُشري هذا املصطلح غالبًا إلى
نوع َّ
معني من الكشف :وهو كشف سيناريو نهاية الزمان أو نهاية العالم .وفي السياقات
الدينية ،نجد مصطلح »الأخروية« :وهو جزء من علم اللاهوت يتع َّلق بالأحداث النهائية
للتاريخ واملصري النهائي للبشرية .وتنطوي معظم الأفكار الأخروية وتلك التي تتع َّلق
بنهاية العالم على تخريب أو تدمري ِجذري وغالبًا عنيف للعالم ،والاتجاه نحو مستوى
أعلى من الواقع والكينونة والوعي .ويُذكرنا ذلك ً
أيضا بالطوائف والجماعات املتطرفة
املتشائمة التي كانت وما تزال تتنب َّأ بالكوارث ونهاية العالم .ورغم أن مؤيدي تجاوز
الإنسانية في العادة ليس لهم علاقة بمثل هذه الطوائف واملمارسات الدينية ،فإن فكرة
التفرد التكنولوجي تُشبه إلى ح ٍّد ما سرديات نهاية العا َلم والأخروية والتنبؤ بالكوارث،
وهذا أمر واضح.
بالتالي ،بينما يستند تطوير الذكاء الاصطناعي إلى عل ٍم من ا ُملفترَض أنه لا خيالي ولا
اقتراح
ديني ،وبينما ينأى مؤيدو تجاوز الإنسانية بأنفسهم عاد ًة عن الدين ويرفضون أي َّ
ٍ
بأن أعمالهم تستنِد إلى الخيال ،إلا أن الخيال العلمي والأفكار الدينية والفلسفية القديمة
تلعب بالضرورة دو ًرا مُهمٍّ ا عندما نناقش مُستقبل الذكاء الاصطناعي من هذا املنطلق.
كيفية تجاوز سرديات املنافسة وتجاوز الضج َّ ة ا ُملثارة حول الذكاء الاصطناعي
يمكن للمرء أن يتساءل الآن :هل هناك سبُل للنجاة؟ هل يُمكننا تجاوز سرديات املنافسة
ً
رسوخا لفهم مستقبل الذكاء الاصطناعي والتكنولوجيا ا ُملماثلة؟ أم
طرق أكثر
وإيجاد
ٍ
إن التفكري الغربي حول الذكاء الاصطناعي محكوم عليه بالبقاء في سجن هذه املخاوف
أخلاقيات الذكاء الاصطناعي

العصرية وجذورها القديمة؟ هل يُمكننا تجاوز الضجة املثارة حول الذكاء الاصطناعي؟
ُنصب َّة على الذكاء الفائق؟ أعتقد أن لدَينا ً
أم ستظ ُّل املناقشة م َ
سبلا للنجاة.
رغم أن مؤيدي تجاوز الإنسانية في العادة ليس لهم علاقة بمثل هذه الطوائف وا ُملمارسات الدينية،
فإن فكرة التف ُّرد التكنولوجي تُشبه إلى ح ٍّد ما سرديات نهاية العالم والأخروية والتنبؤ بالكوارث.

ً
أولا ،يمكننا تجاوز الثقافة الغربية للعثور على أنواع مختلفة من السردي َّات غري
ا َملبنية على »عقدة فرانكنشتاين« فيما يخص التكنولوجيا وطرق التفكري غري الأفلاطونية.
على سبيل املثال ،في اليابان حيث تتأثر ثقافة التكنولوجيا بديانات الطبيعة أكثر من
الغرب ،وتحديدًا بديانة الشنتو ،وحيث صو َّرت الثقافة الشعبية الآلات كمُساعدين ،نجد
ً
موقفا أكثر ودٍّا تجاه الروبوتات والذكاء الاصطناعي .هنا ،لا نجد عقدة فرانكنشتاين.
وتنطوي طريقة التفكري التي يُطلق عليها أحيانًا »الأرواحية« على أن الذكاء الاصطناعي
يمكن ً
نفسا ،ويمكن أن ي َ
ً
أيضا من حيث املبدأ أن يمتلك روحً ا أو ً
مقدسا .وهذا يعني
ُعتبر
عدم وجود سردية ُ
تنافسية؛ وعدم وجود رغبة أفلاطونية في تجاوز املادية والدفاع ا ُملستمر
ً
اختلافا جوهريٍّا.
عن الإنسان بوصفه كائنًا يسمو فوق الآلة ويتجاوزها ،أو يختلف عنها
ِ
تشتمل الثقافة الشرقية على أفكار حول نهاية الزمان .وعلى عكس
في حدود معرفتي ،لا
الديانات التوحيدية ،تحمل ديانات الطبيعة فهمً ا دوريٍّا للزمن .وبالتالي ،يمكن أن يساعد
النظر إلى ما هو أبعد من الثقافة الغربية )أو في واقع الأمر إلى املاضي القديم للغرب ،حيث
نجد ً
أيضا ديانات طبيعة( في التقييم النقدي للسرديات السائدة حول مستقبل الذكاء
الاصطناعي.
ثانيًا :لتجاوز الضجة ا ُملثارة حول الذكاء الاصطناعي وتجن ُّب حصر مناقشة أخلاقيات
الذكاء الاصطناعي في أحلام املستقبل البعيد وكوابيسه ،يُمكننا ) (١استخدام الفلسفة
والعلم لفحص ومناقشة الافتراضات املتع ِّلقة بالذكاء الاصطناعي والإنسان الذي يلعب
دو ًرا في هذه السيناريوهات واملناقشات )مثل :هل الذكاء العام مُمكن؟ ما الفارق
بني الإنسان والآلة؟ ما العلاقة بني الإنسان والتكنولوجيا؟ ما الوضع الأخلاقي للذكاء
بتفصيل أكثر إلى ماهية الذكاء الاصطناعي املوجود وما
الاصطناعي؟(؛ و) (٢النظر
ٍ
يفعله اليوم في التطبيقات املختلفة؛ و) (٣مناقشة املشكلات الأخلاقية والاجتماعية الأكثر
ً
واقعية وإلحاحً ا التي يُثريها الذكاء الاصطناعي كما يُطبق اليوم؛ و) (٤التفكري في سياسة
الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي

الذكاء الاصطناعي للمستقبل القريب؛ و) (٥طرح تساؤل عما إذا كان التركيز على الذكاء
الاصطناعي في الخطاب الجماهريي الحالي مُفيدًا في ضوء املشكلات الأخرى التي تُواجهنا،
وما إذا كان تركيزنا ينبغي أن ينصب َّ على الذكاء الاصطناعي وحدَه .وسوف نتبع هذه
املسارات في الفصول القادمة من الكتاب.
الفصل الثالث

كل ما له علاقة بالبشر

هل الذكاء الاصطناعي العام مُمكن؟
هل هناك فروق جوهرية بني الإنسان والآلة؟
تفترض رؤية أنصار تجاوز الإنسانية للمُستقبل التكنولوجي أن الذكاء الاصطناعي العام
)أو الذكاء الاصطناعي القوي( ممكن ،ولكن هل هو كذلك؟ بعبار ٍة أخرى ،هل يُمكننا
إنشاء آلات تتمت َّع بقدرات معرفية تُشبه تلك الخاصة بالبشر؟ إذا كانت الإجابة لا ،فإن
رؤية الذكاء الفائق بالكامل تُصبح غري ذات ِصلة بأخلاقيات الذكاء الاصطناعي .فإذا
كان ِمن ا ُملستحيل أن تتمت َّع الآلات بالذكاء البشري العام ،فإننا غري مُضطرين إلى أن نقلق
ِ
يعتمد على فهمنا
بشكل عام ،يبدو أن تقييمنا للذكاء الاصطناعي
بشأن الذكاء الفائق.
ٍ
ملاهية الذكاء الاصطناعي في الوقت الحالي وما يُمكن أن يصبح عليه في املستقبل ،كما يعتمد
على رؤيتنا للفروق بني الإنسان والآلة .على الأقل منذ منتصف القرن العشرين ،ناقش
الفلاسفة والعلماء ما تستطيع أجهزة الكمبيوتر أن تقوم به وما يُمكن أن تُصبح عليه،
والفروق بني الإنسان والآلة الذكية .دعونا نُلقي نظر ًة على بعض هذه النقاشات ،التي
تتناول ماهية الإنسان وما يجب أن يكون عليه ،بقدْر ما تتناول ماهية الذكاء الاصطناعي
وما يجب أن يكون عليه.
هل يمكن لأجهزة الكمبيوتر أن تتمت َّع بالذكاء والوعي والإبداع؟ هل يُمكنها فهم
الأشياء وإدراك املعاني؟ هناك تاريخ من النقد والشك في إمكانية وجود ذكاء اصطناعي
مُشا ِب ٍه لذكاء الإنسان .في عام ،١٩٧٢نشر هيوبرت دريفوس ،فيلسوف ذو خلفية في علم
الظواهر ،كتابًا بعنوان »ما لا تستطيع أجهزة الكمبيوتر فعله« 1 .منذ الستيني َّات ،كان
دريفوس يُظهر انتقادًا شديدًا للأساس الفلسفي للذكاء الاصطناعي وش َّكك في وعوده:
وقال إن برنامج الذكاء الاصطناعي البحثي محكوم عليه بالفشل .وقبل أن ينتقل إلى

أخلاقيات الذكاء الاصطناعي

بريكلي ،كان يعمل في معهد ماساتشوستس للتكنولوجيا ،وهو مكان مُهم لتطوير الذكاء
ً
أساسا في ذلك الوقت على ا ُملعالجة الرمزية .رأى دريفوس
الاصطناعي ،والذي كان يعتمد
أن الدماغ ليس جهاز كمبيوتر وأن العقل لا يعمل عن طريق ا ُملعالجة الرمزية .إن لدَينا
خلفية لا واعية من املعرفة املشتركة القائمة على الخبرة وما يمكن أن يُطلِق عليه هايدجر
»كينونتنا في العالم« ،وهذه املعرفة ِضمنية ولا يمكن تشكيلها .وتعتمد خبرة الإنسان،
حسب رأي دريفوس ،على ا ُملمارسة ً
بدلا من املعرفة .ولا يستطيع الذكاء الاصطناعي
ا ْلتِقاط هذا املعنى واملعرفة الضمنية؛ وإذا كان هذا هو هدف الذكاء الاصطناعي ،فهذا
ُ
محض أساطري .فالبشر وحدَهم قادرون على رؤية ما هو ذو صلة لأنهم ،بوصفِ هم كائنات
م ِّ
ُتجسدة ووجودية ،يشاركون في العالم وقادرون على الاستجابة ملتطلبات الوضع.
هناك تاريخ من النقد والشك في إمكانية وجود ذكاء اصطناعي مُشا ِب ٍه لذكاء الإنسان.

في ذلك الوقت ،واج َه دريفوس الكثري من املعارضة ،ولكن في ٍ
وقت لاحق ،لم يعُ د
الكثريون من باحثي الذكاء الاصطناعي يعِ دُون بتحقيق الذكاء الاصطناعي العام أو
 َّ
يتوقعون تحقيقه .وانتقلت أبحاث الذكاء الاصطناعي من الاعتماد على مُعالجة الرموز إلى
نماذج جديدة ،ومنها تع ُّلم الآلة القائم على الإحصاء .وفي حني كانت هناك فجوة هائلة
في وقت دريفوس بني عِ لم الظواهر والذكاء الاصطناعي ،فإن العديد من باحثي الذكاء
 ِّ
املتجسدة واملوجودة ،التي تد َّعي أنها
الاصطناعي اليوم يعتنِقون مناهج العلوم املعرفية
أقرب إلى علم الظواهر.
ً
صائبة وتُظهر كيف يمكن أن تتعا َرض
ومع ذلك ،فإن اعتراضات دريفوس لا تزال
وجهات نظر الإنسان غالبًا مع الآراء العلمية ،خاصة — ولكن ليس حصريٍّا — فيما يُسم َّ ى
بالفلسفة القارية .يُشد ِّد الفلاسفة القاريون عاد ًة على أن البشر والعقول البشرية مختلفة
ً
اختلافا جوهريٍّا عن الآلات ،ويُر ِّكزون على التجربة الإنسانية الواعية والوجود الإنساني،
الذي لا يمكن ولا ينبغي اختزاله في أوصاف شكلية أو تفسريات علمية .من جهة أخرى،
يؤيد بعض الفلاسفة — غالبًا من منطلق التقليد التحليلي للفلسفة — رؤية للإنسان
تدعم الباحثني في مجال الذكاء الاصطناعي الذين يعتقدون أن الدماغ والعقل البشري
يُشبهان ويعملان ٍّ
حقا مثل نماذج الكمبيوتر الخاصة بهم .ومن أمثلة هؤلاء الفلاسفة
كل ما له علاقة بالبشر

بول تشريشلاند ودانييل دنيت .يعتقد تشريشلاند أن العلم ،وخاصة عِ لم الأحياء التطو ُّري
ً
كاملا .ويعتقد
وعلم الأعصاب ،والذكاء الاصطناعي يُمكنهما تفسري الوعي البشري تفسريًا
ٍ
شبكة عصبية مُتك ِّررة .وينكر وجود أفكار أو تجارب غري ماد ِّية فيما
أن الدماغ عبارة عن
ُ
يُط َلق عليه املادية الإقصائية .فما نسم ِّ يه أفكا ًرا وتجارب ما هو إلا حالات للدماغ .وينكر
دنيت ً
أيضا وجود أي شيءٍ بخلاف ما يحدُث في الجسم :ويرى أننا »نحن أنفسنا نوع من
الروبوتات« ) .(Dennett 1997وإذا كان الإنسان في الأساس آلة واعية ،فإن مثل هذه
الآلات مُمكنة ،وليس فقط من حيث املبدأ ولكن في الواقع .يُمكننا أن نحاول صنعها .ومن
بمكان أن ٍّ
كلا من الفلاسفة القاريني والتحليليني يُعارضان الثنائية الديكارتية
الأهمية
ٍ
لأسباب مختلفة :فالفلاسفة القاريون يعتقدون أن
التي تفصل بني العقل والجسم ،ولكن
ٍ
وجود الإنسان يتع َّلق بكونه في العا َلم الذي لا يُفصل فيه العقل عن الجسم ،أما الفلاسفة
ٍّ
ُستقلا عن الجسم.
لأسباب مادية أن العقل ليس شيئًا م
القاريون فيعتقدون
ٍ
ولكن ليس جميع الفلاسفة التحليلي ِّني ي َرون أن الذكاء الاصطناعي العام أو القوي
مُمكن .من وجهة نظر الفيلسوف فيتجنشتاين )في ٍ
وقت لاحق( ،يمكن للشخص أن يُجادل
ٍ
ملجموعة من القواعد أن تصف ظاهر ًة معرفية ،فإن ذلك لا يعني
بأنه في حني يمكن
بالضرورة أن لدَينا فعليٍّا قواعد في رءوسنا ) .(Arkoudas and Bringsjord 2014كما
لنوع واحد من أنواع الذكاء الاصطناعي،
هو الحال مع انتقاد دريفوس ،يُثري هذا مشكلة
ٍ
وهو الذكاء الاصطناعي الرمزي ،إذا افترض أن هذه هي الطريقة التي يُف ِّكر بها البشر.
ثم َّ ة انتقاد فلسفي َ
آخر للذكاء الاصطناعي يأتي من جون سريل ،الذي يُعارض فكرة أن
برامج الكمبيوتر يمكن أن تكون لديها حالات معرفية حقيقية أو فهم للمعنى )Searle
 .(1980وفيما يلي التجربة الفكرية التي يُقد ِّمها ،والتي تُع َرف باسم حج َّ ة الغرفة
الصينية :يُحبَس سريل في غرفة ويُعطى كتابات صينية ولكنه لا يعرف الصينية .ومع
ٌ
أشخاص خارج الغرفة يتحدثون بالصينية
ذلك ،يستطيع الرد على الأسئلة التي يطرحها
لأنه يستخدم ُكتي ِّب القواعد الذي يُم ِّكنه من إنتاج الإجابات الصحيحة )مُخرجات( استنادًا
إلى املستندات )املدخلات( التي َّ
بنجاح دون فهم اللغة
يتلقاها .وهو يستطيع القيام بذلك
ٍ
الصينية .وباملثل ،يُجادل سريل ،يُمكن لبرامج الكمبيوتر إنتاج مُخرجَ ات استنادًا إلى
مدخلات بالاستعانة بالقواعد التي تُزو َّد بها ،ولكنها لا تفهم شيئًا .بمصطلحات فلسفية
 ُّ
تخص ً
صا :لا تمتلك برامج الكمبيوتر قصدية ،ولا يمكن خلق فهم حقيقي بواسطة
أكثر
الحوسبة الشكلية .أو كما يقول بودن ) ،(٢٠١٦الفكرة هي أن املعنى يأتي من البشر.
أخلاقيات الذكاء الاصطناعي

على الرغم من أن برامج الكمبيوتر الحالية للذكاء الاصطناعي غالبًا ما تختلف عن
تلك التي انتقدها دريفوس وسريل ،فإن النقاش لا يزال مُستم ٍّرا .يعتقد العديد من
ً
فروقا حاسمة بني طريقة تفكري البشر وأجهزة الكمبيوتر .على سبيل
الفلاسفة أن هناك
َ
ْ
املثال ،يمكن للمرء اليوم أن يُجادل بأننا كائنات قادرة على خلق املعنى ،وواعية وم ِّ
ُتجسدة
وحية ،ولا يمكن تفسري طبيعتنا وعقولنا ومعرفتنا باملقارنة بالآلات .ومع ذلك ،عليك أن
تلاحظ أنه حتى العلماء والفلاسفة الذين يعتقدون أن هناك الكثري من التشابُه بني البشر
ري من
والآلات من حيث املبدأ ،وأن الذكاء الاصطناعي العام مُمكن نظريٍّا ،يرفضون في كث ٍ
عتبر أن الذكاء الاصطناعي ا ُملشابه
الأحيان رؤية بوستروم للذكاء الفائق وأفكار مُماثلة تَ ِ
 ُّ
التحقق .فبودن ودنيت كلاهما يعتقدان
لذكاء الإنسان قد أصبح قاب قوسني أو أدنى من
أن الذكاء الاصطناعي العام صعب جدٍّا تحقيقه عمليٍّا ،وبالتالي ليس شيئًا يجب القلق
بشأنه في الوقت الحالي.
نحن كائنات قادرة على َخ ْلق املعنى ،وواعية ومتجسدة وحية ،ولا يمكن تفسري طبيعتنا وعقولنا
ومعرفتنا باملقارنة بالآلات.

وبناءً عليه يمكننا القول إن هناك ،في خلفية النقاش حول الذكاء الاصطناعي ،تبايُن
عميق في الآراء حول طبيعة الإنسان والذكاء البشري والعقل والفهم والوعي والإبداع
واملعنى واملعرفة البشرية والعلوم ،وهكذا .فإذا كان ثمة »معركة« من الأساس ،فهي
معركة تتع َّلق بالإنسان بقدْر ما تتع َّلق بالذكاء الاصطناعي.
الحداثة و)ما بعد( الإنسانية وما بعد الظاهرية
نظر َ
أوسع في العلوم الإنسانية ،من املهم أن نضع هذه النقاشات حول
من وجهة
ٍ
سياق َ
أوسع للوقوف على ماهيتها وما تنطوي عليه .فهذه
الذكاء الاصطناعي والإنسان في
ٍ
ٍ
انقسامات عميقة في
النقاشات لا تتع َّلق بالتكنولوجيا والإنسان فحسب ،ولكنها تعكس
بشكل غري مباشر في
الحداثة .دعوني أم ُّر مرور الكرام على ثلاثة انقسامات تُساهم
ٍ
تشكيل املناقشات الأخلاقية حول الذكاء الاصطناعي .الانقسام الأول هو انقسام ظهَ َر في
مُستهَ ِّل عصر الحداثة بني حركتَي التنوير والرومانسية .أما َ
الآخران فهما تطو ُّرات حديثة
كل ما له علاقة بالبشر

نسبيٍّا :الأول بني الإنسانية وتجاوز الإنسانية ،ويبقى حبيس توترات الحداثة ،والثاني بني
الإنسانية وما بعد الإنسانية ،والذي يُحاول تخ ِّ
طي الحداثة.
إحدى وسائل فهم النقاش حول الذكاء الاصطناعي والإنسان هي أن نضع في الاعتبار
التوت ُّر القائم بني التنوير والرومانسية في الحداثة .في القرنَني الثامن عشر والتاسع عشر،
تحدى العلماء وا ُملفكرون التنويريون الآراء الدينية التقليدية وزعموا أن العقل والشك
ظهر لنا ماهية الإنسان والعالم الحقيقية ،على عكس ا ُملعتقدات ا ُملس َّلم بها غري
والعلم تُ ِ
ا ُملبررة بالحجج أو غري املدعومة بالأدلة .وكانوا متفائلني حيال ما يمكن أن يقد ِّمه العلم
لصالح الإنسانية .ردٍّا على ذلك ،قال الرومانسيون إن العقل املج َّرد والعلم الحديث قد
أفقدا العا َلم ِسحره وأننا في حاجة إلى إعادة الغموض والسحر اللذَين يُريد العلم القضاء
عليهما .عند النظر إلى النقاش حول الذكاء الاصطناعي ،يبدو لنا أننا لم نبتعِ د كثريًا
عن ذلك .على سبيل املثال ،يستهدف عمل دنييت حول الوعي وعمل بودين حول الإبداع
ٍ
تفسريات لكل شيء ،أو كما يقول دنييت »فك السحر« .فهذان الفيلسوفان مُتفائلان
تقديم
 َّ
بأن العلم يُمكنه كشف غموض الوعي والإبداع وغريهما .إنهما يُعارضان كل مَ ن يقاوم
جهود فك سحر الإنسان ،مثل الفلاسفة القاريني الذين يسريون في ركب ما بعد الحداثة
ويُشد ِّدون على غموض معنى أن تكون إنسانًا؛ بعبارة أخرى :الرومانسيني الجُ دد .يبدو
أن سؤال »هل نف ُّك السحر أم نحتفظ بغموض الإنسان؟« هو السؤال الرئيسي في املناقشات
التي تتناول الذكاء الاصطناعي العام ومُستقبله.
أما التوتر الثاني فهو بني مؤيدي الإنسانية ومؤيدي تجاوز الإنسانية .ما هو
 َّ
يتعني
»الإنسان« ،وماذا يجب أن يكون؟ هل من ا ُملهم الدفاع عن الإنسان كما هو ،أم
علينا تعديل تصو ُّرنا له؟ يحتفي دُعاة الإنسانية بالإنسان كما هو .ومن الناحية الأخلاقية،
يُشد ِّدون على القيمة الجوهرية واملتفو ِّقة للبشر .ويُمكننا العثور على أفكار دعاة الإنسانية
في النقاش الدائر عن الذكاء الاصطناعي في الحجج التي تُدافع عن حقوق الإنسان وكرامته
كأساس لأخلاقيات الذكاء الاصطناعي ،أو في الحجة املؤيدة لأن يكون البشر و ِقيَمُهم في
ٍ
قلب وفي مركز مسألة تطوير الذكاء الاصطناعي ومُستقبله .هنا غالبًا ما تت َّفق الإنسانية
أشكالا أكثر تحف ً
ً
مع التفكري التنويري .ولكن يُمكن أن تأخذ ً
ظا أو رومانسية .كذلك
أيضا
يُمكننا أن نعثر على الإنسانية في مقاومة مشروع دُعاة تجاوز الإنسانية .فبينما يعتقد
دُعاة تجاوز الإنسانية َّ
أن علينا ا ُمل ُضي قدمً ا نحو نوع جدي ٍد من الإنسان يتم تحسينُه
بواسطة العلم والتكنولوجيا ،يدافع الإنسانيون عن الإنسان كما هو ،ويشددون على قيمته
وكرامته ،التي يُقال إنها مهد َّدة من قِ بل علوم دعاة تجاوز الإنسانية وفلسفتهم.
أخلاقيات الذكاء الاصطناعي

ردود الفعل الدفاعية تجاه التكنولوجيا الجديدة لها تاريخها الخاص .ففي العلوم
الاجتماعية والإنسانية ،كثريًا ما تُ َ
نتقد التكنولوجيا باعتبارها تهديدًا للإنسانية واملجتمع.
على سبيل املثال ،كان كثريٌ من فلاسفة القرن العشرين شديدي التشاؤم حيال العلم،
وحذروا من سيطرة التكنولوجيا على املجتمع .ولكن الصراع الآن لا يتع َّلق فقط بحياة
الإنسان واملجتمع ،بل يتع َّلق بالإنسان نفسه :هل نحن بصدد تحسينه وتطويره أم لا؟ هذا
هو السؤال .فمن جهة ،يُصبح الإنسان نفسه مشروعً ا علميٍّا تكنولوجيٍّاً ،
قابلا للتحسني
والتطوير .وبمج َّرد أن ي َُفك سحر الإنسان — من خلال داروين وعلم الأعصاب والذكاء
الاصطناعي — يُمكننا أن نبدأ في تحسينه .ويمكن للذكاء الاصطناعي أن يُساعدنا في
ِ
نحتضن الإنسان كما هو .وربما يقول
تحسني الإنسان .ومن جهة أخرى ،يجب علينا أن
البعض :دائمً ا ما يفوتنا أن نُدرك ماهية الإنسان .فنحن لا نستطيع أن نفهمه فهمً ا تامٍّ ا
بواسطة العلم.
تستمر هذه التوت ُّرات في تقسيم العقول والقلوب في هذا النقاش .فهل يُمكننا تخ ِّ
طيها؟
 َّ
يتخلى عن هدف إنشاء ذكاءٍ اصطناعي شبيه بالإنسان .ولكن حتى
عمليٍّا ،يمكن للمرء أن
في هذه الحالة ،تظ ُّل هناك خلافات بشأن وضع »آلات الذكاء الاصطناعي كنماذج للبشر«
ا ُملستخدَم في علم الذكاء الاصطناعي .هل تُع ِّلمنا ٍّ
حقا شيئًا عن كيفية تفكري البشر؟ أم
نوع َّ
معني من التفكري ،على سبيل املثال تفكري يمكن صياغته
إنها تُع ِّلمنا فقط شيئًا عن ٍ
بواسطة الرياضيات ،أو تفكري يهدف إلى السيطرة والتلاعُ ب؟ إلى أي مدًى يُمكننا ٍّ
حقا
التع ُّلم من هذه التقنيات عن الإنسان؟ هل البشرية أكبر مما يستطيع العلم أن يُدرك؟
ً
اعتدالا ،تظهر الصراعات بشأن الحداثة.
حتى في املناقشات الأكثر
نهج دارسي العلوم الاجتماعية والإنسانية
للخروج من هذا املأزق ،يُمكن للمرء اتباع ِ
ً
طرقا »غري حديثة« للتفكري خلال الخمسني عامً ا املاضية .أوضح كت َّابٌ
الذين استكشفوا
ً
أمثال برونو لاتور وتيم إنجولد أنه يمكننا العثور على طرق أقل ميلا للمُقارنة بني ثنائيات
وأكثر ً
ميلا ل ُّلجوء إلى اللاحداثة عند التعامُل مع العا َلم من أجل تجاوز الخلاف ما بني
التنوير والرومانسية .يُمكننا عندئ ٍذ أن نُحاول اجتياز الفجوة الحديثة بني البشر وغري
البشر ليس من خلال العِ لم الحديث أو من خلال تجاوز الإنسانية ،التي ترى من وجهة
صراع أساسي ،ولكن من خلال الفكر ما بعد الإنساني
نظرها أن البشر والآلات ليسا في
ٍ
من وجهة النظر )ما بعد( الإنسانية .وهذا يؤدي إلى التوتر الثالث :بني الإنسانية وما بعد
الإنسانية .يُش ِّكك مؤيدو ما بع َد الإنسانية ،الذين يُعارضون الإنسانيني ا ُملتهمني بالعُ نف
كل ما له علاقة بالبشر

مع غري البشر ،مثل الحيوانات ،تحت مُسم َّ ى القيمة الفائقة للإنسان ،يُش ِّككون في مركزية
الإنسان في الأنظمة الأنطولوجية والأخلاقية الحديثة .فهم ي َرون أن غري البشر مُهم ُّ ون
ً
أيضا ،وأننا يجب ألا نخاف من عبور الحدود بني البشر وغري البشر .وهذا اتجاه مُثري
للاستكشاف لأنه ُ
يأخذنا خارج سردية املنافسة بني البشر والآلات.
ً
رؤية تصو ِّر أن العيش
يُقدم مناصرو ما بعد الإنسانية ،من أمثال دونا هاراواي،
مع الآلات ،بل ربما الاندماج معها ،لم يعُ د يُرى كتهدي ٍد أو ككابوس ،كما كان يرى من
 َّ
يتحقق ملناصري تجاوز الإنسانية ،ولكنه وسيلة يُمكن من
قبل دعاة الإنسانية ،أو كحل ٍم
خلالها عبور الحدود الأنطولوجية والسياسية بني البشر وغري البشر .ومن ثَم يمكن أن
يكون الذكاء الاصطناعي جزءًا ليس من مشروع دُعاة تجاوز الإنسانية ،ولكن من مشروع
دُعاة ما بعد الإنسانية ا ُملهم ،الذي يدخل من جانب العلوم الإنسانية والفنون ً
بدلا من
العلم .يتم عبور الحدود ليس باسم العلم والتقد ُّم العاملي ،كما قد يرغب بعض مناصري
تجاوز الإنسانية التنويريني في القول ،ولكن باسم سياسة مناصري ما بعد الإنسانية
أيضا أن تُقد ِّم شيئًا َ
وأيديولوجية عبور الحدود .ويمكن ملا بعد الإنسانية ً
آخر يتع َّلق
بالذكاء الاصطناعي :يمكنها أن تحُ ث َّنا على الاعتراف بأنه »ليس ثمة حاجة لأن يكون غري
البشر مُماثِلني لنا ويجب عدم جعلهم مُماثِلني لنا« .يبدو أن الذكاء الاصطناعي يمكنه،
بالاستناد إلى آراء ما بعد الإنسانية ،أن يُح ِّرر نفسه من عبء تقليد الإنسان أو إعادة
أشكال مختلفة من الوجود والذكاء والإبداع ،وما إلى ذلك .ليس
بنائه ويمكنه استكشاف
ٍ
هناك حاجة لأن يُصن َّع الذكاء الاصطناعي على صورتنا .فالتقد ُّم هنا يعني تجاوز الإنسان
وقبول غري البشر لكي نتع َّلم منهم .وعلاو ًة على ذلك ،يمكن أن يتفق ك ٌّل من دعاة تجاوز
ُ
الإنسانية وما بعد الإنسانية على أنه ً
التنافس مع الذكاء الاصطناعي لأداء مهمة
بدلا من
معي َّنة ،يُمكننا ً
ٍ
 ُّ
التوصل إليه من خلال التعاون وحشد
هدف مشترك ،يتم
أيضا تحديد
أفضل ما يمكن أن يقد ِّمه البشر والذكاء الاصطناعي من أجل التوج ُّ ه نحو تحقيق ذلك
الهدف املشترك.
وسيلة أخرى لتجاوز سردية املنافسة — وهي وسيلة تقترب في بعض الأحيان من
مفاهيم ما بعد الإنسانية — هي نهج في فلسفة التكنولوجيا يُسم َّ ى ما بعد الظاهرية.
يستنِد دريفوس إلى علم الظواهر أو الظاهرية ،ولا سيما أعمال هايدجر .ولكن الأفكار
ما بعد الظاهرية ،التي بدأها الفيلسوف دون إيده ،تتجاوز فلسفة التكنولوجيا الظاهرية
التي ابتكرها هايدجر بالتركيز على كيفية تفاعل البشر مع تقنيات ِبعَ ينها ولا سيما
أخلاقيات الذكاء الاصطناعي

ري من الأحيان مع دراسات العلوم
املصنوعات املادية .يُر ِّكز هذا النهج ،الذي يتعاون في كث ٍ
والتكنولوجيا ،على البُعد املادي للذكاء الاصطناعي .قد يُن َ
ظر إلى الذكاء الاصطناعي في
ٍ
بمصنوعات مادية و ِبنيات
طابع مُج َّرد أو شكلي ،غري مُتصل
بعض الأحيان على أنه ذو
ٍ
ً
سابقا
أساسية مُحد َّدة .ولكن جميع الشكليات والتجريدات والعمليات الرمزية املذكورة
ٍ
ِ
أدوات مادية و ِبنيات أساسية مادية .على سبيل املثال ،كما سنرى في الفصل
تعتمد على
التاليِ ،
بشكل كبري على الشبكات وإنتاج كمي َّات ضخمة
يعتمد الذكاء الاصطناعي الحالي
ٍ
من البيانات باستخدام الأجهزة الإلكترونية .تلك الشبكات والأجهزة ليست مجرد أشياء
»افتراضية« ولكن َّ
بشكل مادي .وعلاو ًة على ذلك ،يتحد َّث ما بعد
يتعني إنتاجها وصيانتها
ٍ
الظاهِ ري ِّني ،مثل بيتر بول فريبيك ،عكس التقسيم الحديث بني املوضوع واملحمول ،عن
التشكيل ا ُملتبادل بني البشر والتكنولوجيا ،أو على الأحرى التشكيل ا ُملتبادل بني املوضوع
ً
وبدلا من رؤية التكنولوجيا كتهديد ،يؤ ِّكدون أن البشر مَ ي َّالون إلى التكنولوجيا
واملحمول.
)بمعنى أنهم كانوا دائمً ا يستخدمون التكنولوجيا؛ أي إنها جزء من وجودنا وليست
شيئًا خارجيٍّا يُهد ِّد هذا الوجود( ،وأن التكنولوجيا تُساعد البشر على التعامُل مع العالم.
بالنسبة إلى الذكاء الاصطناعي ،يبدو أن هذه الرؤية تَعني أن املعركة الإنسانية للدفاع
وبدلا من ذلكً ،
ً
وفقا لهذا النهج ،كان
عن الإنسان ضد التكنولوجيا هي معركة مُضل َلة.
الإنسان دائمً ا مي ً َّالا إلى التكنولوجيا ،ولهذا علينا أن نسأل كيف يُساعد الذكاء الاصطناعي
بشكل تفاعُ لي بينما لا يزال
البشر في التعامُل مع العالم ونحاول تشكيل هذه ا ُملساعدات
ٍ
بإمكاننا :إننا نستطيع مناقشة الأخلاقيات في مرحلة تطوير الذكاء الاصطناعي ،بل َّ
يتعني
علينا ذلكً ،
بدلا من أن نشكو فيما بع ُد من املشكلات التي يُسب ِّبها.
يبدو أن الذكاء الاصطناعي يُمكنه ،بالاستناد إلى آراء ما بعد الإنسانية ،أن يُح ِّرر نفسه من عبء
أشكال مختلفة من الوجود والذكاء والإبداع ،وما
تقليد الإنسان أو إعادة بنائه ويُمكنه استكشاف
ٍ
إلى ذلك.

ومع ذلك ،ربما يشعُ ر املرء بالقلق من َّ
أن ُرؤى مُناصري ما بعد الإنسانية وما بعد
الظاهرية ليست ناقد ًة بما فيه الكفاية؛ لأنها شديدة التفاؤل وشديدة البُعد عن املمارسة
العلمية والهيكلية ،وبالتالي فهي ليست َّ
حساسة بما فيه الكفاية تجاه الأخطار الحقيقية
والعواقب الأخلاقية وا ُملجتمعية للذكاء الاصطناعي .إن عبور الحدود التي لم يسبق عبورها
كل ما له علاقة بالبشر

لا يكون بالضرورة من دون مشكلات ،وفي املمارسة العملية قد لا تفيد أفكار ما بعد
الإنسانية وما بعد الظاهرية في حمايتنا من التس ُّلط والاستغلال الذي قد نُعاني منه ج َّراء
استخدام تقنيات كالذكاء الاصطناعي .يُمكن للمرء ً
أيضا أن يُدافع عن رؤية أكثر تقليدية
بنوع جديد من الإنسانيةً ،
بدلا من أن يدعم ما بع َد الإنسانية .وهكذا
للإنسان أو يُطالب
ٍ
يستمر النقاش.
الفصل الرابع

أهي حقا مجرد آلات؟

التشكيك في املكانة الأخلاقية للذكاء الاصطناعي:
الوكالة الأخلاقية واكتساب املكانة الأخلاقية
إحدى القضايا التي أُثريَت في الفصل السابق تتع َّلق بما إذا كان غري البشر مُهم ِّ ني ً
أيضا.
يعتقد الكثريون اليوم أن الحيوانات مُهم َّ ة من الناحية الأخلاقية .ولكن لم ي ُكن الأمر كذلك
دائمً ا .على ما يبدو ،كن َّا مُخطئني في املاضي بشأن الحيوانات .فإذا كان الكثريون اليوم
يعتقدون أن الآلات املدعومة بالذكاء الاصطناعي مجرد آلات ،فهل يرتكِبون خطأ ً م ً
ُماثلا؟
ً
مكانة أخلاقية؟ هل ينبغي
هل تستحِ ُّق الآلات املدعومة بالذكاء الاصطناعي الفائقة الذكاء
ً
بمكان أن نُف ِّكر حتى في مسألة ما إذا كانت الآلات
حقوقا؟ أم إنه من الخطورة
أن نُعطيها
ٍ
ٍ
بمكانة أخلاقية؟
يُمكن أن تحظى
إحدى الطرق ملناقشة ما هو الذكاء الاصطناعي وما يمكن أن يُصبح عليه هي
ٍ
أسئلة فلسفية
السؤال عن املكانة الأخلاقية للذكاء الاصطناعي .ونحن هنا نتط َّرق إلى
مُتع ِّلقة بالذكاء الاصطناعي ،ليس عبر امليتافيزيقا أو الإبستمولوجيا أو تاريخ الأفكار،
ولكن عبر فلسفة الأخلاق .يمكن أن يُشري مصطلح »املكانة الأخلاقية« )ويُسمى أحيانًا
»الأهمية الأخلاقية«( إلى نوعَ ني من الأسئلة .الأول يتع َّلق بما يُمكِن للذكاء الاصطناعي
القيام به من الناحية الأخلاقية؛ بعبار ٍة أخرى ،ما إذا كان يمكن أن يتمت َّع بما يُطلق
عليه الفلاسفة »الوكالة الأخلاقية« ،وإذا كان الأمر كذلك ،فهل يتمت َّع بالوكالة الأخلاقية
ِ
الكاملة؟ ماذا يعني هذا؟ يبدو أن أفعال الذكاء الاصطناعي اليوم لها بالفعل عواقِ ب
ً
ً
»ضعيفا« من أشكال
شكلا
أخلاقية .سيت َّفق معظم الناس على أن لدى الذكاء الاصطناعي
الوكالة الأخلاقية بهذا املعنى ،والذي يُش ِبه ،على سبيل املثال ،مُعظم السيارات اليوم؛ إذ

أخلاقيات الذكاء الاصطناعي

يمكن أن يكون للأخرية ً
أيضا عواقِ ب أخلاقية .ولكن إذا س َّلمنا بأن الذكاء الاصطناعي
ً
بشكل أقوى من أشكال الوكالة الأخلاقية؟
واستقلالا ،فهل يمكن أن يتمت َّع
يزداد ذكاءً
ٍ
يجب أن يتم منحُ ه أو سيتطو َّر لدَيه بعض القدرة على التفكري الأخلاقي والقدرة
هل ِ
على إصدار الأحكام واتخاذ القرارات؟ على سبيل املثال :هل يُمكن وهل يجب أن نعتبر
السيارات الذاتية القيادة التي تستخدِم الذكاء الاصطناعي ذات وكالة أخلاقية؟ هذه
الأسئلة تتع َّلق بأخلاقيات الذكاء الاصطناعي ،بمعنى أنها تتط َّرق إلى ماهية القدرات
الأخلاقية التي يمكن أو ينبغي أن يتمت َّع بها الذكاء الاصطناعي؟ ولكن الأسئلة ا ُملتعلقة ب
»املكانة الأخلاقية« يمكن ً
أيضا أن تُشري إلى كيف ينبغي أن نُعامل الذكاء الاصطناعي .هل
ً
شكلا من أشكال الاحترام الأخلاقي؟ هل
الذكاء الاصطناعي »مجرد آلة« ،أم أنه يستحق
ً
ٍ
بطريقة مختلفة عن الطريقة التي نتعامل بها مثلا مع آلة التحميص
يجب علينا مُعاملته
ً
لكيان صناعي ذكي للغاية ،إذا تم تطوير مثل
أو املغسلة؟ هل يجب أن نمنح حقوقا
ٍ
هذا الكيان يومً ا ما ،حتى لو لم ي ُكن بشريٍّا؟ هذا ما يُطلِق عليه الفلاسفة السؤال املتعلق
ب »اكتساب املكانة الأخلاقية« .هذا السؤال يتعلق بأخلاقيات الذكاء الاصطناعي بذاته،
ولكنه يتع َّلق بأخلاقياتنا تجاهه .هنا يكون الذكاء الاصطناعي موض َع اهتما ٍم من الناحية
وكيلا أخلاقيٍّا م ً
ً
الأخلاقيةً ،
ُحتملا في ح ِّد ذاته.
بدلا من كونه
هل الذكاء الاصطناعي »مجرد آلة«؟ هل يجب علينا معاملته بطريقةٍ مختلفة عن الطريقة التي
نتعامل بها ً
مثلا مع آلة التحميص أو املغسلة؟

الوكالة الأخلاقية
لنبدأ بالتحد ُّث عن سؤال الوكالة الأخلاقية .إذا كان الذكاء الاصطناعي يُمكن أن يُصبح
أكثر ذكاءً مما هو عليه اليوم ،فيُمكننا أن نفترض أنه يستطيع أن يُطو ِّر قدرته على التفكري
الأخلاقي وأنه يستطيع أن يتع َّلم كيف يت َّخِ ذ البشر القرارات بشأن القضايا الأخلاقية.
ولكن هل سيكون هذا كافيًا لكي يحظى بالوكالة الأخلاقية الكاملة؛ أي الوكالة الأخلاقية
ً
خيالا علميٍّا بالكامل .فإذا كنا ِ
نعتمد اليوم على
التي يتمت َّع بها الإنسان؟ هذا السؤال ليس
الخوارزميات في اتخاذ بعض قراراتنا ،على سبيل املثال في السيارات أو املحاكم ،فيبدو
ً
سليمة من الناحية الأخلاقية .ولكن ليس
أنه سيكون من ا ُمله ِّم أن تكون تلك القرارات
أهي ٍّ
حقا مجرد آلات؟

من الواضح ما إذا كانت الآلات يمكن أن تتمت َّع بنفس القدرات الأخلاقية التي يتمت َّع بها
بأفعال في العا َلم ،وهذه الأفعال لها
البشر .إنها تتمت َّع بالوكالة الأخلاقية بمعنى أنها تقوم
ٍ
عواقب أخلاقية .على سبيل املثال ،قد تتسب َّب سيارة ذاتية القيادة في حادث ،أو قد يوصي
الذكاء الاصطناعي بسجن شخص َّ
معني .هذه السلوكيات والخيارات ليست حيادية من
الناحية الأخلاقية؛ إذ إن لها عواقب أخلاقية واضحة على الأشخاص ذوي الصلة .ولكن
للتعامُل مع هذه املشكلة ،هل يجب منح الوكالة الأخلاقية للذكاء الاصطناعي؟ وهل يمكن
أن يتمت َّع بوكالة أخلاقية كاملة؟
هناك مواقف فلسفية مُتنو ِّعة حيال هذه الأسئلة .يقول بعض الأشخاص إن الآلات لا
يمكن أن تتمت َّع أبدًا بالوكالة الأخلاقية .ويرى هؤلاء أن الآلات ليس لدَيها القدرات اللازمة
للوكالة الأخلاقية ،مثل الحالات العقلية أو الانفعالات أو الإرادة الحرة .ولذلك هناك خطورة
ِ
ٍ
نعتمد عليها في اتخاذ
قرارات سليمة أخلاقيٍّا وأن
نفترض أنها تستطيع اتخاذ
في أن ِ
ً
كاملا .على سبيل املثال ،قالت ديبورا جونسون ) (٢٠٠٦إن
مثل هذه القرارات اعتمادًا
ٍ
بوكالة أخلاقية خاصة بها :إنها من إنتاج البشر وتُستخدَم من
أنظمة الكمبيوتر لا تتمت َّع
قِ بَلهم ،والبشر وحدَهم لديهم الحرية والقدرة على التصر ُّف واتخاذ القرارات من الناحية
الأخلاقية .وبالطريقة نفسها ،يمكن للمرء أن يقول إن الذكاء الاصطناعي من إنتاج البشر،
وبالتالي يجب أن يكون اتخاذ القرارات الأخلاقية في املمارسات التكنولوجية من اختصاص
ٍ
بوكالة
البشر .على النقيض من ذلك ،هناك أولئك الذين يعتقدون أن الآلات يمكن أن تتمت َّع
أخلاقية كاملة تمامً ا مثل البشر .ويزعم الباحثون مثل مايكل وسوزان أندرسون ،على
سبيل املثال ،أنه من حيث املبدأ يمكن ،بل يجب ،أن تُمنح الآلات نوعً ا من الأخلاق البشرية
) .(Anderson and Anderson 2011ويُمكننا تزويد الذكاء الاصطناعي باملبادئ ،وربما
تكون الآلات حتى أفضل من البشر في الوصول إلى القرارات الأخلاقية نظ ًرا لأنها أكثر
عقلانية ولا تنجرف وراء عواطفها .وقد جادل البعض ،لدحض هذه الفكرة ،بأن القواعد
الأخلاقية كثريًا ما تتضارب )على سبيل املثال ،انظر إلى قصص الروبوتات لأسيموف،
حيث تتسب َّب القوانني الأخلاقية للروبوتات دائمً ا في مشكلات للبشر والروبوتات( ،وأن
ٍ
افتراضات خاطئة
مشروع إنشاء »آلات أخلاقية« من خلال تغ ِذيَتها بالقواعد يستند إلى
بخصوص طبيعة الأخلاق .فالأخلاق لا يمكن اختزالها في ات ِّباع القواعد ،كما أنها ليست
مسألة عواطف بشرية فحسب؛ ولكن هذه العواطف قد تكون ضرورية للغاية للحُ كم
الأخلاقي .فإذا كان الذكاء الاصطناعي العام مُمكنًا على الإطلاق ،فإننا لا نُريد نوعً ا من
أخلاقيات الذكاء الاصطناعي

»الذكاء الاصطناعي املريض نفسيٍّا« أي الذي يتمت َّع بالعقلانية الكاملة ولكن َّه لا يهت ُّم
باهتمامات الإنسان لأنه يفتقر إلى املشاعر ).(Coeckelbergh 2010
لهذه الأسباب ،يمكن أن نرفض فكرة تمت ُّع الذكاء الاصطناعي بوكالة أخلاقية كاملة
ً
موقفا وس ً
ً
طا :يجب أن نمنح الذكاء الاصطناعي نوعً ا من
رفضا تامٍّ ا ،أو يمكن أن نت َّخِ ذ
القواعد الأخلاقية ،ولكن ليس كل القواعد الأخلاقية .يستخدم وينديل فالاخ وكولني ألني
مُصطلح »القواعد الأخلاقية الوظيفية« ) .(٣٩ ،٢٠٠٩تحتاج أنظمة الذكاء الاصطناعي
إلى بعض القدرة على تقييم العواقب الأخلاقية لأفعالِها .واملنطق وراء هذا القرار واضح
في حالة السيارات ذاتية القيادة :ستتو َّرط السيارة على الأرجح في مواقف تتط َّلب اتخاذ
 ُّ
التدخل
خيار أخلاقي ولكن لا يوجَ د وقت للاستعانة بالبشر لاتخاذ القرار أو انتظار
ٍ
البشري .وفي بعض الأحيان ،تكون هذه الخيارات عبارة عن معضلة .يتحد َّث الفلاسفة عن
معضلة عربة الترام ،وهي تجربة فكرية تتعلق َ
بسري عربة ترام على مسار سكك حديدية
ويجب عليك الاختيار بني عدم فِ عل أي شيء ،الأمر الذي سيؤد ِّي إلى مَ وت خمسة أشخاص
مسار َ
آخر ،حيث يكون هناك
مُقي َّدين باملسار ،أو سحب الرافعة وإرسال العربة إلى
ٍ
ٌ
تعرفه .ما هو الشيء السليم أخلاقيٍّا الذي يتوج َّ ب
شخص واحد مقي َّد به ولكنه شخص ِ
عليك القيام به؟ باملثل ،يقول أنصار هذا النهج إن السيارة الذاتية القيادة قد تُض َ
ط ُّر إلى
اتخاذ خيار أخلاقي ،على سبيل املثال ،بني قتْل املشاة العابرين على الطريق والاصطدام
يجب أن تت َّخِ ذه السيارة؟ يبدو أنه
بحائط ،مما يؤدي إلى موت السائق .ما الخيار الذي ِ
سيتعني علينا اتخاذ هذه القرارات الأخلاقية )م ً
ُسبقا( والتأ ُّكد من تغذية السيارات بها
من قِ بَل ا ُملطو ِّرين .أو ربما نحتاج إلى بناء سيارات مزو َّدة بالذكاء الاصطناعي تتع َّلم من
اختيارات البشر .ومع ذلك ،قد يُثار سؤال عما إذا كان إعطاء الذكاء الاصطناعي قواعد هو
وسيلة جيدة لتمثيل الأخلاق البشرية ،هذا إن كان من ا ُملمكن »تمثيل« الأخلاق من الأساس،
وإذا كانت مُعضلة عربة الترام تبني شيئًا جوهريٍّا في الحياة والتجربة الأخلاقية .أو ،من
منظور مختلف تمامً ا ،يمكن للمرء أن يتساءل عما إذا كان البشر في الواقع قادِ رين على
ٍ
اتخاذ قرارات أخلاقية بكفاءة .وملاذا نُقلد أخلاق البشر من الأساس؟ إن مُناصري تجاوز
بأخلاق فائقة لأنه
الإنسانية ،على سبيل املثال ،ي َرون أن الذكاء الاصطناعي سوف يتمتع
ٍ
سيكون أكثر ذكاءً من َّا.
ً
موقف َ
ٍ
وكالة أخلاقية
آخر ،لا يتط َّلب
هذا التشكيك في التركيز على الإنسان يُوج ِّ هنا إلى
تمحور حول الإنسان .وقد دافع لوتشيانو فلوريدي
كاملة ويُحاول ترك املوقف الأخلاقي ا ُمل ِ
أهي ٍّ
حقا مجرد آلات؟

أخلاق لا عقل لها وغري مُستندة إلى خصائص يمتلكها
وجيه دبليو ساندرز ) (٢٠٠٤عن
ٍ
ٍ
ِ
كاف من التفاعل
تعتمد على التمت ُّع بمستوًى
البشر .ويُمكننا جعل الوكالة الأخلاقية
والاستقلال والقدرة على التكي ُّف وكذلك القدرة على القيام بتصر ُّفات ذات طابع أخلاقي.
ً
ووفقا لهذه املعايري ،فإن كلب البحث والإنقاذ يتمت َّع بالوكالة الأخلاقية ،ولكن كذلك روبوت
 َّ
يتولى تصفية الرسائل البريدية غري املرغوب فيها .وباملِ ثل ،يمكن
الذكاء الاصطناعي الذي
تطبيق معايري لا تتمحوَر حول الإنسان ملنح الروبوتات الوكالة الأخلاقية ،كما اقترح جون
ٍّ
ُستقلا عن ا ُملبرمجني ويمكننا تفسري سلوكه
سالينز ) :(٢٠٠٦إذا كان الذكاء الاصطناعي م
بأن نعزو إليه القصد الأخلاقي )مثل قصد فعل الخري أو الشر( ،وإذا ن َّم سلوكه عن
آخرين ،فإن هذا الذكاء الاصطناعي يتمت َّع بالوكالة
َفهم مسئوليته تجاه وكلاء أخلاقِ ي ِّني ِ
الأخلاقية .ومن ثَم ،فإن هذه الآراء لا تتط َّلب الوكالة الأخلاقية الكاملة إذا كان ذلك يعني
ٍ
بطريقة تكون من حيث املبدأ
الوكالة الأخلاقية البشرية ،ولكنها تُع ِّرف الوكالة الأخلاقية
ُستقلة عن الوكالة الأخلاقية الكاملة للبشر ُ
ً
والقدرات البشرية املطلوبة لذلك .ومع ذلك،
م
ً
ً
هل ستكون مثل هذه الوكالة الأخلاقية الاصطناعية كافية إذا حُ ِك َم عليها وفقا للمعايري
الأخلاقية البشرية؟ عمليٍّا ،يكمن القلق ،على سبيل املثال ،في أن السيارات ذاتية القيادة
قد لا تُطبق القواعد الأخلاقية الكافية .أما من حيث املبدأ ،فيكمن القلق في أننا نبتعِ د
كثريًا عن الأخلاق البشرية هنا .ويعتقد الكثريون أن الوكالة الأخلاقية مُرتبطة ويجب أن
تكون مرتبطة بالإنسانية والشخصية .وهؤلاء لا يميلون إلى اعتناق أفكار مؤي ِّدي ما بعد
الإنسانية أو مؤيدي تجاوز الإنسانية.
اكتساب املكانة الأخلاقية
ثمة موضوع َ
ٍ
ملكانة أخلاقية .تخي َّل
آخر مُثري للجدَل ويتع َّلق باكتساب الذكاء الاصطناعي
أن لدَينا ذكاءً اصطناعيٍّا ً
فائقا .هل من ا َملقبول أخلاقيٍّا إيقاف تشغيل ِه ،أو »قتله«؟ وإذا
كلب آلي مُزود
ما نظرنا عن كثَب إلى الذكاء الاصطناعي الحالي :هل من املقبول ركل ٍ
بالذكاء الاصطناعي؟ 1إذا كانت الآلات املدعومة بالذكاء الاصطناعي ستكون جزءًا من
الحياة اليومية ،كما َّ
يتوقع العديد من الباحثني ،فإن مثل هذه الحالات ستظهر بالضرورة
يجب على البشر التصر ُّف تجاه هذه الكيانات الاصطناعية .ومع ذلك،
وتُثري مسألة كيف ِ
ليس ع َلينا أن نن ُ
ظر إلى ا ُملستقبل البعيد أو إلى الخيال العلمي .فقد أظهرت الأبحاث أن
الناس في الوقت الحالي يتعاطفون مع الروبوتات ويترد َّدون في »قتلها« أو »تعذيبها«
أخلاقيات الذكاء الاصطناعي

) ،(Suzuki et al. 2015; Darling, Nandy, and Breazeal 2015حتى إذا لم ت ُكن
مزو َّدة بالذكاء الاصطناعي .ويبدو أن البشر لا يحتاجون من الكيانات الاصطناعية سوى
القليل جدٍّا من أجل إضفاء الإنسانية أو الشخصية عليهم والتعا ُ
طف معهم .فإذا أصبحت
هذه الكيانات الآن مزود ًة بالذكاء الاصطناعي ،مما يجعلها أشبَه بالإنسان )أو بالحيوان(،
يبدو أن هذا يجعل مسألة إكساب املكانة الأخلاقية أكثر إلحاحً ا .على سبيل املثال ،ماذا
ينبغي أن يكون ر ُّد فعلنا تجاه الأشخاص الذين يتعاطفون مع الذكاء الاصطناعي؟ هل
ُهم مُخطئون؟
ربما يكون قول إن الآلات املدعومة بالذكاء الاصطناعي هي مجرد آلات وإن الأشخاص
ٍ
ببساطة مُخطئون في تقديرهم للأمور وفي عواطفهم وتجربتِهم
الذين يتعاطفون معها
الأخلاقية هو الأقرب إلى البديهة .إذ يبدو لنا ،عند النظرة الأولى ،أننا لا ندين بشيءٍ
ً
أشخاصا .ويُفكر الكثري من الباحِ ثني في مجال الذكاء
إلى الآلات .فهي أشياء ،وليست
الاصطناعي بهذا املنطق .على سبيل املثال ،ترى جوانا برايسون أن الروبوتات هي أدوات
ٍ
التزامات تجاهها ) .(Bryson 2010قد يتفق الذين يتبن َّون
ومُمتلكات وأنه ليس لدَينا أي
هذا املوقف بشد َّة على أنه إذا كان لدى الآلات املدعومة بالذكاء الاصطناعي ُ
القدرة على
ً
مكانة أخلاقية.
الوعي ،ولدَيها حالات عقلية ،وما إلى ذلك ،فإننا مُطالبون بأن نمنحها
 َّ
يتحقق اليوم .وكما رأينا في الفصول السابقة ،قد
ولكنهم سيقولون إن هذا الشرط لا
ُ
 َّ
يتحقق أبدًا؛ ويقول َ
تحقيقه من حيث املبدأ ،ولكن
آخرون إنه يمكن
يقول البعض إنه لن
ُ
ُ
 ِّ
هذا لن يحدث في املستقبل القريب .ولكن النتيجة املترتبة على السؤال املتعلق باملكانة
الأخلاقية هي أنه في الوقت الحالي وفي املستقبل القريب ،يُفترَض أن نتعامَ ل مع الآلات
املدعومة بالذكاء الاصطناعي كأشياء ،إلا إذا ثبت خلاف ذلك.
تواجهنا عند اتخاذ هذا املوقف ،وهي أنه
على الرغم من ذلك ،فثم َّ ة مشكلة واحدة
ِ
لا يفسر ولا يُبرر إحساسنا البديهي الأخلاقي ولا تجاربنا الأخلاقية التي تُخبرنا بأن ثم َّ ة
شيئًا خاطئًا في »إساءة معاملة« الذكاء الاصطناعي ،حتى إذا لم ت ُكن لدَيه خصائص
شبيهة بالبشر أو الحيوانات مثل الوعي أو الإحساس .للعثور على مثل هذه التبريرات،
يُمكن للمرء اللجوء إلى كانط ،الذي اعتبر أنه من الخطأ إطلاق النار على كلب؛ ليس لأن
ٍ
التزامات تجاه هذا الكلب ،ولكن لأن مثل هذا الشخص
كلب ينتهك أي
إطلاق النار على ٍ
»يضر ُّ بصفات الرحمة والإنسانية في نفسه ،والتي يجب أن يُمارسها بناءً على واجباته
ٍ
بطريقة مختلفة تجاه
تجاه البشر« ) .(Kant 1997أما اليوم فنحن نميل إلى التفكري
أهي ٍّ
حقا مجرد آلات؟

الكلاب )على الرغم من أن هذا ليس حال الجميع وليس الحال في كل مكان( .ولكن
يبدو أنه يُمكن تطبيق الحج َّ ة نفسها على الآلات املدعومة بالذكاء الاصطناعي :يُمكننا أن
نقول إننا لا ندين بشيءٍ إلى الآلات املدعومة بالذكاء الاصطناعي ،ولكن َّنا مع ذلك ينبغي
لنا عدم ر ْكل أو »تعذيب« آلة مزو َّدة بالذكاء الاصطناعي؛ لأن ذلك يجعلنا غري رحماء
أيضا استخدام حج َّ ِة أخلاقيات الفضيلة ،وهي حُ ج َّ ة غري مباشرة ً
تجاه البشر .يُمكن ً
أيضا
َ
بالبشر وليس بالذكاء الاصطناعي» :إساءة معاملة« الذكاء الاصطناعي خطأ
لأنها تتع َّلق
ليس لأن ثم َّ ة ضر ًرا سيلحق بالذكاء الاصطناعي ،ولكن لأن طابعنا الأخلاقي سيتأذ َّى إذا
ً
أشخاصا أفضل .وعلى النقيض من هذا النهج يُمكننا أن
ما فعلنا ذلك .وهذا لا يجعلنا
ٍ
بقيمة جوهرية
نقول إنه في ا ُملستقبل قد تتمت َّع بعض الآلات املزو َّدة بالذكاء الاصطناعي
 ُّ
وتستحق اهتمامنا الأخلاقي ،بشرط أن تكون لدَيها خصائص مثل الإحساس .ولا يبدو
َ
»الآخر« من العلاقة الأخلاقية
أن النهج غري املباشر للواجب أو الفضيلة يأخذ هذا الجانب
على محمل الجد .فهو يُعنى فقط بالبشر .فماذا عن الآلات املزو َّدة بالذكاء الاصطناعي؟
ولكن هل يُمكن للآلات املزو َّدة بالذكاء الاصطناعي أو الروبوتات أن تكون هي »الآخر«
كما سأل ديفيد جنكل )(٢٠١٨؟ مرة أخرى ،يبدو أن املنطق يقول :لا ،الآلات املزو َّدة
بالذكاء الاصطناعي ليست لدَيها الخصائص املطلوبة.
»إساءة معاملة« الذكاء الاصطناعي خطأ؛ ليس لأن ثمة ضر ًرا سيلحق بالذكاء الاصطناعي ،ولكن
لأن طابعنا الأخلاقي سيتأذ َّى إذا ما فعلنا ذلك.

ثمة نهج مختلف تمامً ا يرى أن طريقة تعامُلنا مع مسألة املكانة الأخلاقية هي
نفسها تنطوي على إشكالية .يعتمد التفكري الأخلاقي الشائع بشأن املكانة الأخلاقية على ما
تملِكه الكيانات من خصائص ذات ٍ
صلة بالأخلاق؛ على سبيل املثال ،الوعي أو الإحساس.
ولكن كيف نع َلم ما إذا كان لدى الذكاء الاصطناعي ً
ٍ
صلة
فعلا خصائص مُعينة ذات
بالأخلاق أم لا؟ وهل نحن متأ ِّكدون من ذلك في حالة البشر؟ يقول ا ُملتش ِّككون إننا لسنا
ً
مكانة
متأ ِّكدين .ومع ذلك ،حتى دون هذا اليقني ا َملعرفي ،فإننا لا نزال نُضفي على الإنسان
أخلاقية على أساس املظهر .ومن ا ُملرج َّ ح أن يحدُث الشيء نفسه إذا ُقد ِّر للآلات املزو َّدة
بمظهر وسلوك شبيهَ ني بالبشر في املستقبل .يبدو أنه ِّ
بغض
بالذكاء الاصطناعي أن تتمت َّع
ٍ
أخلاقيات الذكاء الاصطناعي

النظر عم َّ ا يعتبره الفلاسفة من الصواب أخلاقيٍّا ،سيُضفي البشر ،بأية حال ،على هذه
ً
حقوقا ،على سبيل املثال .علاوة على ذلك ،إذا نظرنا عن
الآلات مكانة أخلاقية ،ويمنحونها
َ
ِ
املكانة الأخلاقية »في الواقع« ،فإنه يت َّضح على
الطريقة ا َّلتي يُضفي بها البشر
كثَب إلى
سبيل املثال أن ٍّ
كلا من العلاقات الاجتماعية القائمة وال ُّلغة تلعب دو ًرا .على سبيل املثال،
ري أخلاقي بشأن قِ َّ
إذا عامَ ْلنا ق َّ
طتنا ،ولكن لأن
طتنا بلُطف ،فهذا ليس لأننا
ننخرط في تفك ٍ
ِ
لدَينا بالفعل نوعً ا من العلاقة الاجتماعية معها .إنها بالفعل حيوا ٌن أليف ومُرافق لنا قبل
أن نقوم بالعمل الفلسفي الذي ن ُ ِ
كسبها بموج ِبه مكانة أخلاقية؛ هذا إذا شعرنا من الأساس
ٍ
ٍّ
خاصا على كلبنا ،فإننا — على عكس
بحاجة إلى مثل هذه املمارسة .وإذا أطلقنا اسمً ا
ً
الحيوانات التي لا ِ
 َّ
خاصة،
مكانة أخلاقية
تحمل اسمً ا التي نأ ُكلها — قد منحناه بالفعل
بصرْف النظر عن خصائصه املوضوعية .باستخدام مثل هذا النهج العلاقاتي والنقدي
وغري ا ُملتزم ِّ ت ) ،(Coeckelbergh 2012يُمكننا القول إن البشر سوف يمنحون الآلات
ً
مكانة أخلاقية بناءً على كيفية تضمينها في حياتنا الاجتماعية
املزو َّدة بالذكاء الاصطناعي
وفي لُغتنا وفي ثقافتنا البشرية.
علاو ًة على ذلك ،نظ ًرا إلى أن مثل هذه الظروف مُتغرية تاريخيٍّا — فكر مرة أخرى
في كيفية مُعاملتنا وتفكرينا بشأن الحيوانات — ربما تكون هناك حاجة إلى اتخاذ سبُل
بشكل عام أو لآلة
الحيطة الأخلاقية قبل »تحديد« املكانة الأخلاقية للذكاء الاصطناعي
ٍ
بشكل عام
مُعي َّنة مزو َّدة بالذكاء الاصطناعي .وملاذا حتى نتحد َّث عن الذكاء الاصطناعي
ٍ
بشكل مجرد؟ يبدو أن هناك شيئًا خاطئًا في الإجراء الأخلاقي ملنح املكانة الأخلاقية:
أو
ٍ
كيان ما ،نُخرج هذا الكيان من سياق علاقاته ،وقبل أن نحصل على
فمن أجل الحُ كم على ٍ
ٍ
ككيان نتخذ
بطريقة رتبوية ،سلطوية ،مُهيمنة،
نتيجة إجرائنا الأخلاقي ،نتعامَ ل معه
ٍ
نحن البشر ا ُملتفو ِّقني قرا ًرا بشأنه .ويبدو أننا قبل حتى أن نفكر في مكانته الأخلاقية ،قد
منزلة مُعي َّنة وربما ً
ٍ
ككائن نت َّخذ
أيضا ما َر ْسنا عليه العنف بمعاملته
وضعناه بالفعل في
ٍ
ونصبنا أنفسنا ً
آلهة محورية قوية عاملة على الأرض ُّ
قرارات بشأنه ، َّ
يحق لها منح املكانة
ً
ِ
للكائنات الأخرى .لقد جعلنا أيضا جميع السياقات وامللابسات الاجتماعية غري
الأخلاقية
مَ رئية .كما في حالة مُعضلة عربة الترام ،لقد اختزلنا الأخلاق في صورة كاريكاتريية.
ُ
الفلاسفة املؤيدون
باستخدام مثل هذا التفكري ،يبدو أن فلاسفة الأخلاق يفعلون ما ات ُّ ِهم
لدريفوس الباحثني في مجال الذكاء الاصطناعي الرمزي ب ِفعله :تشكيل وتجريد ثروة من
 ِّ
التخلي عما يجعلنا بشرًا ،وليس ذلك
التجربة الأخلاقية واملعرفة الأخلاقية على حساب
أهي ٍّ
حقا مجرد آلات؟

فحسب ،بل وعلى حساب التضحية بمسألة املكانة الأخلاقية لغري البشر .وبصرف النظر
عن املكانة الأخلاقية الفعلية للآلات املزو َّدة بالذكاء الاصطناعي ،كما لو كان هذا يمكن
بمكان أن نفحص توج ُّ هنا
بشكل مُستقل تمامً ا عن ذاتية الإنسان ،فمن الأهمية
تحديده
ٍ
ٍ
الأخلاقي ومشروع التفكري الأخلاقي املجرد نفسه ،بأسلوب نقدي.
»إساءة معاملة« الذكاء الاصطناعي خطأ؛ ليس لأن ثمة ضر ًرا سيلحق بالذكاء الاصطناعي ،ولكن
لأن طابعنا الأخلاقي سيتأذ َّى إذا ما فعلنا ذلك.

نحو قضايا أخلاقية أكثر عملية
كما تُظهر املناقشات في هذا الفصل والفصل السابق ،فإن التفكري في الذكاء الاصطناعي
يُع ِّلمنا أشياء أخرى إلى جانب ما نتع َّلمه بشأن الذكاء الاصطناعي .إنه يُعلمنا ً
أيضا أشياء
عن أنفسنا :عن طريقة تفكرينا ،وطريقة تصر ُّفنا في الواقع ،والطريقة التي ينبغي أن
ِ
لأخلاقيات الذكاء الاصطناعي،
نتعامَ ل بها مع غري البشر .فإذا نظرنا إلى الأُسس الفلسفية
ً
عميقة حول طبيعة ومستقبل الإنسانية والعلم والحداثة .إن التشكيك في
نرى خلافات
الاصطناعي يكشف اللثام عن عا َلم مُظلم من الأسئلة النقدية حول املعرفة البشرية
الذكاء
 ِّ
وا ُملجتمع البشري وطبيعة الأخلاق البشرية.
هذه املناقشات الفلسفية أقل بُعدًا وأقل »أكاديمية« مما قد يعتقِ د البعض .وستظ ُّل
ً
لاحقا في هذا الكتاب ،املزي َد من املسائل الأخلاقية
تُعاود الظهور أمامنا عندما نتناول،
ً
عملية التي يُثريها الذكاء الاصطناعي .وسرعان ما ستُواجهنا
والقانونية والسياسية الأكثر
ٍ
موضوعات مثل املسئولية والسيارات ذاتية القيادة،
من جدي ٍد بمج َّرد أن نُحاول التط ُّرق إلى
أو شفافية تع ُّلم الآلة ،أو الذكاء الاصطناعي ا ُملتحيز ،أو أخلاقيات الروبوتات الجنسية .إذا
كانت أخلاقيات الذكاء الاصطناعي تُريد أن تكون أكثر ِمن مج َّرد قائمة بالقضايا ،فيجب
أن يكون لدَيها ما تقوله حول مثل هذه املسائل.
بعد ك ِّل ما قيل ،حان الوقت الآن للتحو ُّل إلى قضايا أكثر عملية .هذه القضايا لا
تتع َّلق با ُملشكلات الفلسفية التي يطرحُ ها الذكاء الاصطناعي العام ا ُملفترض ،أو باملخاطر
املت َّصلة بالذكاء الفائق في املستقبل البعيد ،أو بالوحوش املخيفة الأخرى التي يخلقها
الخيال العلمي .إنها تتعلق بحقائق الذكاء الاصطناعي القائمة بالفعل ،والتي هي أق ُّل
أخلاقيات الذكاء الاصطناعي

وضوحً ا وربما أقل جاذبية ،ولكنها لا تزال شديدة الأهمية .إن الذكاء الاصطناعي في
الوقت الحالي لا ُ
يأخذ دور وحش فرانكنشتاين أو الروبوتات ا ُملذهلة املزو َّدة بالذكاء
الاصطناعي التي تُهد ِّد الحضارة ،كما أنه أكثر من مجرد تجرب ٍة فكرية فلسفية .الذكاء
ٍ
بتقنيات سري ٍة غري مرئية ولكنها مُتغلغلة ومنتشرة وقوية ومتزايدة
الاصطناعي يتع َّلق
الذكاء ،تلك التقنيات التي تُش ِّكل بالفعل حياتنا اليوم .ومن ثَم َّ ،فإن أخلاقيات الذكاء
الاصطناعي تتع َّلق بالتحديات الأخلاقية التي يُثريها الذكاء الاصطناعي في الوقت الحالي وفي
ا ُملستقبل القريب ،كما تتعلق بتأثري هذه التحد ِّيات على مجتمعاتنا وديمقراطياتنا َّ
الهشة.
إن أخلاقيات الذكاء الاصطناعي تتع َّلق بحياة الناس وبالسياسة .إنها تتعلق بحاجتنا،
كأفرادٍ وكمجتمعات ،إلى التعامُل مع القضايا الأخلاقية الآن.
الفصل الخامس

التكنولوجيا

قبل مناقشة القضايا الأخلاقية الواقعية ا ُملتعلقة بالذكاء الاصطناعي بمزي ٍد من التفاصيل،
ٌ
مهمة أخرى علينا إنجازها لتمهيد الطريق :بعيدًا عن الضج َّ ة ا ُملثارة حول
لدَينا
الذكاء الاصطناعي ،علينا أن نفهم هذه التكنولوجيا وتطبيقاتها .فلنُنَح ِّ جانبًا الخيالَ
العلمي لتجاوز الإنسانية والتط ُّلعات الفلسفية للذكاء الاصطناعي العام ،ولن ُ ْل ِق نظر ًة على
 َّ
ماهية تكنولوجيا الذكاء الاصطناعي وكيفية استخدامها اليوم .وبما أن تعريفات الذكاء
الاصطناعي وغريها من ا ُملصط َلحات هي نفسها غري ُمت َّفق عليها ،فإنني لن أتعم َّ ق في
ٍ
نقاشات فلسفية أو سياقات تاريخية .إن هدفي الرئيسي هنا هو أن أُعطي القارئ فكر ًة
عن التكنولوجيا املعنية وكيفية استخدامها .وسوف أبدأ بالتحد ُّث عن الذكاء الاصطناعي
بشكل عام؛ أما الفصل التالي ،فسيتناول تقنيات تع ُّلم الآلة وعلم البيانات وتطبيقاتهما.
ٍ
ما هو الذكاء الاصطناعي؟
يمكن تعريف الذكاء الاصطناعي بأنه الذكاء الذي تُظهره أو تُحاكيه الرموز البرمجية
ً
سؤالا حول كيفية تعريف الذكاء .من
)الخوارزميات( أو الآلات .ويُثري هذا التعريف
ً
الناحية الفلسفية ،ي َ
غامضا .ويمكن القول بأنه ذكاءٌ شبيه بالذكاء
ُعتبر الذكاء مفهومً ا
البشري .على سبيل املثال ،يُع ِّرف فيليب جانسن وآخرون الذكاء الاصطناعي بأنه »علم
ذكية ً
ً
وفقا ملعايري الذكاء البشري« )،٢٠١٨
وهندسة الآلات ذات القدرات التي تُعتبر
ً .(٥
وفقا لهذا التعريف ،يتعلق الذكاء الاصطناعي بإنشاء آلات ذكي َّة تُفكر أو تتفاعل
مثل البشر .ومع ذلك ،يعتقد العديد من الباحثني في مجال الذكاء الاصطناعي أنه ليس
تعريفا أكثر حيادًا ِص َ
ً
يغ
داع لأن يكون الذكاء شبيهً ا بالذكاء البشري ،ويفضلون
هناك ٍ

أخلاقيات الذكاء الاصطناعي

بشكل مُستقل عن الذكاء البشري وأهداف الذكاء الاصطناعي العام أو القوي ذات الصلة.
ٍ
ويسردون جميع أنواع الوظائف املعرفية واملهام مثل التع ُّلم والإدراك والتخطيط ومُعالجة
اللغة الطبيعية والتفكري واتخاذ القرارات وح ِّل املشكلات؛ وغالبًا ما يُعادل ذلك الذكاءَ
نفسه .على سبيل املثال ،تزعم مارجريت بودين أن الذكاء الاصطناعي »يسعى إلى جعل
أجهزة الكمبيوتر تقوم بالأشياء التي يُمكن للعقول البشرية القيام بها« .يبدو الأمر في
البداية وكأن البشر هم النموذج الوحيد .إلا أنها ،تسرد بعد ذلك كل أنواع املهارات النفسية
مثل الإدراك والتنب ُّؤ والتخطيط ،التي تُشكل جزءًا من »الفضاء الغني بقدرات مُعالجة
املعلومات املتنوعة« ) .(١ ،٢٠١٦ويمكن أن تكون مُعالجة املعلومات هذه ليست حك ًرا على
الإنسان .فالذكاء العامً ،
وفقا ملارجريت بودين ،لا يكون بالضرورة بشريٍّا .فهناك بعض
بعقول مُستقبلية لا
الحيوانات التي يُمكننا اعتبارها ذكية .ويحلم مؤيدو تجاوز الإنسانية
ٍ
تكون مضمنة بيولوجيٍّا مثلما هو الحال الآن .ومع ذلك ،كان هدف تحقيق قدرات شبيهة
بقدرات البشر وربما ذكاء عام شبيه بذكاء البشر جزءًا من الذكاء الاصطناعي منذ البداية.
طا ً
يرتبط تاريخ الذكاء الاصطناعي ارتبا ً
 ُّ
والتخصصات
وثيقا بتاريخ علوم الكمبيوتر
ذات ِّ
الصلة مثل الرياضيات والفلسفة ،ومن ث َ َّم فهو يمت ُّد على الأقل إلى العصور الحديثة
الباكرة )مثل جوتفريد فيلهلم لايبنيتس ورينيه ديكارت( إن لم يكن إلى العصور القديمة،
ٍ
ٍ
ِ
وآلات ذكية يُمكنها
كائنات اصطناعية
تنتشر فيها قصص عن حرفي ِّني يصنعون
التي
ُ
خداع الناس )تذ َّكر الشخصيات املتحركة في اليونان القديمة أو الشخصيات الآلية
الشبيهة بالبشر في الصني القديمة( .ولكن على العموم يُعتبر الذكاء الاصطناعي قد بدأ
ٍّ
 ُّ
تخص ً
مستقلا ،بعد اختراع الكمبيوتر
صا
في الخمسينيات من القرن العشرين بوصفه
 ُّ
تخصص علم التح ُّكم الآلي
الرقمي القابل للبرمجة في أربعيني َّات القرن العشرين وولادة
)السيبرانية( ،الذي ع َّرفه نوربرت وينر في عام ١٩٤٨على أنه الدراسة العلمية »للتح ُّكم
ُ
والتواصل في الحيوان والآلة« ) .(Wiener 1948وكان نشر ورقة ألان تورينج البحثية
لعام ١٩٥٠بعنوان »الآلات الحاسبة والذكاء« في مجلة »مايند« ،والتي قدمت اختبار
بشكل عام سؤال ما إذا كانت الآلات قادر ًة على
تورينج الشهري ولكن كانت تتناول
ٍ
التفكري ،وسبقت بالفعل في التكه ُّ ن بالآلات التي يُمكنها التع ُّلم وأداء مهام مج َّردة ،كانت
لحظة هامة في تاريخ الذكاء الاصطناعي .ومع ذلك ،تُعتبر ورشة العمل التي عُ قدت في
بشكل عام هي محل
جامعة دارتموث في صيف عام ١٩٥٦في هانوفر ،نيو هامبشاير،
ٍ
ميلاد الذكاء الاصطناعي ا ُملعاصر .وقد صاغ مُنظمها جون مكارثي فيها مصطلح الذكاء
التكنولوجيا

الاصطناعي ،وشاركت فيها أسماءٌ مهمة مثل مارفن مينسكي ،وكلود شانون ،وألن نيويل،
وهريبرت سايمون .وفي حني كان يُنظر إلى علم التح ُّكم الآلي على أنه شديد الانشغال
بالآلات التناظرية ،اهتم َّ ت ورشة عمل الذكاء الاصطناعي في دارتموث بالآلات الرقمية.
كانت الفكرة هي »محاكاة« الذكاء البشري )وليس إعادة خلقِ ه :فالعملية مختلفة عما
 َّ
وظن الكثري من املشاركني في ورشة العمل هذه أن إنشاء ٍ
آلة تتمت َّع بنفس
يحدث في البشر(.
جيل واحد.
ذكاء البشر أمر وشيك الحدوث :توقعوا أنها لن تستغرق في ظهورها أكثر من ٍ
هذا هو هدف »الذكاء الاصطناعي القوي« .الذكاء الاصطناعي »القوي« أو »العام«
قادر على أداء أي مهام معرفية يمكن للبشر أداؤها ،في حني أن الذكاء الاصطناعي
ٍ
مجالات مُحددة مثل الشطرنج،
»الضعيف« أو »املحدود« يمكن أن يؤدي فقط في
وتصنيف الصور ،وما إلى ذلك .حتى اليوم ،لم ن ُ ِّ
حقق الذكاء الاصطناعي العام ،وكما رأينا
في الفصول السابقة ،فإن الشكوك تحُ وم حول ما إذا كن َّا سن ُ ِّ
حققه على الإطلاق .وعلى
الرغم من أن بعض الباحثني والشركات يُحاولون تطوير الذكاء الاصطناعي العام ،ولا
سيما هؤلاء الذين يؤمِنون بنظرية حاسوبية العقل ،فإنه لن يتم تطويره في ا ُملستقبل
القريب .ولذا ،تُركز الأسئلة الأخلاقية والسياسية في الفصل التالي على الذكاء الاصطناعي
الضعيف أو املحدود ،املوجود بالفعل حاليٍّا والذي من ا ُملرج َّ ح أن يُصبح أكثر قو ًة وانتشا ًرا
في املستقبل القريب.
يمكن تعريف الذكاء الاصطناعي باعتباره علمً ا وكذلك باعتباره تكنولوجيا .يمكن
أن يكون الهدف من الذكاء الاصطناعي هو تفسري الذكاء والوظائف املعرفية املذكورة
تفسريًا علميٍّا أدق .ويُمكن أن يُساعدنا في فهم البشر وغريهم من الكائنات التي تمتلك ذكاءً
 ُّ
وتخص ً
صا يدرس
طبيعيٍّا فهمً ا أفضل .وبهذه الطريقة ،يكون الذكاء الاصطناعي علمً ا
بشكل منهجي ) ،(Jansen et al. 2018وأحيانًا يدرس العقل أو الدماغ.
ظاهرة الذكاء
ٍ
ومن هذا املنطلق ،يرتبط الذكاء الاصطناعي بعلو ٍم أخرى مثل العلوم املعرفية وعلم النفس
وعلم البيانات )انظر القسم اللاحق( ،وأحيانًا ً
أيضا عِ لم الأعصاب ،الذي يسعى حثيثًا إلى
َفهم الذكاء الطبيعي .ولكن قد يكون الهدف من الذكاء الاصطناعي ً
أيضا هو تطوير
ٍ
لأغراض عملية مُختلفة ،أو كما يقول بودن »لإنجاز أشياء مُفيدة« :يمكن أن يأخذ
تقنيات
ٍ
لأغراض عملية .ويمكن
شك َل أدوات ،صم َّ مها البشر ،وتخلق مظهر الذكاء والسلوك الذكي
ٍ
للآلات املدعومة بالذكاء الاصطناعي أن تفعل ذلك عن طريق تحليل البيئة )في صورة
ٍ
بدرجة كبرية من الاستقلالية .في بعض الأحيان ،تلتقي الاهتمامات
بيانات( والتصر ُّف
أخلاقيات الذكاء الاصطناعي

العلمية-النظرية والأغراض التكنولوجية ،على سبيل املثال في عِ لم الأعصاب الحوسبي،
ٍ
ٍ
مشروعات مُحددة
أدوات من علوم الكمبيوتر لفهم الجهاز العصبي ،أو في
الذي يستخدِم
ً
وأيضا الروبوتات
مثل »مشروع الدماغ البشري« الأوروبي ،الذي يشمل العلوم العصبية
والذكاء الاصطناعي؛ وتجمع بعض مشروعاته ما بني عِ لم الأعصاب وتع ُّلم الآلة فيما يُع َرف
بعلم أعصاب البيانات الضخمة )مثل فو وآخرين .(٢٠١٨
 ُّ
التخصصات ويرتبط بها ،بما
بشكل أعم ،يعتمد الذكاء الاصطناعي على العديد من
ٍ
في ذلك الرياضيات )على سبيل املثال ،الإحصاء( ،والهندسة ،واللغويات ،والعلوم املعرفية،
وعلوم الكمبيوتر ،وعلم النفس ،وحتى الفلسفة .وكما رأينا ،يهتم الفلاسفة والباحثون في
مجال الذكاء الاصطناعي على ح ٍّد سواء بفهم العقل وظواهر مثل الذكاء والوعي والإدراك
والفعل والإبداع .وقد أث َّر الذكاء الاصطناعي على الفلسفة والعكس صحيح .وقد أق َّر كيث
فرانكيش وويليام رامزي بهذا الارتباط بني الذكاء الاصطناعي والفلسفة ،وشد َّدا على
 ُّ
تخصصات الذكاء الاصطناعي ،وجمعا الجانبَني العلمي والتكنولوجي في تعريفهما
تعد ُّد
 ُّ
التخصصات لفهم ونمذجة ومُحاكاة الذكاء
للذكاء الاصطناعي باعتباره »نهجً ا مُتعد ِّد
والعمليات املعرفية عن طريق الاستناد إلى مبادئ وأجهزة حوس ِبي َّة ورياضية ومنطقية
وميكانيكية وحتى بيولوجية متنوعة« ) .(١ ،٢٠١٤لذلك ،يعتبر الذكاء الاصطناعي نظريٍّا
وعمليٍّا ،علمً ا وتكنولوجيا .ويركز هذا الكتاب على الذكاء الاصطناعي باعتباره تكنولوجيا،
على الجانب الأكثر عملية :ليس فقط لأن التركيز داخل الذكاء الاصطناعي قد تحو َّل في
هذا الاتجاه ،ولكن ،على وجه الخصوص ،لأن الذكاء الاصطناعي في هذه الصورة له عواقب
أخلاقية واجتماعية؛ على الرغم من أن البحث العلمي ً
أيضا ليس خاليًا تمامً ا من العواقب
الأخلاقية.
ً
ً
باعتباره تكنولوجيا ،يُمكن للذكاء الاصطناعي أن يأخذ أشكالا مختلفة وعادة ما
يكون جزءًا من نُظم تكنولوجية أكبر :الخوارزميات ،والآلات ،والروبوتات ،وما إلى ذلك.
لذلك ،في حني قد يتع َّلق الذكاء الاصطناعي ب »الآلات« ،فإن هذا املصطلح لا يُشري إلى
ً
شكلا بشريٍّا .يُمكن أن يُضم َّ ن الذكاء
الروبوتات وحدَها ،ناهيك عن الروبوتات التي تت َّخِ ذ
الاصطناعي في العديد من أنواع الأنظمة والأجهزة التكنولوجية الأخرى .ويمكن لأنظمة
الذكاء الاصطناعي أن ُ
برنامج يعمل على الويب )مثل الدردشة الآلية ومُحركات
تأخذ شك َل
ٍ
البحث وتحليل الصور( ،ولكن يُمكن أن يُضم َّ ن ً
أيضا الذكاء الاصطناعي في الأجهزة
امللموسة مثل الروبوتات أو السيارات أو تطبيقات »إنترنت الأشياء« .بالنسبة إلى إنترنت
التكنولوجيا

الأشياء ،يُستخدَم أحيانًا مصطلح »الأنظمة الإلكترونية-املادية« ،وهي عبارة عن أجهزة
تعمل في العا َلم املادي وتتفاعل معه .وتُعَ د الروبوتات نوعً ا من الأنظمة الإلكترونية-املادية،
التي تؤث ِّر تأثريًا مباشرًا على العالم ).(Lin, Abney, and Bekey 2011
إذا ت َّم تضمني الذكاء الاصطناعي في روبوت ،فإنه يُطلق عليه أحيانًا الذكاء
 ِّ
»املتجسد« .وتعتمد الروبوتات في تأثريها على العا َلم املادي تأثريًا مباشرًا
الاصطناعي
على مكو ِّنات مادية .ولكن كل نظام ذكاءٍ اصطناعي ،بما في ذلك البرامج النشطة على
الويب» ،يفعل« شيئًا ولدَيه ً
أيضا مكو ِّنات مادية مثل الكمبيوتر الذي يعمل عليه ،وا ُملكونات
املادية للشبكة وال ِبنية الأساسية التي ِ
يعتمد عليها ،وما إلى ذلك .وهذا يجعل التفرقة ما بني
تطبيقات الويب »الافتراضية« والتطبيقات »البرمجية« من ناحية ،والتطبيقات املادية أو
ً
مسألة صعبة وم ِّ
ُحرية .إن برامج الذكاء الاصطناعي
تطبيقات »الأجهزة« من ناحي ٍة أخرى
تحتاج إلى مكو ِّنات مادية و ِبنية أساسية مادية لكي تعمل ،والأنظمة الإلكترونية-املادية لا
يمكن اعتبارها ذكاءً اصطناعيٍّا إلا إذا تم توصيلها بالبرامج املناسبة .علاو ًة على ذلك ،من
وجهة نظر الظاهرية ،قد تندمج املكونات املادية والبرمجية أحيانًا في تجربتنا واستخدامنا
ً
شكلا بشريٍّا ويعمل بواسطة
للأجهزة :فنحن لا نشعر بأن الروبوت التفاعُ لي الذي يأخذ
الذكاء الاصطناعي ،أو أن جهاز املحادثة بالذكاء الاصطناعي مثل أليكسا ،عبارة عن
مكونات برمجية أو مكونات مادية ،ولكننا نشعر أنهما جهاز تكنولوجي واحد )وأحيانًا
نشعر أنهما ِشبه أشخاص ،مثل دُمية »هالو باربي«(.
من ا ُملرج َّ ح أن يكون للذكاء الاصطناعي تأثري كبري على علم الروبوتات ،وذلك على
ُ
والتواصل الشبيه بتواصل الإنسان.
سبيل املثال من خلال التقد ُّم في معالجة اللغة الطبيعية
ري من الأحيان يُط َلق على هذه الروبوتات اسم »الروبوتات الاجتماعية«؛ لأنها مُصم َّ مة
في كث ٍ
كرفاق أو مساعِ دين،
بهدف املشاركة في الحياة الاجتماعية اليومية للبشر ،على سبيل املثال،
ٍ
ٍ
بطريقة طبيعية .ومن ثَم َّ ،يمكن أن يُعزز الذكاء الاصطناعي
من خلال التفاعُ ل مع البشر
مزيدًا من التطورات في الروبوتات الاجتماعية.
ومع ذلك ،بغض النظر عن املظهر والسلوك الكلي للنظام وتأثريه على البيئة ا ُملحيطة
به ،وهو ما يُعتبر مهمٍّ ا جدٍّا من الناحية الظاهرية والأخلاقية ،فإن أساس »الذكاء« في
الذكاء الاصطناعي هو برنامج» :خوارزمية« أو مجموعة من الخوارزميات .والخوارزمية
ُ
وتسلسل من التعليمات ،مثل الوصفة ،تُخبر الكمبيوتر أو الهاتف الذكي أو
هي مجموعة
الآلة أو الروبوت أو أي شيءٍ َ
آخر يتم تضمينها فيه بما يجب أن يفعل .وهي تؤدي إلى
أخلاقيات الذكاء الاصطناعي

ٍ
مشكلة
مُخرجات مُعي َّنة بناءً على املعلومات املتاحة )املدخلات( .وتُطب َّق الخوارزمية لح ِّل
ما .ولكي نفهم أخلاقيات الذكاء الاصطناعي ،علينا ً
أولا أن نفهم كيفية عمل خوارزميات
الذكاء الاصطناعي وما تقوم به .وسوف أتحد َّث أكثر عن هذا املوضوع هنا وفي الفصل
القادم.
املناهج واملجالات الفرعية ا ُملختلفة
هناك أنواع مختلفة من الذكاء الاصطناعي .يمكن القول ً
أيضا إن هناك مناهج أو نماذج
ٍ
بحث مختلفة .كما رأينا في انتقاد دريفوس ،غالبًا ما كان الذكاء الاصطناعي على مدار
التاريخ ذكاءً اصطناعيٍّا رمزيٍّا .وكان هذا هو النموذج السائد حتى أواخر الثمانينيات.
ِ
ويعتمد الذكاء الاصطناعي الرمزي على التمثيلات الرمزية للمها ِّم املعرفية العالية ا ُملستوى
مثل التفكري التجريدي واتخاذ القرارات .على سبيل املثال ،قد يت َّخِ ذ قرا ًرا استنادًا إلى
نموذج للقرارات وعواقِ بها ا ُملمكنة ،ويُمث َّل
الهيكل الشجري لاتخاذ القرار؛ وهو عبارة عن
ٍ
بشكل رسومي يُشبه ا ُملخطط الانسيابي .وتحتوي الخوارزمية التي تفعل ذلك على
غالبًا
ٍ
ٍ
عبارات شرطية :قواعد لاتخاذ القرار على صورة ... ،if ... thenبحيث يلي ifالشرط ويلي
ٍ
بيانات تُمث ِّل
 thenالنتيجة .وهذه العملية حاسمة وغري عشوائية .وبالاستناد إلى قاعدة
املعرفة الخبرية البشرية ،يُمكن ملِ ثل هذا الذكاء الاصطناعي اتخاذ القرار ،مُعتمدًا على ك ٍّم
ٍ
قرارات حكيمة أو يصل
هائل من املعلومات ،والتصر ُّف كنظا ٍم خبري .ويستطيع أن يت َّخذ
إلى توصيات استنادًا إلى ٍ
كتلة ضخمة من املعرفة ،قد يكون من الصعب أو من ا ُملستحيل
بالنسبة إلى البشر الاطلاع عليها .على سبيل املثال ،تُستخدَم هذه الأنظمة الخبرية في القطاع
ِ
خطة العلاج .وقد ظ َّلت هذه الأنظمة هي الأنجح في مجال
الطب ِّي لتشخيص املرض ووضع
الذكاء الاصطناعي لفتر ٍة طويلة.
ولا يزال الذكاء الاصطناعي الرمزي مُفيدًا حتى اليوم ،ولكن ظهرت ً
أيضا أنواع
جديدة من الذكاء الاصطناعي ،يُمكن دمجها أو عدم دمجها مع الذكاء الاصطناعي
الرمزي ،وهي قادرة على التع ُّلم ذاتيٍّا من البيانات ،على عكس الأنظمة الخبرية .ويتم
نهج مختلف تمامً ا .ويعتمد نموذج البحث »التشابُكي« ،الذي تم
ذلك من خلال استخدام ٍ
كبديل ملا أُطلِق عليه اسم »الذكاء الاصطناعي
تطويره في الثمانينيات من القرن العشرين
ٍ
القديم« ويعرف اختصا ًرا ب ،GOFAIوتكنولوجيا »الشبكات العصبية« على فكرة أننا ً
بدلا
التكنولوجيا

ٍ
وحدات
من تمثيل الوظائف املعرفية العُ ليا ،يجب علينا بناء شبكات مُترابطة بالاستناد إلى
بسيطة .ويدعي مؤيدو هذا النهج أن هذا يُشبه الطريقة التي يعمل بها الدماغ البشري؛
ِ
وحدات املعالجة البسيطة ا ُملسم َّ اة »الخلايا العصبية«
إذ ينشأ الإدراك من تفاعُ لات بني
)ومع ذلك ،فهي لا تُشبه الخلايا العصبية البيولوجية( .ويُستخدَم العديد من الخلايا
العصبية ا ُملترا ِبطة .يُستخدَم هذا النهج وهذه التكنولوجيا كثريًا في »تع ُّلم الآلة« )انظر
الفصل التالي( ،والذي يُطلق عليه بعد ذلك »التع ُّلم العميق« إذا كانت الشبكات العصبية
طبقات من الخلايا العصبية .وتُ َ
ٍ
عتبر بعض الأنظمة هجينة؛ على سبيل
تتكو َّن من عدة
املثال ،ي َ
ُعتبر »ألفا جو« الذي ط َّو َرته شركة »ديب مايند« نظامً ا هجينًا .وقد أد َّى التع ُّلم
العميق إلى حدوث تطو ُّر في مجالات مثل رؤية الآلة ومُعالجة اللغة الطبيعية .ويمكن أن
يكون تع ُّلم الآلة الذي يَستخدِم شبكة مُحايدة بمنزلة »صندوق أسود«؛ بمعنى أنه في حني
أن ا ُملبرمِجني يعرفون تصميم الشبكة ،فإنه ليس واضحً ا للآخرين ماذا يحدث بالضبط
في طبقاتها الوسيطة )بني املدخلات واملخرجات( وبالتالي كيف تت َّخِ ذ قرا ًرا .وهذا عكس
ً
وقابلا للتفسري ،ومن ثَم
ما يحدُث في الهيكل الشجري لاتخاذ القرار ،الذي يكون واضحً ا
ُ
فحصه وتقييمه من قِ بل البشر.
يمكن
ثم َّ ة نموذج مُهم َ
آخر في مجال الذكاء الاصطناعي وهو ذلك الذي يَستخدِم مناهج أكثر
ً
تجسيدية وأكثر اعتمادًا على املواقف ،مرك ًزا على التفاعُ ل واملهام الحركية ً
بدلا مما نُطلق
عليه املهام املعرفية العُ ليا .والروبوتات التي صنعها باحثون في مجال الذكاء الاصطناعي
ٍ
تمثيلات رمزية ولكن
مثل رودني بروكس من »إم آي تي« لا تح ُّل املشكلات باستخدام
عن طريق التفاعُ ل مع البيئة ا ُملحيطة .على سبيل املثالُ ،
صم ِّ َم الروبوت »كوج« الشبيه
بالبشر ،الذي ت َّم تطويره في التسعينيات من القرن العشرين ،بحيث يتع َّلم من خلال
التفاعل مع العالم ،كما يفعل الأطفال .وعلاو ًة على ذلك ،يعتقد بعض الأشخاص أن العقل
يمكن أن ينشأ فقط من الحياة؛ وبالتالي ،لإنشاء الذكاء الاصطناعي ،يجب أن نُحاول
إنشاء حيا ٍة اصطناعية .ويتبع بعض املهندسني نهجً ا أق َّل ِميتافيزيقية وأكثر عملية؛ إذ
تطبيقات تكنولوجية عملية .وهناك ً
ٍ
أيضا آلات تطو ُّرية
يأخذون الأحياء نموذجً ا لتطوير
مزودة بالذكاء الاصطناعي تستطيع أن تتطو َّر .ويمكن لبعض البرامج ،باستخدام ما
يُسم َّ ى بخوارزميات الوراثة ،تغيري نفسها.
هذا التن ُّوع في مناهج الذكاء الاصطناعي ووظائفه يشري إلى أن الذكاء الاصطناعي
اليوم له العديد من املجالات الفرعية :تع ُّلم الآلة ،ورؤية الكمبيوتر ،ومعالجة اللغة
أخلاقيات الذكاء الاصطناعي

الطبيعية ،والأنظمة الخبرية ،والحوسبة التطو ُّرية ،وهل َّم ج ٍّرا .وغالبًا ما يكون التركيز
مجال واحد من مجالات الذكاء الاصطناعي،
اليوم على تع ُّلم الآلة ،ولكن هذا ليس سوى
ٍ
حتى وإن كانت هذه املجالات الأخرى م ً
ُتصلة غالبًا بتع ُّلم الآلة .وقد تم تحقيق تطورات
هائلة مؤخ ًرا في رؤية الكمبيوتر ومعالجة اللغة الطبيعية وتحليل البيانات الضخمة عن
طريق تع ُّلم الآلة .على سبيل املثال ،يمكن استخدام تع ُّلم الآلة ملعالجة اللغة الطبيعية
استنادًا إلى تحليل الكلام واملصادر املكتوبة مثل النصوص املوجودة على الإنترنت .وقد
أثمر هذا العمل عن إنشاء أجهزة املحادثة الحديثة .مثال َ
آخر هو التع ُّرف على الوجوه
استنادًا إلى رؤية الكمبيوتر والتع ُّلم العميق ،ويمكن استخدامه ،على سبيل املثال ،في مجال
املراقبة.
التطبيقات والتأثري
ٍ
مجالات مختلفة )لها تطبيقات متنوعة(،
يمكن تطبيق تكنولوجيا الذكاء الاصطناعي في
تتراوح ما بني التصنيع والزراعة والنقل ،والرعاية الصحية والتمويل والتسويق والجنس
ُ
التواصل الاجتماعي .في مجال البيع بالتجزئة والتسويق،
والترفيه والتعليم ووسائل
ٍ
إعلانات مستهدفة .أما في
تُستخدَم أنظمة التوصية للتأثري في قرارات الشراء ولتقديم
َ
ُ
يشغل الذكاء الاصطناعي الروبوتات :وهي
التواصل الاجتماعي ،يمكن أن
مجال وسائل
ِ
ٌ
أشخاص حقيقيون ولكنها في الواقع
حسابات مُستخدمني تظهر على أنها
عبارة عن
ً
برامج .ويُمكن ملِ ثل هذه الروبوتات أن تنشر محتوًى سياسيٍّا أو تُجري دردشة مع
مُستخدِمني من البشر .وفي مجال الرعاية الصحية ،يُستخدَم الذكاء الاصطناعي لتحليل
بيانات من ملايني املرضى .وما زالت الأنظمة الخبرية تُستخدَم ً
ٍ
أيضا في هذا املجال.
ٍ
مجموعات ضخمة من البيانات
في مجال التمويل ،يُستخدَم الذكاء الاصطناعي لتحليل
لتحليل السوق وأتْمَ تَ ِة التعامُلات املالية .وغالبًا ما يتم تضمني نوع من الذكاء الاصطناعي
ً
مرافقا للإنسان .والطيار الآلي والسيارات ذاتية القيادة
في الروبوتات ا ُملصم َّ مة لتكون
تستخدم الذكاء الاصطناعي .ويمكن لأصحاب العمل استخدام الذكاء الاصطناعي ملراقبة
ٍ
شخصيات مدعومة بالذكاء الاصطناعي.
املوظفني .كما أن ألعاب الفيديو تحتوي على
ُ
وتستطيع الآلات املزو َّدة بالذكاء الاصطناعي تأليف املوسيقى أو كتابة مقالات الأخبار.
كما تستطيع تقلي َد أصوات الأشخاص وحتى إنشاء مقاطع فيديو مُزيفة لخطابات.
التكنولوجيا

نظ ًرا إلى تنو ُّع تطبيقات الذكاء الاصطناعي ،من ا ُملرج َّ ح أن يكون له تأثري واسع
النطاق ،سواء اليوم أو في ا ُملستقبل القريب .فإذا ف َّك ْرنا ً
مثلا في الشرطة التنب ُّؤية وإمكانية
التع ُّرف على الكلام ،اللذَين يخلقان إمكانيات جديدة للأمان واملراقبة ،ووسائل النقل بني
مدن بأكملها ،والتداول
الأفراد والسيارات ذاتية القيادة التي يُمكن أن تُحدِث تحو ً ُّلا في ٍ
الخوارزمي العالي الترد ُّد الذي يُش ِّكل بالفعل الأسواق املالية ،أو التطبيقات التشخيصية
في القطاع الطبي التي تؤثر في اتخاذ القرارات السليمة .يجب ً
أيضا ألا ننسى العلوم
كأحد املجالات الرئيسية التي تأث َّ َرت إلى ح ٍّد كبري بالذكاء الاصطناعي :عن طريق تحليل
ٍ
مجموعات ضخمة من البيانات ،يمكن للذكاء الاصطناعي مساعدة العلماء في اكتشاف
ارتباطات لم يكونوا ليُدركوها لولاه .وهذا ينطبق على العلوم الطبيعية مثل الفيزياء ،ولكن
ً
أيضا على العلوم الاجتماعية والعلوم الإنسانية .ومن ا ُملؤ َّكد أن يؤثر الذكاء الاصطناعي في
مجال العلوم الإنسانية الرقمية الناشئ ،على سبيل املثال ،عن طريق تعليمنا املزيد عن
البشر وعن ا ُملجتمعات البشرية.
يؤثر الذكاء الاصطناعي ً
أيضا على العلاقات الاجتماعية ،كما أن له تأثريًا اجتماعيٍّا
واقتصاديٍّا وبيئيٍّا أوسع ) .(Jansen et al. 2018ومن ا ُملرج َّ ح أن يشكل الذكاء الاصطناعي
التفاعلات البشرية ويؤثر على الخصوصية .ويُقال إنه قد يزيد من التحي ُّز والتمييز .ومن
 َّ
املتوقع أن يؤدي إلى فقدان الوظائف وربما إلى إحداث تحو ٍ ُّل اقتصادي كامل .فمن ا ُملمكن
ً
معجلا الظلم
أن يزيد الفجوة بني الأغنياء والفقراء وبني أصحاب النفوذ وا ُملستضعَ فني،
والتفاوت الاجتماعي .أما التطبيقات العسكرية ،فقد تُ ِّ
غري الطريقة التي يتم بها تنفيذ
يجب أن
الحروب ،على سبيل املثال ،عند استخدام الأسلحة القاتلة ذاتية التشغيل .كذلك ِ
ُ
نأخذ في اعتبارنا التأثري البيئي للذكاء الاصطناعي ،والذي يشمل زيادة استهلاك الطاقة
ً
لاحقا بعض الآثار الأخلاقية والاجتماعية بمزي ٍد من التفصيل،
والتلو ُّث .وسوف أُناقش
مرك ًزا على مشكلات الذكاء الاصطناعي ومَ خاطره .ولكن يمكن أن يكون للذكاء الاصطناعي
ً
أيضا آثار إيجابية؛ على سبيل املثال ،يمكن أن يخلق مُجتمعات جديدة عن طريق وسائل
ُ
التواصل الاجتماعي ،ويُق ِّلل املهام املتك ِّررة والخطرية عن طريق تكليف الروبوتات بها،
وي ِّ
ُحسن سلاسل الإمداد ،ويُق ِّلل استهلاك املياه ،وهكذا.
فيما يتع َّلق بالتأثري — إيجابي أو سلبي — يجب ألا نسأل فقط عن طبيعة التأثري
ومداه؛ بل أن نسأل ً
أيضا »مَ ن« هم املتأثرون وكيف سيتأث َّرون .قد يكون التأثري أكثر
إيجابية بالنسبة إلى البعض منه بالنسبة إلى َ
الآخرين .فهناك العديد من الأطراف ا َملعنية،
أخلاقيات الذكاء الاصطناعي

بدءًا من العمال واملرضى وا ُملستهلكني ،إلى الحكومات وا ُملستثمرين والشركات ،وجميعهم
قد يتأثرون بط ُرق مختلفة .وتنشأ هذه الاختلافات في املكاسب والخسائر من تأثريات
الذكاء الاصطناعي ليس فقط داخل البلدان ولكن ً
أيضا بني البلدان وأجزاء العا َلم .فهل
سيعود الذكاء الاصطناعي بالن َّفع على البلدان املتقد ِّمة وا ُملتطورة في املقام الأول؟ وهل
من ا ُملمكن أن يكون مفيدًا ً
أيضا للأشخاص ذوي التعليم ا ُملنخفِ ض والدخل ا ُملنخفض،
على سبيل املثال؟ مَ ن ستكون لدَيه القدرة على الوصول إلى التكنولوجيا ويكون قاد ًرا على
جنْي فوائدها؟ مَ ن سيتمكن من تمكني نفسه باستخدام الذكاء الاصطناعي؟ ومَ ن سيكون
مُستبعدًا من هذه الفوائد؟
مَ ن ستكون لدَيه القدرة على الوصول إلى التكنولوجيا ويكون قاد ًرا على جني فوائدها؟ مَ ن سيتم َّكن
من تمكني نفسه باستخدام الذكاء الاصطناعي؟ ومَ ن سيكون مُستبعدًا من هذه الفوائد؟

الذكاء الاصطناعي ليس التكنولوجيا الرقمية الوحيدة التي تُثري مثل هذه الأسئلة.
فهناك تقنيات رقمية أخرى خاصة باملعلومات والاتصالات ،وهي ً
أيضا تؤثر تأثريًا كبريًا
على حياتنا ومُجتمعاتنا .وكما سنرى ،بعض املشكلات الأخلاقية التي يُثريها الذكاء
الاصطناعي ليست حك ًرا على الذكاء الاصطناعي وحدَه .على سبيل املثال ،هناك مشكلات
موازية في تكنولوجيا الأجهزة الذاتية التشغيل .تذ َّكر ً
مثلا الروبوتات الصناعية التي تم َّ ت
برمجتها ولا تُ َ
عتبر ذكاءً اصطناعيٍّا ،ولكنها لا تزال لها تأثريات اجتماعية عندما تؤدي إلى
البطالة .وبعض مشكلات الذكاء الاصطناعي مُرتبطة بالتقنيات التي يت َّ ِصل بها الذكاء
ٍ
ُ
بتحديات جديدة
التواصل الاجتماعي والإنترنت ،التي تُواجهنا
الاصطناعي ،مثل وسائل
 َّ
منصات
عندما يتم دمجُ ها مع الذكاء الاصطناعي .على سبيل املثال ،عندما تستخدم
لتعرف املزيد عن مُستخدميها،
التواصل الاجتماعي مثل »فيسبوك« الذكاء الاصطناعي
ِ
فإن هذا يُثري مخاوف تتع َّلق بالخصوصية.
هذا الاتصال مع التقنيات الأخرى يعني ً
أيضا أن الذكاء الاصطناعي يكون غري
ٍ
ملحوظ في كثري من الأحيان .ويرجع هذا في املقام الأول إلى كونه أصبح بالفعل جزءًا
لا يتجزأ من حياتنا اليومية .فالذكاء الاصطناعي كثريًا ما يُستخدَم في تطبيقات جديدة
يجب ألا ننسى الذكاء الاصطناعي الذي يشغل بالفعل
ومذهلة مثل »ألفا جو« .ولكننا ِ
ُ
 َّ
التواصل الاجتماعي ،ومُحركات البحث ،وغريها من الوسائط والتقنيات التي
منصات
التكنولوجيا

أضحت جزءًا من تجربتنا اليومية .إن الذكاء الاصطناعي م ِّ
ُتوغل في كل شيء .ويمكن
ً
غامضا،
وأشكال أُخرى من التكنولوجيا
أن يكون الفارق بني الذكاء الاصطناعي الفعلي
ٍ
مم َّ ا يجعل الذكاء الاصطناعي غري مرئي :إذا تم تضمني أنظمة الذكاء الاصطناعي في
نعرف بالفعل أنه مُضم َّ ن ،فإنه من الصعب
التكنولوجيا ،فإننا عاد ًة لا نُلاحظها .وإذا كنا ِ
أن نقول ما إذا كان الذكاء الاصطناعي هو الذي يُسب ِّب املشكلة أو التأثري ،أو إذا كانت
التكنولوجيا الأخرى ا ُملت َّصلة به هي املسئولة عن ذلك .بعبارة أخرى ،لا يوجد »ذكاء
اصطناعي« في ح ِّد ذاته :فالذكاء الاصطناعي يعتمد دائمً ا على تقنيات أُخرى ويتم تضمينه
في مُمارسات وإجراءات علمية وتكنولوجية أوسع .وفي حني أن الذكاء الاصطناعي ً
أيضا
ٍ
مشكلات أخلاقية خاصة به ،فإن »أخلاقيات الذكاء الاصطناعي« تحتاج إلى أن
يُثري
تكون مُرتبطة بالأخلاقيات العامة للمعلومات الرقمية وتكنولوجيا الاتصالات ،وأخلاقيات
الكمبيوتر ،وما إلى ذلك.
يجب ألا ننسى الذكاء الاصطناعي الذي يشغل بالفعل َّ
منصات التواصل الاجتماعي ،ومُحركات البحث،
وغريها من الوسائط والتقنيات التي أضحت جزءًا من تجربتنا اليومية .إن الذكاء الاصطناعي م ِّ
ُتوغل
في ك ِّل شيء.

ثم َّ ة منطق َ
آخر يؤكد أنه لا يوجد شيء يُعرف باسم الذكاء الاصطناعي في ح ِّد ذاته،
ً
وهو أن التكنولوجيا ً
اجتماعية وإنسانية :فالذكاء الاصطناعي لا يتعلق
أيضا دائمً ا ما تكون
فقط بالتكنولوجيا ولكن ً
أيضا بما يفعله البشر بها ،وكيف يستخدمونها ،وكيف يُدركونها
ٍ
بيئات اجتماعية وتقنية أوسع .وهذا أمر مُهم للأخلاقيات
ويعيشونها ،وكيف يُضم ِّ نونها في
أيضا بقرارات الإنسان — ويعني ً
— التي تتعلق ً
منظور تاريخي
أيضا أنه يجب تضمني
ٍ
واجتماعي ثقافي .الضجة الإعلامية املثارة حاليٍّا حول الذكاء الاصطناعي ليست الضج َّ ة
الأولى التي تُثار حول التقنيات املتقدمة .قبل الذكاء الاصطناعي ،كانت »الروبوتات«
أو »الآلات« هي الكلمات الرئيسية .كما شهدت تقنيات مُتقدمة أخرى مثل التكنولوجيا
النووية ،وتكنولوجيا النانو ،والإنترنت ،والتكنولوجيا الحيوية الكثري من الجدل .ومن ا ُملفيد
أن نضع ذلك في اعتبارنا خلال مناقشاتنا حول أخلاقيات الذكاء الاصطناعي؛ إذ ربما
يُمكننا أن نستفيد من هذه النقاشات والجدالات .إن استخدام التكنولوجيا وتطويرها
أخلاقيات الذكاء الاصطناعي

يحدث في سياق اجتماعي .وكما يع َلم الأشخاص ا ُملهتمون بتقييم التكنولوجيا ،عندما
تكون التكنولوجيا جديدة ،يميل الناس إلى أن يُثريوا حولها الكثري من الجدل ،ولكن
بمجرد أن تُصبح جزءًا من الحياة اليومية ،تنخفِ ض الضجة ا ُملثارة حولها والجدل بشأنها
بشكل كبري .ومن ا ُملرجح أن يحدث هذا ً
أيضا مع الذكاء الاصطناعي .وفي حني أن مثل
ٍ
 ُّ
التوقع ليس سببًا وجيهً ا لترك مُهمة تقييم الجوانب الأخلاقية والعواقب الاجتماعية
هذا
للذكاء الاصطناعي ،فإنه يُساعدنا في رؤية الذكاء الاصطناعي في سياقه ،ومن ث َ َّم يساعدنا
في ِ
نحو أفضل.
فهمه على ٍ
الفصل السادس

تنس )علم( البيانات
لا َ
تع ُّلم الآلة
بما أن العديد من الأسئلة الأخلاقية حول الذكاء الاصطناعي تتعلق بتقنيات ِ
تعتمد كليٍّا أو
جزئيٍّا على تع ُّلم الآلة وعلم البيانات ذي ِّ
الصلة ،فإنه يجدُر بنا أن نُلقي الضوء على هذه
التقنية والعلم.
يُشري »تع ُّلم الآلة« إلى البرامج التي يُمكنها »التع ُّلم« .واملصطلح مُثري للجدل :فالبعض
يقولون إن ما تقوم به ليس تع ُّلمً ا حقيقيٍّا لأنها لا تتمت َّع بإدراكٍ حقيقي؛ والتع ُّلم مقصور
على َ
ً
ضئيلا أو مُنعدمً ا مع
البشر فحسب .على أي حال ،يحمل تع ُّلم الآلة الحديث »تشابهً ا
ما قد يحدُث في عقول البشر« ) .(Boden 2016, 46وهو يعتمد على الإحصاءات؛ إذ إنه
عملية إحصائية .ويُمكن استخدامه ملها َّم متنوعة ،ولكن املهمة الأساسية غالبًا ما تكون
هي التع ُّرف على الأنماط .ويُمكن للخوارزميات التع ُّرف على الأنماط أو القواعد املوجودة
 ُّ
وتوقع البيانات ا ُملستقبلية.
في البيانات واستخدام تلك الأنماط أو القواعد لتفسري البيانات
ٍ
تعليمات وقواعد مباشرة يُعطيها املبرمج.
يحدُث ذلك ذاتيٍّا؛ بمعنى أنه يحدُث دون
ِ
تعتمد على خبراء بشريني في املجال يشرحون القواعد
وعلى عكس الأنظمة الخبرية التي
للمُبرمِجني الذين يتو َّلون بعد ذلك برمجة هذه القواعد ،تبحث خوارزمية تع ُّلم الآلة عن
ٍ
أنماط لم يُحد ِّدها املبرمج .كل ما عليك هو تحديد الهدف أو املهمة فقط .وسوف
قواعد أو
يستطيع البرنامج أن يُكي ِّف سلو َكه بما يتوافق مع مُتطلبات املهمة .على سبيل املثال،
يمكن لتع ُّلم الآلة املساعدة في التمييز بني البريد الإلكتروني العشوائي غري املرغوب فيه
ُعتبر عشوائيٍّا .مثال َ
والبريد ا ُملهم من خلال فحص عددٍ كبري من الرسائل وتع ُّلم ما ي َ
آخر:

أخلاقيات الذكاء الاصطناعي

ً
مجموعة من
لإنشاء خوارزمية تتع َّرف على صور القطط ،لا يُقد ِّم املبرمجون للكمبيوتر
 ٍّ
خاص بها
نموذج
القواعد تُع َّرف فيها ما هي القطط ،ولكنهم يُتيحون للخوارزمية إنشاء
ٍ
حسن الخوارزمية من أدائها ذاتيٍّا لتحقيق أعلى َّ
لصور القطط .وتُ ِّ
دقة تنبؤ بالاستناد إلى
ٍ
مجموعة من صور القطط وغري القطط .وبالتالي ،تهدف إلى تع ُّلم ما هي صور القطط.
ٍ
بتعليمات أو قواعد مُحددة.
ويُقد ِّم البشر تقارير ،ولكنهم لا يُغذ ُّونها
ٍ
نظريات لتفسري البيانات والتنب ُّؤ بها؛ في حني يُنشئ
كان العلماء في السابق يُنشئون
الكمبيوتر في تع ُّلم الآلة نماذج خاصة به تتناسب مع البيانات .إذَن فنقطة البداية هي
البيانات ،وليس النظريات .ومن هذا ا ُملنطلق ،لم تعُ د البيانات »سلبية« بل »نشطة«:
»فالبيانات نفسها هي التي تُحد ِّد ما يجب القيام به بعد ذلك« )Alpaydin 2016,
 .(11يُد ِّرب الباحثون الخوارزمية باستخدام مجموعات البيانات املوجودة )على سبيل
املثال ،رسائل البريد الإلكتروني القديمة( ،وعندئ ٍذ تستطيع الخوارزمية التنب ُّؤ بالنتائج من
البيانات الجديدة )على سبيل املثال ،البريد الإلكتروني الوارد الجديد( ) .(CDT 2018يُشار
ٍ
كميات كبرية من املعلومات )البيانات الضخمة( باسم
أحيانًا إلى التع ُّرف على الأنماط في
»التنقيب عن البيانات« ،تشبيهً ا له باستخراج املعادن َ
القي ِّمة من الأرض .ومع ذلك ،فإن
ٍ
أنماط من البيانات ،وتحليل البيانات ،وليس
املصطلح مُض ِّلل لأن الهدف هو استخراج
استخراج البيانات نفسها.
متغري م َّ
 ِّ
ُعني
يمكن أن يكون تع ُّلم الآلة »مُوج َّ هً ا« ،مما يَعني أن الخوارزمية تر ِّكز على
يُع َرف باسم هدف التنبؤ .على سبيل املثال ،إذا كان الهدف هو تقسيم الأشخاص إلى فئتَني
)على سبيل املثال ،خطورة أمنية عالية أو منخفضة( ،فإن ا ُملتغريات التي تتنبأ بهاتَني
الفئتَني معروفة بالفعل ،وبالتالي تتع َّلم الخوارزمية التنب ُّؤ بالانتماء إلى إحدى الفئتَني
)الخطورة الأمنية العالية أو الخطورة الأمنية املنخفضة( .يُد ِّرب املبرمج النظام عن طريق
توفري أمثلة وغريها ،على سبيل املثال ،صور للأشخاص الذين يُش ِّكلون خطورة أمنية
عالية وأمثلة للأشخاص الذين لا يُشكلون خطورة أمنية .يكون الهدف أن يتع َّلم النظام
التنب ُّؤ بمَ ن ينتمي إلى كل فئة ،أي مَ ن يُشكل خطور ًة أمنية عالية ومَ ن لا يشكل بناءً على
البيانات الجديدة .إذا أ ُ ِ
عطي النظام ما يكفي من الأمثلة ،فإنه سيكون قاد ًرا على التعميم
لراكب يم ُّر
من هذه الأمثلة ومعرفة كيفية تصنيف البيانات الجديدة ،مثل صور ٍة جديدة
ٍ
عَ ْبر أمن املطار .أما تع ُّلم الآلة »غري ا ُملوج َّ ه« فيعني عدم تقديم هذا النوع من التدريب،
ٍ
 َّ
خاصة بها .على سبيل املثال،
فئات
وأن الفئات غري معروفة :ومن ثَم تُنشئ الخوارزميات
لا َ
تنس )علم( البيانات

ً
ً
ٍ
خاصة به استنادًا إلى ا ُملتغريات التي يُحددها؛ لا
أمنية
فئات
يُنشئ الذكاء الاصطناعي
ٍ
أنماط لم يُحد ِّدها خبراء
التي يُقدمها إليه املبرمج .وربما يعثر الذكاء الاصطناعي على
املجال )في هذا السياق :الخبراء الأمنيون( .ويمكن أن تبدو الفئات التي أنشأها الذكاء
الاصطناعي من منظور البشر عشوائية للغاية .وربما لا يكون لها معنى .ولكنها موجودة
من الناحية الإحصائية .وفي بعض الأحيان يكون لها معنى ،وفي هذه الحالة يمكن لهذه
ً
معرفة جديدة حول الفئات في العالم الواقعي .أما التع ُّلم »ا ُملع َّزز«،
الطريقة أن تُعطينا
فإنه يتطلب تقييمً ا للمُخرجات إن كانت جيدة أم سيئة .وهذا يُشبه فكرة الثواب والعقاب.
ُخبر أي ُّ الإجراءات يجب أن ي َ
فالبرنامج لا ي َ
ُتخذ ،ولكنه »يتعلم« من خلال عملية تكرارية
أي الإجراءات التي تؤدي إلى الثواب .ففي املثال الأمني السابق ،يتلقى النظام تقري ًرا )أو
بعمل جيد عندما يجري
بيانات( من الخبراء الأم ِني ِّني بحيث »يعرف« ما إذا كان قد قام
ٍ
تنب ًؤا معينًا .فإذا لم يُسبب الشخص الذي تنبأ النظام بأنه ذو خطورة أمنية منخفضة
ٍ
مشكلات أمنية ،فإن النظام يتلقى تقري ًرا بأن مخرجاته كانت جيدة ومن ثَم »يتعلم«
أي َّ
ً
ً
دقيقا بنسبة ١٠٠في
نسبة من الخطأ :فالنظام ليس
منه .يجب ملاحظة أن هناك دائمً ا
املائة .يجب ً
أيضا ملاحظة أن ا ُملصط َلحَ ني الفن ِّي َّني »موج َّ ه« و»غري موج َّ ه« لا علاقة لهما
 ُّ
التدخل البشري في استخدام التكنولوجيا :ففي حني أن الخوارزمية تتمت َّع ببعض
بمدى
 َّ
بطرق مختلفة.
يتدخلون
الاستقلالية ،فإن البشر في جميع أنواع تع ُّلم الآلة
ٍ
هذا صحيح ً
 ُّ
يخص البيانات في مجال الذكاء الاصطناعي ،بما في ذلك
أيضا فيما
ما يُسم َّ ى ب »البيانات الضخمة« .اكتسب تع ُّلم الآلة القائم على البيانات الضخمة الكثري
من الاهتمام بسبب توفر كميات كبرية من البيانات وزيادة قدرة الكمبيوتر )الأرخص(.
يتحد َّث بعض الباحثني عن »زلزال البيانات« ) .(Alpaydin 2016, xنحن جميعً ا نُنتِج
بيانات من خلال أنشطتنا الرقمية ،مثلما يحدُث على سبيل املثال عندما نستخدِم وسائل
ٍ
منتجات عبر الإنترنت .هذه البيانات مهمة بالنسبة
التواصل الاجتماعي أو عندما نشتري
ً
وأيضا بالنسبة إلى الحكومات والعلماء .لقد صار جمع البيانات
إلى الجهات التجارية
وتخزينها ومعالجتها أسهل بكثري على املؤسسات ).(Kelleher and Tierney 2018
وليس ذلك بسبب تع ُّلم الآلة فقط :فالبيئة الرقمية الأوسع وتقنيات الوسائط الرقمية
ُ
التواصل
الأخرى تلعب دو ًرا مُهمٍّ ا في هذا الصدد .إذ تيسر التطبيقات عبر الإنترنت ووسائل
الاجتماعي جمع البيانات من الأفراد .كما أن تخزين البيانات أصبح أق َّل تكلفة ،وأصبحت
أخلاقيات الذكاء الاصطناعي

ٍ
بشكل
إمكانيات أكبر .كل هذا كان مُهمٍّ ا لتطوير الذكاء الاصطناعي
أجهزة الكمبيوتر ذات
ٍ
عام ،وعلم البيانات بشكل خاص.
علم البيانات
نستنتِج مما سبق أن تع ُّلم الآلة يرتبط ب »علم البيانات« .إذ يهدف علم البيانات إلى
ٍ
أنماط مفيدة وذات معنًى من مجموعات البيانات ،وفي الوقت الحالي هذه
استخراج
املجموعات كبرية جدٍّا .يستطيع تع ُّلم الآلة تحليل هذه املجموعات الكبرية من البيانات آليٍّا.
ِ
ويعتمد تع ُّلم الآلة وعلم البيانات على الإحصاءات ،أو على الانتقال من امللاحظات الفردية
ٍ
ٍ
ارتباطات في البيانات من خلال
توصيفات عامة .فعلماء الإحصاء يهتم ُّ ون بالعثور على
إلى
التحليل الإحصائي .وتبحث عمليات إنشاء النماذج الإحصائية عن العلاقات الرياضية بني
املدخلات واملخرجات .وهذا هو ما تساعد فيه خوارزميات تع ُّلم الآلة.
نحن جميعً ا نُنتج بيانات من خلال أنشطتنا الرقمية ،كما يحدث على سبيل املثال عندما نستخدِم
ُ
التواصل الاجتماعي أو عندما نشتري مُنتجات عبر الإنترنت.
وسائل

ولكن علم البيانات ينطوي على أكثر من مجرد تحليل البيانات بواسطة تع ُّلم الآلة .إذ
يجب جمع البيانات وإعدادها قبل تحليلها ،وبعد ذلك يجب تفسري نتائج التحليل .وينطوي
علم البيانات على تحد ِّيات مثل كيفية الحصول على البيانات وتنقيتها )على سبيل املثال،
من وسائل التواصل الاجتماعي والويب( ،وكيفية الوصول إلى كمي ٍة كافية من البيانات،
وكيفية جمع مجموعات البيانات معً ا ،وكيفية إعادة هيكلة مجموعات البيانات ،وكيفية
اختيار مجموعات البيانات ذات الصلة ،وأي نوع من البيانات يتم استخدامه .لذلك لا يزال
َ
البشر يلعبون دو ًرا مهمٍّ ا في جميع املراحل وفيما يتعلق بجميع هذه الجوانب ،بما في ذلك
صياغة املشكلة ،والحصول على البيانات ،وإعداد البيانات )مجموعة البيانات التي تتد َّرب
عليها الخوارزمية ومجموعة البيانات التي ستُطبق عليها( ،وإنشاء خوارزمية التع ُّلم أو
اختيارها ،وتفسري النتائج ،واتخاذ قرار حول الإجراء الذي يجب اتخاذه )Kelleher and

.(Tierney 2018
لا َ
تنس )علم( البيانات

تظهر التحد ِّيات العلمية في كل مرحلة من هذه العملية ،وعلى الرغم من أن البرامج
قد تكون سهلة الاستخدام ،فإن مواجهة هذه التحديات تتط َّلب وجود املعرفة البشرية
تخصصة .وعاد ًة ما يكون التعاون بني البشر أم ًرا ضروريٍّا ً
الخبرية ا ُمل ِّ
أيضا ،على سبيل
املثال ،بني علماء البيانات واملهندسني .ومن الوارد حدوث أخطاء طوال الوقت ،لذا فإن
الاختيار البشري واملعرفة البشرية والتفسري البشري أمر حاسم الأهمية .فالبشر مهم ُّ ون في
نحو معقول وتوجيه التكنولوجيا نحو البحث عن عوامل
هذا السياق لتفسري الأمور على ٍ
وعلاقات مختلفة .والذكاء الاصطناعي ،من وجهة نظر بودن ) ،(٢٠١٦يفتقر إلى فهمنا
للصلات والعلاقات .ويمكننا أن نُضيف أنه يفتقر ً
 ِّ
أيضا إلى الفهم والتجربة والحساسية
والحكمة .وهذه حجة جيدة تدعم نظريٍّا ومبدئيٍّا ضرورة مشاركتنا نحن البشر في
الأمر .ولكن ثمة حجة عملية ً
أيضا تدعم عدم خروج البشر من املشهد؛ وهي أن البشر
يشاركون بالفعل عمليٍّا في الأمر .فدون املبرمجني وعلماء البيانات ،لن تستطيع التكنولوجيا
القيام بوظيفتها ببساطة .علاو ًة على ذلك ،كثريًا ما يتم دمج الخبرة البشرية مع الذكاء
الاصطناعي ،على سبيل املثال ،عندما يستخدم الطبيب استراتيجية علاج سرطان يوصي بها
الذكاءُ الاصطناعي ،ولكنه في الوقت نفسه يعتمد على تجاربه وحدسه كخبري .فإذا ألغي
التدخل البشري ،يمكن أن تسوء الأمور أو تفقد معناها أو ببساطة تُصبح غري منطقية.
ولنضرب ً
مثلا باملشكلة املعروفة التالية من الإحصاء ،والتي تؤثر بدَورها على
ٍ
علاقات سببية .يُقدم تايلر فيجني في
استخدام تع ُّلم الآلة :الارتباطات لا تعني بالضرورة
كتابه »الارتباطات الزائفة« ) (٢٠١٥بعض الأمثلة الجيدة على ذلك .في الإحصاء ،الارتباط
ٍ
بعلاقات سببية
الزائف هو الارتباط الذي تكون فيه ا ُملتغريات غري مرتبطة فيما بينها
عامل ثالث غري مرئي .من بني
ولكنها قد تبدو كذلك؛ ويكون الارتباط ناجمً ا عن وجود
ٍ
الأمثلة التي يُقد ِّمها فيجني الارتباط بني معدل الطلاق في ولاية مني ومعدل استهلاك
السمن النباتي للفرد الواحد ،أو الارتباط بني معدل استهلاك جبن املوتزاريلا للفرد الواحد
والحصول على دكتوراه في الهندسة ا َملدنية 1 .ربما يعثر الذكاء الاصطناعي على مثل هذه
 َّ
 ُّ
تستحق مزيدًا من
يتدخل البشر لتقرير الارتباطات التي
الارتباطات ،ولكن يجب أن
ٍ
علاقات سببية.
الدراسة من أجل العثور على
ً
فضلا عن ذلك ،في املرحلة التي يتم فيها جمع البيانات وتصميم أو إنشاء مجموعة
ٍ
 ُّ
يخص كيفية التجريد عن الواقع )Kelleher and Tierney
اختيارات فيما
البيانات ،نجري
 .(2018والتجريد عن الواقع لا يكون مُحايدًا أبدًا ،والتجريد نفسه ليس واقعً ا؛ وإنما هو
أخلاقيات الذكاء الاصطناعي

تمثيل للواقع .وهذا يَعني أنه يُمكننا مناقشة مدى جودة هذا التمثيل وملاءمته ،فيما يتعلق
بغ َرض مُعني .قارن هذا بأية خريطة :الخريطة نفسها ليست هي الإقليم ،وقد اختار َ
البشر
طريقة تصميم الخريطة لغ َر ٍض مُعني )على سبيل املثال ،خريطة مللاحة السيارات مقابل
خريطة طوبوغرافية للتن ُّزه سريًا على الأقدام( .في تع ُّلم الآلة ،يعمل التجريد باستخدام
الأساليب الإحصائية على إنشاء نموذج للواقع؛ إنه ليس الواقع الفعلي .كما يتضم َّ ن ذلك
اختيارات :اختيارات بشأن الخوارزمية نفسها التي تُ ِّ
وفر العملية الإحصائية التي تأخذنا
من البيانات إلى النمط/القاعدة ،ولكن ً
أيضا اختيارات بشأن تصميم مجموعة البيانات
التي تتد َّرب عليها الخوارزمية .يعني هذا الجانب الاختياري ،ومن ثَم الجانب البشري ،في
ً
أسئلة نقدية حول الاختيارات التي تُت َّ َخذ ،بل يجب علينا
تع ُّلم الآلة أنه يُمكننا أن نطرح
أن نفعل ذلك .على سبيل املثال ،هل مجموعة البيانات التي سيتم التدريب عليها تُمثل
ً
تمثيلا جيدًا؟ هل هناك أي تحي ُّزات في البيانات؟ كما سنرى في الفصل القادم،
السكان
هذه الاختيارات والقضايا ليست مجرد أسئلة فنية ولكن لها ً
أيضا جانب أخلاقي شديد
الأهمية.
التطبيقات
تطبيقات عديدة ،ذَ ُ
ٌ
كرت بعضها بالفعل تحت العنوان الأعم
لتع ُّلم الآلة وعلم البيانات
ا ُملتمثل في الذكاء الاصطناعي .هذه التقنيات يُمكن استخدامها للتع ُّرف على الوجوه
)بل للتع ُّرف على الانفعالات بناءً على تحليل الوجوه( ،أو تقديم اقتراحات بحث ،أو
قيادة السيارة ،أو إجراء ُّ
توقعات شخصية ،أو التنب ُّؤ بمَ ن سيعاود ارتكاب الجريمة،
أو التوصية بموسيقى مُعينة للاستماع إليها .وتستخدَم في مجال املبيعات والتسويق،
للتوصية بمنتجات وخدمات .على سبيل املثال ،عندما تشتري شيئًا على موقع أمازون،
ٍ
بيانات عنك ثم يُقدم توصيات على أساس نموذج إحصائي يستند إلى
سيجمع املوقع
ٍ
بيانات من جميع العملاء .استخدمت شركة ووملارت في متاجرها تقنية التع ُّرف على
ُ
الوجوه للتصدي للسرقة؛ وقد تستخدم في املستقبل التقنية نفسها لتحديد ما إذا كان
ا ُملتسوقون سعداء أم مُحبَطني .كما أن للتقنيات تطبيقات مختلفة في مجال التمويل.
تعاونت وكالة إكسبريان للمرجعية الائتمانية مع الذكاء الاصطناعي املدعوم بتع ُّلم الآلة
لتحليل البيانات ا ُملتعلقة با ُملعاملات والقضايا املنظورة في املحاكم من أجل التوصية بما
قرض ُملقد ِّم طلب لرهن عقاري .وتستخدم أمريكان إكسبريس تع ُّلم
إذا كان يجب تقديم ٍ
لا َ
تنس )علم( البيانات

الآلة لتوقع املعاملات الاحتيالية .وفي مجال النقل ،يُستخدَم الذكاء الاصطناعي والبيانات
الضخمة لإنشاء سيارات ذاتية القيادة .على سبيل املثال ،تستخدِم شركة بي إم دبليو نوعً ا
من تقنية التع ُّرف على الصور لتحليل البيانات الواردة من أجهزة الاستشعار والكامريات
في السيارة .وفي مجال الرعاية الصحية ،يمكن أن يُساعد الذكاء الاصطناعي املدعوم بتع ُّلم
الآلة في تشخيص السرطان )على سبيل املثال ،في تحليل صور الأشعة لتشخيص مرض
السرطان( أو اكتشاف الأمراض ا ُملعدية .على سبيل املثال ،أجرى نظام الذكاء الاصطناعي
ً
تحليلا ملليون صورة من صور أشعة العيون وبيانات املرضى ،مُدربًا
لشركة ديب مايند
نفسه على تشخيص أعراض حالات العيون املرضية ا ُملتدهورة .وقد تجاوز نظام واتسون
ٍ
توصيات بشأن
الذي أنشأته شركة آي بي إم مُمارسة لعبة »جيوباردي« ويستخدم لتقديم
علاج السرطان .كما تُزو ِّد أجهزة الرياضة والصحة التي يمكن ارتداؤها تطبيقات تع ُّلم
الآلة بالبيانات .وفي مجال الصحافة ،يمكن لتع ُّلم الآلة كتابة تقارير إخبارية .على سبيل
املثال ،في اململكة املتحدة ،تستخدِم وكالة أنباء »بريس أسوسييشن« الروبوتات في كتابة
تقارير الأخبار املحلية .ويدخل الذكاء الاصطناعي ً
أيضا إلى املنزل واملجال الشخصي ،على
 َّ
تتولى جمع البيانات وأجهزة تفاعُ لية مساعدة مت َّصلة
سبيل املثال ،في شكل روبوتات
بمعالجة اللغة الطبيعية .تتحد َّث دُمية »هالو باربي« إلى الأطفال باستخدام مُعالجة اللغة
الطبيعية التي تُحلل املحادثات املسجلة .فك ُّل ما يقوله الأطفال يتم تسجيلُه وتخزينه
وتحليله في وحدات الخدمة الخاصة ب »توي توك« .ثم يُرسل ردٍّا إلى الجهاز :وتجيب دمية
»هالو باربي« على أساس ما »تعلمته« عن مُستخدمها .ويستخدِم فيسبوك تقنيات التع ُّلم
العميق والشبكات العصبية لهيكلة وتحليل البيانات الآتية مما يق ُرب من مليا َري مستخدم
ٍ
 َّ
بيانات غري مُهيكلة .وهذا يساعد الشركة في تقديم إعلانات مُستهدفة.
للمنصة يُنتجون
ويح ِّلل إنستجرام صور ٨٠٠مليون مُستخدِم بهدف بيع الإعلانات إلى الشركات .ويستخدم
نتفليكس محركات التوصية التي تُح ِّلل بيانات العملاء ،لكي يُحو ِّل نفسه من موزع إلى
منتج محتوى :فإذا َ
كنت تستطيع التنب ُّؤ بما يرغب الناس في مشاهدته ،فيُمكنك إنتاجه
بنفسك وتحقيق ربح منه .بل إن علم البيانات استُخدِم في مجال الطهي .على سبيل املثال،
بناءً على تحليل نحو ١٠٠٠٠وصفة ،يُنشئ نظام شيف واتسون الذي أنتجته شركة آي
بي إم وصفاته الخاصة التي تقترح توليفات جديدة للمكونات 2 .ويمكن ً
أيضا استخدام
الذكاء الاصطناعي املدعوم بتع ُّلم الآلة في التعليم ،والتوظيف ،والعدالة الجنائية ،والأمن
أخلاقيات الذكاء الاصطناعي

)على سبيل املثال ،الشرطة التنبؤية( ،واسترجاع املوسيقى ،والأعمال املكتبية ،والزراعة،
والأسلحة العسكرية ،وما إلى ذلك.
في املاضي ،كانت الإحصاء من املجالات غري الجذابة .أما اليوم ،فبعد أن أصبحت جزءًا
شكل يُدمَ ج فيه الذكاء الاصطناعي مع البيانات الضخمة ،أصبحت
من عِ لم البيانات وفي
ٍ
الإحصاء شديدة الجاذبية .إنها السحر الجديد .إنها املجال الذي تُ ِّ
فضله وسائل الإعلام.
نوع جديد من التنقيب عن
كما أنها تُعتبر مجا َل أعمال ضخمً ا .فالبعض يتحد َّثون عن ٍ
ً
خيالا
الذهب؛ والتوقعات هائلة .علاو ًة على ذلك ،فهذا النوع من الذكاء الاصطناعي ليس
َ
محض نبوءة ،كما تُبني الأمثلة التي ضربناها أن ما يُسم َّ ى بالذكاء الاصطناعي
علميٍّا أو
املحدود أو الضعيف موجود بالفعل وواسع الانتشار .وفيما يتعلق بتأثريه ا ُملحتمَ ل ،فليس
هناك ما يُمكننا أن ِ
نصفه بأنه محدود أو ضعيف .لذلك ،فإنه من الضروري جدٍّا أن نُح ِّلل
ونُناقش العديد من القضايا الأخلاقية التي أثارتها تقنيات تع ُّلم الآلة وغريها من تقنيات
الذكاء الاصطناعي وتطبيقاتها .وهذا هو موضوع الفصول القادمة.
في املاضي ،كانت الإحصاء من املجالات غري الجذ َّابة .أما اليوم ،فبعد أن أصبحت جزءًا من علم
شكل يُدمج فيه الذكاء الاصطناعي مع البيانات الضخمة ،أصبحت الإحصاء شديدة
البيانات وفي
ٍ
الجاذبية .إنها السحر الجديد.
الفصل السابع

الخصوصية وغيرها من القضايا

إن العديد من املشكلات الأخلاقية ا ُملتعلقة بالذكاء الاصطناعي معروفة من مجال أخلاقيات
بشكل أعم ،من مجال أخلاقيات التكنولوجيا الرقمية وتكنولوجيا
الروبوتات والأتمتة أو،
ٍ
الاتصالات .ولكن هذا في ح ِّد ذاته لا يُق ِّلل من أهميتها .وعلاو ًة على ذلك ،فإن هذه القضايا
ٍ
بتقنيات أخرى — تكتسب بُعدًا جديدًا وتُصبح
— بسبب التكنولوجيا وطريقة ارتباطها
أكثر أهمية وإلحاحً ا.
الخصوصية وحماية البيانات
فلنُفكر ،على سبيل املثال ،في مسألة الخصوصية وحماية البيانات .ينطوي الذكاء
الاصطناعي ،ولا سيما تطبيقات تع ُّلم الآلة التي تتعامَ ل مع البيانات الضخمة ،غالبًا
على جمع املعلومات الشخصية واستخدامها .ويُمكن ً
أيضا استخدام الذكاء الاصطناعي
ً
وأيضا في مكان العمل وفي كل مكان ،وذلك من خلال الهواتف الذكية
للمُراقبة ،في الشارع
ُ
ري من الأحيان ،لا يعلم الناس حتى أن البيانات
ووسائل
التواصل الاجتماعي .وفي كث ٍ
سياق
سياق ما تُستخدَم بواسطة أطراف أخرى في
تُجمَ ع ،أو أن البيانات التي قدموها في
ٍ
ٍ
آخر .كما أن البيانات الضخمة غالبًا ما تَعني أن )مجموعات( البيانات التي تحصل عليها
املنظمات املختلفة يتم دمجها معً ا.
يتط َّلب الاستخدام الأخلاقي للذكاء الاصطناعي جمع البيانات ومعالجتها ومشاركتها
 َّ
ٍ
وحقهم في معرفة ما يحدث لبياناتهم ،والوصول إلى
بطريقة تحترم خصوصية الأفراد
بياناتهم ،والاعتراض على جمع بياناتِهم أو على مُعالجتها ،ومعرفة أن بياناتهم تُجمع
ٍ
لقرارات يتخذها الذكاء الاصطناعي )في حالة حدوث ذلك
وتُعالج وأنهم بعدئ ٍذ يخضعون

أخلاقيات الذكاء الاصطناعي

بالفعل( .وتُثار العديد من هذه القضايا ً
أيضا في سياقات تكنولوجيا املعلومات وتكنولوجيا
طا مُهمٍّ ا ً
الاتصالات الأخرى ،وكما سنرى فيما بع ُد في هذا الفصل ،تعتبر الشفافية شر ً
أيضا
في تلك الحالات )انظر ً
لاحقا في هذا الفصل( .كما تُثار قضايا حماية البيانات في أخلاقيات
البحث ،على سبيل املثال ،في أخلاقيات جمع البيانات لأبحاث العلوم الاجتماعية.
ومع ذلك ،عند النظر إلى السياقات التي يُستخدَم فيها الذكاء الاصطناعي اليوم،
تُصبح قضايا الخصوصية وحماية البيانات أكثر تعقيدًا .فإن احترام هذه القِ يَم والحقوق
ً
استبيان كعالِم اجتماع :إذ يمكن للباحث إبلاغ املشاركني
سهلا إلى ح ٍّد ما عند إجراء
يكون
ٍ
بشكل صريح ،ومِن ثَم سيكون من املعروف نسبيٍّا ما
في الاستبيان وطلب موافقتهم
ٍ
سيحدث للبيانات .ولكن البيئة التي يُستخدَم فيها الذكاء الاصطناعي وعلم البيانات اليوم
ً
مختلفة تمامً ا .فلنتناول ً
مثلا وسائل التواصل الاجتماعي :على الرغم من
عاد ًة ما تكون
معلومات الخصوصية والتطبيقات التي تطلُب من ا ُملستخدِمني املوافقة ،فإن ا ُملستخدِمني
لا يعرفون بوضوح ما يحدُث لبياناتهم أو حتى أي بيانات يتم جمعها؛ وإذا كانوا يرغبون
ري من الأحيان ،لا
في استخدام التطبيق والاستمتاع بفوائده ،فعليهم أن يوافقوا .وفي كث ٍ
يعلم ا ُملستخدمون حتى أن الذكاء الاصطناعي ي ِّ
ُشغل التطبيق الذي يستخدمونه .وغالبًا
ما تُ َ
نطاق َ
آخر واستخدامها لأغراض مختلفة )إعادة
سياق ما إلى
نقل البيانات ا ُملعطاة في
ٍ
ٍ
أغراض أخرى( ،على سبيل املثال ،عندما تبيع الشركات بياناتها إلى
استخدام البيانات في
ٍ
شركات أخرى أو تنقل البيانات بني أجزاءٍ مختلفة من نفس الشركة دون عِ لم املستخدِمني
بهذا.
التلاعُ ب والاستغلال وا ُملستخدِمني ا ُملستهدفني
تُشري هذه الظاهرة الأخرية ً
أيضا إلى احتمالية التلاعُ ب با ُملستخدمني واستغلالهم .يُستخدَم
الذكاء الاصطناعي للتحكم فيما نشتريه ،وفي الأخبار التي نُتابعها ،وفي الآراء التي نثِق
بها ،وغري ذلك .وقد أشار الباحثون في النظرية النقدية إلى السياق الرأسمالي الذي يحدث
فيه استخدام وسائل التواصل الاجتماعي .على سبيل املثال ،يمكن القول إن مُستخدمي
ً
»عملا رقميٍّا« مجانيٍّا ) (Fuchs 2014من خلال إنتاج
وسائل التواصل الاجتماعي يؤد ُّون
البيانات لصالح الشركات .ويُمكن أن يشمل هذا الشكل من أشكال الاستغلال ً
أيضا الذكاء
الاصطناعي .فبوصفنا مُستخدمني لوسائل التواصل الاجتماعي ،نحن نتعرض لخطر أن
نصبح القوة العاملة ا ُملستغ َّلة غري املأجورة ،التي تنتج البيانات لصالح الذكاء الاصطناعي
الخصوصية وغريها من القضايا

الذي يُحلل بياناتنا بعد ذلك لصالح الشركات التي تستخدم البيانات ،والتي عاد ًة ما
ً
أيضا .وهذا يُذ ِّكرنا ً
أطرافا أخرى ً
أيضا بتحذير هريبرت ماركوزه في ستينيات
تتضم َّ ن
القرن العشرين بأنه حتى في املجتمعات ا ُملسم َّ اة مجتمعات »حرة« ،و»غري شمولية« ،هناك
أشكال خاصة من السيطرة ،وخاصة استغلال ا ُملستهلكني ) .(Marcuse 1991يكمن
أشكال
الخطر هنا في أن الذكاء الاصطناعي قد يؤدي حتى في الديمقراطيات الحديثة إلى
ٍ
جديدة من التلاعُ ب واملراقبة والاستبداد ،ليس بالضرورة في شكل سياسات استبدادية
ولكن بطريقة أكثر خفاءً وفعالية :من خلال تغيري الاقتصاد بطريقة تُحو ِّلنا جميعً ا —
في استخدامنا للهواتف الذكية والتفاعلات الرقمية الأخرى — إلى ما يُشبه الأبقار التي يتم
حلبها للحصول على بياناتها .ولكن يمكن ً
أيضا استخدام الذكاء الاصطناعي للتلاعُ ب في
ُ
التواصل
بشكل أكثر مباشرة ،على سبيل املثال ،من خلال تحليل بيانات وسائل
السياسة
ٍ
الاجتماعي لدعم حملات سياسية مُعينة )كما في الحالة الشهرية لشركة كامبريدج أناليتيكا،
التي استخدمت بيانات مُستخدمي فيسبوك — دون موافقتهم — لأغراض سياسية في
انتخابات الرئاسة الأمريكية عام ،(٢٠١٦أو عن طريق استخدام روبوتات لنشر رسائل
ُ
التواصل الاجتماعي استنادًا إلى تحليل بيانات الأفراد من حيث
سياسية على وسائل
تفضيلاتهم السياسية للتأثري على عمليات التصويت .كما أن البعض يُساورهم القلق من
ً
نيابة عن البشر ،قد يُحو ِّل
أن يُحو ِّل الذكاء الاصطناعي ،من خلال تو ِّليه املهام املعرفية
مُستخدِميه إلى أطفال على املستوى العقلي عن طريق »تقليل قدرتهم على التفكري بمحض
أنفسهم أو اتخاذ قراراتهم الخاصة بما يجب فعله« ) .(Shanahan 2015, 170علاو ًة على
ذلك ،لا يكمن خطر الاستغلال في جانب املستخدم فحسب :فالذكاء الاصطناعي يعتمد على
أجهزة صنعها أشخاص ،وقد ينطوي إنشاء هذه الأجهزة على استغلال هؤلاء الأشخاص.
وقد يدخل الاستغلال ً
أيضا في تدريب الخوارزميات وإنتاج البيانات التي تُستخدَم لصالح
الذكاء الاصطناعي وعن طريقه .إن الذكاء الاصطناعي ربما يجعل الحياة أيسر بالنسبة
إلى مُستخدِميه ،ولكن ليس بالضرورة بالنسبة إلى أولئك الذين ي ِّ
ُنقبون عن املعادن ،أو
بالنسبة إلى مَ ن يتعاملون مع ا ُملخلفات الإلكترونية ،أو إلى مَ ن يُدربون الذكاء الاصطناعي.
على سبيل املثال ،لا يقتصر ما يقوم به تطبيق »أليكسا« الذي طو َّرته أمازون إكو على
إنشاء مُستخدِمني يؤد ُّون ً
عملا مجانيٍّا ويُصبحون مصادر للبيانات ويُباعون كمنتجات؛
بل هناك عا َلم من العمل البشري يكمُن خلف الكواليس :فعُ م َّ ال التنقيب عن املعادن،
والعمال على السفن ،والعمال الذين يُصنفون مجموعات البيانات ،كل هؤلاء في خدمة
تجميع رءوس الأموال وترا ُكمها لدى عدد قليل جدٍّا من الأشخاص ).(Schwab 2018
أخلاقيات الذكاء الاصطناعي

أشكال جديدة من التلاعُ ب واملراقبة والاستبداد ،ليس بالضرورة في
قد يؤدي الذكاء الاصطناعي إلى
ٍ
ٍ
سياسات استبدادية ولكن بطريقةٍ أكثر خفاءً وفعالية.
شكل

بعض مُستخدمي الذكاء الاصطناعي أكثر تع ُّر ً
ضا للخطر من غريهم .ونظريات
الخصوصية والاستغلال غالبًا ما تفترض أن املستخدِم شخص بالِغ سليم الجسم ،صغري
السن نسبيٍّا ،في كامل قواه العقلية . َّ
لكن العا َلم الحقيقي مليء بالأطفال وكبار السن
والأشخاص الذين لا يتمتعون بقوًى عقلية »طبيعية« أو »كاملة« ،وغريهم .مثل هؤلاء
ا ُملستخدمني الضعفاء أكثر عُ ً
رضة للخطر .ويمكن انتهاك خصوصيتهم أو التلاعب بهم
 ِّ
ً
فرصا جديدة لهذه الانتهاكات وعمليات التلاعب .ف ِّكر
ويوفر الذكاء الاصطناعي
بسهولة،
ً
مثلا في الأطفال الصغار الذين يتحدثون مع دمي ٍة متصلة بنظام تكنولوجي مدعوم بالذكاء
الاصطناعي :على الأرجح ،هؤلاء الأطفال لا يعلمون شيئًا عن الذكاء الاصطناعي ا ُملستخدَم
أو عن جمع بياناتهم ،فما بالك بما يُفعَ ل بمعلوماتهم الشخصية .إن روبوت الدردشة
أو الدمية الذكية املدعومة بالذكاء الاصطناعي لا تستطيع فقط أن تجمع الكثري من
املعلومات الشخصية عن الطفل وأبويه بهذه الطريقة ،بل يُمكنها ً
أيضا التلاعُ ب بالطفل
باستخدام واجهة اللغة والصوت .ومع تحو ُّل الذكاء الاصطناعي إلى جزءٍ من »إنترنت
الألعاب« ) (Druga and Williams 2017وإنترنت الأشياء )الأخرى( ،تُصبح هذه مشكلة
أخلاقية وسياسية .إن شبح الشمولية والاستبداد يُعاود الظهور مجددًا :ليس في قصص
الخيال العلمي ا ُملتشائمة أو في كوابيس ما بعد الحروب القديمة ،ولكن في التكنولوجيا
الاستهلاكية املوجودة بالفعل في الأسواق.
الأخبار الكاذبة ،وخطر الشمولية ،وتأثريها على العلاقات الشخصية
يمكن أن يُستخدَم الذكاء الاصطناعي ً
أيضا في إنتاج خطاب الكراهية واملعلومات الزائفة،
كأشخاص ولكنها في الواقع مجرد برامج مدعومة بالذكاء
أو في إنشاء روبوتات تبدو
ٍ
الاصطناعي .وقد سبق وأشرت بالفعل إلى روبوت الدردشة »تاي« وخطاب أوباما الزائف.
قد يؤدي ذلك إلى عا َل ٍم لا يمكن فيه التمييز بوضوح بني ما هو حقيقي وما هو زائف،
َ
يجب تسميتها »ما بعد الحقيقة«
عالم
تتداخل فيه الحقائق مع الخيال .وسواء كان ِ
بشكل واضح في
أم لا ) ،(McIntyre 2018تساهم هذه التطبيقات للذكاء الاصطناعي
ٍ
الخصوصية وغريها من القضايا

املشكلة .بالطبع ،كان يُوجَ د تلاعب ومعلومات كاذبة قبل ظهور الذكاء الاصطناعي.
فالأفلام ،على سبيل املثال ،كانت دائمً ا تخلُق أوهامً ا ،والصحف كانت تنشر الدعاية
جنب مع إمكانيات وبيئة الإنترنت
الكاذبة .ولكن بعد ظهور الذكاء الاصطناعي ،جنبًا إلى ٍ
ووسائل التواصل الاجتماعي الرقمية ،يبدو أن املشكلة تزداد تعقيدًا وحِ د َّة .ويبدو أن
هناك املزيد من ُ
الف َرص للتلاعُ ب ،مما يعرض التفكري النقدي للخطر .وكل هذا يُذكرنا مرة
أخرى بخطورة الشمولية ،التي تستفيد من ا ْلتباس الحقيقة وتنتج أخبا ًرا زائفة لأغراض
أيديولوجية.
ومع ذلك ،حتى في اليوتوبيا الليبرالية قد لا تكون الحياة غاية في الإشراق والبهاء .إذ
إن املعلومات الكاذبة تنخر في جدار الثقة ومن ثَم تفسد النسيج الاجتماعي .ويُمكن أن
ُ
التواصل ،أو على الأقل التواصل الهادف،
يؤدي الاستخدام ا ُملفرط للتكنولوجيا إلى تقليل
بني الأفراد .في عام ،٢٠١١قدمت شريي تريكل ادعاءً يتعلق بالتكنولوجيا مثل أجهزة
الكمبيوتر والروبوتات :لقد انتهى بنا الأمر إلى ُّ
توقع املزيد من التكنولوجيا ،والقليل من
أنفسنا .ويمكن ً
أيضا استخدام هذه الحج َّ ة فيما يتعلق بالذكاء الاصطناعي :تكمُن املشكلة
في أن الذكاء الاصطناعي ،في شكل وسائل التواصل الاجتماعي أو في شكل »الرفاق«
الرقميني ،يُعطينا ْ
وهم الرفقة ولكنه يُزعزع استقرار العلاقات الحقيقية مع الأصدقاء
والأحباء والعائلات .وعلى الرغم من أن هذه املشكلة كانت موجود ًة بالفعل قبل الذكاء
ٍ
وسيط جديد من الوسائط )قراءة الصحف أو
الاصطناعي وتزداد تفاقمً ا مع ظهور كل
مشاهدة التلفيزيون ً
بدلا من التحد ُّث وإدارة حوار( ،فإنه يمكن القول إن التكنولوجيا
ري في خلق ْ
وهم الرفقة،
الآن ،في وجود الذكاء الاصطناعي وتطبيقه ،قد أصبحت أفضل بكث ٍ
وأن هذا يزيد من خطر الوحدة أو تدهور العلاقات الشخصية.
السلامة والأمان
هناك ً
أيضا مخاطر أوضح .فالذكاء الاصطناعي ،لا سي َّما في حال تضمينه في أنظمة
أيضا إلى أن يكون آمنًا .ولنضرب ً
الأجهزة التي تعمل في العا َلم الفعلي ،يحتاج ً
مثلا على
ذلك بالروبوتات الصناعية :يفترض ألا تُلحِ ق هذه الروبوتات الأذى بالعمال .ومع ذلك،
تحدث أحيانًا حوادث في املصانع .ويمكن للروبوتات أن تقتُل ،حتى لو كان ذلك ناد ًرا
نسبيٍّا .ومع ذلك ،في الروبوتات التي ِ
تعتمد على الذكاء الاصطناعي ،تُصبح مشكلة السلامة
جنب مع البشر ،وقد تتم َّكن
أكثر تح ِّديًا :فهذه الروبوتات قد تتم َّكن من العمل جنبًا إلى
ٍ
أخلاقيات الذكاء الاصطناعي

نحو ذكي« .ولكن ماذا يعني ذلك بالضبط؟ هل يجب
من تجن ُّب إلحاق الأذى بالبشر »على ٍ
ً
قريبة من البشر ،مما يُبطئ العملية ،أم أنه من املقبول
أن تتحرك ببطءٍ أكبر عندما تكون
ٍ
بسرعة عالية من أجل إنجاز العمل بكفاءة وسرعة؟ هناك دائمً ا احتمالات لحدوث
التحرك
خطأ من نوع ما .فهل يجب أن تنطوي أخلاقيات السلامة على الوصول إلى حلول وسط؟
تُثري الروبوتات املدعومة بالذكاء الاصطناعي في بيئة املنزل أو في الأماكن العامة ً
أيضا
قضايا تتع َّلق بالسلامة .على سبيل املثال ،هل يجب على الروبوت دائمً ا تجن ُّب الاصطدام
ً
شخصا من أجل الوصول إلى هدفه؟
بالبشر أم أنه من املقبول أحيانًا أن يُعرقل الروبوت
هذه ليست مسائل تقنية بحتة ولكن لها جانب أخلاقي :إنها مسألة حياة بشرية و ِقيَم مثل
ٍ
مشكلات تتع َّلق باملسئولية )سنتحدث عن هذا بتفصيل
الحرية والكفاءة .كما أنها تُثري
أكثر ً
لاحقا(.
ثم َّ ة مشكلة أخرى كانت موجودة بالفعل قبل ظهور الذكاء الاصطناعي في املشهد،
 ُّ
تستحق تجديد اهتمامنا بها؛ ألا وهي مشكلة الأمان .في عالم مُتصل بالشبكات،
ولكنها
يمكن اختراق أي جهاز إلكتروني أو برنامج واختراقه والتلاعُ ب به من قبل أشخاص لديهم
نوايا خبيثة .فك ُّلنا نعلم بشأن فريوسات الكمبيوتر ،على سبيل املثال ،التي يمكن أن تُخ ِّرب
جهاز الكمبيوتر الخاص بك .ولكن عند تزويد أجهزتنا وبرامجنا بالذكاء الاصطناعي،
ٍ
بوكالة أخلاقية أكبر ويكون لهذا
يمكن أن تزيد إمكانياتها وقدراتها ،وعندما تحظى
عواقب مادية في العالم الفعلي ،تُصبح مشكلة الأمان أكبر بكثري .على سبيل املثال ،إذا
ُ
اختر َقت سيارتك الذاتية القيادة التي تعمل بالذكاء الاصطناعي ،فسوف تُعاني مما هو
أكثر من مجرد »مشكلة في الكمبيوتر« أو »مشكلة في البرنامج«؛ قد تلقى حتفك .وإذا
اخترق برنامج إحدى البَنى التحتية املهمة )مثل الإنترنت ،أو املياه ،أو الطاقة ... إلخ( أو
ُِ
ٍ
اضطراب
قدرات مدمرة ،فمن املرج َّ ح أن يتعرض املجتمع بأكمله إلى
جهاز عسكري ذي
ٍ
كبري وسوف يتعرض الكثري من الأشخاص للضرر .في التطبيقات العسكرية ،يش ِّكل
استخدام الأسلحة الفتاكة الذاتية التشغيل خطورة أمنية واضحة ،لا سي َّما على ا ُملستهدَفني
بالطبع بهذه الأسلحة )وعادة ما لا يكونون من الغرب( ولكنه يش ِّكل خطورة ً
أيضا على
أولئك الذين ينشرونها :إذ يمكن دائمً ا اختراقها وتحويلها ضدهم .علاو ًة على ذلك ،قد
حرب عاملية جديدة .ولا يلزمنا أن ننظر
يؤدي سباق التس ُّلح الذي يشمل هذه الأسلحة إلى
ٍ
بعيدًا في ا ُملستقبل :فإذا كانت الطائرات دون طيار )غري ا ُملزودة بالذكاء الاصطناعي(
مطار كبري في لندن ،فإنه ليس من الصعب تخي ُّل مدى
يُمكنها بالفعل حاليٍّا السيطرة على
ٍ
الخصوصية وغريها من القضايا

هشاشة منشآت ِبنيتنا الأساسية اليومية وكيف يمكن للاستخدام املؤذي أو لاختراق الذكاء
ً
تدمريية هائلة .لاحظ ً
ٍ
ٍ
أيضا أنه ،على
وعمليات
اضطرابات جسيمة
الاصطناعي أن يُسبب
عكس التكنولوجيا النووية على سبيل املثال ،فإن استخدام تكنولوجيا الذكاء الاصطناعي
ً
طويلا؛ ومِن ثَم فالعائق أمام استخدام
الحالية لا يتط َّلب معد َّات باهظة الثمن أو تدريبًا
لأغراض خبيثة مُنخفض نسبيٍّا.
الذكاء الاصطناعي
ٍ
تُذكرنا ً
أيضا املشكلات العادية املتعلقة بالأمان مع السيارات ومنشآت البنية التحتية
ً
عرضة للخطر من غريهم،
مثل املطارات بأنه على الرغم من أن بعض الأشخاص أكثر
ٍ
تقنيات مثل الذكاء الاصطناعي لأننا ،مع زيادة
فإننا »جميعً ا« مُع َّرضون للخطر في ظ ِّل
تمت ُّع هذه التقنيات بالوكالة وزيادة تفويضنا لها لتأدية املزيد من املهام ،نُصبح جميعً ا
أكثر اعتمادًا عليهم .وهناك احتما ٌل دائم أن تسري الأمور على غري ما نروم .ومن ثَم ،يُمكننا
القول إن املخاطر التكنولوجية الجديدة ليست مجرد مخاطر تكنولوجية ،وإنما تتجاوز
ذلك لتُصبح مخاطر تهد ِّد وجودنا بصفتنا بشرًا ) .(Coeckelbergh 2013يمكن رؤية
املشكلات الأخلاقية املطروحة هنا على أنها مخاطر إنسانية :فاملخاطر التكنولوجية تُهدد
كبشر في نهاية املطاف .وبقدْر ما نعتمد على الذكاء الاصطناعي ،وبقدْر ما يكون
وجودنا
ٍ
الذكاء الاصطناعي أكثر من مجرد أدا ٍة نستخدمها؛ فإنه يُصبح جزءًا من هويتنا ومن
املخاطر التي تحيق بنا في العالم.
في عال ٍم مُتصل بالشبكات ،يمكن اختراق أي جهاز إلكتروني أو برنامج واختراقه والتلاعُ ب به من
قبل أشخاص لديهم نوايا خبيثة.

كذلك يُثري تمت ُّع الذكاء الاصطناعي بالوكالة الأخلاقية ،لا سيما إذا كانت تح ُّل مح َّل
ً
أهمية مع مرور الوقت :ألا وهي
الوكالة الأخلاقية البشرية ،مشكلة أخلاقية أخرى تزداد
املسئولية .وهذا هو موضوع الفصل القادم.
الفصل الثامن

ُ
لامسئولية الآلات والقرارات غير المُبررة
كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟
نواج ُه
عند استخدام الذكاء الاصطناعي لاتخاذ قرارات وللقيام بأشياء بالنيابة عن َّا ،فإننا ِ
ً
أهمية عندما يُم ِّكننا
مشكلة مشتركة في جميع تقنيات الأتمتة ،غري أن هذه املشكلة تزداد
ري مما كنا
الذكاء الاصطناعي من تفويض املزيد واملزيد من القرارات إلى الآلات أكثر بكث ٍ
نفعل في املاضي :وهذه املشكلة هي إسناد املسئولية 1 .إذا مُنح الذكاء الاصطناعي وكالة
أكبر وأخذ على عاتقه ما كان َّ
يتولاه البشر في املاضي ،فكيف نُسند املسئولية الأخلاقية عن
أفعاله؟ مَ ن املسئول عن الأضرار والفوائد التي تنشأ عن التكنولوجيا عندما يفوض البشر
 ُّ
يخص املخاطر تحديدًا :مَ ن املسئول عند
الوكالة والقرارات إلى الذكاء الاصطناعي؟ وفيما
حدوث خطأ ما؟
عندما يقوم َ
البشر بأداء مها َّم واتخاذ قرارات ،فنحن عاد ًة ما نربط الوكالة باملسئولية
الأخلاقية .فأنت مسئول عما تفعله وعن القرارات التي تت َّخذها .وإذا كان لدَيك تأثري على
العالم وعلى الآخرين ،فأنت مسئول عن عواقب أفعالكً .
وفقا لأرسطو ،هذا هو الشرط الأول
للمسئولية الأخلاقية ،املعروف باسم الشرط التح ُّكمي :في الأخلاقيات النيقوماخية ،يقول
أرسطو إن الفعل يجب أن ينشأ من الفاعل .ولهذا الرأي ً
أيضا جانب تقييمي :إذا كان
لديك وكالة وإذا َ
كنت قاد ًرا على اتخاذ قرارات ،فينبغي أن تتحم َّ ل املسئولية عن أفعالك.
وما نريد تجن ُّبه من الناحية الأخلاقية هو أن يُوجَ د شخص يتمتع بالوكالة والقدرة ولكنه
طا َ
أيضا شر ً
لا يتحمل املسئولية .أضاف أرسطو ً
آخر فيما يخص املسئولية الأخلاقية :أنت
مسئول إذا كنت تعلم ما تفعله .وهذا شرط إدراكي :يجب أن تكون واعيًا بما تفعل وعلى

أخلاقيات الذكاء الاصطناعي

دراية بعواقبه املحتملة .وما نحتاج إلى تجن ُّبه هنا هو شخص تصدُر عنه أفعال لا يدري
ماهيتها ،وهو ما قد يؤدي في النهاية إلى عواقب وخيمة.
ً
وكالة أكبر وأخذ على عاتِقِ ه ما كان َّ
يتولاه البشر في املاضي ،فكيف نُسند
إذا ُمنِح الذكاء الاصطناعي
املسئولية الأخلاقية عن أفعاله؟

 َّ
تتحقق هذه الشروط عند تفويض القرارات والأعمال إلى الذكاء
الآن دعونا نرى هل
ً
ٍ
أفعالا
قرارات ويؤدي
الاصطناعي .املشكلة الأولى هي أن الذكاء الاصطناعي يمكن أن يت َّخذ
لها عواقب أخلاقية ،ولكنه لا يُدرك ما يفعله وغري قادر على التفكري الأخلاقي وبالتالي لا
ً
مسئولا من الناحية الأخلاقية عما يفعله .يمكن أن تتمت َّع الآلات بالوكالة
يُمكن اعتباره
ولكن ليس بالوكالة الأخلاقية؛ لأنها تفتقِ ر إلى الوعي والإرادة الحرة والعواطف ُ
والقدرة
على تكوين النوايا وما شابَ َه ذلك .على سبيل املثالً ،
وفقا لرؤية أرسطو ،يمكن للبشر
فقط أداء الأفعال التطو ُّعية والتفكري في أفعالهم .إذا كان هذا صحيحً ا ،فإن الح َّل الوحيد
هو جعْ ل البشر مسئولني عما تفعله الآلة .ومن ثَم فإن البشر يُفو ِّضون الوكالة إلى الآلة،
ولكنهم يحتفِ ظون باملسئولية .ونحن نفعل ذلك بالفعل في أنظمتنا القانونية؛ إذ إننا لا
عتبر الكلاب أو الأطفال الصغار مسئولني عن أفعالهم ،ولكننا نضع املسئولية القانونية
نَ ِ
ً
ٍ
شخص ما
مهمة معينة إلى
مؤسسة ما ،قد نُفو ِّض
على عاتق مَ ن يتو َّلون رعايتهم .وفي
ٍ
ولكننا نُحم ِّ ل املسئولية للمدير املسئول عن املشروع العام ،على الرغم من أن الشخص
ا ُملفوض في هذه الحالة يتحم َّ ل جزءًا من املسئولية 2 .إذَن ملاذا لا نسمح للآلة بأداء الأعمال
ونحتفظ باملسئولية على الجانب البشري؟ يبدو أن هذه هي أفضل وسيلة نمضي بها قدمً ا،
حيث إن الخوارزميات والآلات بلا مسئولية.
يواجه هذا الح ُّل عدة مشكلات في حالة الذكاء الاصطناعيً .
أولا ،يمكن
ومع ذلك،
ِ
 َّ
للنظام املزو َّد بالذكاء الاصطناعي أن يتخذ قراراته ويؤدي أفعاله بسرعة كبرية للغاية،
على سبيل املثال ،في التداول العالي الترد ُّد أو في السيارات الذاتية القيادة ،مما يحرم
 ُّ
التدخل في الفعل .فكيف يُمكن للبشر
الإنسان من الوقت الكافي لاتخاذ القرار النهائي أو
أن يتحم َّ لوا املسئولية عن مثل هذه الأفعال والقرارات؟ ثانيًا ،لأنظمة الذكاء الاصطناعي
تطبيق مُعني ،فربما يُصبح من
تواريخ .عندما يقوم الذكاء الاصطناعي بأشياء في سياق
ٍ
ُ
لامسئولية الآلات والقرارات غري ا ُملبررة

غري الواضح مَ ن أنشأه ،ومَ ن استخدمه ً
أولا ،والكيفية التي يجب بها توزيع املسئولية بني
هذه الأطراف املختلفة املعنية .على سبيل املثال ،في حالة إنشاء خوارزمية ذكاء اصطناعي
مشروع علمي في الجامعة ،ثم تطبيق هذه الخوارزمية للمرة الأولى في ا ُملختبر في
في سياق
ٍ
الجامعة ،ثم في قطاع الرعاية الصحية ،وفي ٍ
سياق عسكري .فمَ ن يتحم َّ ل
وقت لاحق في
ٍ
املسئولية؟ قد يكون من الصعب تتب ُّع جميع البشر املتو ِّرطني في تاريخ هذه الخوارزمية
ٍ
نتيجة معي َّنة تَ ِ
حمل إشكالية أخلاقية .فنحن لا
بالذات ،بل في التاريخ السببي الذي أد َّى إلى
نعرف دائمً ا جميع الأشخاص ا َملعني ِّني في اللحظة التي تُثار فيها مشكلة تتعلق باملسئولية.
فخوارزمية الذكاء الاصطناعي غالبًا ما يكون لها تاريخ طويل يشارك فيه العديد من
الأشخاص .وهذا يُفضي بنا إلى مشكلة نمطية في إسناد املسئولية عن الأفعال التكنولوجية؛
إذ غالبًا ما يكون هناك الكثري من الأطراف ويُمكنني أن أضيف ،الأشياء.
هناك الكثري من الأطراف بمعنى أن الكثري من الأشخاص يشاركون في الفعل
التكنولوجي .في حالة الذكاء الاصطناعي ،يبدأ الأمر باملبرمج ،ولكن لدينا ً
أيضا املستخدم
النهائي وآخرون .دعونا نفكر ً
مثلا في السيارة الذاتية القيادة :هناك املبرمج ،ومُستخ ِد ُم
السيارة ،وأصحابُ شركة السيارات ،واملستخدِمون الآخرون للطريق ،وهكذا .في مارس
ٍ
حادث في أريزونا أد َّى إلى وفاة أحد
 ،٢٠١٨تسب َّبَت سيارة ذاتية القيادة لشركة أوبر في
ا ُملشاة .فمَ ن املسئول عن هذه النتيجة املأساوية؟ يمكن أن يكون املسئولون هم مَ ن
برمجوا السيارة ،والأشخاص املسئولني عن تطوير املنتج في الشركة ،وشركة أوبر نفسها،
ومستخدم السيارة ،والشخص السائر ،واملشرع )على سبيل املثال ،ولاية أريزونا( ،وهكذا.
إذَن فليس من الواضح على مَ ن تقع املسئولية .قد يكون الأمر هو أن املسئولية لا يمكن
شخص واحد؛ وربما تقع على أكثر من شخص .ولكن هذا يعني
ولا يجب إسنادها إلى
ٍ
أنه ليس من الواضح كيفية توزيع املسئولية .فقد تقع املسئولية على بعضهم أكثر من
الآخرين.
هناك ً
أيضا الكثري من الأشياء ،بمعنى أن النظام التكنولوجي يتألف من العديد
من العناصر املتصلة؛ وعاد ًة ما يكون هناك العديد من املكونات التي تدخل في النظام.
هناك خوارزمية الذكاء الاصطناعي ،ولكن هذه الخوارزمية تتفاعل مع أجهزة استشعار،
وتستخدم جميع أنواع البيانات ،وتتفاعل مع جميع أنواع املكونات املادية والبرمجية.
كل هذه الأشياء لها تاريخها ومتصلة بالأشخاص الذين برمجوها أو أنتجوها .وعندما
يحدُث خطأ ،لا يكون واضحً ا لنا بالضرورة ما إذا كان »الذكاء الاصطناعي« هو الذي
أخلاقيات الذكاء الاصطناعي

سب َّب املشكلة أم مُكو ِّن َ
آخر من مكونات النظام؛ بل إننا لا نعرف بالضرورة أين تنتهي
مسئولية الذكاء الاصطناعي وتبدأ مسئولية بقية املكونات التكنولوجية .وهذا يجعل من
الصعب إسناد املسئولية وتوزيعها .دعونا نفكر ً
أيضا في تعلم الآلة وعلم البيانات :كما
رأينا ،ليس هناك فقط خوارزمية ،ولكن ً
أيضا عملية تشمل مراحل مختلفة مثل جمع
البيانات ومعالجتها ،وتدريب الخوارزمية ،وهكذا؛ وجميع هذه املراحل يدخل فيها عناصر
تقنية مختلفة وتتط َّلب قرارات بشرية .مرة أخرى ،هناك تاريخ سببي يشترك فيه الكثري
من البشر والأجزاء ،وهذا يجعل إسناد املسئولية أم ًرا صعبًا.
لكي نُحاول التعامل مع هذه القضايا ،يمكننا أن نتعلم من الأنظمة القانونية أو
نلقي نظرة على كيفية عمل التأمني؛ وسوف أتحد َّث عن بعض املفاهيم القانونية في
الفصول املتعلقة بالسياسة .ولكن ثم َّ ة أسئلة أكثر عمومية تلوح لنا من وراء هذه الأنظمة
القانونية وأنظمة التأمني حول وكالة الذكاء الاصطناعي واملسئولية عنه :إلى أي مدى
نريد أن نعتمد على تقنية الأتمتة ،وهل يُمكننا أن نتحمل املسئولية عما يقوم به الذكاء
الاصطناعي ،وكيف يُمكننا إسناد املسئوليات وتوزيعها؟ على سبيل املثال ،مفهوم الإهمال
في القانون يتع َّلق بما إذا كان الشخص قد أد َّى ما عليه من واجب العناية .ولكن ماذا يعني
ً
خاصة أنه من الصعب التنب ُّؤ بجميع العواقب
هذا الواجب في حالة الذكاء الاصطناعي،
الأخلاقية ا ُملحتملة؟
وهذا يقودنا إلى القضية التالية .حتى إذا ت َّم ح ُّل مشكلة التحكم ،فهناك الشرط
الثاني للمسئولية الأخلاقية ،والذي يتع َّلق بمشكلة املعرفة .لكي تتحم َّ ل املسئولية ،يجب
أن تعرف ما تفعله والنتائج ا ُملترت ِّبة على فعلك ،وفيما بعد ،تعرف ما َ
قمت به .وبالإضافة
 َّ
نتوقع أن يتمكن الشخص من
إلى ذلك ،هذه املسألة لها جانب سردي :في حالة البشر،
شرح ما قام به أو ق َّر َره .املسئولية إذَن تعني القدرة على الرد والتفسري .فإذا حدث خطأ
ما ،فنحن نريد ردٍّا وتفسريًا .على سبيل املثال ،نطلب من القاضي أن ي ِّ
ُفسر قراره ،أو
ً
إشكالية للغاية في حالة الذكاء
نسأل الجاني ملاذا فعل ما فع َله .وهذه الشروط تُصبح
الاصطناعيً .
أولا ،من حيث املبدأ ،لا »يعرف« الذكاء الاصطناعي في الوقت الحاضر ما
يفعله ،بمعنى أنه ليس واعيًا وبالتالي لا يدرك ما يقوم به ولا يدرك نتائج أفعاله .يمكنه
تخزين ما يفعله وتسجيله ،ولكنه لا »يعرف ما يقوم به« كما يفعل البشر ،الذين يُدركون،
بوصفهم كائنات واعية ،ما يفعلون ويمكنهم — ً
وفقا لأرسطو مرة أخرى — التفكري
والتأمل في أفعالهم وعواقب تلك الأفعال .وعندما لا تُلب َّى هذه الشروط في حالة البشر ،على
ُ
لامسئولية الآلات والقرارات غري ا ُملبررة

سبيل املثال ،في حالة الأطفال الصغار جدٍّا ،فإننا لا نحم ِّ لهم املسئولية .وكذلك عاد ًة ما لا
نُحم ِّ ل الحيوانات املسئولية ً
أيضا 3 .وإذا لم يُلب ِّ الذكاء الاصطناعي هذه الشروط ،فإننا لا
نستطيع أن نُحم ِّ له املسئولية .والحل مرة أخرى هو تحميل املسئولية للبشر عن أعمال
الذكاء الاصطناعي ،على افتراض أنهم يعرفون ما يقوم به الذكاء الاصطناعي وما يفعلونه
باستخدام الذكاء الاصطناعي — وبمراعاة الجانب السردي — وأنهم قادرون على الر ِّد عن
أفعاله ويُمكنهم تفسري ما قام به الذكاء الاصطناعي.
ومع ذلك ،فإن مدى صحة هذا الافتراض ليس أم ًرا من السهل تقريره كما قد يبدو
للوهلة الأولى .عاد ًة ما يعرف املبرمجون واملستخدمون ما الذي يرغبون في القيام به
باستخدام الذكاء الاصطناعي ،أو َّ
بدقة أكبر :يعرفون ما يريدون من الذكاء الاصطناعي
أن يفعله لهم .إنهم يعرفون الهدف النهائي؛ ولهذا السبب يفو ِّضون املهمة إلى الذكاء
الاصطناعي .وقد يكونون ً
بشكل عام .ولكن،
أيضا على دراية بكيفية عمل التكنولوجيا
ٍ
كما سنرى ،هم لا يعرفون َّ
بدق ٍة دائمً ا ما يفعله الذكاء الاصطناعي )في أي لحظة( ولا
يُمكنهم دائمً ا تفسري ما فعله أو كيف وصل إلى قراره.
الشفافية والقابلية للتفسري
نحن نواجه هنا مشكلة الشفافية والقابلية للتفسري .في بعض أنظمة الذكاء الاصطناعي،
تكون الطريقة التي يستخدمها الذكاء الاصطناعي لاتخاذ قراره واضحة .على سبيل املثال،
إذا كان الذكاء الاصطناعي يستخدم شجرة اتخاذ القرارات ،فإن الطريقة التي يصل بها
إلى قراره تكون واضحة .فقد تم َّ ت برمجتُه بطريقة تُحد ِّد القرار ،بناءً على مدخلات
مُعي َّنة .وبالتالي يمكن للبشر تفسري كيف وصل الذكاء الاصطناعي إلى قراره ،ويمكن أن
»نطلُب« من الذكاء الاصطناعي أن »يُفسر« قراره .بعد ذلك ،يمكن للبشر تحم ُّ ل مسئولية
القرار أو ،على الأحرى ،اتخاذ قرار بناءً على التوصية التي قد َّمَ ها الذكاء الاصطناعي.
ومع ذلك ،مع بعض أنظمة الذكاء الاصطناعي الأخرى ،ولا سيما تلك التي تستخدم تع ُّلم
الآلة وخاصة التع ُّلم العميق الذي يستخدم الشبكات العصبية ،لم يعُ د من املمكن للإنسان
ٍ
قرارات من هذا النوع .حيث لم يعُ د واضحً ا كيف يصل
تقديم هذا التفسري أو اتخاذ
الذكاءُ الاصطناعي إلى قراره ،وبالتالي لا يُمكن َ
بشكل كامل .إنهم
للبشر تفسري القرار
ٍ
قرار َّ
معني.
يعرفون كيف يعمل النظام الخاص بهم،
ٍ
بشكل عام ،ولكن لا يُمكنهم تفسري ٍ
ولنضرب ً
مثلا بلعبة الشطرنج املزودة بالتع ُّلم العميق :يعرف املبرمجون كيف يعمل الذكاء
أخلاقيات الذكاء الاصطناعي

ٍ
حركة معي َّنة )أي
الاصطناعي ،ولكن الطريقة الدقيقة التي يصل من خلالها الجهاز إلى
ما يحدث في طبقات الشبكة العصبية( ليست واضحة ولا يمكن تفسريها .وهذه مشكلة
 ُّ
يخص تحم ُّ ل املسئولية ،حيث لا يستطيع البشر الذين يُنشئون الذكاء الاصطناعي أو
فيما
يستخدمونه تفسري قرار معني ،وبالتالي يفشلون في معرفة ما يقوم به الذكاء الاصطناعي
ولا يُمكنهم تبرير أفعالهِ .
فمن ناحية ،يعرف البشر ما الذي يقوم به الذكاء الاصطناعي
)على سبيل املثال ،يعرفون الرموز البرمجية الخاصة بالذكاء الاصطناعي ويعرفون كيف
بشكل عام( ،ولكن من ناحية أخرى ،هم لا يعرفون )لا يُمكنهم تفسري قرار
يعمل
ٍ
 َّ
معني( ،وتكون نتيجة ذلك أن البشر الذين يتأثرون بالذكاء الاصطناعي لا يمكن إعطاؤهم
 ُّ
ٍ
التوقع .وبالتالي ،على الرغم
معلومات دقيقة حول ما الذي دفع الآلة إلى الوصول إلى هذا
ً
مشكلة
من أن كل تكنولوجيا الأتمتة تُثري مشكلات فيما يتعلق باملسئولية ،فإننا هنا نواجه
 ُّ
تخص بعض أنواع الذكاء الاصطناعي؛ وهي ما يط َلق عليها مشكلة الصندوق الأسود.
ً
ٍ
بمعرفة حول
علاوة على ذلك ،حتى الافتراض بأن البشر في مثل هذه الحالات يتمتعون
بشكل عام وحول رموزه البرمجية ليس دائمً ا صحيحً ا .فعلى الأرجح
الذكاء الاصطناعي
ٍ
يعرف املبرمجون الأصليون الرموز البرمجية وكيفية عمل كل شيءٍ )أو على الأقل يعرفون
الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين
ٍ
لتطبيقات محد َّدة يعرفون تمامً ا ما يفعله الذكاء
يُغريون الخوارزمية أو يستخدمونها
الاصطناعي .على سبيل املثال ،قد لا يفهم الشخص الذي يستخدم خوارزمية التداول الذكاء
الاصطناعي تمام املعرفة ،أو قد لا يعرف مُستخدمو وسائل التواصل الاجتماعي حتى
أن الذكاء الاصطناعي يُستخدَم ،فما بالك بأن يفهموه .ومن جهة املبرمِجني )الأصليني(،
نحو دقيق الاستخدام »ا ُملستقبلي« للخوارزمية التي يُطورونها
فهم قد لا يعرفون على ٍ
أو مختلف مجالات التطبيق التي يُمكن استخدامها فيها ،فما بالك بك ِّل الت ِبعات غري
 ِّ
بغض النظر عن املشكلة
املقصودة للاستخدام ا ُملستقبلي لهذه الخوارزمية .لذلك ،حتى
الخاصة بتع ُّلم الآلة )التعلم العميق( ،هناك مشكلة تتع َّلق باملعرفة لدرجة َّ
أن الكثريين مم َّ ن
يستخدمونه لا يعرفون ما يفعلون؛ لأنهم لا يعرفون ما الذي يفعله الذكاء الاصطناعي،
وما هي تأثرياته ،أو حتى أنه مُستخدَم من الأساس .وهذه ً
 ُّ
يخص جانب
أيضا مشكلة فيما
املسئولية ،وبالتالي فهي مشكلة أخلاقية خطرية.
في بعض الأحيان ،يتم تسليط الضوء على هذه املشكلات في سياق الثقة :فغياب
الشفافية يؤدي إلى غياب الثقة في التكنولوجيا وفي الأشخاص الذين يستخدمون هذه
ُ
لامسئولية الآلات والقرارات غري ا ُملبررة

التكنولوجيا .لذلك يسأل بعض الباحثني كيف يُمكننا زيادة الثقة في الذكاء الاصطناعي،
كعامل من العوامل التي يمكن أن تزيد من
ويُحد ِّدون الشفافية والقابلية للتفسري
ٍ
ً
فضلا عن تجن ُّب التحي ُّز ) (Winikoff 2018أو صور الذكاء الاصطناعي ا ُملرعبة
الثقة،
)»ترمينيتور«( ) .(Siau and Wang 2018وكما سنرى في الفصل القادم ،غالبًا ما تهدف
سياسات الذكاء الاصطناعي ً
أيضا إلى بناء الثقة .ومع ذلك ،فإن مصطلحات مثل الذكاء
يجب أن نحتفظ
الاصطناعي »الجدير بالثقة« مُثرية للجدل؛ إذ تجعلنا نتساءل هل ِ
بمصطلح »الثقة« للحديث عن العلاقات الإنسانية ،أم يمكن استخدامه للحديث عن الآلات
ً
أيضا؟ تقول جوانا برايسون ) ،(٢٠١٨الباحثة في مجال الذكاء الاصطناعي ،إن الذكاء
الاصطناعي ليس شيئًا يمكن الوثوق به ولكنه مجموعة من تقنيات تطوير البرامج؛ ومن
ثَم فهي تعتقد أن مصطلح »الثقة« يجب أن ي َ
ُحتفظ به للحديث عن البشر ومؤسساتهم
ٍ
تساؤلات حول نوع
الاجتماعية .وعلاو ًة على ذلك ،يُثري موضوع الشفافية والقابلية للتفسري
املجتمع الذي نرغب في العيش فيه .فهنا لا يكمُن الخطر في مجرد تلاعُ ب الرأسماليني أو
النخب التكنوقراطية وهيمنتهم ،مما يخلق مجتمعً ا يُعاني من الانقسام إلى ح ٍّد كبري .وإنما
مجتمع عالي التقنية،
يتمثل الخطر الأكبر وربما الأعمق الذي يَحيق بنا في أن نعيش في
ٍ
مجتمع لا تعود فيه حتى هذه النخب قادر ًة على معرفة ما تفعله ،مجتمع لا يستطيع فيه
أح ٌد أن ي ِّ
ُفسر ما يحدث.
كما سنرى ،يقترح صانعو السياسات في بعض الأحيان »الذكاء الاصطناعي القابل
للتفسري« و»حق التفسري« .إلا إننا لا ندري إن كان من ا ُملمكن أن يكون الذكاء الاصطناعي
ً
ً
ُستحيلا
شفافا طوال الوقت .يبدو هذا سه َل التحقيق في الأنظمة الكلاسيكية .ولكن إذا بدا م
من حيث املبدأ شرح ك ِّل خطوة في عملية اتخاذ القرار وشرح القرارات ا ُملتعلقة بأفراد
مُحد َّدين مع تطبيقات تعلم الآلة ا ُملعاصرة ،فلدَينا مشكلة إذَن .هل من املمكن »فتح
الصندوق الأسود«؟ قد يكون هذا شيئًا جيدًا ،ليس فقط للأخلاق ولكن ً
أيضا لتحسني
النظام )أي ،النموذج( والتع ُّلم منه .على سبيل املثال ،إذا كان النظام أكثر قابلية للتفسري،
ٍ
سمات غري ملائمة ،عندئ ٍذ يمكن للبشر
وإذا كان الذكاء الاصطناعي يَستخدِم ما نعتبره
اكتشاف هذه املشكلات واملساعدة في القضاء على الارتباطات الزائفة .وإذا كان الذكاء
الاصطناعي يُحدد استراتيجيات جديدة ُملمارسة لعب ٍة ويجعل هذه الاستراتيجيات أكثر
شفافية للبشر ،عندئ ٍذ يمكن للبشر تع ُّلمها من الآلة لتحسني أدائهم في اللعبة .وهذا مُفيد
ليس فقط في مجال الألعاب ،ولكن ً
أيضا في مجالات ِمثل الرعاية الصحية والعدالة الجنائية
أخلاقيات الذكاء الاصطناعي
والعلوم .لذلك ،يُحاول بعض الباحثني تطوير تقنيات لفتح الصندوق الأسود )Samek,

 .(Wiegand, and Müller 2017ولكن إذا لم يكن ذلك مُمكنًا بع ُد أو كان مُمكنًا بدرجة
محدودة ،فكيف لنا أن نمضي قدمً ا؟ هل تتع َّلق املشكلة الأخلاقية هنا بالاختيار بني الأداء
وإمكانية التفسري )(Seseri 2018؟ وإذا كانت تكلفة إنشاء نظام ذي أداءٍ جيد هي نقص
يجب علينا استخدام مثل هذا النظام ،أم لا؟ أم يجب أن نُحاول تجن ُّب
في الشفافية ،فهل ِ
هذه املشكلة والبحث عن حلول تقنية أخرى ،بحيث تكون حتى أنظمة الذكاء الاصطناعي
الأكثر تقدمً ا قادر ًة على تبرير أفعالها للبشر؟ هل يُمكننا تدريب الآلات على القيام بذلك؟
علاو ًة على ذلك ،حتى إذا كانت الشفافية مرغوبة ومُمكنة ،فقد يكون من الصعب
تحقيقها عمليٍّا .على سبيل املثال ،ربما لا تكون الشركات الخاصة على استعدادٍ للكشف
عن خوارزمياتها؛ لأنها ترغب في حماية مصالحها التجارية .كذلك قد تحُ ول قوانني امللكية
الفكرية التي تحمي تلك املصالح دون ذلك .وكما سنرى في فصول لاحقة ،إذا كان الذكاء
الاصطناعي في أيدي الشركات القوية ،فإن هذا يُثري السؤال حول مَ ن يصنع قوانني الذكاء
الاصطناعي ومَ ن يجب أن يصنعها.
ومع ذلك ،يجب مراعاة أن الشفافية والقابلية للتفسري من الناحية الأخلاقية لا تتع َّلق
بالضرورة بالكشف عن الرموز البرمجية ،وهي بالتأكيد لا تقتصر على ذلك فحسب.
ً
أساسا بتفسري القرارات للبشر .إنها لا تتع َّلق في املقام الأول بتفسري »كيف
املسألة تتع َّلق
 َّ
ً
مسئولا
املتوقع منه أن يكون
يعمل« وإنما تتع َّلق بكيف يُمكنني أنا ،بوصفي إنسانًا من
ويتصر َّف بمسئولية ،تفسري قراري .ويُمكن أن تكون كيفية عمل الذكاء الاصطناعي،
وكيفية وصوله إلى هذه التوصية ،جزءًا من ذلك التفسري .علاو ًة على ذلك ،فإن الكشف عن
ً
معرفة حول كيفية عمل الذكاء الاصطناعي.
الرموز البرمجية بمُفردها لا يعطي بالضرورة
فهذه املعرفة ِ
تعتمد على الخلفية التعليمية للإنسان ومهاراته .فإذا كان يفتقر إلى الخبرة
نوع َ
آخر من التفسري .وهذا لا يُذ ِّكرنا فحسب بمشكلة
التقنية ذات الصلة ،فإننا نحتاج إلى ٍ
سؤال حول نوع التفسري الذي نحتاجُ ه ،ثم ماهية التفسري في
التعليم ولكنه يؤد ِّي بنا إلى
ٍ
ح ِّد ذاته.
وهكذا تَط َرح قضية الشفافية والقابلية للتفسري ً
أيضا أسئلة فلسفية وعلمية مُثرية
للاهتمام ،مثل الأسئلة املتعلقة بطبيعة التفسري ) .(Weld and Bansal 2018ومما يتألف
التفسري الجيد؟ وما الفرق بني التفسريات والأسباب ،وهل يمكن للآلات تقديم أي منها؟
وكيف يت َّخذ البشر القرارات في الواقع؟ وكيف يُبر ِّرون قراراتهم؟ هناك أبحاث حول هذا
ُ
لامسئولية الآلات والقرارات غري ا ُملبررة

املوضوع في علم النفس املعرفي والعلوم املعرفية ،والتي يُمكن استخدامها للتفكري في الذكاء
ً
سببية كاملة؛
الاصطناعي القابل للتفسري .على سبيل املثال ،لا يُقدم الناس عمومً ا سلاسل
تفسريات ويجيبون عما يعتقدون أنها مُعتقدات الشخص الذي ي ِّ
ٍ
ُفسر لهم:
وإنما يختارون
التفسريات اجتماعية ) .(Miller 2018وربما نتوقع ً
أيضا أن تكون تفسريات الآلات مختلفة
ري من الأحيان بأنها نتيجة للعواطف.
عن تفسريات البشر ،الذين يُبررون أفعالهم في كث ٍ
ولكن إذا فعلنا ذلك ،فهل يعني هذا أننا نعتبر طريقة اتخاذ الآلات للقرارات أفضل من
طريقة اتخاذ البشر لها ) ،(Dignum et al. 2018وإذا كان الأمر كذلك ،فهل يجب أن
نفعل؟ يتحدث بعض الباحثني عن الاستدلال ً
بدلا من التفسري .بل إن وينيكوف )(٢٠١٨
يطلب »الاستدلال بناءً على القِ يَم« من الذكاء الاصطناعي وغريه من الأنظمة ا ُملستقلة ،التي
يجب أن تكون قادر ًة على تمثيل القيم البشرية والاستدلال باستخدام تلك القِ يَم .ولكن هل
يمكن للآلة أن تقوم بالاستدلال ،وكيف يمكن للنظام التكنولوجي »استخدام« القِ يَم أو
»تمثيلها« من الأساس؟ أي نوع من املعرفة يمتلكها هذا النظام؟ وهل يمتلك معرفة من
الأساس؟ وهل يستطيع الفهم من الأساس؟ وكما يسأل بودينجتون ) ،(٢٠١٧هل يمكن
للبشر أن ي ِّ
بشكل كامل عن قي َِمهم الجوهرية؟
ُعبروا
ٍ
مثل هذه املشكلات مُثرية للاهتمام من منظور الفلاسفة ،ولكنها ً
ٍ
صلة
أيضا ذات
مباشرة بالأخلاقيات ،كما أنها واقعية وعملية للغاية .وكما يقول كاستيلفيتشي ):(٢٠١٦
إن فتح »الصندوق الأسود« مشكلة في العا َلم الحقيقي .على سبيل املثال ،يجب على البنوك
أن تُ ِّ
قرض ما؛ ويجب على القضاة تفسري سبب إصدار الأوامر بحبس
فسر سبب رفض ٍ
شخص ما )مر ًة أخرى( .إن تفسري القرارات ليس فقط جزءًا من طبيعة البشر عندما
ٍ
ً
يتواصلون ) ،(Goebel et al. 2018بل هو أيضا مطلب أخلاقي .إن القدرة على التفسري
شرط ضروري للسلوك واتخاذ القرارات بشكل مسئول وقابل للمساءلة .ويبدو أنه
ضروري لأي مجتمع يرغب في احترام البشر بوصفهم أفرادًا مُستقلني اجتماعي ِّني يُحاولون
بشكل مسئول وفي الوقت نفسه يُطالبون ،عن استحقاق،
التصرف واتخاذ القرارات
ٍ
أسباب للقرارات التي تؤثر عليهم وتفسريات لها .وسواءٌ أكان بإمكان
بالحصول على
ٍ
الذكاء الاصطناعي توفري تلك الأسباب والتفسريات »مباشر ًة« أم لا ،فإن البشر لا بد أن
يواجه الباحثني
يكونوا قادرين على الإجابة عند سؤالهم عن الأسباب .إن التحدي الذي
ِ
في مجال الذكاء الاصطناعي هو ضمان أنه في حال استخدام الذكاء الاصطناعي لأغراض
اتخاذ القرارات من الأساس ،فيجب تصميم التكنولوجيا بحيث يتمكن البشر قدْر الإمكان
من الإجابة عند سؤالهم عن أسباب اتخاذ تلك القرارات.
الفصل التاسع

التحيز ومعنى الحياة
التحيز
ً
مشكلة أخرى من املشكلات ذات الجوانب الأخلاقية والاجتماعية في الوقت
يُعد التحي ُّز
 َّ
ً
نفسه ،وهي أيضا تتعلق بالذكاء الاصطناعي القائم على عِ لم البيانات بعيدًا عن غريه من
تقنيات الأتمتة الأخرى .عندما يت َّخذ الذكاء الاصطناعي — أو على الأحرى ،عندما يُوصي
ٍ
منصفة أو غري عادلة تجاه
باتخاذ — قرارات ،قد يُظهر التحي ُّز؛ إذ قد تكون القرارات غري
أفرادٍ أو مجموعات بعينها .وعلى الرغم من أن التحي ُّز قد يظهر ً
أيضا عند استخدام الذكاء
الاصطناعي التقليدي — على سبيل املثال ،نظام خبري يَستخدم شجرة اتخاذ قرارات أو
ً
مرتبطة بتطبيقات تع ُّلم
قاعدة بيانات تتسم بالتحيز — فإن قضية التحيز غالبًا ما تكون
الآلة .وبينما كانت مشكلات التحيز والتمييز موجودة دائمً ا في املجتمع ،إلا أن القلق يكمُن
ُ
وتفاقم آثارها.
في أن يؤدي الذكاء الاصطناعي إلى استمرار هذه املشكلات
بينما كانت مشكلات التحي ُّز والتمييز موجود ًة دائمً ا في املجتمع ،إلا أن القلق يكمُن في أن يؤدي
ُ
وتفاقم آثارها.
الذكاء الاصطناعي إلى استمرار هذه املشكلات

غالبًا ما يكون التحي ُّز غري مقصود؛ فا ُملطو ِّرون واملستخدِمون ،وغريهم من أطراف
ري من الأحيان ،آثار التمييز ض َّد مجموعات أو
مُعنية مثل إدارة الشركة ،لا يتوقعون ،في كث ٍ
أفرادٍ مُعينني .ويمكن أن يكون السبب في ذلك هو عدم فهمهم نظام الذكاء الاصطناعي
بشكل ٍ
كاف بمشكلة التحي ُّز أو حتى بتحي ُّزاتهم الشخصية،
كما ينبغي ،أو عدم وع ِيهم
ٍ

أخلاقيات الذكاء الاصطناعي

بشكل عام عدم تصو ُّرهم وعدم تفكريهم بما فيه الكفاية في العواقب ا ُملحتمَ لة غري
أو
ٍ
ُ
تواصلهم مع بعض الأطراف ذات الصلة .يُعَ د هذا أم ًرا
املقصودة للتكنولوجيا وعدم
إشكاليٍّا نظ ًرا إلى أن القرارات ا ُملتحي ِّزة يمكن أن تكون لها عواقب وخيمة ،على سبيل
املثال ،من حيث الوصول إلى املوارد والتمت ُّع بالحريات )(CDT 2018؛ إذ قد لا يحصل
الأفراد على وظيفة ،أو لا يتم َّكنون من الحصول على ائتمان ،أو قد ينتهي بهم الحال في
ِ
تقتصر على الأفراد فحسب؛ إذ قد تتأثر
السجن ،أو حتى يتع َّرضون للعنف .وا ُملعاناة لا
بأسرها بالقرارات ا ُملتحيزة ،على سبيل املثال ،عندما تُصن َّف منطقة كاملة في
مجتمعات
ِ
املدينة أو جميع الأشخاص مم َّ ن لهم خلفية عرقية مُعي َّنة بواسطة الذكاء الاصطناعي على
أنهم يشكلون خطور ًة أمنية عالية.
ولنعُ د م َّرة أخرى إلى مثال خوارزمية كومباس الذي تحد َّثنا عنه في الفصل الأول،
تلك الخوارزمية التي تتنب َّأ بمدى احتمالية أن يقوم ا ُملد َّعى عليه بإعادة ارتكاب الجريمة
وكان القضاة في فلوريدا يستخدمونها في اتخاذ قراراتهم بشأن إمكانية منح السجني
طاً .
إفراجً ا مشرو ً
ٍ
لدراسة أج َرتْها »بروبابليكا« ،وهي غرفة إخبارية عبر الإنترنت،
وفقا
كانت النتائج الإيجابية الكاذبة للخوارزمية )ا ُملد َّعى عليهم الذين توقعت الخوارزمية أن
ُفرط إلى الأشخاص
يُعيدوا ارتكاب الجرائم ولكنهم في الواقع لم يفعلوا( تميل
ٍ
بشكل م ِ
من ذوي البشرة السمراء ،وكانت النتائج السلبية الكاذبة )ا ُملد َّعى عليهم الذين توقعت
بشكل مُفرط إلى
الخوارزمية ألا يُعيدوا ارتكاب الجرائم ولكنهم في الواقع فعلوا( تميل
ٍ
الأشخاص ذوي البشرة البيضاء ) .(Fry 2018ومِن ثَم رأى َّ
النقاد أن هناك تحي ُّ ًزا ضد
ا ُملد َّعى عليهم من ذوي البشرة السمراء .مثال َ
آخر على ذلك هو أداة »بريدبول« ،وهي
أداة للتنب ُّؤ بالجرائم وقد استُخدِمَ ت في الولايات املتحدة ُّ
ٍ
جريمة
لتوقع احتمالية حدوث
في مناطق مُعي َّنة من املدن وللتوصية بتخصيص موارد الشرطة )على سبيل املثال ،أين
 ُّ
التوقعات.
يجب أن يُجري ضباط الشرطة عمليات التفتيش والتجوال( استنادًا إلى هذه
وتركزت املخاوف في هذا الصدد في أن يكون النظام مُتحي ًزا ضد الأحياء الفقرية وأحياء
ا ُمللو َّنني أو أن تؤدي املراقبة الأمنية ا ُملفرطة إلى كسر الثقة بني الناس في تلك املناطق ،مما
 َّ
تتحقق ذاتيٍّا ).(Kelleher and Tierney 2018
يُحَ و ِّل توقع حدوث الجريمة إلى نبوء ٍة
يقتصر على العدالة الجنائية أو ا ُملراقبة الأمنية؛ بل يُمكن أن يعني ً
ِ
أيضا،
ولكن التحي ُّز لا
ٍ
لتحيزات ضد َّهم إذا صن َّفهم الذكاء
على سبيل املثال ،تع ُّرض مُستخدمي خدمات الإنترنت
ً
تصنيفا سيئًا.
الاصطناعي
التحيز ومعنى الحياة

قد ينشأ التحي ُّز بعد َّة ط ُر ٍق في جميع مراحل التصميم والاختبار والتطبيق .وإذا ما
ر َّكزنا على مرحلة التصميم ،فسنجد أن الت َّحي ُّز قد يظهر في اختيار مجموعة البيانات
التي سيتم التدريب عليها؛ وفي مجموعة البيانات التي سيتم التدريب عليها نفسها،
والتي قد تكون غري مُمثلة أو غري كاملة ،وفي الخوارزمية ،وفي مجموعة البيانات التي
يتم إدخالها إلى الخوارزمية بعد تدريبها ،وفي القرارات القائمة على الارتباطات الزائفة
َ
الأوسع .على
)انظر الفصل السابق( ،وفي املجموعة التي تُنشئ الخوارزمية ،وفي املجتمع
رجال
سبيل املثال ،قد لا تكون مجموعة البيانات مُمث ِّلة للسكان )كأن تكون مَ بنية على
ٍ
أمريكيني بيض( ولكنها تُستخدَم للتنبؤ مع السكان كك ٍّل )الرجال والنساء من خلفيات
عرقية مُتنو ِّعة( .يمكن ً
أيضا أن يكون التحي ُّز مُتع ِّل ًقا بالاختلافات بني البلدان .فكثري من
الشبكات العصبية العميقة ا ُملستخدمة في التع ُّرف على الصور تُد َّرب على مجموعة البيانات
ا ُملحَ د َّدة »إيمدجنت« ،ImageNetالتي تحتوي على كمي ٍة غري متكافئة من البيانات من
ري من
الولايات املتحدة ،في حني أن بلدان مثل الصني والهند ،ال َّلتني تُمثلان جزءًا أكبر بكث ٍ
سكان العالم ،تُسهمان بنسبة صغرية فقط ) .(Zou and Schiebinger 2018وهذا قد
وبشكل عام ،يمكن أن تكون مجموعات البيانات
يؤدي إلى تحي ُّز مجموعة البيانات ثقافيٍّا.
ٍ
ٍ
كاملة أو ذات جودة رديئة ،مما قد يؤدي إلى وجود تحي ُّز .كذلك قد يكون التنب ُّؤ مَ بنيٍّا
غريَ
على قد ٍْر ضئيل من البيانات ،على سبيل املثال في حالة التنب ُّؤ بجرائم القتل :حيث لا يُوجَ د
كمثال آخر ،يشعر
هذا الكم الكبري من جرائم القتل ،مما يجعل التعميم أم ًرا إشكاليٍّا.
ٍ
بعض الباحِ ثني بالقلق إزاء نقص التنو ُّع في فِ رق تطوير الذكاء الاصطناعي وعلم البيانات؛
رجالا ِب ً
ً
يضا من البلدان الغربية
حيث يكون معظم علماء الكمبيوتر ومهندسي الكمبيوتر
تتراوَح أعمارهم ما بني ٢٠عامً ا و ٤٠عامً ا ،وقد تنعكس تجاربهم الشخصية وآراؤهم،
وبالتأكيد تحي ُّزاتهم في العملية ،وهو ما قد يؤثر سلبًا على الأشخاص الذين لا تنطبق
عليهم هذه الأوصاف ،مثل النساء ،والأشخاص ذوي الإعاقة ،وكبار السن ،والأشخاص
ا ُمللونني ،والأشخاص من البلدان النامية.
قد تكون البيانات مُتحيزة ً
ٍ
ٍ
ُمارسة
مجموعات مُعينة؛ لأن هناك تَحي ُّ ًزا في م
أيضا ضد
بشكل عام .على سبيل املثال ،ثمة ادعاءات بأن مجال
بشكل خاص أو في املجتمع
معينة
ٍ
ٍ
ٍ
بيانات من املرضى الذكور ،وبالتالي فإنه مُتحي ِّز ،كذلك
بشكل رئيسي
الطب يَستخدِم
ٍ
بشكل أوسع .إذا كانت
هناك التحي ُّز ضد الأشخاص ا ُمللو َّنني وهو يُعتبر سائدًا في املجتمع
ٍ
الخوارزمية تستخدِم مثل هذه البيانات ،فإن النتائج ستكون ً
أيضا مُتحيزة .وكما ورد
أخلاقيات الذكاء الاصطناعي

في مقال مجلة »نيتشر« الافتتاحي عام :٢٠١٦التحي ُّز في املدخلات يؤدي إلى تحي ُّز في
ا ُملخرجات .وقد تبني ً
ِ
ِ
سمات التحي ُّز من خلال
يكتسب
أيضا أن تع ُّلم الآلة يمكن أن
استخدام البيانات النصي َّة من شبكة الويب العاملية ،حيث تعكس هذه البيانات اللغوية
الثقافة الإنسانية اليومية ،بما فيها من تحيزات )Caliskan, Bryson, and Narayanan
 .(2017على سبيل املثال ،قد تحتوي متون اللغات نفسها على تحيزات جنسية .وا ُملثري
للقلق في هذه الحالة أن الذكاء الاصطناعي ربما يساعد في استمرار هذه التحي ُّزات ،مما
بشكل أكبر الجماعات التي كانت تُعاني من التهميش دائمً ا .يمكن ً
أيضا أن يظهر
يضر ُّ
ٍ
التحيز إذا كان هناك ارتباط ولكن لا يوجد سبب .على سبيل املثال ،في مجال العدالة
الجنائية مرة أخرى :قد تستنتج الخوارزمية أنه إذا كان أحد والدَي ا ُملد َّعى عليه قد أُودِع
السجن ،فإن هذا ا ُملد َّعى عليه من ا ُملرج َّ ح أن يُودَع السجن ً
أيضا .حتى لو كان هذا الارتباط
قائمً ا وحتى لو كان الاستنتاج تنبؤيٍّا ،يبدو أنه من غري العدل أن يحصل هذا ا ُملد َّعى
عليه على عقوبة أشد؛ نظ ًرا إلى عدم وجود علاقة سببية ).(House of Commons 2018
وأخريًا ،يمكن ً
أيضا أن ينشأ التحي ُّز بسبب أن صانعي القرارات من البشر يثقون في دقة
توصيات الخوارزميات أكثر مما ينبغي ) (CDT 2018ويتجاهلون املعلومات الأخرى أو
لا ِ
يعتمدون على حُ كمهم الشخصي بما فيه الكفاية .على سبيل املثال ،قد يعتمد القاضي
اعتمادًا كليٍّا على الخوارزمية ولا يأخذ في اعتباره العناصر الأخرى .وكما هو الحال دائمً ا
مع الذكاء الاصطناعي وغريه من تقنيات الأتمتة ،تلعب القرارات والتفسريات البشرية
دو ًرا مهمٍّ ا ،وهناك دائمً ا خطر الاعتماد الزائد على التكنولوجيا.
ومع ذلك ،ليس ِمن الواضح ما إذا كان من ا ُملمكن تجن ُّب التحي ُّز من الأساس ،أو
حتى ما إذا كان يجب تجن ُّبه ،فإذا كان من الواجب تجن ُّبه ،فما التكلفة التي يمكن تحم ُّ لها
في سبيل ذلك .على سبيل املثال ،إذا كان تغيري خوارزمية تعلم الآلة لتقليل احتمالات
التحي ُّز سيكون على حساب جعل توقعاتها أقل َّ
دقة ،فهل يجب علينا تغيريها؟ قد نُضطر
إلى الاختيار ما بني فعالية الخوارزمية من ناحية ومكافحة التحي ُّز من ناحي ٍة أخرى .هناك
ً
أيضا مشكلة في أنه إذا ت َّم تجاهل سمات مُعينة أو تجاهلها مثل العرق ،فإن أنظمة تع ُّلم
الآلة قد تُحدد ما يعرف بمؤشرات هذه السمات ،مما يؤدي ً
أيضا إلى التحي ُّز .على سبيل
املثال ،في حالة العِ رق ،قد يكون من ا ُملمكن أن تختار الخوارزمية مُتغريات أخرى مرتبطة
بالعِ رق مثل الرمز البريدي .وهل من املمكن وجود خوارزمية خالية تمامً ا من التحيز؟ لا
يُوجَ د توافق بني الفلاسفة أو حتى في املجتمع بشأن العدالة الكاملة أو الإنصاف الكامل.
التحيز ومعنى الحياة

علاو ًة على ذلك ،وكما أشرْ نا في الفصل السابق ،فإن مجموعات البيانات ا ُملستخدمة من قِ بل
الخوارزميات هي تجريدات عن الواقع وهي نتاج اختيارات بشرية ،ومن ث َ َّم فهي لا تكون
 َّ
يتوغل التحيز في عا َلمنا ومُجتمعاتنا؛
مُحايدة أبدًا ).(Kelleher and Tierney 2018
وبالتالي ،على الرغم من أنه يمكن القيام بالكثري ويجب القيام بالكثري لتقليل التحيز ،فإن
نماذج الذكاء الاصطناعي لن تخل َو تمامً ا من التحيز ).(Digital Europe 2018
علاو ًة على ذلك ،يبدو بالتأكيد أن الخوارزميات ا ُملستخدمة في اتخاذ القرار دائمً ا ما
تكون مُتحيزة من منطلق كونها تمييزية؛ إذ إنها مُصممة للتمييز بني مُختلف الاحتمالات.
على سبيل املثال ،في عملية التوظيف ،يُفترَض أن يكون فحص ِّ
الس َري الذاتية ذا طابع
مُتحيز وتمييزي تجاه ِسمات املرشحني التي تُناسب الوظيفة .ويكمُن السؤال الأخلاقي
والسياسي فيما إذا كان هناك تمييز مُعني غري منصف وغري عادل .ولكن مرة أخرى،
تختلف وجهات النظر بشأن ما هو منصف وما هو عادل .وهذا يجعل قضية التحي ُّز
ً
تقنية ولكنها ً
أيضا مرتبطة باملناقشات السياسية حول الإنصاف والعدالة .على
ليست فقط
سبيل املثال ،هل من العدل مُمارسة التمييز الإيجابي أو التدابري الإيجابية ،التي تُحاول
يجب
محو أثر التحي ُّز عن طريق التحيز الإيجابي مع الأفراد أو الجماعات املحرومة؟ هل ِ
أن تكون العدالة عمياء ومحايدة — وبالتالي هل يجب أن تكون الخوارزميات عمياء إزاء
العِ رق ،على سبيل املثال — أم أن العدالة تعني تمييز أولئك ا َملحرومني بالفعل من أي
ميزات ،مما ِ
يصل بنا في النهاية إلى نوع من التحي ُّز والتمييز )التصحيحي(؟ وهل يجب
على السياسة في السياق الديمقراطي أن تُعطي الأولوية لحماية مصالح الأغلبية أم تركز
على تعزيز مصالح الأقلية ،حتى وإن كانت أقلية محرومة قديمً ا أو حاليٍّا؟
يجب أن تكون العدالة عمياء ومُحايدة أم أن العدالة تعني تمييز أولئك املحرومني بالفعل من
هل ِ
أي ميزات؟

وهذا يقودنا إلى السؤال حول الإجراءات .حتى إذا اتفقنا على وجود تحي ُّز ،فهناك
طرق مختلفة للتعامُل مع املشكلة .وتشمل هذه الطرق التكنولوجية وكذلك الإجراءات
يجب علينا اتخاذها؛
ا ُملجتمعية والسياسية والتعليم .وثمة خلاف حول الإجراءات التي ِ
إذ إنها تعتمد مرة أخرى على مفهومنا للعدالة والإنصاف .على سبيل املثال ،تُثري قضية
ً
يجب أن نقبل العالم كما هو أم
التدابري الإيجابية
قضية أكثر عمومية حول ما إذا كن َّا ِ
أخلاقيات الذكاء الاصطناعي

ٍ
بطريقة من شأنها تجن ُّب استمرار
نحو فع َّ ال
أننا يجب أن نُش ِّكل عاملنا ا ُملستقبلي على ٍ
يجب أن نستخدِم مجموعة
الظلم الذي كان مُستشريًا في املاضي .بعض الناس ي َرون أننا ِ
ٍ
بيانات تعكس العالم الواقعي .وقد تُمثل البيانات التحيزات املوجودة في املجتمع وقد
تُنشئ الخوارزمية نموذجً ا من التحي ُّزات املوجودة لدى الناس الآن ،ولكن هذه ليست
ً
مشكلة يجب أن يقلق بشأنها ا ُملطورون .بينما يرى آخرون أن مثل هذه املجموعة من
قرون من التحيز ،وأن هذا التحي ُّز والتمييز غري عادل
البيانات موجودة فقط بسبب
ٍ
يجب تغيري تلك املجموعة من البيانات أو الخوارزمية من أجل تعزيز
وظالِم ،وعليه فإنه ِ
التدابري الإيجابية .على سبيل املثال ،في استجاب ٍة إلى نتائج خوارزمية البحث في جوجل التي
ٍ
ببساطة
تبدو مُتحيز ًة ضد أساتذة الرياضيات الإناث ،يمكن للمرء أن يقول إن هذا يعكس
حقيقة العالم )وأن هذا هو بالضبط ما يجب أن تفعله خوارزمية البحث(؛ أو يمكن أن
ً
أولوية لصور أساتذة الرياضيات الإناث من أجل تغيري التصور
نجعل الخوارزمية تُعطي
وربما تغيري العا َلم ) .(Fry 2018ويمكن ً
أيضا أن نُحاول إنشاء فِ َرق تطوير تكون أكثر
بشكل أفضل الفئات التي ِمن املحتمَ ل
تنوعً ا من حيث الخلفية والرأي والتجربة ،وتُمثل
ٍ
أن تتأثر بالخوارزمية ).(House of Commons 2018
لن يصح الرأي القائل بأنها تعكس الواقع إذا كانت مجموعة البيانات التي سيتم
ٍ
بيانات قديمة لا تعكس الوضع
التدريب عليها لا تعكس العالم الواقعي وتحتوي على
الحالي .كما أن القرارات املبنية على هذه البيانات تساعد بالفعل في استمرار التمييز
الذي كان موجودًا في املاضي ً
بدلا من الاستعداد للمستقبل .وعلاو ًة على ذلك ،ثم َّ ة اعتراض
َ
آخر على الرأي القائل بأنها تعكس الواقع وهو أنه حتى إذا كان النموذج يعكس العالم
وأضرار أخرى قد تقع على أفرادٍ أو
الواقعي ،فإن هذا يمكن أن يؤدي إلى تدابري تمييزية
ٍ
مجموعات بعينها .على سبيل املثال ،قد ترفض شركات الائتمان منحَ
قروض إلى ا ُملتقدمني
ٍ
على أساس مح ِّل الإقامة ،أو قد تفرض املواقع الإلكترونية رسومً ا أكبر على بعض العملاء
ً
مقارنة بغريهم استنادًا إلى ملفات العملاء التعريفية التي أنشأها الذكاء الاصطناعي.
كذلك يمكن أن تتبع امللفات التعريفية الأفراد عبر النطاقات املختلفة )Kelleher and
شكل
 .(Tierney 2018ويمكن أن تربط وظيفة الإكمال التلقائي البسيطة في ظاهرها ِب ٍ
ٍ
بجريمة ما )الأمر الذي قد يؤد ِّي إلى عواقب وخيمة( ،حتى إذا كانت خوارزمية
خطأٍ اسمَ ك
بشكل صحيح؛ بمعنى أن معظم الناس يُريدون
البحث الكامنة وراءها تعكس العا َلم
ٍ
البحث عن اسم املجرم وليس عن اسمك .وثم َّ ة مثال آخر على التحي ُّز ،ولكنه ربما ليس
التحيز ومعنى الحياة

واضحً ا بالقدْر نفسه :فنظام استرجاع املوسيقى ا ُملستخدَم في خدمات مثل »سبوتيفاي«،
ٍ
توصيات بناءً على السلوك الحالي )املسارات املوسيقية التي ينقر عليها معظم
الذي يقد ِّم
الناس( ،قد يتحي َّز ضد املوسيقى واملوسيقيني الذين هم أق ُّل شيوعً ا .وحتى إذا كان النظام
َ
العيش
وضع لا يستطيع فيه بعض املوسيقيني
يعكس العا َل َم الواقعي ،فإن هذا يؤدي إلى
ٍ
من موسيقاهم ويجعل بعض املجتمعات تشعُ ر بعدم التقدير وعدم الاحترام.
حني أن هذه حالات واضحة من التمييز الذي ينطوي على مشكلات ،إلا
مرة أخرى ،في ِ
ً
يجب أن نسأل دائمً ا :هل يمكن أن يكون التمييز في ٍ
عادلا أم لا؟ وإذا كان
حالة مُعينة
أننا ِ
غري عادل ،فما الإجراء الذي سيُت َّ َخذ حياله ومَ ن الذي سيتخِ ذُه؟ على سبيل املثال ،ما الذي
يُمكن أن يفعله علماء الكمبيوتر حياله؟ هل يجب أن يجعلوا مجموعات البيانات التي يتم
ٍ
بيانات ومجموعات بيانات »مثالية« كما اقترح
التدريب عليها أكثر تنوعً ا ،وربما يُنشئون
إريك هورفيتز من شركة مايكروسوفت )(Surur 2017؟ أم يجب أن تعكس مجموعات
البيانات العا َلم؟ هل يجب على املطو ِّرين تضمني التمييز الإيجابي في خوارزمياتهم ،أم يجب
عليهم إنشاء خوارزميات »عمياء«؟ إن كيفية التعامُل مع التحيز في الذكاء الاصطناعي
ليست مسألة تقنية فحسب؛ بل هي مسألة سياسية وفلسفية .إن املسألة تتع َّلق بنوع
الواجب علينا أن نُحاول تغيريه ،وإذا كان الأمر
املجتمع والعا َلم الذي نريده ،وإذا كان من
ِ
كذلك ،فما هي الطرق املقبولة والعادلة لتغيريه .إنها ً
أيضا مسألة تتع َّلق بالبشر بقدْر ما
تتعلق بالآلات :هل نعتقد أن اتخاذ القرارات البشرية عادل ومنصف ،وإذا لم يكن الأمر
كذلك ،فما دور الذكاء الاصطناعي؟ ربما يُمكن أن يُع ِّلمنا الذكاء الاصطناعي شيئًا عن
البشر ومجتمعاتهم من خلال الكشف عن تَحي ُّزاتنا .وقد تكشف مناقشة أخلاقيات الذكاء
الاصطناعي الاختلال الكبري في موازين القوى الاجتماعية واملؤسسية.
وهكذا ِ
تصل املناقشات حول أخلاقيات الذكاء الاصطناعي إلى عُ مق قضايا مجتمعية
ٍ
وسياسية َّ
بأسئلة فلسفية حول العدالة والإنصاف ،وأسئلة فلسفية وعِلمية
حساسة ترتبط
حول البشر ومجتمعاتهم .واحدة من هذه القضايا هي مُستقبل العمل.
مستقبل العمل ومعنى الحياة
 َّ
املتوقع أن تُحو ِّل الأتمتة التي تعتمد على الذكاء الاصطناعي اقتصاداتنا ومجتمعاتنا
ِمن
ً
ٍ
فضلا عن مستقبل الحياة
تساؤلات حول مُستقبل العمل ومعناه،
بشكل جذري ،مما يُثري
ٍ
البشرية ومعناها.
أخلاقيات الذكاء الاصطناعي

ً
أولا ،هناك مَ خاوف من أن يؤدي الذكاء الاصطناعي إلى تدمري الوظائف ،الأمر الذي
قد يؤدي إلى البطالة الشاملة .وهناك ً
أيضا سؤال حول نوع الوظائف التي يستطيع الذكاء
ِ
ستقتصر على وظائف ذوي الياقات الزرقاء )العمالة اليدوية(،
الاصطناعي تو ِّليها :وهل
كما يُط َلق عليها ،أم أن هناك وظائف أخرى يمكن أن َّ
يتولاها؟ يتنب َّأ تقرير شهري لك ٍّل من
بنيديكت فري ومايكل أوزبورن ) (٢٠١٣بأن ٤٧في املائة من جميع الوظائف في الولايات
املتحدة يُمكن أتمتَتُها .وتحمل تقارير أخرى أرقامً ا أق َّل إثار ًة للجدل ،ولكن معظمها يتنبأ
بأن فقدان الوظائف سيكون كبريًا .ويتفق العديد من الكت َّاب على أن الاقتصاد قد تأثر
بشكل كبري ) ،(Brynjolfsson and McAffee 2014بما في ذلك التغريات
وسيظ ُّل يتأثر
ٍ
امللحوظة التي حدثت في التوظيف الآن والتي ستحدث في املستقبل .ومن ا ُمل َّ
توقع أن يؤدي
ِ
العاملني ،ليس
فقدان الوظائف بسبب الذكاء الاصطناعي إلى التأثري على جميع أنواع
بشكل متزايد على أداء
فقط ذوي الياقات الزرقاء ،حيث أصبح الذكاء الاصطناعي قاد ًرا
ٍ
املهام ا َملعرفية ا ُملعقدة .إذا كان هذا صحيحً ا ،فكيف يُمكننا أن نُعِ َّد الأجيال الجديدة لهذا
املستقبل؟ ماذا يجب أن يتع َّلموا؟ وماذا يجب أن يفعلوا؟ وماذا لو كان الذكاء الاصطناعي
يُفيد بعض الأشخاص أكثر من غريهم؟
بهذا السؤال الأخري ،نعود مر ًة أخرى إلى قضايا العدالة والإنصاف ،التي شغلت
 ِّ
سيوسع
تفكري الفلاسفة السياسيني لعصور .على سبيل املثال ،إذا كان الذكاء الاصطناعي
ً
عادلا ،فما الذي يمكن
الفجوة بني الأثرياء والفقراء ،فهل هذا أمر عادل؟ وإذا لم يكن
القيام به حيال ذلك؟ يمكن ً
أيضا صياغة املشكلة من حيث عدم املساواة )هل سيزيد
الذكاء الاصطناعي من عدم املساواة في املجتمعات وفي العالم؟( أو من حيث التع ُّرض إلى
التأثريات السلبية :هل سيحظى أصحاب الوظائف والأثرياء وا ُملتع َّلمون في الدول املتقدمة
تكنولوجيٍّا بفوائد الذكاء الاصطناعي بينما سيكو ُن العاطلون عن العمل والفقراء والأقل
ً
عرضة لتأثرياته السلبية )(Jansen et al. 2018؟ وللتعامُل
تعليمً ا في الدول النامية أكثر
مع قضية أخلاقية وسياسية أخرى أكثر حداثة :ماذا عن العدالة البيئية؟ ما هو تأثري
الذكاء الاصطناعي على البيئة وعلاقتنا بالبيئة؟ ماذا يعني »الذكاء الاصطناعي ا ُملستدام«؟
هناك ً
أيضا سؤال حول ما إذا كانت أخلاقيات الذكاء الاصطناعي وسياساته مُرتبطة ب ِقيَم
البشر ومصالحهم فقط أم لا) .انظر الفصل الثاني عشر(.
التحيز ومعنى الحياة
 َّ
بشكل
املتوقع أن تُحو ِّل الأتمتة التي تعتمد على الذكاء الاصطناعي اقتصاداتنا ومُجتمعاتنا
من
ٍ
ً
جذري ،مما يُثري أسئلة حول مُستقبل العمل ومعناه ،فضلا عن مُستقبل الحياة البشرية ومعناها.

ثمة سؤال َ
تفترض
آخر ذو طابع وجودي يتع َّلق بمعنى العمل والحياة البشريةِ .
املخاوف من فقدان الوظائف أن العمل هو القيمة الوحيدة واملصدر الوحيد للدخل واملعنى.
ولكن إذا كانت الوظائف هي الشيء الوحيد ذو القيمة ،فربما علينا عندئ ٍذ خلق املزيد من
الأمراض العقلية ،ورفع مُعدل التدخني ،وزيادة معدلات السمنة؛ لأن هذه املشكلات هي
التي تؤدي إلى خلق وظائف 1 .ونحن لا نُريد ذلك .إذَن فمن الواضح أننا نؤمن بأن هناك
قيمً ا أخرى أهم من خلق الوظائف في ح ِّد ذاته .وملاذا نعتمد على الوظائف لتحقيق الدخل
ٍ
بطريقة مختلفة .يُمكننا أن نفصل بني
واملعنى؟ يُمكننا تنظيم مجتمعاتنا واقتصاداتنا
ً
ً
ودخلا .فهناك الكثريون يقومون بالعمل
»عملا«
العمل والدخل ،أو بالأحرى ما نعتبره
ُ
ً
 ِّ
مج َّ انًا ،على سبيل املثال في املنزل ورعاية الأطفال واملسنني .فلماذا لا يُعتبر هذا »عملا«؟
ً
قيمة وأهمية من غريه من الأعمال؟ وملاذا
وملاذا يكون القيام بذلك النوع من العمل أق َّل
لا نجعله مصد ًرا للدخل؟ علاو ًة على ذلك ،يعتقد بعض الأشخاص أن الأتمتة يُمكن أن
ً
متعة وإبداعً ا ،ليس
تُتيح لنا املزيد من الرفاهية والراحة .ربما يُمكننا القيام بأشياء أكثر
بالضرورة في شكل وظيفة .يُمكننا ،بعبار ٍة أخرى ،الاعتراض على فكرة أن الحياة ذات
عمل مدفوع الأجر ومُنظم م ً
املعنى هي فقط حياة تُ َ
ُسبقا من قِ بل الآخرين أو
قضى في أداء ٍ
عمل يتم في إطار ما يُط َلق عليه »التوظيف الذاتي« .ربما يُمكننا فرض تدابري مُعي َّنة مثل
تحديد »دخل أساسي« لنسمح للجميع بفعل ما ي َرونه ذا معنًى وقيمة .وبالتالي ،ردٍّا على
مشكلة مُستقبل العمل ،يُمكننا أن نُفكر فيما يجعل العمل ذا معنًى ،وفي نوع العمل الذي
ينبغي للبشر عملُه )أو بالأحرى يُسمَ ح لهم بعمله( ،وفي كيفية إعادة تنظيم مجتمعاتنا
واقتصاداتنا بحيث لا يرتبط الدخل بالوظائف والتوظيف.
على الرغم من ك ِّل ما قيل ،فإن الأفكار اليوتوبية حول املجتمعات ا ُمل َّ
رفهة وغريها
 َّ
ٍ
موجات من
تتحقق حتى الآن .لقد شهدنا بالفعل عدة
من الجنان ما بعد الصناعية لم
الأتمتة بدءًا من القرن التاسع عشر حتى الآن ،ولكن إلى أي مدًى ح َّر َرتنا الآلات وأعتقت
ً
بعض الأعمال ا ُملضجرة والخطرية ،ولكنها استُخدِمت ً
َ
أيضا
نيابة عنا
رقابنا؟ ربما تو َّلت
للاستغلال ولم تُ ِّ
بشكل جذري الهيكل اله َرمي للمجتمع .وقد استفاد بعض الناس
غري
ٍ
أخلاقيات الذكاء الاصطناعي

استفاد ًة هائلة من الأتمتة ،بينما لم يفعل آخرون .وربما تكون الأوهام حول عدم وجود
ً
فضلا عن
وظائف هي رفاهية محفوظة فقط لأولئك الذين كانوا في جانب ا ُملستفيدين.
ذلك ،هل ح َّر َرتنا الآلات لنعيش حيا ًة ذات معنًى أكثر من ذي قبل؟ أم أنها تُهد ِّد إمكانية
هذه الحياة نفسها؟ هذا نقاش طويل ولا تُوجَ د إجابات سهلة عن هذه الأسئلة ،ولكن
املخاوف التي لدينا تُعد أسبابًا وجيهة لأن نتش َّكك على الأقل في العالم الجديد الجميل
ُ
نبوءات الذكاء الاصطناعي.
الذي رسمَ تْه لنا
ً
استغلالا يجب
علاو ًة على ذلك ،قد لا يكون العمل بالضرورة شقاءً يجب تجن ُّبُه أو
مقاومته؛ فثمة وجهة نظر أخرى تُشري إلى أن العمل له قيمة في ح ِّد ذاته ،وأنه يمنح
العامل ً
ُ
التواصل الاجتماعي مع الآخرين ،والانتماء
هدفا ومعنًى ،وأن له فوائد مُتنوعة مثل
إلى شيءٍ أكبر ،والتمت ُّع بالصحة ،والحصول على ُف َرص ملمارسة املسئولية )Boddington
 .(2016فإذا كان هذا هو الحال ،فلربما كان علينا أن نحتفِ ظ بالعمل للبشر؛ أو على
الأقل ببعض أنواع العمل ،كالعمل ذي ا َملغزى الذي ي ِّ
ً
فرصا لتحقيق هذه الفوائد .أو
ُوفر
ربما علينا أن نحتفِ ظ على الأقل ببعض املهام .وليس على الذكاء الاصطناعي أن ُ
يأخذ
 َّ
يتولى بعض املهام ذات القيمة الأقل .ويُمكننا
على عاتقه وظائف بأكملها ،ولكن يُمكن أن
أن نتعاون مع الذكاء الاصطناعي .على سبيل املثال ،يُمكننا اختيار عدم تفويض العمل
يقترحه بوستروم( أو يُمكننا اختيار التعاون
الإبداعي إلى الذكاء الاصطناعي )وهو ما ِ
مع الذكاء الاصطناعي للقيام بأشياء إبداعية .ما يُثري القلق في هذا الصدد هو أنه إذا
ستتولى القيام بك ِّل ما نقوم به في حياتنا الآن ،فلن َّ
 َّ
يتبقى لنا شيء نقوم
كانت الآلات
ً
به ،وسنجد حياتنا بلا معنى .ومع ذلك ،فنحن نقول »إذا«؛ ويجب أن نضع في اعتبارنا
الش َّك فيما يمكن أن يقوم به الذكاء الاصطناعي )انظر الفصل الثالث( وحقيقة أن العديد
ً
»عملا« ولكنها ذات مغ ًزى كبري ،وبالتالي فإننا سنحتفظ على الأرجح
من أنشطتنا ليست
بالكثري لنقوم به .على هذا ،يُمكننا أن نقول إن السؤال الآن ليس ماذا سيفعل البشر
 َّ
تتولى الآلات القيام بجميع أعمالهم وأنشطتهم ،ولكن أي املهام نريد أو نحتاج إلى
عندما
الاحتفاظ بها للبشر ،وما هي الأدوار التي يمكن أن َّ
يتولاها الذكاء الاصطناعي ،إن كان
سيتولى أي أدوار ،لدعمنا في هذه املها ِّم بطرق أخلاقية ومقبولة اجتماعيٍّا.
ختامً ا ،تدعونا أخلاقي َّات الذكاء الاصطناعي إلى التفكري في ماهية املجتمع َ
الخ ِّري
والعادل ،وماهية الحياة البشرية ذات املعنى ،وماهية الدور الذي تضطلِع به التكنولوجيا
والذي يمكن أن تضطلع به فيما يتع َّلق بك ِّل ذلك .ويمكن أن تكون الفلسفة ،بما فيها
التحيز ومعنى الحياة

الفلسفة القديمة ،مصدر إلها ٍم للتفكري في تقنيات اليوم واملشكلات التي تجلِبها بالفعل
والتي يُحتمَ ل أن تجلبها من الناحية الأخلاقية وا ُملجتمعية .فإذا كان الذكاء الاصطناعي
يُثري هذه الأسئلة القديمة حول الحياة الجيدة ذات املعنى ،فلدَينا مصادر في مختلف
التقاليد الفلسفية والدينية يمكن أن تُساعدنا في التعامُل مع هذه الأسئلة .على سبيل املثال،
كما اقترحت شانون فالور ) ،(٢٠١٦فإن تقليد أخلاقيات الفضيلة الذي وضعه أرسطو
وكونفوشيوس وفلاسفة قدماء آخرون ربما ما زال يستطيع أن يُساعدنا اليوم للتفكري في
معنى ازدهار الإنسان وكيف ينبغي أن يكون في عصر التكنولوجيا .وبعبار ٍة أخرى ،قد
تُوجَ د لدينا بالفعل إجابات عن هذه الأسئلة ،ولكن علينا القيام ببعض العمل للتفكري في
معنى الحياة الجيدة في سياق التكنولوجيا الحديثة ،بما في ذلك الذكاء الاصطناعي.
واجه فكرة تطوير »أخلاقيات الذكاء الاصطناعي للحياة الجيدة«
ومع ذلك ،تُ ِ
بشكل عا ٍّم عدة مشكلات .تتمث َّل املشكلة
وأخلاقيات الذكاء الاصطناعي للعا َلم الواقعي
ٍ
الأولى في السرعة .يفترض نموذج أخلاقيات الفضيلة الذي ورثته الفلسفة الغربية من
ٍ
يتغري ببطءٍ ولا َّ
أرسطو مجتمعً ا َّ
بسرعة كبرية ،ويمتلك فيه الناس
تتغري فيه التكنولوجيا
وقتًا لتع ُّلم الحكمة العملية؛ ولذا ،فإنه من غري الواضح كيف يمكن استخدامه للتعامُل
 ُّ
التغري ) (Boddington 2016ومع التطو ُّر السريع للتقنيات مثل الذكاء
مجتمع سريع
مع
ٍ
الاصطناعي .هل ما زال لدَينا الوقت الكافي للاستجابة ولتطوير الحكمة العملية ونقلها
فيما يتع َّلق باستخدام تقنيات مثل الذكاء الاصطناعي؟ هل تأتي الأخلاقيات بعد فوات
الأوان؟ عندما ُ
تنشر بومة ِمينريفا جناحَ يها )التي ترمز للحكمة عند اليونان( ،ربما يكون
شكل العالم قد َّ
تغري تمامً ا ولم يعُ د بالإمكان التعرف عليه .فما هو دور مثل هذه
الأخلاقيات ،وماذا ينبغي أن يكون دورها في سياق التطو ُّرات التي تحدث في العالم
الواقعي؟
أما املشكلة الثانية ،فنظ ًرا إلى تنوع وتعدد وجهات النظر في هذا الأمر داخل
املجتمعات ،والاختلافات الثقافية بني املجتمعات ،فإن الأسئلة الخاصة بماهية الحياة
نحو مختلف في
الجيدة ذات املعنى في ظل وجود التكنولوجيا يمكن الإجابة عنها على ٍ
الأماكن والسياقات ا ُملختلفة ،وهي تخضع ،من الناحية العملية إلى كل أنواع العمليات
السياسية التي قد تنتهي أو لا تنتهي بالتوافق .والاعتراف بهذا التنو ُّع والتعد ُّد قد يؤدي
إلى نهج يميل إلى التعد ُّدية .كما يمكن أن يأخذ شكل النسبية .وقد أثارت الفلسفة
ً
خاصة ما يُع َرف بمدرسة ما بعد الحداثة ،الكثري
ونظرية املجتمع في القرن العشرين،
أخلاقيات الذكاء الاصطناعي

سياق جغرافي
من الشكوك حول الإجابات التي يُزعَ م كونها عاملية في حني أنها نشأت من
ٍ
وتاريخي وثقافي مُعني )من »الغرب« ،على سبيل املثال( وأنها مرتبطة بمصالح وعلاقات
ُ
التوافق من
قوة مُعينة .كما أثريت شكوك حول ما إذا كانت السياسة يجب أن تهدُف إلى
ُ
التوافق
الأساس )انظر أعمال شانتال موف ،على سبيل املثال ،موف (٢٠١٣؛ وما إذا كان
مرغوبًا فيه دائمً ا ،أم أن الصراع الشرس حول مستقبل الذكاء الاصطناعي يمكن أن
يكون له بعض الفوائد؟ وعلاو ًة على ذلك ،هناك مشكلة أخرى تتعلق بالهيمنة :فالتفكري
في الأخلاقيات في العالم الحقيقي يعني التفكري ليس فقط فيما يجب القيام به فيما
يتعلق بالذكاء الاصطناعي ولكن ً
أيضا فيمَ ن سيقرر ،ومَ ن يجب عليه أن يقرر ،مستقبل
الذكاء الاصطناعي وبالتالي مستقبل مجتمعنا .ودعونا نفكر معً ا مرة أخرى في قضايا
الحكم الشمولي وهيمنة الشركات الكبرية .وإذا رفضنا الحكم الشمولي والبلوتوقراطية
)حكم الأثرياء( ،فماذا يعني اتخاذ قرار ديموقراطي بشأن الذكاء الاصطناعي؟ ما هو
نوع املعرفة املتعلق بالذكاء الاصطناعي الذي يحتاجه السياسيون واملواطنون؟ إذا كان
هناك َفهم ضعيف للغاية للذكاء الاصطناعي ومشكلاته املحتمَ لة ،فإننا نواجه خطر
التكنوقراطية أو ببساطة عدم وجود سياسة للذكاء الاصطناعي على الإطلاق.
ومع ذلك ،كما يُوضح الفصل التالي ،يبدو أن واحدة على الأقل من العمليات السياسية
املتعلقة بالذكاء الاصطناعي التي ظهرت مؤخ ًرا جاءت في الوقت املناسب .وتلك هي صنع
ظهر
سياسات خاصة بالذكاء الاصطناعي ،وهي عملية استباقية ،وتهدف إلى التوافق ،وتُ ِ
ً
درجة متزايدة من التقارب ،ويبدو أنها تلتزم بنوع من العاملية بلا خجل ،وتعتمد على
املعرفة الخبرية ،وتزعم — ولو على الأقل شفهيٍّا — احترام مبادئ الديمقراطية ،وخدمة
الصالح العام واملصلحة العامة ،ومشاركة جميع الأطراف ا َملعنية.
الفصل العاشر

السياسات المقترحة

 َّ
يتعني على صانعي السياسات الإجابة عنها
ما يجب القيام به وأسئلة أخرى
نظ ًرا إلى املشكلات الأخلاقية ا ُملرتبطة بالذكاء الاصطناعي ،فإنه من الواضح أن شيئًا ما
يجب القيام به .ولذا ،تتضم َّ ن معظم مبادرات السياسات ا ُملتعلقة بالذكاء الاصطناعي
أخلاقيات الذكاء الاصطناعي .وجدير بالذكر أن هناك الكثري من املبادرات في هذا املجال
يجب القيام به ،وما املسار الذي
في الوقت الحالي .ومع ذلك ،ليس من الواضح بالضبط ما ِ
يجب ات ِّخاذه .على سبيل املثال ،ليس واضحً ا كيفية التعامُل مع مشكلة الشفافية أو التحي ُّز،
نظ ًرا إلى التقنيات نفسها ،والتحي ُّز الذي يُعاني منه املجتمع بالفعل ،والآراء ا ُملتباينة حول
العدالة والإنصاف .وهناك ً
أيضا العديد من التدابري ا ُملمكن اتخاذها :إذ يمكن أن تعني
السياسة التنظي َم من خلال إصدار القوانني واللوائح ،على سبيل املثال ،الأنظمة القانونية،
ولكن هناك ً
أيضا استراتيجيات أخرى قد تكون مُتصلة أو غري متصلة بالأنظمة القانونية،
مثل التدابري التكنولوجية ،وقواعد الأخلاق ،والتعليم .ولا يقتصر التنظيم على القوانني ولكنه
أيضا معايري مثل معايري الآيزو .وعلاوة على ذلك ،هناك ً
يتضمن ً
أيضا أنواع أخرى من
الأسئلة التي َّ
يجب القيام
يتعني الإجابة عنها في السياسات املقترحة؛ فالأمر ليس فقط ما ِ
به ،ولكن ً
يجب القيام به ،وما ِمقدار ما يجب القيام به،
أيضا ملاذا يجب القيام به ،ومتى ِ
ومَ ن يجب عليه أن يقوم به ،وما هي طبيعة املشكلة ومَ داها ودرجة خطورتها وإلحاحها.
ً
أولا :من ا ُملهم تبرير التدابري املقترحة .على سبيل املثال ،قد تستنِد السياسة ا ُملقترحة
ِ
تعتمد على
اقتراح بالتقليل من اتخاذ القرارات التي
إلى مبادئ حقوق الإنسان لتبرير
ٍ
خوارزميات مُتحيزة .ثانيًا :استجابة إلى التطو ُّر التكنولوجي ،غالبًا ما تأتي السياسة
بعد فوات الأوان ،عندما تكون التكنولوجيا قد َّ
توغلت بالفعل في املجتمع ودخلت في ك ِّل

أخلاقيات الذكاء الاصطناعي

شيءً .
ِ
يكتمل تطوير التكنولوجيا
بدلا من ذلك ،يمكن أن نُحاول وضع سياسة قبل أن
 ُّ
يخص الذكاء الاصطناعي ،يمكن القول إن هذا ما زال مُمكنًا،
ويبدأ استخدامها .وفيما
إلى ح ٍّد ما ،على الرغم من أن الكثري من الأنظمة املدعومة بالذكاء الاصطناعي موجودة
بالفعل حولنا .والبُعد الزمني مُهم ً
أيضا فيما يتع َّلق بالنطاق الزمني للسياسة :هل هي
م َّ
ُخصصة فقط للسنوات الخمس أو العشر املقبلة ،أم تهدف إلى أن تُكو ِّن إطار عمل
على املدى البعيد؟ هنا علينا أن نختار .على سبيل املثال ،يمكن تجاهل التنبؤات على
املدى البعيد والتركيز على املستقبل القريب ،كما تفعل معظم السياسات ا ُملقترحة ،أو
يمكن طرح رؤية ملستقبل الإنسانية .ثالثًا :لا يتفق الجميع على أن ح َّل املشكلات يتط َّلب
الكثري من التدابري الجديدة .يزعم بعض الأشخاص واملؤسسات أن التشريعات الحالية
كافية للتعامُل مع الذكاء الاصطناعي .فإذا كان هذا هو الحال ،فإنه يبدو أن ا ُملشر ِّعني
ليسوا في حاجة إلى القيام بالكثري ،في حني أن الذين يُفسرون القانون والذين يُطو ِّرون
الذكاء الاصطناعي هم مَ ن يحتاجون إلى العمل الدءوب .ويعتقد َ
آخرون أنه يجب أن نُعيد
التفكري في جوهر املجتمع ومؤسساته ،بما في ذلك أنظمتنا القانونية ،من أجل التعامُل مع
املشكلات الأساسية وإعداد أجيال ا ُملستقبل .رابعً ا :يجب أن ِّ
توضح السياسة املقترحة مَ ن
يقتصر هذا على ٍ
ِ
جهة واحدة وإنما أكثر من جهة.
الذي يجب أن يتخذ الإجراءات .وقد لا
ً
سؤالا حول كيفية توزيع
عمل تكنولوجي .ويُثري هذا
فكما رأينا ،يشترك الكثريون في أي ٍ
ً
أساسا هي املسئولة عن اتخاذ إجراءات،
املسئولية عن السياسة والتغيري :هل الحكومات
ٍ
إجراءات خاصة بها لضمان
أم يجب ،على سبيل املثال ،على الشركات والصناعة اتخاذ
الذكاء الاصطناعي الأخلاقي؟ وفيما يتع َّلق بالشركات ،هل يجب مخاطبة الشركات الكبرية
فقط أم ً
واملتوسطة الحجم؟ وما هو دور العلماء )ا ُمل ِّ
 ِّ
ختصني
أيضا الشركات الصغرية
بالكمبيوتر( واملهندسني الأفراد؟ وما هو دور املواطنني؟
ً
خامسا :تعتمد الإجابة عما يجب القيام به ومقدار ما يجب القيام به ،وعن أسئلة
أخرى ،على كيفية تعريف طبيعة املشكلة نفسها ومَ داها ودرجة خطورتها وإلحاحها.
على سبيل املثال ،هناك اتجاه في سياسات التكنولوجيا )وفي الواقع ،في أخلاقيات الذكاء
ٍ
مشكلات جديدة في ك ِّل مكان .ومع ذلك ،كما رأينا في الفصل السابق،
الاصطناعي( لرؤية
فالعديد من املشكلات قد لا تكون حك ًرا على التقنيات الجديدة ،ولكنها ربما تكون موجود ًة
وقت طويل .علاو ًة على ذلك ،كما أظهر النقاش حول التحي ُّزِ ،
منذ ٍ
يعتمد ما نقترح القيام
به على كيفية تعريف املشكلة :هل هي مشكلة خاصة بالعدالة ،وإذا كانت كذلك ،فما هو
السياسات املقترحة

نوع العدالة ا ُملهد َّدة؟ سيشكل تعريف املشكلة التدابري التي نقترحها .على سبيل املثال ،إذا
ٍ
تعريف مُعني للمشكلة .وأخريًا ،يلعب
قد َّمنا تدابري للعمل الإيجابي ،فإن هذا يستند إلى
ً
أيضا تعريف الذكاء الاصطناعي دو ًرا في تحديد السياسة املقترحة ونطاقها ،وقد كان هذا
َ
ستحسن
التعريف دائمً ا مُثريًا للجدل والنقاشات .على سبيل املثال ،هل ِمن ا ُملمكن ومن ا ُمل
أن نُميز بوضوح بني الذكاء الاصطناعي والخوارزميات الذكية ا ُملستقلة ،أو بني الذكاء
الاصطناعي وتقنيات الأتمتة؟ جميع هذه الأسئلة تجعل من صنع السياسات ا ُملتعلقة
بشكل كبري .وبالفعل ،نجد العديد من الاختلافات
بالذكاء الاصطناعي أم ًرا قد يُثري الجدل
ٍ
والجدالات ،على سبيل املثال حول مدى الحاجة إلى تشريعات جديدة ،وحول املبادئ التي
يجب الاستناد إليها بالضبط لتبرير التدابري ،وحول مسألة ما إذا كان ينبغي تحقيق توازن
بني أخلاقيات الذكاء الاصطناعي والاعتبارات الأخرى )مثل تنافسية الشركات والاقتصاد(.
ً
درجة ملحوظة من التقا ُرب.
ومع ذلك ،إذا ف َّكرنا في وثائق السياسة الفعلية ،فسنجد
املبادئ الأخلاقية والتبريرات
لقد أد َّى الإحساس الواسع الانتشار بضرورة وأهمية التعامُل مع التحديات الأخلاقية
وا ُملجتمعية التي أثارها الذكاء الاصطناعي إلى َسيل من املبادرات ووثائق السياسات التي
لا تُع ِّرف فقط بعض املشكلات الأخلاقية ا ُملرتبطة بالذكاء الاصطناعي ولكنها تهدف
أيضا إلى توفري توجيهات ِمعيارية للسياسات .وقد ُ
ً
اقترحت سياسات خاصة بالذكاء
عنصر أخلاقي من قِ بل مجموعة متنوعة من الجهات ،بما في ذلك
الاصطناعي تشتمل على
ٍ
الحكومات والهيئات الحكومية مثل اللجان الوطنية للأخلاقيات ،وشركات التكنولوجيا
مثل جوجل ،واملهندسني ومنظماتهم املهنية مثل معهد مهندسي الكهرباء والإلكترونيات،
والهيئات الحكومية الدولية مثل الاتحاد الأوروبي ،والجهات غري الحكومية وغري الهادفة
للربح ،والباحثني.
لقد أد َّى الإحساس الواسع الانتشار بضرورة وأهمية التعامُل مع التحديات الأخلاقية وا ُملجتمعية
التي أثارها الذكاء الاصطناعي إلى َسيل من املبادرات ووثائق السياسات.

إذا راجعنا بعض املبادرات واملقترحات الحديثة ، َّ
يتبني أن معظم الوثائق تبدأ بتبرير
السياسة من خلال توضيح املبادئ ،ثم تُقدم بعض التوصيات فيما يتعلق باملشكلات
أخلاقيات الذكاء الاصطناعي

الأخلاقية ا ُملحددة .وكما سنرى ،هذه املشكلات واملبادئ شديدة التشابُه .وفي كثري من
ِ
تعتمد املبادرات على مبادئ أخلاقية عامة ومبادئ من قانون أخلاقيات املهنة.
الحالات،
راجع معكم بعض املقترحات.
فدعوني أ ُ ِ
ترفض معظم املقترحات سيناريو الخيال العلمي الذي تستولي فيه الآلات الفائقة
 َّ
وتتولى فيه السيطرة .على سبيل املثال ،في فترة رئاسة أوباما،
الذ َّكاء على زمام الأمور
نشرت حكومة الولايات املتحدة تقري ًرا بعنوان »الاستعداد ُملستقبل الذكاء الاصطناعي«،
ً
صراحة على أن املخاوف الطويلة الأمد بشأن الذكاء الاصطناعي الفائق العام
تؤ ِّكد فيه
»يجب ألا يكون لها تأثري كبري على السياسة الحالية« )املكتب التنفيذي للرئيس ،٢٠١٦
وبدلا من ذلك ،يتناول التقرير ا ُملشكلات الحالية وا ُمل َّ
ً
توقعة في املستقبل القريب التي
.(٨
يُثريها تع ُّلم الآلة ،مثل التحي ُّز ومشكلة أنه حتى ا ُملطورون قد لا يفهمون نظامهم بما فيه
الكفاية لتجن ُّب مثل هذه العواقب .ويؤ ِّكد التقرير أن الذكاء الاصطناعي مُفيد للابتكار
والنمو الاقتصادي ويُشد ِّد على الرقابة الذاتية ،ولكنه يقول إن حكومة الولايات املتحدة
لزم الأمر.
يُمكنها مراقبة سلامة التطبيقات وعدالتها ،وتعديل الأطر القانونية إذا ِ
علاو ًة على ذلك ،تملك العديد من الدول الأوروبية حاليٍّا استراتيجيات للذكاء
ً
هدفا
الاصطناعي تتضم َّ ن عنصرًا أخلاقيٍّا .ويُعد »الذكاء الاصطناعي القابل للتفسري«
مشتر ًكا بني العديد من صانعي السياسات .يقول مجلس عموم اململكة املتحدة )(٢٠١٨
إن الشفافية وحق التفسري أمور أساسية لنتم َّكن من مساءلة الخوارزميات ،ويجب
على الصناعات والجهات التشريعية التعامُل مع مسألة اتخاذ القرارات ا ُملتحيزة من
قِ بل الخوارزميات .كذلك تفحص لجنة مجلس لوردات اململكة املتحدة املختارة ا َملعنية
بالذكاء الاصطناعي التداعِ يات الأخلاقية للذكاء الاصطناعي .وفي فرنسا ،يقترح تقرير
ُ
تفاقم مشكلات
فيلاني العمل نحو تطوير »ذكاء اصطناعي ذي معنًى« لا يؤدي إلى
الإقصاء ،أو يزيد من التفاوت الاجتماعي ،أو يؤدي إلى مجتمع تح ُكمنا فيه خوارزميات
ً
»صناديق سوداء«؛ إذ يجب أن يكون الذكاء الاصطناعي ً
وصديقا للبيئة
قابلا للتفسري
ً
مجلسا استشاريٍّا وطنيٍّا معنيٍّا بالروبوتات
) .(Villani 2018كما أنشأت النمسا مؤخ ًرا
ٍ
ٍ
لسياسة تستنِد إلى حقوق الإنسان ،والعدالة
توصيات
والذكاء الاصطناعي 1 ،والذي قد َّم
والإنصاف ،والإشراك والتضامُن ،والديمقراطية واملشاركة ،وعدم التمييز ،واملسئولية،
قابل للتفسري
و ِقيَم أخرى شبيهة .كما تُوصي ورقتها البيضاء بتطوير ذكاء اصطناعي
ٍ
ً
صراحة إن املسئولية تظ ُّل على عاتق البشر؛ ولا يمكن أن يكون الذكاء الاصطناعي
وتقول
السياسات املقترحة

ً
مسئولا أخلاقيٍّا ) .(ACRAI 2018كذلك ،فإن الهيئات واملؤتمرات الدولية نشطة للغاية.
فقد نشر املؤتمر الدولي ُملفوضي حماية البيانات والخصوصية إعلانًا بشأن الأخلاقيات
وحماية البيانات في الذكاء الاصطناعي ،ويتضم َّ ن مبادئ العدالة ،واملساءلة ،والشفافية
والفهم ،والتصميم املسئول ،والخصوصية ا ُملتضمنة في التصميم )مفهوم يُطالب بمراعاة
الخصوصية في جميع مراحل عملية الهندسة( ،وتمكني الأفراد ،والح ِّد من التحيز أو
التمييز وتخفيف آثارهما ).(ICDPPC 2018
يضع بعض صانعي السياسات هدفهم في إطار »الذكاء الاصطناعي الجدير بالثقة«.
فعلى سبيل املثال ،تؤ ِّكد ا ُملفوضية الأوروبية ،التي تُعَ د بلا ش ٍّك واحدة من أبرز الهيئات
العاملية في مجال ُ
صنع سياسات الذكاء الاصطناعي ،على أهمية هذا املصطلح .وفي أبريل
َ
ٍ
مجموعة
فريق خبراء رفيع املستوى مع ِنيٍّا بالذكاء الاصطناعي لوضع
 ،٢٠١٨أنشأت
جديدة من إرشادات الذكاء الاصطناعي؛ وفي ديسمبر ،٢٠١٨أصدر الفريق مُسودة
نهج في الذكاء الاصطناعي يتمحور حول
وثيقة عمل تتضم َّ ن إرشادات أخلاقية تدعو إلى ٍ
الإنسان ،وإلى تطوير ذكاءٍ اصطناعي جدير بالثقة ،يحترم الحقوق الأساسية واملبادئ
الأخلاقية .وكانت الحقوق املذكورة هي كرامة الإنسان ،وحرية الفرد ،واحترام الديمقراطية،
والعدالة ،وسيادة القانون ،وحقوق املواطن .أما املبادئ الأخلاقية ،فهي الإحسان )فعل
الخري( وعدم إلحاق الأذى ،والاستقلال )الحفاظ على وكالة الإنسان( ،والعدالة )أن تكون
ً
عادلا( ،والقابلية للتفسري )شفافية التنفيذ( .هذه املبادئ مألوفة من مجال أخلاقيات علم
ٍ
تفسريات تسلط الضوء على
الأحياء ،ولكن الوثيقة تُضيف إليها القابلية للتفسري ،وتتضم َّ ن
املشكلات الأخلاقية الخاصة التي يُثريها الذكاء الاصطناعي .على سبيل املثال ،ي ِّ
ُفسر مبدأ
عدم إلحاق الأذى على املطالبة بأن خوارزميات الذكاء الاصطناعي يجب أن تتجن َّب التمييز،
ويجب أن تحمي الفئات الضعيفة مثل الأطفال واملهاجرين.
والتلاعُ ب ،والتوجيه السلبيِ ،
 ِّ
أما مبدأ العدالة ،في َّ
ومنفذيه
ُفسر على أنه يتضمن مطالبة مطوري الذكاء الاصطناعي
بضمان احتفاظ الأفراد واملجموعات الأقلية بالتح ُّرر من التحي ُّز .ويفسر مبدأ القابلية
للتفسري على أنه يُطالب بأن تكون أنظمة الذكاء الاصطناعي قابلة للتدقيق و»مفهومة
من قِ بل البشر على اختلاف مستويات فهمهم وخبرتهم« )European Commission AI
 ٍّ
خاص
بشكل
 .(HLEG 2018, 10وتُحد ِّد النسخة النهائية ،التي صدرت في أبريل ،٢٠١٩
ٍ
أن قابلية التفسري لا تتع َّلق فقط بتفسري العملية التقنية ولكن ً
أيضا بالقرارات البشرية
ذات ِّ
الصلة بها ).(European Commission AI HLEG 2019, 18
أخلاقيات الذكاء الاصطناعي

في ٍ
وقت سابق ،أصدرت هيئة استشارية أخرى تابعة إلى الاتحاد الأوروبي ،وهي
املجموعة الأوروبية ا َملعنية بالأخلاقيات في العلوم والتقنيات الجديدة بيانًا حول الذكاء
ً
مقترحة مبادئ الكرامة الإنسانية ،والاستقلال،
الاصطناعي والروبوتات والأنظمة ا ُملستقلة،
واملسئولية ،والعدالة ،واملساواة ،والتضامُن ،والديمقراطية ،وسيادة القانون واملساءلة،
والأمان والسلامة ،وحماية البيانات والخصوصية ،والاستدامة .ويُقال إن مبدأ الكرامة
الإنسانية يقتضي إعلام الأفراد بما إذا كانوا يتفاعلون مَ ع آلة أم م َع إنسان آخر )EGE
 .(2018كذلك عليك ملاحظة أن الاتحاد الأوروبي لدَيه بالفعل تشريعات قائمة تتعلق
بتطوير الذكاء الاصطناعي واستخدامه .وتهدف لائحة حِ ماية البيانات العامة ،التي
اعتُ ِمدت في مايو ،٢٠١٨إلى حماية جميع مواطني الاتحاد الأوروبي وتمكينهم فيما يتع َّلق
بخصوصية البيانات .وتتضم َّ ن مبادئ مثل حق الفرد في نسيان بياناته )يمكن للفرد أن
يطلب مسح بياناته الشخصية ووقف معالجة تلك البيانات في املستقبل( وا ْلخصوصية
ا ُملتضم َّ نة في التصميم .كما تمنح الأفراد املعنيني حق الوصول إلى »معلومات ذات معنى
حول املنطق ا ُملضم َّ ن« في اتخاذ القرارات املؤتمتة ومعلومات حول »العواقب ا ُمل َّ
توقعة«
لِمثل هذه املعالجة )البرملان الأوروبي ومجلس الاتحاد الأوروبي .(٢٠١٦الاختلاف عن
وثائق السياسة هو أن هذه املبادئ املذكورة هنا تُعد مُتطلبات قانونية .إنها بمثابة تشريع
 َّ
املؤسسات التي تنتهك لائحة حماية البيانات العامة يُمكن تغريمها.
مفروض؛ بمعنى أن
ومع ذلك ،ثمة تساؤل مطروح عما إذا كانت أحكام لائحة حماية البيانات العام َّ ة تكافئ
الحق الكامل في تفسري القرار ) ،(Digital Europe 2018وبشكل عام ،إذا كانت ِّ
توفر
حماية كافية ضد مخاطر اتخاذ القرار املؤتمت )Wachter, Mittelstadt, and Floridi
 .(2017توفر لائحة حماية البيانات العام َّ ة الحق في الإعلام باتخاذ القرار املؤتمت ولكن
قرار بعَ ينه .وهذه ً
أيضا مشكلة فيما
يبدو أنها لا تُطالِب بتفسري الأساس املنطقي لأي ٍ
ٌ
دراسة أجراها مجلس أوروبا،
يتع َّلق باتخاذ القرار في املجال القانوني .وقد طالبت
ٍ
ٍ
محاكمة عادلة
لجنة من خبراء حقوق الإنسان ،بأن يكون للأفراد الحق في
استنادًا إلى عمل
وإجراءات قانونية سليمة بشروط يُمكنهم فهمها ).(Yeung 2018
تُعَ د املناقشات القانونية ذات أهمي ٍة بالطبع في املناقشات ا ُملتعلقة بأخلاقيات الذكاء
الاصطناعي وسياسة الذكاء الاصطناعي .وقد ناقش ترينر ) (٢٠١٩املقارنات بالحيوانات
)كيف عومِلت وتُعامل في القانون وما إذا كانت تتمت َّع بحقوق( وراجع عددًا من الصكوك
القانونية فيما يتعلق بما يمكن أن تعني للذكاء الاصطناعي .على سبيل املثال ،عند وقوع
السياسات املقترحة

ٌ
شخص ما مُلتزمً ا بواجب الرعاية لتجن ُّب
الضرر ،فإن مسألة الإهمال تتعلق بما إذا كان
وقوع ضرر ،حتى إذا لم يكن الضرَ ر الواقع مقصودًا .يمكن أن ينطبق ذلك على مُصمم أو
مُدرب الذكاء الاصطناعي .ولكن ما مدى سهولة التنبؤ بعواقب الذكاء الاصطناعي؟ أما
القانون الجنائي ،فعلى العكس من ذلك ،فهو يتط َّلب ِني َّة إيقاع الضرر .ولكن هذا غالبًا
ليس الحال مع الذكاء الاصطناعي .من ناحي ٍة أخرى ،لا تتعلق املسئولية عن املنتَج بخطأ
ٍ
تعويضات عن الأضرار،
تفرض على الشركة التي أنتجت التكنولوجيا دفع
الأفراد ولكنها ِ
 ِّ
بغض النظر عن الخطأ .ويمكن أن يكون هذا أحد الحلول ا ُملمكنة للمسئولية القانونية عن
الذكاء الاصطناعي .كذلك تت َّصل قوانني امللكية الفكرية بالذكاء الاصطناعي ،مثل حقوق
الطبع والنشر وبراءات الاختراع ،وقد بدأت مناقشات حول »الشخصية الاعتبارية« للذكاء
ً
افتراضا قانونيٍّا ولكنه ذريعة تُطب َّق حاليٍّا على الشركات ومختلف
الاصطناعي ،وهو ما يُعد
ا ُملنظمات .فهل يجب أن يُطب َّق ً
قرار مُثري للجدل في عام
أيضا على الذكاء الاصطناعي؟ في ٍ
 ،٢٠١٧اقترح البرملان الأوروبي أن منح الروبوتات الذاتية التشغيل الأكثر تطو ًرا منزلة
الأشخاص الإلكترونيني هو ح ٌّل قانوني مُمكن لقضية املسئولية القانونية؛ وهذه الفكرة لم
يتم الاعتراف بها من قِ بل املفوضية الأوروبية في استراتيجيتها للذكاء الاصطناعي 2في عام
ً
حقوق وشخصية للآلات،
اعتراضا حازمً ا على فكرة إعطاء
 .٢٠١٨كذلك اعترض آخرون
ٍ
مُجادِ لني ،على سبيل املثال ،بأنه سيُصبح من الصعب ،إن لم ي ُكن من ا ُملستحيل ،محاسبة
لأغراض ذاتية )Bryson,
شخص لأن الناس سيسعَ ون إلى استغلال هذه الفكرة
أي
ٍ
ٍ
ً
 .(Diamantis, and Grant 2017كان هناك أيضا الحالة الشهرية لصوفيا ،الروبوت
الذي منحته السعودية »الجنسية« في عام .٢٠١٧تُثري مثل هذه الحالة مجددًا مسألة
املكانة الأخلاقية للروبوتات والذكاء الاصطناعي )انظر الفصل الرابع(.
اقترحَ ت ً
أيضا سياسات ذكاء اصطناعي خارج نطاق أمريكا الشمالية وأوروبا.
ُِ
فالصني ،على سبيل املثال ،لدَيها استراتيجية وطنية للذكاء الاصطناعي .وتُقر ُخطتها
التنموية بأن الذكاء الاصطناعي هو تكنولوجيا هد َّامة يمكن أن تضر َّ بالاستقرار الاجتماعي،
وتنتهك الخصوصية الشخصية ،وتخلق
وتؤثر على القانون والأخلاقيات الاجتماعية،
ِ
ُ
مخاطر أمنية؛ ومِن ثَم تُوصي الخطة بتعزيز الوقاية املستقبلية وتقليل املخاطر املحتمَ لة
)مجلس الدولة الصيني .(٢٠١٧وتروي بعض الجهات الفاعلة في الغرب سردية منافسة:
َ
حرب عاملية
نقترب من اندلاع
يخشون أن تتجاوزهم الصني أو حتى فكرة أننا
إنهم
ِ
ٍ
جديدة .بينما يُحاول آخرون التع ُّلم من استراتيجية الصني .وقد يتساءل الباحثون ً
أيضا
أخلاقيات الذكاء الاصطناعي

عن كيفية تعامُل الثقافات املختلفة مع الذكاء الاصطناعي بط ُرق مختلفة .ويمكن أن
يُسهم البحث في مجال الذكاء الاصطناعي نفسه في بناء وجهة نظر مقارنة عابرة للثقافات
بشأن أخلاقيات الذكاء الاصطناعي ،على سبيل املثال ،عندما يُذكرنا بالفروق بني الثقافات
الفردية والجماعية فيما يتع َّلق با ُملعضلات الأخلاقية ) .(Awad et al. 2018ويمكن أن يُثري
ٍ
مشكلات لأخلاقيات الذكاء الاصطناعي إذا كانت تهدف إلى أن تكون عاملية .ويمكن
هذا
ً
أيضا استكشاف كيف تختلف السرديات حول الذكاء الاصطناعي في الصني أو اليابان ،على
سبيل املثال ،عن السرديات الغربية .ومع ذلك ،على الرغم من الاختلافات الثقافية ، َّ
يتبني أن
ٍ
بدرجة كبرية وملحوظة .فبينما تؤكد خطة
سياسات أخلاقيات الذكاء الاصطناعي مُتشابهة
الصني أكثر على الاستقرار الاجتماعي والصالح العام الجماعي ،إلا أن املخاطر الأخلاقية
ا ُملحددة واملبادئ املذكورة ليست مختلفة كثريًا عن تلك ا ُملقترحة من قِ بل الدول الغربية.

على الرغم من الاختلافات الثقافية ، َّ
يتبني أن سياسات أخلاقيات الذكاء الاصطناعي متشابهة بدرجة
كبرية وملحوظة.

ً
سابقا ،سياسة أخلاقيات الذكاء الاصطناعي ليست مقصور ًة
ولكن ،كما ذكرنا
على الحكومات ولجانها وهيئاتها فقط .فقد أخذ الأكاديميون ً
أيضا زمام املبادرة .على
اقترحَ إعلان مونتريال بشأن الذكاء الاصطناعي املسئول من قِ بل جامعة
سبيل املثالِ ُ ،
مونتريال وشمل استشارة املواطنني والخبراء وغريهم من أصحاب الشأن .ويقول الإعلان
إن تطوير الذكاء الاصطناعي يجب أن يُع ِّزز رفاه جميع املخلوقات الحية ويُع ِّزز استقلال
البشر ،ويقضي على جميع أنواع التمييز ،ويحترم الخصوصية الشخصية ،ويَحمينا
من الدعاية والتلاعُ ب ،ويُع ِّزز النقاش الديمقراطي ،ويجعل مختلف الجهات الفاعلة
مَ سئولني عن مكافحة مخاطر الذكاء الاصطناعي ).(Université de Montréal 2017
وقد اقترح باحثون آخرون مبادئ الإحسان ،وعدم التسب ُّب في الأذى ،والاستقلال ،والعدالة،
وقابلية التفسري ) .(Floridi et al. 2018وتعمل الجامعات مثل كامبريدج وستانفورد
على أخلاقيات الذكاء الاصطناعي ،غالبًا من وجهة نظر الأخلاق التطبيقية .وكذلك يؤدي
أيضا ً
العاملون في مجال الأخلاق املهنية ً
الأشخاص ِ
عملا مُفيدًا .على سبيل املثال ،قدم مركز
ً
مجموعة من النظريات الأخلاقية كأدا ٍة
ماركولا للأخلاق التطبيقية في جامعة سانتا كلارا
السياسات املقترحة

ُملمارسة التكنولوجيا والهندسة ،والتي قد تُفيد ً
أيضا في إثراء أخلاقيات الذكاء الاصطناعي
باملعلومات 3 .كما أبدى فلاسفة التكنولوجيا اهتمامً ا كبريًا بالذكاء الاصطناعي مؤخ ًرا.
نجد ً
أيضا مُبادرات بشأن أخلاقيات الذكاء الاصطناعي في عالم الشركات .على سبيل
املثال ،يدخل في الشراكة بشأن الذكاء الاصطناعي شركات مثل ديب مايند ،وآي بي إم،
وإنتل ،وأمازون ،وأبل ،وسوني ،وفيسبوك 4 .وتدرك العديد من الشركات الحاجة إلى الذكاء
الاصطناعي الأخلاقي .على سبيل املثال ،نشرت جوجل مبادئ أخلاقيات الذكاء الاصطناعي:
تقديم فائدة اجتماعية ،وتجن ُّب التسب ُّب في التحي ُّز غري العادل أو تعزيزه ،وفرض السلامة،
والحفاظ على تحم ُّ ل املسئولية ،والحفاظ على تصميم الخصوصية ،وتعزيز التمي ُّز العلمي،
وتقييد التطبيقات التي يُحتَمل كونها ضارة أو مُسيئة مثل الأسلحة أو التكنولوجيا
تنتهك مبادئ القانون الدولي وحقوق الإنسان 5 .وتتحد َّث شركة مايكروسوفت عن
التي ِ
فكرة »الذكاء الاصطناعي من أجل الخري« وتقترح مبادئ العدالة ،واملوثوقية والسلامة،
والخصوصية والأمان ،والتضمني ،والشفافية ،واملساءلة 6 .كما اقترحت شركة أكسنتشر
مبادئ عاملية لأخلاقيات البيانات ،بما في ذلك احترام الأشخاص الكامنة وراء البيانات،
والخصوصية ،والتضمني ،والشفافية 7 .وعلى الرغم من أن وثائق الشركات تَميل إلى التركيز
على الرقابة الذاتية ،فإن بعض الشركات تعترف بضرورة اللوائح التنظيمية الخارجية.
وقد قال تيم كوك الرئيس التنفيذي لشركة أبل إن اللوائح التنظيمية التكنولوجية ،على
سبيل املثال ،لضمان الخصوصية أمر لا غِ نى عنه لأن السوق الحرة التي لا تخضع لرقابة
حكومية لا تُفيد في هذه الحالة 8 .ومع ذلك ،هناك جدل حول ما إذا كان هذا يتطلب لوائح
تنظيمية جديدة .ويدعم البعض مسار اللوائح التنظيمية ،بما في ذلك القوانني الجديدة.
فقد قدمت ولاية كاليفورنيا بالفعل مشروع قانون يطالب بالكشف عن الروبوتات:
بطريقة تُض ِّلل َّ
ٍ
الشخص الآخر حول هويته الاصطناعية أمر غري
فإن استخدام الروبوت
ً
موقفا أكثر تحف ً
ظا .فقد جادلت شركة ديجيتال يوروب
قانوني 9 .وتتخذ شركات أخرى
) ،(٢٠١٨التي تمثل الصناعة الرقمية في أوروبا ،بأن الإطار القانوني الحالي مُجه َّ ز ملعالجة
املشكلات املتعلقة بالذكاء الاصطناعي ،بما فيها التحي ُّز والتمييز ،ولكن لبناء الثقة ،فإن
الشفافية والقابلية للتفسري أمران غاية في الأهمية :يجب أن يفهم الأفراد والشركات متى
ٍ
ٍ
معلومات ذات
بحاجة إلى توفري
وكيف تُستخدَم الخوارزميات في اتخاذ القرارات ،ونحن
معنى وتيسري عملية تفسري القرارات الخوارزمية.
تلعب الجهات غري الهادفة إلى الربح دو ًرا ً
أيضا .على سبيل املثال ،تطرح الحملة
الدولية لوقف الروبوتات القاتلة العديد من الأسئلة الأخلاقية بشأن التطبيقات العسكرية
أخلاقيات الذكاء الاصطناعي

للذكاء الاصطناعي 10ومن جانب دُعاة تجاوز الإنسانية ،تُوجَ د مبادئ الذكاء الاصطناعي
التي ات َّفق عليها املشاركون الأكاديميون والصناعيون في مؤتمر أسيلومار ،وهو مؤتمر
عقده »معهد مستقبل الحياة« )ماكس تيجمارك وآخرون( .وكان الهدف العام هو
الحرص على أن يظل الذكاء الاصطناعي مفيدًا ،واحترام املبادئ والقيم الأخلاقية مثل
السلامة والشفافية واملسئولية ،وتوجيه القيم ،والخصوصية ،والتحكم البشري 11 .هناك
ً
أيضا منظمات مهنية تعمل في مجال سياسات الذكاء الاصطناعي .فقد طرح معهد مهندسي
الكهرباء والإلكترونيات ،الذي يزعم أنه أكبر منظمة مهنية فنية في العالم ،مبادر ًة عاملية
ٍ
مناقشات بني الخبراء ،أثمرت املبادرة عن
حول أخلاقيات الأنظمة الذكية وا ُملستقلة .وبعد
ٍ
وثيقة تتضم َّ ن رؤية ل »تصمي ٍم موج َّ ه أخلاقيٍّا« ،تقترح أن يكون تصميم هذه التقنيات
وتطويرها وتنفيذها موجهً ا بواسطة املبادئ العامة لحقوق الإنسان والرفاه واملساءلة
والشفافية والتوعية بشأن سوء ْ
الاستِخدام .ويمكن أن يكون تضمني الأخلاق في املعايري
التكنولوجية العاملية وسيلة فع َّ الة للمساهمة في تطوير الذكاء الاصطناعي الأخلاقي.
الحلول التكنولوجية ومسألة الأساليب والتنفيذ
تبني املبادرة العاملية التي طرحها معهد مهندسي الكهرباء والإلكترونيات أنه فيما يتعلق
بالتدابري ،تُركز بعض وثائق السياسات على الحلول التكنولوجية .على سبيل املثال ،كما
ذكرنا في الفصل السابق ،دعا بعض الباحِ ثني إلى الذكاء الاصطناعي القابل للتفسري ،إلى
فتح الصندوق الأسود .وهناك أسباب وجيهة للرغبة في فِ عل ذلك؛ إذ إن تفسري املنطق وراء
القرار الذي يُت َّ َخذ ليس مطلبًا أخلاقيٍّا فقط ولكنه ً
أيضا جانب مُهم من الذكاء البشري
) .(Samek, Wiegand, and Müller 2017إذَن فالفكرة وراء الذكاء الاصطناعي القابل
 َّ
الشفاف هي أن يكون من السهل فهم أفعال الذكاء الاصطناعي وقراراته.
للتفسري أو
وكما رأينا ،فإن هذه الفكرة من الصعب تنفيذها في حالة تع ُّلم الآلة الذي يستخدم
الشبكات العصبية ) .(Goebel et al. 2018ولكن يمكن للسياسات بالطبع دعم البحث
في هذا الاتجاه.
بشكل عام ،فإن فكرة تضمني الأخلاق في تصميم التقنيات الجديدة هي فكرة رائعة.
 َّ
الحساس
ويمكن أن تُساعدنا الأفكار مثل الأخلاقيات ا ُملتضمنة في التصميم أو التصميم
ٍ
بطريقة تؤدي إلى مزي ٍد
للقيم ،التي لها تاريخها الخاص 12 ،في تصميم الذكاء الاصطناعي
من املساءلة واملسئولية والشفافية .على سبيل املثال ،يمكن أن تنطوي الأخلاقيات ا ُملتضم َّ نة
السياسات املقترحة

في التصميم على ضمان التتب ُّع في جميع املراحل ) ،(Dignum et al. 2018مما يُسهم في
إمكانية مساءلة الذكاء الاصطناعي .ويمكن تحقيق فكرة التتبع حرفيٍّا ،بمعنى تسجيل
بيانات حول سلوك النظام .وقد طالب وينفيلد وجريوتكا ) (٢٠١٧بتنفيذ »صندوق
أسود أخلاقي« في الروبوتات والأنظمة ا ُملستق َّلة ،ليُسجل ما يفعله الروبوت )البيانات من
ٍ
بطريقة تُشبه الصندوق الأسود
الأجهزة الاستشعارية ومِن الوضع »الداخلي« للنظام(
ا ُملثب َّت في الطائرات .ويمكن تطبيق هذه الفكرة ً
أيضا في الذكاء الاصطناعي ا ُملستقل:
فعندما يحدث خطأ ما ،قد تُساعدنا مثل هذه البيانات في تفسري ما حدث بالضبط.
وهذا بدَوره قد يُساعد في التحليل الأخلاقي والقانوني للحالة .وعلاو ًة على ذلك ،كما
يقول الباحثون ،وهم م ُّ
ُحقون في قولهم ،يُمكننا أن نتع َّلم شيئًا من صناعة الطائرات،
 ُّ
للتحقق من السلامة وعمليات مرئية
التي تخضع إلى تنظي ٍم صارم ولدَيها عمليات دقيقة
للتحقيق في الحوادث .فهل يُمكن تثبيت ِبنية أساسية مُماثلة تضمن التنظيم والسلامة في
حالة الذكاء الاصطناعي؟ وللمُقارنة بمجال َ
آخر من مجالات وسائل النقل ،قد اقترحت
صناعة السيارات ً
أيضا شهاد ًة أو نوعً ا من »رخصة القيادة« للمركبات الذاتية التشغيل
املدعومة بالذكاء الاصطناعي .يذهب بعض الباحثني إلى أبعَ َد من ذلك ويهدفون إلى
ٍ
إنشاء ٍ
ُحاولة لتحقيق »أخلاقيات الآلة« بمعنى أن تستطيع الآلات نفسها
آلات أخلاقية ،في م
ٍ
يجب الاحتفاظ بهذه
اتخاذ
قرارات أخلاقية .ويُجادل آخرون بأن هذه فكرة خطرية وأنه ِ
القدرة َ
للبشر ،وأنه من ا ُملستحيل خلق آلات تتمت َّع بالوكالة الأخلاقية الكاملة ،ولا حاجة
إلى أن تتمت َّع الآلات بالوكالة الأخلاقية الكاملة ،ويكفي أن تكون الآلات ً
آمنة وملتزمة
بالقانون ) ،(Yampolskiy 2013أو قد تُ َ
نشأ أشكال من »الأخلاق الوظيفية« )Wallach
 (and Allen 2009التي لا تكافئ الوكالة الأخلاقية الكاملة ،ولكنها مع ذلك تجعل الآلة
م ً
ُراعية نسبيٍّا لقواعد الأخلاق .تُعد هذه املناقشة ،التي تتع َّلق مجددًا بموضوع املكانة
الأخلاقية ،ذات ِصلة ،على سبيل املثال ،في حالة السيارات الذاتية القيادة :وإلى أي مدًى
َ
ُستحسن تضمني القواعد الأخلاقية في هذه السيارات ،وما نوع هذه
يتعني ويمكن وي
القواعد الأخلاقية وكيف يُمكن تنفيذها تقنيٍّا؟
 َّ
الحساس للقِ يَم ،في
يمكن أن تُساعدنا الأفكار مثل الأخلاقيات ا ُملتضمنة في التصميم أو التصميم
إنشاء الذكاء الاصطناعي بطريقةٍ تؤدي إلى مزي ٍد من املساءلة واملسئولية والشفافية.
أخلاقيات الذكاء الاصطناعي

يميل صانعو السياسات إلى دعم العديد من هذه الاتجاهات في البحث والابتكار في
وبشكل عام ،تضمني
مجال الذكاء الاصطناعي ،مثل الذكاء الاصطناعي القابل للتفسري
ٍ
الأخلاق في التصميم .على سبيل املثال ،إلى جانب الأساليب غري التقنية مثل اللوائح
التنظيمية ،ووضع املعايري ،والتعليم ،وحوار الأطراف ا َملعنية وفِرق التصميم الشاملة،
ذكر تقرير فريق الخبراء الرفيع املستوى عددًا من الأساليب التقنية ومنها تضمني
القواعد الأخلاقية وسيادة القانون في التصميم ،وهياكل الذكاء الاصطناعي الجدير بالثقة،
والاختبار والتحقق ،والتتبع والتدقيق ،والتفسري .على سبيل املثال ،يُمكن أن تشتمل
الأخلاقيات ا ُملضمنة في التصميم على الخصوصية ا ُملضمنة في التصميم .ويُشري التقرير
ً
أيضا إلى بعض الطرق التي يُمكن بها تنفيذ الذكاء الاصطناعي الجدير بالثقة ،مثل التتب ُّع
ٍ
يجب
كطريقة للمساهمة في الشفافية :وفي حالة الذكاء الاصطناعي ا ُملستند إلى قواعد ِ
توضيح كيفية بناء النموذج ،وفي حالة الذكاء الاصطناعي ا ُملستنِد إلى التع ُّلم يجب توضيح
وسيلة تدريب الخوارزمية ،بما في ذلك كيفية جمع البيانات واختيارها .ومن ا ُملفترَض أن
يضمَ ن هذا أن يكون نظام الذكاء الاصطناعي ً
قابلا للتدقيق ،ولا سي َّما في املواقف الخطرية
).(European Commission AI HLEG 2019
َ
حاسمة الأهمية :حيث إن تحديد عددٍ من املبادئ
تُع ُّد مَ سألة الأساليب والتنفيذ
الأخلاقية شيء ،واكتشاف طريقة تنفيذ هذه املبادئ عمليٍّا شيءٌ مختلف تمامً ا .وحتى
املفاهيم مثل الخصوصية ا ُملضم َّ نة في التصميم ،التي يُفترض أن تكون أقرب إلى عملية
ٍ
بطريقة مجردة وعامة؛ ومِن ثَم فإننا ما زلنا لا ندري
التطوير والهندسة ،فغالبًا ما تُصاغ
ٍ
ملناقشة موجزة حول بعض
بالتحديد ما ينبغي أن نفعله .ويقودنا هذا إلى الفصل التالي
ِ
سياسات أخلاقيات الذكاء الاصطناعي.
تواجه
التحديات التي ِ
الفصل الحادي عشر

التحديات التي ُتواجه صانعي السياسات

الأخلاقيات الاستباقية :الابتكار املسئول وتضمني القِ يَم في التصميم
تواجه العديد من
ربما لا يُدهشنا أن نعرف أن سياسات أخلاقيات الذكاء الاصطناعي
ِ
ً
رؤية استباقية لأخلاقيات الذكاء
التحد ِّيات .وقد رأينا أن بعض السياسات ا ُملقترحة تؤيد
ٍ
بحاجة إلى مراعاة الأخلاق في املرحلة ا ُملبكرة من تطوير تكنولوجيا
الاصطناعي؛ بمعنى أننا
الذكاء الاصطناعي .وتكمُن الفكرة في تجن ُّب املشكلات الأخلاقية وا ُملجتمعية التي يخلقها
الذكاء الاصطناعي والتي سيكون من الصعب التعامُل معها بمجرد حدوثها .ويتماشى
هذا مع أفكار الابتكار املسئول ،وتضمني القِ يَم في التصميم ،وغريها من الأفكار ا ُملشابهة
اقترحت على مدار السنوات الأخرية .وهذا يُحو ِّل املشكلة من معالجة الآثار السلبية
التي ُ ِ
للتقنيات ا ُملستخدمة على نطاق واسع بالفعل إلى تحمل املسئولية تجاه التقنيات التي يتم
تطويرها اليوم.
 َّ
نتوقع العواقِ ب غري املقصودة للتقنيات الجديدة في
ومع ذلك ،ليس من السهل أن
مرحلة التصميم .إحدى الطرق لتخفيف هذه املشكلة هو بناء سيناريوهات حول العواقب
الأخلاقية ا ُملستقبلية .وهناك أساليب مُختلفة ملمارسة الأخلاقيات في البحث والابتكار
) ،(Reijers et al. 2018إحداها ليست فقط دراسة تأثري سرديات الذكاء الاصطناعي
ً
الحالية وتقييمها ) (Royal Society, 2018ولكن ً
واقعية
أيضا خلق سرديات جديدة أكثر
حول تطبيقات مُعينة للذكاء الاصطناعي.

أخلاقيات الذكاء الاصطناعي

النهج ا ُملوج َّ ه للمُمارسة والنهج التصاعدي :كيف نترجمهما عمليٍّا؟
الابتكار املسئول لا يتعلق فقط بتضمني الأخلاقيات في التصميم ،ولكنه يتط َّلب ً
أيضا
مراعاة آراء مُختلف الأطراف ا َملعنية ومصالحهم .وتنطوي الحوكمة الشاملة على إشراك
نقاش عام ،والتدخل ا ُملجتمعي ا ُملبكر في مرحلة
نطاق واسع من الأطراف ا َملعنية ،وإجراء ٍ
ٍ
ً
البحث والابتكار ) .(Von Schomberg 2011وهذا قد يعني ،مثلا ،تنظيم مجموعات
نقاش مركزة واستخدام تقنيات أخرى ملعرفة رأي الناس في التكنولوجيا.
ٍ
يتعارض هذا النهج التصاعدي في الابتكار املسئول مع نهج الأخلاقيات التطبيقية
الذي يتبعه معظم وثائق السياسات ،والذي يميل في الغالب إلى أن يكون نهجً ا تنازليٍّا
ومجردًاً .
أولا ،يتم إنشاء السياسات غالبًا من قِ بل خبراء ،دون أن يشارك فيها نطاق
واسع من الأطراف ا َملعنية .ثانيًا ،حتى إذا أي َّدت هذه السياسات مبادئ مثل الأخلاقيات
ا ُملضمنة في التصميم ،فإنها تظ ُّل شديدة الغموض فيما يتعلق بما يَعنيه تطبيق هذه
جسر بني
املبادئ عمليٍّا .ولإنجاح سياسة الذكاء الاصطناعي ،يظ ُّل التحدي كبريًا لبناء
ٍ
املبادئ الأخلاقية والقانونية ا ُملجردة والعالية املستوى من ناحية ،وبني مُمارسات تطوير
ٍ
سياقات مُعينة ،والتقنيات ،وأصوات أولئك الذين يشاركون
التكنولوجيا واستخدامها في
في هذه املمارسات ويعملون في هذه السياقات من ناحية أخرى .يُترك بناء هذا الجسر َملن
تُوج َّ ه إليهم هذه السياسات املقترحة .فهل يُمكننا القيام باملزيد في املرحلة الأولى من صنع
يجب علينا ذلك؟ نحتاج على الأقل إلى املزيد من العمل على الأساليب
السياسات ،وهل ِ
 َّ
واملؤسسات التي نحتاجها لجعل أخلاقيات الذكاء الاصطناعي تنجح عمليٍّا.
والإجراءات
ويجب علينا أن نُولي املزيد من الاهتمام للعملية.
الابتكار املسئول لا يتعلق فقط بتضمني الأخلاقيات في التصميم ،ولكنه يتطلب ً
أيضا مراعاة آراء
مختلف الأطراف ا َملعنية ومصالحهم.

فيما يتعلق بالسؤال عم َّ ن يشارك في وضع أخلاقيات الذكاء الاصطناعي ،فإننا
نحتاج إلى تطبيق نهج تصاعدي إلى جانب النهج التنازلي ،بمعنى الاستماع أكثر إلى
الباحثني واملهنيني الذين يتعاملون مع الذكاء الاصطناعي عمليٍّا ،بل وإلى الأشخاص الذين
من ا ُملحتمَ ل أن يضر َّ هم الذكاء الاصطناعي .إذا كنا نؤيد مبدأ الديمقراطية وإذا كان
التحديات التي تُواجه صانعي السياسات

هذا املفهوم يشمل التضمني واملشاركة في صنع القرار بشأن مُستقبل مجتمعاتنا ،فإن
سماع صوت الأطراف ا َملعنية ليس أم ًرا اختياريٍّا ولكنه إلزامي من الناحيتَني الأخلاقية
والسياسية .بينما يشارك بعض صانعي السياسات في نوع من التشاور مع الأطراف
املعنية )على سبيل املثال ،لدى املفوضية الأوروبية تحالف الذكاء الاصطناعي الخاص
بها( 1 ،لا يزال من املشكوك فيه ما إذا كانت مثل هذه الجهود تصل ٍّ
حقا إلى ا ُملطورين
 َّ
سيتعني عليهم تحم ُّ ل
واملستخدمني النهائيني للتكنولوجيا ،والأهم من ذلك ،إلى أولئك الذين
معظم املخاطر والتعايش مع آثارها السلبية .فهل ُ
صنع القرار والسياسات الخاصة
ٍّ
بالذكاء الاصطناعي أم ٌر ديمقراطي ينطوي على مشاركة حقا؟
إن مفهوم الديمقراطية مُهد َّد ً
 َّ
أيضا بحقيقة تركز السلطة في أيدي عددٍ صغري نسبيٍّا
من الشركات الكبرية .ويرى بول نيميتز ) (٢٠١٨أن ترا ُكم السلطة الرقمية في أيدي
شركات قليلة ينطوي على إشكالية :إذا مارست حفنة من الشركات ُسلطتها ليس فقط
على الأفراد — من خلال تكوين َّ
ات تعريفية عنا — ولكن ً
ملف ٍ
أيضا على البنية الأساسية
للديمقراطية ،فإن هذه الشركات ،على الرغم من نواياها الحسنة للمساهمة في الذكاء
عقبات أمامه .ولذلكِ ،
ٍ
فمن الضروري وضع لوائح
الاصطناعي الأخلاقي ،سوف تضع
تنظيمية وحدود لحماية املصلحة العامة ،ولضمان أن هذه الشركات لن تُشكل القواعد
بمفردها .وأشار موراي شاناهان إلى أن »ا َمليل إلى تر ُّكز السلطة والثروة واملوارد في أيدي
عدد قليل يت َّسم بالاستدامة الذاتية« ) ،(١٦٦ ،٢٠١٥مما يجعل من الصعب تحقيق
ً
إنصافا .كما أنه يجعل الأفراد عُ رضة لجميع أنواع املخاطر ،بما في ذلك
مجتمع أكثر
ٍ
الاستغلال وانتهاكات الخصوصية ،على سبيل املثال ،ما تُسم ِّ يه دراسة أجراها املجلس
الأوروبي »التأثري ا ُملرو ِّع لإعادة استخدام البيانات« ).(Yeung 2018, 33
إذا قارن َّا الوضع مع سياسة البيئة ،يُمكن أن نكون مُتشائمني ً
أيضا بشأن إمكانية أن
ُ
فلنأخذ ،على سبيل
تت َّخذ البلدان إجراءً فع َّ ًالا وتعاونيٍّا بشأن أخلاقيات الذكاء الاصطناعي.
 ُّ
بتغري املناخ في الولايات املتحدة ،حيث يتم في بعض
املثال ،العمليات السياسية ا ُملتعلقة
 ُّ
وتغري املناخ نفسها ،وحيث تعمل بعض القوى
الأحيان إنكار مشكلة الاحترار العاملي
السياسية ذات النفوذ ضد اتخاذ أي إجراءٍ حيال ذلك ،أو النجاح املحدود للغاية ملؤتمرات
 ُّ
يواجه أولئك الذين
تغري املناخ الدولية في الاتفاق على سياسة مناخية مشتركة وفع َّ الة .وقد ِ
يسعون إلى اتخاذ إجراءٍ عا َلمي في ظل املشكلات الأخلاقية واملجتمعية التي أثارها الذكاءُ
أخلاقيات الذكاء الاصطناعي

الاصطناعي صعوبات مُماثلة .فغالبًا ما تتفوق املصالح الأخرى على املصلحة العامة،
وهناك ندرة في السياسات الحكومية الدولية الخاصة بالتكنولوجيا الرقمية الجديدة ،بما
فيها الذكاء الاصطناعي .ومع ذلك ،هناك استثناءٌ واحد لذلك وهو الاهتمام العاملي بحظر
الأسلحة القاتلة الذاتية التشغيل ،التي تحتوي ً
أيضا على جانب ذكاء اصطناعي .ولكن هذا
لا يزال استثناءً ،ولا يحظى ً
أيضا بدعم جميع البلدان )على سبيل املثال ،ما زال موضع
جدل في الولايات املتحدة(.
علاو ًة على ذلك ،ورغم حسن النية ،فإن لك ٍّل من أخلاقيات التصميم والابتكار املسئول
قيودهما الخاصةً .
أولا ،تفترض أساليب مثل التصميم الحساس للقِ يَم أنه يُمكننا التعبري
عن قِ يَمنا ،وتفترض جهود بناء الآلات الأخلاقية أننا يمكن أن ن ُ ِّ
بشكل كامل عن
عبر
ٍ
بوضوح
أخلاقياتنا .ولكن هذا لا يحدث بالضرورة دائمً ا؛ إذ إننا قد لا نستطيع التفكري
ٍ
ولا التعبري عن أخلاقياتنا اليومية .ففي بعض الأحيان ،نستجيب إلى مشكلات أخلاقية
ٍ
بطريقة مُعينة دون أن نتمكن من تبرير استجابتنا بشكل كامل ).(Boddington 2017
شكل من
وكما قال فيتجنشتاين :أخلاقياتنا ليست فقط متجسدة ولكنها مُضم َّ نة في
ٍ
نحو عميق بطريقة قيامنا بالأفعال ككائنات متجسدة
أشكال الحياة .إنها متصلة على ٍ
واجتماعية ،وكمجتمعات وثقافات .وهذا يفرض حدودًا على مشروع التعبري الكامل عن
الأخلاق والتفكري الأخلاقي .ويمثل ً
أيضا مشكلة ملشروع تطوير الآلات الأخلاقية ،ويتحدى
الافتراضات التي تقول إن الأخلاق والديمقراطية يمكن مناقشتهما والتعبري عنهما بالكامل.
كما يخلق مشكلة لصانعي السياسات الذين يعتقدون أن أخلاقيات الذكاء الاصطناعي
يمكن التعامل معها تمامً ا من خلال قائمة من املبادئ أو من خلال أساليب قانونية وتقنية
ٍ
بحاجة إلى أساليب وإجراءات وعمليات .ولكن كل هذا ليس كافيًا؛
مُحد َّدة .نحن بالتأكيد
فالأخلاقيات لا تعمل مثل الآلة ،وكذلك السياسة والابتكار املسئول.
ثانيًا ،يُمكن أن يكون هذان النهجان ً
عائقا أمام الأخلاقيات عندما يكون من الواجب
أخلاقيٍّا إيقاف تطوير التكنولوجيا .فغالبًا ما تكون وظيفتهما من الناحية العملية هي
تيسري عملية الابتكار ،وتعزيز تحقيق الأرباح ،وضمان قبول التكنولوجيا .وقد لا يكون
هذا بالضرورة سيئًا .ولكن ماذا لو كانت املبادئ الأخلاقية تُشري إلى أنه يجب إيقاف أو
تعليق التكنولوجيا ،أو تطبيق م َّ
ُعني من تطبيقاتها؟ اعتبر كروفورد وكالو ) (٢٠١٦أن
 َّ
الحساس للقِ يَم والابتكار املسئول تعتمدان على افتراض أن التكنولوجيا
أداتَي التصميم
سيجري تطويرها؛ وتَق ُّل فعالي َّتهما عندما يتعلق الأمر باتخاذ قرار حول ما إذا كان يجب
التحديات التي تُواجه صانعي السياسات

إنشاء هذه التكنولوجيا من الأساس .على سبيل املثال ،في حالة الذكاء الاصطناعي ا ُملتقد ِّم
مثل تطبيقات تع ُّلم الآلة الجديدة ،ربما تكون هذه التكنولوجيا لا تزال غري جديرة بالثقة
أو لها عيوب أخلاقية خطرية ،وأن بعض تطبيقاتها على الأقل قد يتوجب عدم استخدامها
)بعد( .وسواء أكان وقف التكنولوجيا هو الحل الأفضل دائمً ا أم لا ،فإن القضية هي أننا
يجب على الأقل أن نتمت َّع بالحق في طرح السؤال وتقرير ما ينبغي فعله .فإذا كان هذا
ِ
الحق غائبًا ،فسوف يظ ُّل الابتكار املسئول ستا ًرا نُخفي وراءه مواصلة العمل كاملعتاد.
نحو أخلاقيات إيجابية
بشكل عا ٍّم لا تتع َّلق
على الرغم من ك ِّل ما قيل ،فإن أخلاقيات الذكاء الاصطناعي
ٍ
ٌ
عائق آخر يَحُ ول دون مُمارسة
بالضرورة بمنع الأشياء ) .(Boddington 2017هناك
أخلاقيات الذكاء الاصطناعي عمليٍّا ،وهذا العائق هو َّ
أن العديد من الجهات الفاعلة في
مجال الذكاء الاصطناعي مثل الشركات والباحثني التقني ِّني لا يزالون يعتبرون الأخلاقيات
بشكل كامل؛ إذ غالبًا ما يجب على
قيودًا ،أو أشياءً سلبية .هذه الفكرة ليست مُضللة
ٍ
الأخلاق أن تُقي ِّد ،وتَحُ د ،وتقو َل إن شيئًا ما غري مقبول .وإذا أخذنا أخلاقيات الذكاء
الاصطناعي على مَ حمل الجد َّ
واجه بعض التنا ُزلات ،ولا سي َّما على
ونفذنا توصياتها ،فقد ن ُ ِ
املدى القصري .فقد يكون للأخلاقيات ثمَ ن لا بد من دفعه؛ سواءٌ على مستوى املال أو
الوقت أو الطاقة .ومع ذلكِ ،
فمن خلال تقليل املخاطر ،تدعم الأخلاقيات والابتكار املسئول
َ
التنمية ا ُملستدامة للأعمال التجارية واملجتمع على املدى البعيد .ولا يزال هناك تَح ٍّد في
إقناع جميع الجهات الفاعلة في مجال الذكاء الاصطناعي ،بمَ ن فيهم صانعي السياسات،
فعلا .لاحظ ً
بأن هذا هو الحال ً
أيضا أن السياسة واللوائح التنظيمي َّة لا تتع َّلق فقط بحظر
ً
صعوبة وتعقيدًا؛ بل يُمكن أن تكون داعمة ،من خلال تقديم
الأشياء أو بجعلِها أكثر
حوافز ،على سبيل املثال.
علاو ًة على ذلك ،إلى جانب الأخلاقيات السلبية التي تفرض قيودًا ،نحن في حاجة
إلى توضيح الأخلاقيات الإيجابية وشرحها :لوضع رؤية للحياة الجيدة واملجتمع الجيد.
وبينما تلمح بعض املبادئ الأخلاقية املقترحة أعلاه إلى ِمثل هذه الرؤية ،فلا يزال
توجيه املناقشة إلى هذا الاتجاه تحديٍّا .كما سبق وذكرنا ،لا تتع َّلق املسائل الأخلاقية
الخاصة بالذكاء الاصطناعي بالتكنولوجيا فحسب؛ بل تتع َّلق بحياة الإنسان وازدهاره،
وتتع َّلق بمُستقبل املجتمع ،وربما تتعلق ً
أيضا بغري البشر ،وبالبيئة ،وبمُستقبل الكوكب
أخلاقيات الذكاء الاصطناعي

)انظر الفصل التالي( .وهكذا تُعيدنا املناقشات حول أخلاقيات الذكاء الاصطناعي
وسياساته من جدي ٍد إلى الأسئلة الكبرية التي يجب أن نطرحها على أنفسنا؛ أفرادًا،
ٍ
ُجتمعات ،وربما بشرًا .ويمكن للفلاسفة أن يُساعدونا في التفكري في هذه الأسئلة.
وم
وبالنسبة إلى صانعي السياسات ،يكمُن التحد ِّي في تطوير رؤية واسعة للمُستقبل
التكنولوجي تتضم َّ ن أفكا ًرا حول ما هو مُهم وما هو ذو معنًى وما هو ذو قيمة .على
بشكل عا ٍّم تتعم َّ د تجاهل مثل هذه الأسئلة وتركها
الرغم من أن الديمقراطيات الليبرالية
ٍ
 َّ
تتدخل في مثل هذه املوضوعات العميقة مثل ماهية الحياة الجيدة ومِن ثَم
للأفراد ،ولا
فهي »سطحية« )ابتكار سياسي أد َّى إلى تجن ُّب بعض أنواع الحروب على الأقل وساهم
تواجهنا ،فإن
في الاستقرار والازدهار( ،فإنه في ظ ِّل التحد ِّيات الأخلاقية والسياسية التي
ِ
ً
»عمقا« يُعتبر من قبيل انعدام املسئولية .وينبغي أن تتع َّلق
تجاهل الأسئلة الأخلاقية الأكثر
السياسة ً
أيضا ،بما فيها سياسات الذكاء الاصطناعي ،بالأخلاقيات الإيجابية.
بشكل عام ،لا تتع َّلق أخلاقيات الذكاء الاصطناعي بالضرورة بمنع الأشياء؛ بل نحن في حاجة إلى
ٍ
أخلاقيات إيجابية :لوضع رؤية للحياة الجيدة وا ُملجتمع الجيد.

ومع ذلك ،فالسبيل إلى ذلك من منظور صانعي السياسات ،ليس من خلال العمل
 ِّ
وتولي دور امللك الفيلسوف كما في فلسفة أفلاطون ،ولكن بالعثور على
بشكل فردي
ٍ
التوازن الصحيح بني التكنوقراطية والديمقراطية التشاركية .الأسئلة التي تُواجهنا هي
أسئلة تُهمنا جميعً ا؛ وعلينا أن نتشارك جميعً ا في الإجابة عنها .لذلك ،لا يُمكننا تركها في
أيدي ٍ
فئة قليلة من الأشخاص ،سواء أكانوا في الحكومة أم في الشركات الكبرية .ويُعيدنا هذا
إلى الأسئلة حول كيفية إنجاح الابتكار املسئول واملشاركة في سياسات الذكاء الاصطناعي.
املشكلة لا تتع َّلق فقط بالسلطة؛ إنها تتع َّلق ً
أيضا بالخري :الخري للأفراد والخري للمجتمع.
إن أفكارنا الحالية حول الحياة الجيدة واملجتمع الجيد — إذا كنا قادِ رين على التعبري
نقاش نقدي أعمق بكثري .ودعوني أقترح أنه قد يكون
عنها من الأساس — قد تحتاج إلى ٍ
ٍ
أنظمة سياسية أخرى
من ا ُملفيد للغرب ،على الأقل أن يستكشفوا خيار مُحاولة التع ُّلم من
غري غربية وثقافات سياسية أخرى .لا يجوز لسياسة الذكاء الاصطناعي الفع َّ الة وا ُملبررة
تجن ُّب املشاركة في مثل هذه النقاشات الأخلاقية الفلسفية والسياسية الفلسفية.
التحديات التي تُواجه صانعي السياسات

ُ
 ُّ
 ُّ
التخصصات
التخصصات وتجاوز
تداخل
هناك عوائق أخرى يجب تجاوزها إذا أردْنا جعل أخلاقيات الذكاء الاصطناعي أكثر
ً
فعالية وأردنا دعم التطوير املسئول للتكنولوجيا ،تجن ُّبًا ملا يُسميه الباحثون التقنيون
»شتاءَ« الذكاء الاصطناعي الجديد :إبطاء عملية تطوير الذكاء الاصطناعي والاستثمار
ُ
 ُّ
 ُّ
التخصصات الكافي .ما
التخصصات وتجاوز
تداخل
فيه .أحد هذه العوائق هو نقص
نواجه فجوة شاسعة في الخلفية والفهم بني ا ُمل ِّ
ختصني في العلوم الإنسانية والعلوم
زلنا
ِ
ٍ
الاجتماعية من جهة ،وا ُمل ِّ
جهة أخرى ،داخل
ختصني في العلوم الطبيعية والهندسية من
 َّ
املؤسسي لس ِّد الفجوة الواسعة
ا ُملجتمع الأكاديمي وخارجه .حتى الآن ،ما زلنا نفتقد الدعم
بني هذَين »العا َملني« ،سواء في املجتمع الأكاديمي أو في املجتمع الأوسع .ولكن إذا كن َّا نُريد
ٍّ
حقا أن نمتلك تكنولوجيا متقدمة أخلاقية مثل الذكاء الاصطناعي الأخلاقي ،فيجب علينا
أن نُق ِّرب بني هؤلاء الأشخاص وبني هذَين العا َملني ،في أقرب ٍ
وقت ممكن.
ً
فمثلا ،يجب أن
ويتط َّلب هذا إحداث تغيري في كيفية إجراء البحث والتطوير —
يُشارك فيه ليس فقط الأشخاص التقنيون ورجال الأعمال ولكن ً
أيضا م ُّ
ُختصون في
العلوم الإنسانية — وكذلك تغيري كيفية »تعليم« الأشخاص ،من الشباب وغريهم .يجب
أن نحرص على أن يُدرك الأشخاص الذين لدَيهم خلفية في العلوم الإنسانية أهمية التفكري
في التقنيات الجديدة مثل الذكاء الاصطناعي ويُحاولوا اكتساب بعض املعرفة حول هذه
ً
حساسية
التقنيات وما تقوم به .ومن ناحي ٍة أخرى ،يجب جعل العلماء واملهندسني أكثر
َ
ِ
واستخدامها .ومن ثم عندما
تجاه الجوانب الأخلاقية وا ُملجتمعية لتطوير التكنولوجيا
يتع َّلمون استخدام الذكاء الاصطناعي ،ويُساهمون بعد ذلك في تطوير تكنولوجيا الذكاء
 ُّ
يمت ِ
بص ٍلة إلى
الاصطناعي الجديدة ،فإنهم لن ي َروا الأخلاقيات موضوعً ا هامشيٍّا لا
مُمارساتهم التكنولوجية ولكن ي َرونها »جزءًا أساسيٍّا« من هذه املمارسات .وعندئذٍ ،في
الحالة املثالية ،ستعني »ممارسة الذكاء الاصطناعي« أو »ممارسة علم البيانات« أن يت َّم
نطاق أوسع ،يُمكننا
تضمني الأخلاقيات ببساطة بوصفها جزءًا أساسيٍّا لا غِ نى عنه .على
ٍ
 ُّ
التخصصات
شكل أكثر تنو ُّعً ا وشمولية من التعليم أو السرد تتداخل فيه
أن نفكر في
ٍ
ً
وأيضا بالوسائط والتقنيات .بعبار ٍة
جذريٍّا فيما يتعلق بالأساليب واملناهج ،وباملوضوعات،
أخرى أوضح ،إذا تع َّل َم املهندسون كيفية العمل باستخدام النصوص وتعلم ا ُملختصون في
العلوم الإنسانية كيفية العمل باستخدام أجهزة الكمبيوتر ،فسيزداد الأمل في أخلاقيات
التكنولوجيا وفي سياسة تصلح للتنفيذ عمليٍّا.
أخلاقيات الذكاء الاصطناعي

مخاطر »شتاء« الذكاء الاصطناعي وخطر الاستخدام اللاواعي
للذكاء الاصطناعي
وبشكل عام،
إذا لم يبدأ تنفيذ هذه التوجيهات في السياسة والتعليم على أرض الواقع،
ٍ
واجه فقط مخاطر »شتاء«
إذا فشل مشروع الذكاء الاصطناعي الأخلاقي ،فإننا لن ن ُ ِ
الذكاء الاصطناعي؛ بل إن الخطر الأدهى والأمَ َّر سيكمن في الكارثة الأخلاقية والاجتماعية
والاقتصادية التي ستُل ُّم بنا وسيدفع ثمنها البشر وغري البشر والبيئة .هذا لا يتعلق بالتفرد
التكنولوجي ،أو بالآلات التي ستدمر العالم ،أو بسيناريوهات نهاية العالم الأخرى حول
املستقبل البعيد ،ولكنه يتعلق بالزيادة البطيئة ولكن املؤكدة في تراكم املخاطر التكنولوجية
وما ينجم عنها من تفاقم الضعف البشري والاجتماعي والاقتصادي والبيئي .هذه الزيادة
في املخاطر والضعف مرتبطة باملشكلات الأخلاقية املشار إليها هنا وفي الفصول السابقة،
بما فيها الاستخدام الجاهل واملتهور لتقنيات الأتمتة ا ُملتقد ِّمة مثل الذكاء الاصطناعي.
بشكل عام :حتى
إن الفجوة في التعليم ربما تزيد من تأثري مخاطر الذكاء الاصطناعي
ٍ
لو لم تتسب َّب دائمً ا في مخاطر جديدة مباشرة ،فإنها تُضاعف املخاطر املوجودة بالفعل
نحو استثنائي .حتى الآن ،لا يُوجَ د ما يُسمى »رخصة قيادة« لاستخدام الذكاء
على ٍ
الاصطناعي ،ولا يُوجَ د تعليم إلزامي لأخلاقيات الذكاء الاصطناعي للباحثني التقني ِّني،
ورجال الأعمال ،ومسئولي الحكومة وغريهم من الأشخاص املشاركني في ابتكار الذكاء
الاصطناعي واستخدامه وسياساته .هناك الكثري من آلات الذكاء الاصطناعي غري ا ُملرو َّضة
أشخاص لا يعرفون املخاطر واملشكلات الأخلاقية ا ُملرتبطة بها ،أو الذين قد تكون
في أيدي
ٍ
لديهم توقعات خطأ بشأن التكنولوجيا .ويكمن الخطر ،مرة أخرى ،في ممارسة السلطة
دون معرفة و)بالتالي( دون مسئولية؛ والأسوأ من ذلك أن يخضع الآخرون إلى هذه
السلطة .وإذا كان هناك شر ٌّ على الإطلاق ،فإنه يُقيم حيثما قالت فيلسوفة القرن العشرين
حنة آرنت :في غياب الوعي عن القرارات والعمل اليومي ا ُململ .وعندما يُفترَض أن الذكاء
الاصطناعي غري مُتحيز ويُستخدَم دون َفهم ملا يتم القيام به ،فإن هذا من شأنه أن يُسهم
في تعميق غياب الوعي ،ثم في النهاية ،في الفساد الأخلاقي للعالم .وتستطيع سياسات
التعليم املساعَ دة في التخفيف من ذلك وبالتالي املساهمة في جعل الذكاء الاصطناعي جيدًا
وذا معنًى.
لا تزال هناك العديد من الأسئلة ا ُملزعجة ،وربما املؤلِمة إلى ح ٍّد ما ،التي غالبًا ما يتم
تجاهلها في املناقشات التي تدور حول أخلاقيات الذكاء الاصطناعي وسياساته ،ولكنها
التحديات التي تُواجه صانعي السياسات

 ُّ
ً
ً
كاملا .هل أخلاقيات
تحليلا
تستحق من َّا على الأقل أن نذ ُكرها هنا ،حتى وإن لم نُحللها
الذكاء الاصطناعي تتع َّلق فقط بخري البشر وقيمتهم ،أم إن علينا أن نراعي ً
أيضا قِ يَم غري
البشر وخريهم ومصالحهم؟ وحتى إذا كانت أخلاقيات الذكاء الاصطناعي تتعلق بشكل
رئيسي بالبشر ،فهل يمكن أن تكون أخلاقيات الذكاء الاصطناعي ليست باملسألة الأهم
التي َّ
يتعني على البشرية الاهتمام بها؟ يقودنا هذا السؤال إلى الفصل الأخري من الكتاب.
الفصل الثاني عشر

تغير المناخ :حول الأولويات
 ِّ
تحدي ُّ
وحقبة التأثير البشري

يجب أن تكون أخلاقيات الذكاء الاصطناعي محورها الإنسان؟
هل ِ
على الرغم من أن العديد من املؤ َّلفات ا ُملتعلقة بأخلاقيات الذكاء الاصطناعي والسياسات
تأتي على ذِ كر البيئة أو التنمية ا ُملستدامة ،فإنها تؤ ِّكد على القِ يَم الإنسانية وغالبًا ما
تتمحوَر حول الإنسان بوضوح .على سبيل املثال ،تقول الإرشادات الأخلاقية التي وضعها
نهج متمحور
فريق الخبراء الرفيع ا ُملستوى
 ِّ
املعني بالذكاء الاصطناعي إنه يجب تبن ِّي ٍ
ٍ
بمكانة أخلاقية فريدة وراسخة
حول الإنسان للذكاء الاصطناعي »يتمتع فيه الإنسان
لها أولوية على جميع الأصعدة املدنية والسياسية والاقتصادية والاجتماعية« )European
 (Commission AI HLEG 2019, 10وقد صاغت الجامعات مثل ستانفورد ومعهد
ماساتشوستس للتكنولوجيا سياسات بحثها في سياق الذكاء الاصطناعي ا ُملتمحور حول
الإنسان.
غالبًا ما يتم تعريف هذا التمحوُر حول الإنسان فيما يتعلق بالتكنولوجيا بإعطاء
الأولوية لخري الإنسان وكرامته على حساب ما قد تتط َّلبه أو تفعله التكنولوجيا.
فالتكنولوجيا يجب أن تعود بالفائدة على البشر وأن تخدمهم وليس العكس .ومع
ذلك ،وكما رأينا في الفصول الأولى ،فإن مدى مناسبة هذا التركيز على الإنسان في أخلاقيات
الذكاء الاصطناعي ليس واضحً ا كما قد يبدو للوهلة الأولى ،ولا سي َّما إذا أخذنا في الاعتبار
املناهج املؤيدة لتجاوز الإنسانية أو سرديات املنافسة )ما بني الإنسان والتكنولوجيا(.
وتبني فلسفة التكنولوجيا أن هناك املزيد من الطرق — الأكثر ً
دقة وتعقيدًا — لتحديد
العلاقة بني البشر والتكنولوجيا .علاو ًة على ذلك ،يُعد النهج ا ُملتمحور حول الإنسان غري

أخلاقيات الذكاء الاصطناعي

واضح على أقل تقدير ،إن لم ي ُكن مُثريًا للمشكلات ،في ضوء املناقشات الفلسفية حول
البيئة والكائنات الحية الأخرى .في فلسفة البيئة وأخلاقياتها ،هناك نقاش طويل حول
قيمة غري البشر ،خاصة الكائنات الحية ،وحول كيفية احترام تلك القيمة وهذه الكائنات،
 ُّ
يخص أخلاقيات
وحول املشكلات ا ُملحتملة التي قد تنشأ نتيجة احترام قيمة البشر .وفيما
الذكاء الاصطناعي ،فإن هذا يعني أن علينا على الأقل طرح السؤال بشأن تأثري الذكاء
الاصطناعي على الكائنات الحية الأخرى والنظر في احتمالية وجود تعا ُرض بني قِ يَم
ومصالح البشر وغري البشر.
تحديد الأولويات على النحو الصحيح
يمكن ً
أيضا القول بوجود مشكلات أخرى أكثر خطورة من تلك التي يُسببها الذكاء
بشكل صحيح .وقد ينشأ هذا الاعتراض من
الاصطناعي ،وأنه من ا ُملهم تحديد أولوياتنا
ٍ
تغري املناخ ،التي تُعد ً
النظر إلى املشكلات العاملية مثل ُّ
وفقا للبعض املشكلة الأهم التي
تحتاج البشرية إلى التصد ِّي لها وإيلائها الأولوية نظ ًرا إلى خطورتها وتأثريها ا ُملحتمَ ل على
الكوكب ٍّ
كلا.
واضح على أقل تقدير ،إن لم ي ُكن مُثريًا للمشكلات ،في ضوء
يُعَ د النهج ا ُملتمحور حول الإنسان غري
ٍ
املناقشات الفلسفية حول البيئة والكائنات الحية الأخرى.

بالنظر إلى جدول أعمال الأمم املتحدة للتنمية ا ُملستدامة لعام ) ٢٠١٥الذي يطلق
عليه أهداف التنمية ا ُملستدامة( 2ونظرته العامة إلى القضايا العاملية املتعلقة بما وصفه
الأمني العام للأمم املتحدة بان كي-مون »الإنسان والكوكب« ،نرى العديد من القضايا
العاملية التي تتط َّلب يقظة أخلاقية وسياسية :التفاوت الاجتماعي ا ُملتزايد داخل البلدان
وفيما بينها ،والحروب والتط ُّرف العنيف ،والفقر وسوء التغذية ،وصعوبة الوصول إلى
املياه العذبة ،ونقص املؤسسات الفعالة والديمقراطية ،وزيادة نِسبة السكان ا ُملتقد ِّمني
في السن ،والأمراض ا ُملعدية والوبائية ،ومخاطر الطاقة النووية ،ونقص الفرص للأطفال
َ
الجنسني وأشكال التمييز والإقصاء ا ُملختلفة ،والأزمات
والشباب ،وعدم املساواة بني
الإنسانية وجميع أنواع انتهاكات حقوق الإنسان ،وا ُملشكلات املتعلقة بالهجرة واللاجئني،
تحد ِّي ُّ
تغري املناخ :حول الأولويات وحقبة التأثري البشري

 ُّ
 ُّ
بتغري املناخ — مثل
وتغري املناخ واملشكلات البيئية — التي تتع َّلق في بعض الأحيان
الكوارث الطبيعية ا ُملتك ِّررة وا ُملتفاقمة وأشكال تدهور البيئة مثل الجفاف وفقدان التنوع
البيولوجي .في ضوء هذه املشكلات الضخمة ،هل يجب أن نعتبر الذكاء الاصطناعي
أولويتنا الأولى؟ وهل يُشت ِّت الذكاء الاصطناعي انتباهنا عن قضايا أكثر أهمية؟
من جهة ،يبدو أن التركيز على الذكاء الاصطناعي وغريه من املشكلات التكنولوجية
ٍ
مشكلات أخرى
في غري مح ِّله عندما يُعاني عدد هائل من البشر ويُعاني العالم بأسره من
كثرية للغاية .ففي حني أن الناس في أحد أنحاء العالم يُكافحون من أجل الوصول إلى املياه
ٍ
بيئات عنيفة ،يقلق آخرون في جزءٍ آخر من
العذبة أو من أجل البقاء على قيد الحياة في
ً
العا َلم بشأن خصوصيتهم على الإنترنت ويتخي َّلون مُستقبلا يُحقق فيه الذكاءُ الاصطناعي
الذكاءَ الفائق .من الناحية الأخلاقية ،يبدو أن شيئًا مُريبًا يحدث ،شيئًا يتعلق بالتفاوُت
 َّ
َ
الطرف عن مثل هذه
تغض الأخلاق والسياسات
الاجتماعي والظلم العا َلمي َّني .يجب ألا
املشكلات ،التي لا تتع َّلق بالضرورة بالذكاء الاصطناعي على الإطلاق .على سبيل املثال ،في
البلدان النامية ،يُمكن أحيانًا للتكنولوجيا ا ُملنخفضة التكلفة — وليس التكنولوجيا ا ُملتقدمة
— املساعدة في ح ِّل مُشكلات الناس؛ لأنهم يستطيعون أن يتحم َّ لوا تكاليفها ويستطيعون
تركيبها وصيانتها.
ً
ٍ
وأيضا يعمل
مشكلات جديدة
من جهة أخرى ،يمكن أن يُسبب الذكاء الاصطناعي
ُ
تفاقم املشكلات القائمة بالفعل في ا ُملجتمعات وفي البيئة .على سبيل املثال ،يخشى
على
البعض أن الذكاء الاصطناعي سيوسع الفجوة بني الأغنياء والفقراء ،وأنه ،مثل العديد
من التقنيات الرقمية ،سيزيد من استهلاك الطاقة ،ويخلق مزيدًا من النفايات .من هذا
املنظور ،فإن مناقشة أخلاقيات الذكاء الاصطناعي والتعامُل معها ليس تشتيتًا للانتباه
ولكنه إحدى الطرق التي يُمكننا من خلالها املساهمة في معالجة مشكلات العالم ،بما
بحاجة ً
ٍ
أيضا إلى إيلاء الاهتمام
فيها املشكلات البيئية .ومن ثَم ،يُمكننا أن نستخلص أننا
للذكاء الاصطناعي :نعم ،الفقر والحروب وما إلى ذلك هي مشكلات خطرية ،ولكن الذكاء
الاصطناعي يُمكن ً
أيضا أن يؤد ِّي إلى — أو يُساعد على — تفاقم مشكلات خطرية الآن وفي
ا ُملستقبل ،ويجب أن يكون في قائمة املشكلات التي تحتاج منا إلى إيجاد الحلول .ومع ذلك،
فهذا لا يُجيبنا عن السؤال املتعلق بالأولويات؛ وهو سؤال مُهم على مستوى الأخلاقيات
والسياسة على ح ٍّد سواء .إن القضية لا تتمثل في وجود إجابات سهلة عن ذلك السؤال؛ بل
القضية هي أن هذا السؤال لا يُط َرح حتى في معظم املؤ َّلفات الأكاديمية ووثائق السياسات
حول الذكاء الاصطناعي.
أخلاقيات الذكاء الاصطناعي

ففي حني أن الناس في أحد أنحاء العالم يُكافحون من أجل الوصول إلى املياه العذبة أو من أجل
بيئات عنيفة ،يقلق آخرون في جزء َ
ٍ
آخر من العالم بشأن خصوصيتهم على
البقاء على قيد الحياة في
الإنترنت.

 ُّ
وتغري املناخ وحقبة التأثري البشري
الذكاء الاصطناعي
إحدى أصعب الطرق لطرح السؤال ا ُملتعلق بالأولويات هو التع ُّرض ملناقشة مسألة ُّ
تغري
املناخ واملوضوعات ذات الصلة مثل حقبة التأثري البشري» :ملاذا نقلق بشأن الذكاء
الاصطناعي إذا كانت املشكلة امللح َّ ة هي ُّ
تغري املناخ وكون مُستقبل الكوكب في خطر؟«
أو دعونا نستعري عبار ًة من الثقافة السياسية الأمريكية» :إنه املناخ ،أيها الغبي!« وسوف
 ِّ
أوضح هنا هذا التحد ِّي وأناقش تداعِ ياته على التفكري في أخلاقيات الذكاء الاصطناعي.
في حني يرفض بعض املتط ِّرفني النتائج العلمية ،يُقر العلماء وصانعو السياسات
ً
مشكلة عاملية خطرية ولكنه ً
نطاق واسع بأن ُّ
أيضا »أحد أكبر
تغري املناخ ليس فقط
على
ٍ
التحد ِّيات في عصرنا« ،كما هو مذكور في ِّ
نص أهداف التنمية ا ُملستدامة للأمم املتحدة.
ً
مشكلة مُستقبلية :فدرجة الحرارة العاملية ومستويات البحر ترتفع بالفعل،
وهو ليس
مما يؤثر على البلدان واملناطق الساحلية ا ُملنخفضة .وقريبًا جدٍّا سوف يُضطر املزيد من
الناس إلى التعامُل مع عواقب ُّ
تغري املناخ .ويستنتج الكثريون من هذا أنه يجب علينا
بشكل عاجل للتخفيف من مخاطر تغري املناخ؛ وأنا أقول »التخفيف« لأن
التصر ُّف الآن
ٍ
 ُّ
التوقف .إن الفكرة هي أن هذا ليس فقط الوقت
العملية ربما قد تجاوزت بالفعل نقطة
املناسب للقيام بشيءٍ ولكن ربما فات الأوان بالفعل لتجن ُّب جميع العواقب .وباملقارنة مع
بشكل
مخاوف مؤيدي تجاوز الإنسانية بشأن الذكاء الفائق ،فإن هذه املخاوف مدعومة
ٍ
أفضل بالأدلة العلمية وحازت دعمً ا كبريًا بني الن ُّخب ا ُملثقفة في الغرب — التي ضجرت
من النزعة الشكية ما بعد الحداثية وسياسات الهوية البريوقراطية — التي ترى الآن سببًا
للتركيز على مشكلة يبدو أنها حقيقية للغاية وواقعية للغاية وعاملية للغاية : ُّ
تغري املناخ
يحدث ٍّ
حقا ويؤثر على ك ِّل شخص وكل شيء في هذا الكوكب .وتدعو حملة جريتا ثونبرج
والاعتصامات املناخية ،على سبيل املثال ،إلى توجيه الاهتمام إلى أزمة املناخ.
تحد ِّي ُّ
تغري املناخ :حول الأولويات وحقبة التأثري البشري

»ملاذا نقلق بشأن الذكاء الاصطناعي إذا كانت املشكلة امللح َّ ة هي ُّ
تغري املناخ وكون مُستقبل الكوكب
في خطر؟«

يُستخدَم أحيانًا مفهوم حقبة التأثري البشري لتأطري املشكلة .وهي فكرة طرحها بول
كروتزن الباحث في ُّ
 ُّ
وتنص على أننا نعيش في
تغري املناخ ويوجني ستورمر عالِم الأحياء،
حقبة جيولوجية زادت فيها قوة البشر على الأرض وعلى نظمها البيئية ،مما جعل البشر
قو ًة جيولوجية .ف ِّكر في النمو الأ ُ ِّسي لأعداد البشر واملاشية ،وفي التوسع العمراني املتزايد،
واستنزاف الوقود الأحفوري ،والاستخدام الهائل للمياه العذبة ،وانقراض الأنواع ،وإطلاق
املواد السامة ،وما إلى ذلك .يعتقد البعض أن حقبة التأثري البشري قد بدأت مع الثورة
الزراعية؛ بينما يرى آخرون أنها انطلقت بانطلاق الثورة الصناعية )(Crutzen 2006
أو بعد الحرب العاملية الثانية .على أي حال ،لقد نشأت قصة جديدة وتاريخ جديد،
وربما حتى سردية جديدة .وغالبًا ما يُستخدَم هذا املفهوم في الوقت الحاضر لإثارة القلق
 ُّ
 ُّ
التخصصات )بما في ذلك العلوم
وتغري املناخ ،ولحشد مختلف
بشأن الاحتباس الحراري
الإنسانية( للتفكري في مُستقبل الكوكب.
لا يتبن َّى الجميع هذا املصطلح؛ فهو مصطلح مُثري للجدل حتى بني الجيولوجيني،
وقد شكك البعض في تركيزه على أهمية البشر .على سبيل املثال ،قد جادلت هاراواي
) (٢٠١٥من منظور ما بعد الإنسانية بأن الأنواع الأخرى والعوامل »اللاحيوية« تلعب
ً
أيضا دو ًرا في البيئة املتحولة .ولكن حتى من دون مفهوم مُثري للجدل مثل حقبة التأثري
البشري ،فإن ُّ
ويجب على السياسة
تغري املناخ واملشكلات البيئية )الأخرى( ستظ ُّل باقيةِ ،
التعامُل معها ،والأفضل أن يكون ذلك في أقرب ٍ
وقت ممكن .فماذا يعني هذا بالنسبة إلى
سياسة الذكاء الاصطناعي؟
يعتقد العديد من الباحثني أن الذكاء الاصطناعي والبيانات الضخمة يُمكن أن
تُساعدنا ً
أيضا في علاج العديد من مشكلات العالم ،بما في ذلك ُّ
تغري املناخ .وعلى غرار
بشكل عام ،يمكن أن يُسهم الذكاء الاصطناعي في
املعلومات الرقمية وتقنيات الاتصالات
ٍ
التنمية املستدامة وفي التعامُل مع العديد من املشكلات البيئية .ومن ا ُملرج َّ ح أن يُصبح
ً
اتجاها ناجحً ا في البحث والتطوير .ومع ذلك ،يمكن أن يجعل
الذكاء الاصطناعي ا ُملستدام
 ُّ
 ُّ
يخصنا نحن جميعً ا.
يخص البيئة؛ وبالتالي فيما
الذكاء الاصطناعي الأمور أسوأ فيما
أخلاقيات الذكاء الاصطناعي

ولنتذ َّكر مجددًا زيادة استهلاك الطاقة والنفايات .ومن منظور مشكلة حقبة التأثري
البشري ،فإن املخاطرة تكمُن في أن البشر يمكن أن يستخدموا الذكاء الاصطناعي لإحكام
قبضتهم على الأرض ،مما سيزيد من حدة املشكلة ً
بدلا من ح ِّلها.
بشكل خاص إذا كنا ننظر إلى الذكاء الاصطناعي ليس
هذا يعتبر أم ًرا إشكاليٍّا
ٍ
فقط بوصفه ٍّ
حلا ولكن بوصفه الحل الرئيسي .ولنفكر في سيناريو الذكاء الفائق لذكاء
اصطناعي يعرف أفضل منا نحن البشر ما هو جيد لنا :ذكاء اصطناعي »حميد« يخدم
البشرية من خلال جعل البشر يتصر َّفون لصالحهم ولصالح الكوكب؛ على سبيل املثال،
الآلة الإله التي تُعادل تقنيٍّا امللك الفيلسوف املذكور في فلسفة أفلاطون .يحل الذكاء
الاصطناعي الإله محل الإنسان الإله ) ،(Harrari 2015ويدير نظام دعم الحياة الخاص
بنا ويديرنا .فلحل مشكلات توزيع املوارد ،على سبيل املثال ،يمكن للذكاء الاصطناعي أن
يعمل بوصفه »وحدة خدمة« ،يُدير إمكانية وصول البشر إلى املوارد .وستكون قراراته
حلول تكنولوجية
مُستندة إلى تحليله لأنماط البيانات .ويمكن دمج هذا السيناريو مع
ٍ
مبتكرة مثل الهندسة الجيولوجية .البشر ليسوا الوحيدين الذين يحتاجون إلى الإدارة؛
فالكون كله في حاجة إلى إعادة هندسته .ومن ثَم ،يُمكننا استخدام التكنولوجيا ل »إصلاح«
مشكلاتنا ومشكلات الكوكب.
ومع ذلك ،فإن هذه السيناريوهات لن تكون فقط مستبدة وتتعد َّى على استقلالية
البشر ،بل ستساهم ً
بشكل أساسي في مشكلة حقبة التأثري البشري نفسها :فالوكالة
أيضا
ٍ
البشرية ا ُملفرطة ،هذه املرة يتم تفويضها من قِ بل البشر إلى الآلات ،ستُحول الكوكب بأكمله
ورد وآلة للبشر .يتم »حل« مشكلة حقبة التأثري البشري من خلال الوصول
إلى مجرد مَ ِ
بها إلى النقيض التكنوقراطي ،مما يؤدي إلى عا َل ٍم من الآلات يُعامَ ل فيه البشر ً
أولا كأطفال
يجب رعايتهم وربما في ٍ
وقت لاحق يتم تجاهلهم تمامً ا .وفي هذا النوع من التأثري البشري
ا ُملتعلق بالبيانات الضخمة والسيناريو املألوف جدٍّا الذي يتم فيه إحلال الآلات مح َّل البشر،
نعود م َّرة أخرى إلى سيناريوهات الأحلام والكوابيس.
جنون الفضاء الجديد والإغراء الأفلاطوني
تغري املناخ وحقبة التأثري البشري ،والتي هي ً
ثم َّ ة إجابة أخرى على ُّ
أيضا رؤية مُولعة
بالتكنولوجيا وربما ترتبط أحيانًا بسرديات تجاوز البشرية ،وهي :قد نُدمر هذا الكوكب،
ولكن يُمكننا الهرب من الأرض والذهاب إلى الفضاء.
تحد ِّي ُّ
تغري املناخ :حول الأولويات وحقبة التأثري البشري

كانت الصورة الأيقونية لعام ٢٠١٨هي سيارة إيلون ماسك الرياضية طراز تسلا
وهي تطفو في الفضاء 3 .ماسك ً
أيضا لدَيه ُخطط لاستعمار املريخ .وهو ليس الشخص
ُراوده هذا الحلم :فهناك اهتمام مُتزايد بالذهاب إلى الفضاء .وهذا ليس
الوحيد الذي ي ِ
مجرد حلم .إذ تُستثمر أموال طائلة في مشروعات الفضاء .وعلى عكس سباق الفضاء
الذي حدث في القرن العشرين ،هذه املشروعات يتم دعمُها من قِ بل الشركات الخاصة.
واملليونريات ا ُملولعون بالتكنولوجيا ليسوا الوحيدِين ا ُملهتمني بالفضاء ،بل إن الفنانني ً
أيضا
شغوفون به بشدة .تُخطط شركة سبيس إكس الخاصة بإيلون ماسك لإرسال فنانني إلى
مدار القمر 4 .وتُعد السياحة الفضائية فكر ًة أخرى تزداد شيوعً ا .فمَ ن من َّا لا يرغب في
ُغر للغاية.
الذهاب إلى الفضاء؟ الفضاء م ٍ
ً
مشكلة في ح ِّد ذاته .بل إن له فوائد مُحتملة .على سبيل
لا يمثل الذهاب إلى الفضاء
ً
ٍ
تطرفا في
بيئات أكثر
املثال ،يمكن أن تساعد الأبحاث في كيفية البقاء على قيد الحياة في
التعامُل مع املشكلات على الأرض ،وفي اختبار التقنيات ا ُملستدامة ،واتخاذ منظور كوكبي.
ً
ضع في اعتبارك ً
ناجمة عن أن
أيضا أن مشكلة حقبة التأثري البشري يُمكن أن تكون
تكنولوجيا الفضاء منذ سنوات طويلة أتاحت لنا رؤية الأرض من بُعد .وبالنظر إلى صورة
سيارة ماسك مر ًة أخرى :يعتقد بعض الناس أن السيارة الكهربائية ح ٌّل من حلول
املشكلات البيئية ،دون التشكيك في افتراض أن السيارات هي أفضل وسيلة للنقل ودون
التفكري في كيفية إنتاج الكهرباء .على أي حال ،هناك أفكار مثرية للاهتمام.
ً
إشكالية إذا كانت نتيجتها هي إهمال املشكلات الأرضية،
ولكن أحلام الفضاء تُعد
عرضا من أعراض الحالة التي َّ
ً
شخصتها حنة أرنت ) (١٩٥٨بالفعل عندما
وإذا كانت
كتبت عن البشر :الكثري من التجريد والاغتراب .أشارت حنة إلى أن العِ لم يدعم رغبة دفينة
ً
وأيضا
في مغادرة الأرض :حرفيٍّا ،من خلال تكنولوجيا الفضاء )في عصرها ،سبوتنيك(
من خلال ُ
طرق رياضية تُجردنا وتَعزلنا مما ِ
أصفه بحياتنا الأرضية الفوضوية ا ُمل ِّ
تجسدة
والسياسية .ومن هذا املنظور ،يمكن تفسري أحلام مؤيدي تجاوز البشرية بالذكاء الفائق
وبمُغادرة الأرض على أنها تداعِ يات لنوع إشكالي من الاغتراب والهروب .إنها الفكر
الأفلاطوني وفكر تجاوز الإنسانية في أوضح صوره؛ إن الفكرة هي التغ ُّلب ليس فقط
على قيود الجسد البشري ،ولكن ً
أيضا على قيود ذلك »النظام الداعم للحياة« :أي الأرض
نفسها .فالجسد ليس هو السجن الوحيد ،بل الأرض نفسها ،ومن ثَم علينا أن نه ُرب
منها.
أخلاقيات الذكاء الاصطناعي

بالتالي ،فإحدى مخاطر الذكاء الاصطناعي هي أنه يُم ِّكن هذا النوع من التفكري
ويُصبح آلة للاغتراب :أداة ملغادرة الأرض وإنكار حالتنا الوجودية الاعتمادية الضعيفة
والجسدية والأرضية .بعبار ٍة أخرى :صاروخ .مرة أخرى ،لا تُمثل الصواريخ مشكلة في
ح ِّد ذاتها .إنما املشكلة هي مزج تقنيات مُعينة مع سرديات مُعينة .فعلى الرغم من أن
الذكاء الاصطناعي يمكن أن يكون قوة إيجابية بالنسبة إلى حياتنا الشخصية ،واملجتمع،
والبشرية ،فإن مزيجً ا من تعزيز الاتجاهات التجريدية والاغترابية في العلوم والتكنولوجيا
مستقبل تكنولوجي مؤ ٍذ
مع خيالات تجاوز الإنسانية و»تجاوز الأرض« قد يؤدي إلى
ٍ
للبشر وللكائنات الحية الأخرى على الأرض .إذا هربنا من مشكلاتنا ً
بدلا من التعامُل معها
— كما في مشكلة ُّ
تغري املناخ ،على سبيل املثال — فقد نفوز باملريخ )حتى الآن( ولكننا
سوف نخسر الأرض.
وكالعادة ،هناك جانب سياسي َ
ً
فرصا
آخر لهذا املوضوع :إذ يمتلك بعض الناس
ً
ً
مقارنة بالآخرين .املشكلة ليست فقط في أن تكنولوجيا
ومالا وقدر ًة أكبر على الهروب
الفضاء والذكاء الاصطناعي لهما تكلفة حقيقية بالنسبة إلى الأرض وأن ك َّل املال ا ُملستثمَ ر
في مشروعات الفضاء لم ي َ
ُنفق على مشكلات الأرض الحقيقية مثل الحروب والفقر؛ بل
املشكلة هي أن الأثرياء سيكونون قادِ رين على الهروب من الأرض التي يُدم ِّ رونها ،في
كوكب يستحيل العيش فيه بصورة متزايدة )انظر ،على
حني يجب على بقيتنا البقاء على
ٍ
سبيل املثال ،زيمرمان .(٢٠١٥ومثل الصواريخ والتكنولوجيا الأخرى ،يمكن أن يُصبح
الذكاء الاصطناعي أداة ل »بقاء الأكثر ثراءً« ،كما أوضح أحد املع ِّلقني ).(Rushkoff 2018
في الوقت الحاضر ،يحدث ذلك بالفعل مع تقنيات أخرى :ففي مدن مثل دلهي وبكني،
يُعاني معظم الناس من تلو ُّث الهواء ،بينما يطري الأثرياء إلى مناطق أقل تلوثًا أو يشترون
هواءً نقيٍّا باستخدام تقنيات تنقية الهواء .ليس الجميع َّ
يتنفسون الهواء نفسه .والآن ،هل
سيُساهم الذكاء الاصطناعي في توسيع هذه الفجوات بني الأثرياء والفقراء ،مما يؤدي إلى
َصرفنا الذكاء
حياة أكثر كربًا وغري صحية للبعض وحياة أفضل للبعض الآخر؟ هل سي ِ
الاصطناعي عن املشكلات البيئية؟ يبدو أن فكرة أن الذكاء الاصطناعي ينبغي أن يسعى
إلى تحسني الحياة على الأرض ،للجميع وليس لفئة معينة ،مع الوضع في الاعتبار أن حياتنا
تعتمد على كوكب الأرض ،تعد متطلبًا أخلاقيٍّا .وقد تعيق بعض سرديات الفضاء تحقيق
هذا الهدف ً
بدلا من أن تساعدنا في تحقيقه.
تحد ِّي ُّ
تغري املناخ :حول الأولويات وحقبة التأثري البشري

عودة إلى الأرض :نحو ذكاء اصطناعي مستدام
دعوني أعود إلى املشكلة العملية جدٍّا للأولويات واملخاطر الحالية والحقيقية ا ُملتعلقة
 ُّ
بتغري املناخ .ماذا يجب أن تفعل أخلاقيات الذكاء الاصطناعي وسياساته في ضوء هذه
التحديات؟ وعندما تكون هناك خلافات بشأن قيمة حياة الكائنات غري البشرية ،فكيف
يُمكن حلها؟ سيتفق معظم الناس على أن تسليم السيطرة إلى الذكاء الاصطناعي أو
ً
حلولا جيدة .لكن ما هو الحل الجيد؟ وهل يُوجَ د حل؟ إذا ما
الهروب من الأرض ليست
ً
إجابة نافعة على هذه الأسئلة ،فستقودنا بالضرورة إلى الأسئلة الفلسفية املتعلقة
أجبنا
ً
بكيفية تعامُلنا بوصفنا بشرًا مع التكنولوجيا ومع بيئتنا .كما تقودنا أيضا إلى الفصل
املتعلق بالتكنولوجيا :ماذا يمكن أن يفعل الذكاء الاصطناعي وعلم البيانات من أجلنا،
وماذا يُمكننا أن َّ
نتوقع من الذكاء الاصطناعي منطقيٍّا؟
من الواضح أن الذكاء الاصطناعي يمكن أن يساعدنا في التصدي للمشكلات البيئية.
فلنُفكر ً
مثلا في ُّ
نحو استثنائي أن
تغري املناخ .يبدو أن الذكاء الاصطناعي يستطيع على ٍ
 َّ
املعقدة .إذ يمكن للذكاء الاصطناعي مساعدتنا
يساعدنا في مواجهة مثل هذه املشكلات
في دراسة املشكلة ،على سبيل املثال ،من خلال اكتشاف الأنماط التي لا يُمكننا رؤيتها
في البيانات البيئية ،نظ ًرا إلى كثرة هذه البيانات وتعقيدها .كما يمكن أن يساعدنا في
الحلول ،على سبيل املثال ،من خلال مساعدتنا في التعامل مع تعقيد عمليات التنسيق وفي
تنفيذ تدابري مثل تقليل انبعاثات املواد الضارة ،كما اقترح فلوريدي وآخرون ).(٢٠١٨
وعلى نطاق أوسع ،يمكن أن يساعد الذكاء الاصطناعي من خلال مراقبة ونمذجة الأنظمة
البيئية وتمكني حلول مثل الشبكات الذكية للطاقة والزراعة الذكية ،كما اقترحت مُدونة
املنتدى الاقتصادي العاملي ) .(Herweijer 2018ويمكن للحكومات وللشركات ً
أيضا أن
 َّ
تتولى الأمر هنا .على سبيل املثال ،استخدمت جوجل بالفعل الذكاء الاصطناعي لتقليل
استخدام الطاقة في مراكز البيانات.
ومع ذلك ،لا يعني هذا بالضرورة »إنقاذ الكوكب« .يمكن للذكاء الاصطناعي ً
أيضا
أن يُسبب مشكلات ويجعل الأمور أسوأ .ولنفكر مر ًة أخرى في التأثري البيئي السلبي الذي
ِ
يعتمد
يمكن أن يُخلفه الذكاء الاصطناعي نظ ًرا إلى الطاقة وال ِبنى التحتية واملواد التي
عليها .ولنفكر ليس فقط في استخدام الذكاء الاصطناعي ولكن ً
أيضا في إنتاجه :قد تكون
الكهرباء مُنتجَ ة بطرق غري مستدامة ،كما أن إنتاج الأجهزة املدعومة بالذكاء الاصطناعي
يستهلك الطاقة واملواد الخام وينتج نفايات .أو فلنفكر في »الدفع الذاتي« الذي اقترحه
أخلاقيات الذكاء الاصطناعي

بطرق بيئية
فلوريدي وآخرون؛ إذ يقترحون أن الذكاء الاصطناعي قد يُساعدنا في التصرف
ٍ
جيدة عن طريق مساعدتنا في الالتزام بخيارنا املفروض ذاتيٍّا .ولكن هذا الأمر ينطوي
على مَ خاطره الأخلاقية الخاصة :فليس من الواضح أنه يحترم استقلال البشر وكرامتهم،
كما يدعي ال ُكت َّاب ،وقد يسري في اتجاه الذكاء الاصطناعي الحميد الذي يعتني بالبشر لكنه
يُدمر حريتهم ويُساهم في مشكلة حقبة التأثري البشري .وهناك على الأقل خطورة فرض
أشكال جديدة من السلطة الأبوية والاستبداد .علاو ًة على ذلك ،قد يتماشى استخدام الذكاء
ٍ
الاصطناعي ملواجهة ُّ
تغري املناخ مع النظرة العاملية التي تُحو ِّل العالم إلى مجرد مُستودع
بيانات ومع الرؤية التي تختزل ذكاء الإنسان إلى معالجة البيانات؛ بل ربما نوع أدنى
من معالجة البيانات يتط َّلب التحسني بواسطة الآلات .ومن غري ا ُملرج َّ ح أن تعيد مثل هذه
الرؤى تشكيل علاقتنا بالبيئة بطريقة تُ ِّ
خفف التحديات مثل ُّ
تغري املناخ واملشكلات املشار
إليها بمصطلح التأثري البشري.
نواجه ً
أيضا خطر النزعة للحلول التكنولوجية بمعنى أن الاقتراحات لاستخدام
الذكاء الاصطناعي ملعالجة املشكلات البيئية يُمكن أن تفترض أن هناك ٍّ
حلا نهائيٍّا لجميع
املشكلات ،وأن التكنولوجيا وحدَها يمكن أن تُجيب عن أصعب أسئلتنا ،وأننا يمكن أن
نحل املشكلات بالكامل عن طريق استخدام الذكاء البشري أو الاصطناعي .ولكن املشكلات
البيئية لا يمكن ح ُّلها عن طريق الذكاء التكنولوجي والعلمي؛ فهي مرتبطة ً
أيضا باملشكلات
السياسية والاجتماعية التي لا يمكن التصدي لها بالكامل عن طريق التكنولوجيا وحدَها.
ٍ
مشكلات بشرية .والرياضيات وذُريتها التكنولوجية
كما أن املشكلات البيئية دائمً ا ما تكون
هي أدوات مُفيدة جدٍّا ،ولكنها محدودة فيما يتعلق بفهم املشكلات البشرية والتعامُل
معها .على سبيل املثال ،قد تتعا َرض القِ يَم .ولن يستطيع الذكاء الاصطناعي بالضرورة
أن يُساعدنا في الإجابة عن السؤال حول الأولويات ،وهو سؤال أخلاقي وسياسي مُهم يجب
أن نترك للبشر الإجابة عنه .وتُع ِّلمنا العلوم الإنسانية والاجتماعية أن نكون حذِرين جدٍّا
بشأن الحلول »النهائية«.
ُ
علاو ًة على ذلك ،البشر ليسوا الوحيدِين الذين تواجههم مشكلات؛ فالكائنات غري
البشرية ً
أيضا تواجهها صعوبات ،والتي غالبًا ما تُهمَ ل في املناقشات الخاصة بمستقبل
يجب أن نهرب من الأرض ،أو الرؤية العاملية
الذكاء الاصطناعي .وأخريًا ،الرأي القائل بأننا ِ
التي تقول إن كل شيءٍ عبارة عن بيانات نستطيع نحن البشر التلاعُ ب بها بمساعدة الآلات،
ً
نطاقا
أشكال أوسع
يمكن أن يؤد ِّيا في النهاية إلى توسيع الفجوة بني الأغنياء والفقراء وإلى
ٍ
تحد ِّي ُّ
تغري املناخ :حول الأولويات وحقبة التأثري البشري

من الاستغلال والانتهاكات للكرامة الإنسانية ،بالإضافة إلى تهديد حياة الأجيال القادمة
عن طريق املخاطرة بتدمري ظروف الحياة على كوكبنا .إننا نحتاج إلى التفكري العميق في
كيفية بناء مجتمعات وبيئات مُستدامة؛ إننا نحتاج إلى التفكري البشري.
الذكاء والحكمة
ومع ذلك ،فطريقة تفكري البشر لها جوانب مُتعددة ً
أيضا .والذكاء الاصطناعي مرتبط
بنوع واحد من أنواع التفكري البشري والذكاء البشري :النوع املعرفي الأكثر تجريدًا .هذا
ٍ
النوع من التفكري قد أثبت نجاحً ا كبريًا ،ولكنه له قيوده وهو ليس النوع الوحيد من
التفكري الذي يُمكن أو يجب علينا مُمارسته .والإجابة عن الأسئلة الأخلاقية والسياسية
بشكل أفضل مع
ا ُملتعلقة بكيفية العيش ،وكيفية التعامُل مع بيئتنا ،وكيفية التعامُل
ٍ
الكائنات الحية غري البشرية تتط َّلب ما هو أكثر من الذكاء البشري التجريدي )على سبيل
املثال ،الحُ جج ،والنظريات ،والنماذج( أو التع ُّرف على الأنماط بواسطة الذكاء الاصطناعي.
أشخاص أذكياء وآلات ذكية ،ولكننا ً
ٍ
بحاجة إلى الحدس والخبرة التي لا
أيضا
نحتاج إلى
ٍ
ُ
ً
 ِّ
استجابة إلى
التحلي بالحكمة العملية والفضيلة
وصفها بوضوح كامل ،ونحتاج إلى
يمكن
املشكلات واملواقف املادية ومن أجل تحديد أولوياتنا .قد تستنري هذه الحكمة بالعمليات
املعرفية التجريدية وبتحليل البيانات ،ولكنها تستند ً
أيضا إلى التجارب ا ُمل ِّ
تجسدة الخاصة
بالعلاقات واملواقف التي نم ُّر بها في العالم ،وإلى التعامُل مع أشخاص آخرين ،ومع املادية،
ومع بيئتنا الطبيعية .ومن ا ُملحتمل أن يعتمد نجاحنا في التصدي للمشكلات الكبرية التي
تُواجهنا في عصرنا على مزيج من الذكاء التجريدي — البشري والاصطناعي — والحكمة
العملية امللموسة التي تم تطويرها على أساس التجارب وا ُملمارسات البشرية امللموسة
والخاصة باملواقف ،بما في ذلك تجاربنا مع التكنولوجيا .وأيٍّا كان الاتجاه الذي سيسري
ُواجهون تحد ِّي تطوير هذا
فيه تطوير الذكاء الاصطناعي ،فإن البشر وحدَهم هم مَ ن ي ِ
النوع الأخري من املعرفة والتعلم .وعلى البشر أن يتصد َّوا له .فالذكاء الاصطناعي قادر على
التع ُّرف على الأنماط ،ولكن الحكمة لا يمكن تفويضها إلى الآلات.
مسرد المصطلحات

الابتكار املسئول :نهج يميل إلى جعل الابتكار أكثر أخلاقية ومسئولية على الصعيد
املجتمعي ،وينطوي عاد ًة على تضمني الأخلاق في التصميم ومراعاة آراء أصحاب الشأن
ومصالحهم.
الأخلاقيات الإيجابية :الأخلاقيات املرتبطة بالطريقة التي ينبغي أن نعيش بها )معً ا(،
وتستند إلى رؤية للحياة الجيدة واملجتمع الجيد .وتتناقض مع الأخلاقيات السلبية ،التي
تضع قيودًا وتحدد ما ينبغي ألا نفعله.
الأخلاقيات ا ُملضم َّ نة في التصميم :نهج لأخلاقيات التكنولوجيا وعنصر أساسي في
»الابتكار املسئول« الذي يهدف إلى دمج الأخلاقيات في مرحلة تصميم التكنولوجيا
وتطويرها .وفي بعض الأحيان ،نُسميها »تضمني القيم في التصميم« .ومن املصطلحات
 َّ
الحساس للقِ يَم« و»التصميم ا ُملتماشي مع الأخلاق«.
املشابهة لهذا املصطلح »التصميم
يجب أن يُعززوا أنفسهم من خلال التقنيات
تجاوز الإنسانية :الاعتقاد بأن البشر ِ
ا ُملتقدمة ،وبهذه الطريقة يتجاوزون حالتهم الإنسانية؛ بمعنى أن الإنسانية يجب أن
تنتقِ ل إلى مرحلة جديدة .وهذه ً
أيضا حركة دولية.
التحيز :التمييز ضد أو لصالح أفراد بأعيُنهم أو مجموعات بعينها .في سياق الأخلاقيات
والسياسة ،يُثار السؤال حول ما إذا كان تَحي ُّز معني ظا ًملا أو غري عادل.
تع ُّلم الآلة :آلة أو برنامج يُمكنه أن يتعلم تلقائيٍّا :ليس بالطريقة التي يتع َّلم بها البشر،
ولكن بناءً على عملية حسابية وإحصائية .يمكن لخوارزميات التع ُّلم ،من خلال تغذيتها
بالبيانات ،تحديد الأنماط أو القواعد في البيانات وإجراء توقعات للبيانات املستقبلية.

أخلاقيات الذكاء الاصطناعي

التع ُّلم العميق :شكل من أشكال »تعلم الآلة« يستخدم الشبكات العصبية املكونة من عدة
طبقات من »الخلايا العصبية« :وحدات مُعالجة بسيطة مترابطة فيما بينها وتتفاعل.
التف ُّرد التكنولوجي :الفكرة التي تقول بأنه ستحني لحظة في تاريخ الإنسان عندما
يجلب انفجار في الذكاء الآلي تغيريًا جذريٍّا في حضارتنا يجعلنا لا نفهم بعدها ما يحدث.
حقبة التأثري البشري )الأنثروبوسني( :الحقبة الجيولوجية الحالية املزعومة التي زادت
فيها قوة البشر وتأثريهم على الأرض ونظمها البيئية ،مما جعل البشر قوة جيولوجية.
الذكاء الاصطناعي :الذكاء الذي تُظهره أو تُحاكيه الوسائل التكنولوجية .غالبًا ما
يُفترض أن معنى »الذكاء« في هذا التعريف يستند إلى مقاييس الذكاء البشري ،وي َ
ُقصد
به القدرات والسلوكيات الذكية التي يُظهرها البشر .ويمكن ً
أيضا أن يُشري املصطلح
إلى العلم أو إلى التقنيات ،مثل خوارزميات التعلم.
الذكاء الاصطناعي الجدير بالثقة :الذكاء الاصطناعي الذي يمكن للإنسان الوثوق فيه.
يمكن أن تُشري شروط هذه الثقة إلى مبادئ أخلاقية )أخرى( مثل الكرامة الإنسانية
واحترام حقوق الإنسان ،وما إلى ذلك ،و/أو إلى العوامل الاجتماعية والتقنية التي تؤثر
فيما إذا كان الناس يرغبون في استخدام التكنولوجيا .استخدام مصطلح »الثقة« فيما
يتعلق بالتكنولوجيا مُثري للجدل.
الذكاء الاصطناعي الرمزي :الذكاء الاصطناعي الذي يعتمد على التمثيلات الرمزية
للمهام املعرفية العليا ،مثل التفكري املجرد واتخاذ القرارات .ويمكن أن يستخدم شجرة
اتخاذ القرار ويأخذ شكل نظام خبري يتطلب مدخلات من خبراء املجال.
نطاق واسع
الذكاء الاصطناعي العام :الذكاء ا ُملشابه لذكاء البشر ،ويمكن تطبيقه على
ٍ
ٍ
مشكلة أو مُهمة
باملقارنة مع الذكاء الاصطناعي املحدود ،الذي يمكن تطبيقه على
مُعينة فقط .ويُطلق عليه ً
أيضا الذكاء الاصطناعي »القوي« في مقابل الذكاء الاصطناعي
»الضعيف«.
الذكاء الاصطناعي القابل للتفسري :الذكاء الاصطناعي الذي يمكن أن يشرح للبشر
تصرفاته أو قراراته أو توصياته ،أو يمكن أن يوفر معلومات كافية حول كيفية
الوصول إلى نتيجته.
مسرد املصطلحات

الذكاء الاصطناعي املستدام :الذكاء الاصطناعي الذي يُمَ ِّكن ويساهم في طريقة عيش
ً
)وأيضا
مستدامة للبشرية ولا يدمر النظم البيئية على الأرض التي يعتمد عليها البشر
العديد من غري البشر(.
الذكاء الفائق :الفكرة التي تقول بأن الآلات سوف تتفو َّق على ذكاء الإنسان .ويرتبط
الذكاء الفائق أحيانًا بفكرة »انفجار الذكاء الاصطناعي« الذي يُسب ِّبه تصميم الآلات
الذكية لآلات أكثر ذكاءً.
علم البيانات :علم متعدد التخصصات يستخدم الإحصاءات والخوارزميات وغريها من
ٍ
أنماط مفيدة وذات معنًى من مجموعات البيانات؛ املعروفة أحيانًا
الأساليب لاستخراج
باسم »البيانات الضخمة« .في الوقت الحالي ،يُستخدَم تع ُّلم الآلة في هذا املضمار .وبجانب
تحليل البيانات ،يهتم علم البيانات ً
أيضا باستخراج البيانات وإعدادها وتفسريها.
القابلية للتفسري :القدرة على التفسري أو قابلية التفسري .في سياق الأخلاقيات ،فإنه
يُشري إلى القدرة على الشرح للآخرين ملاذا َ
قمت بشيء مُعني أو ملاذا اتخذت قرا ًرا بعينِه؛
ً
مسئولا.
وهذا جزء مما يَعنيه أن تكون
ً
وخصوصا املكانة
ما بعد الإنسانية :مجموعة من ا ُملعتقدات التي تُشكك في الإنسانية،
املحورية للإنسان ،وتوسع دائرة الاهتمام الأخلاقي لتشمل غري البشر.
ٍ
كمرادف ملعنى أن يتحلى املرء بالأخلاق ،ومن
املسئولية الأخلاقية :يمكن استخدامها
ثَم فإنها تشري إلى تحقيق نتائج جيدة أخلاقيٍّا ،والالتزام باملبادئ الأخلاقية ،والتمتع
بالفضيلة ،واستحقاق الثناء ،وما إلى ذلك؛ حسب النظرية املعيارية ا ُملفترضة .يمكن
للمرء ً
أيضا أن يتساءل عن الشروط التي بموجبها يمكن إسناد املسئولية إليه .تُعد
شروط إسناد املسئولية الأخلاقية هي الوكالة الأخلاقية واملعرفة .وتؤكد نُهُ ج العلاقات
ً
مسئولا أمام الآخرين.
أن املرء يكون دائمً ا
املكانة الأخلاقية :املنزلة الأخلاقية التي يتمت َّع بها كيان ما؛ أي كيف ينبغي التعامُل مع
هذا الكيان.
الوكالة الأخلاقيةُ :
القدرة على الفعل والتفكري والحُ كم واتخاذ القرار الأخلاقيً ،
بدلا من
مجرد وجود عواقب أخلاقية.
ملاحظات

 أيتها املرآة على الحائط:الفصل الأول
(1) See https://www.youtube.com/watch?v=D5VN56jQMWM.
(2) See the case of Paul Zilly as told by Fry (2018, 71-72). More details in Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, “Machine Bias,” ProPublica, May 23, 2016, https://www.propublica.org/article/
machine-bias-risk-assessments-in-criminal-sentencing.
(3) For example, in 2016 a local police zone in Belgium started using
predictive policing software to predict burglaries and vehicle theft (Algorithm Watch 2019, 44).
(4) BuzzFeedVideo, “You Won’t Believe What Obama Says in this
Video!” https://www.youtube.com/watch?v=cQ54GDm1eL0&fbclid=IwA
R1oD0AlopEZa00XHo3WNcey_qNnNqTsvHN_aZsNb0d2t9cmsDbm9oCf
X8A.

 الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي:الفصل الثاني
(1) Some talk of taming or domesticating AI, although the analogy
with wild animals is problematic, if only because in contrast to the “wild”

أخلاقيات الذكاء الاصطناعي
AI some imagine, animals are limited by their natural faculties and can be
trained and developed only up to some point (Turner 2019).
(2) It is often suggested that Mary Shelley must have been influenced
by her parents, who discussed politics, philosophy, and literature, but also
science, and by her partner Percy Bysshe Shelley, who was an amateur scientist especially interested in electricity.

 كل ما له علاقة بالبشر:الفصل الثالث
(1) Dreyfus was influenced by Edmund Husserl, Martin Heidegger, and
Maurice Merleau-Ponty.

ٍّ أهي:الفصل الرابع
حقا مجرد آلات؟
(1) A real-world case of this was the robot dog Spot who was kicked by
its developers to test it, something that met with surprisingly empathetic
responses: https://www.youtube.com/watch?v=aR5Z6AoMh6U.

 التكنولوجيا:الفصل الخامس
(1) See https://www.humanbrainproject.eu/en/.
(2) See, for example, the European Commission’s AI High Level Expert
Group’s (2018) definition of AI.

َ لا:الفصل السادس
تنس )علم( البيانات
(1) See http://tylervigen.com/spurious-correlations.
(2) Concrete examples such as Facebook, Walmart, American Express,
Hello Barbie, and BMW are drawn from Marr (2018).
ملاحظات

ُ
لامسئولية الآلات والقرارات غري ا ُملبررة
:الفصل الثامن
(1) One could ask, however, if decisions made by AIs really count as
decisions, and if so, if there is a difference in the kind of decisions we delegate or should delegate to AIs. In this sense, the problem regarding responsibility of or for AI raises the very question of what a decision is. The problem also connects with issues about delegation: we delegate decisions to
machines. But what does this delegation entail in terms of responsibility?
(2) Indeed, this case is more complicated since one could argue that
the delegate is then still responsible for that particular task—at least to
some extent—and it may not be clear how the responsibility is distributed
in such cases.
(3) Note that this was and is not always the case; as Turner (2019)
reminds us, there are cases of animals being punished.

 التحيز ومعنى الحياة:الفصل التاسع
(1) Thanks to Bill Price for the thought experiment.

 السياسات املقترحة:الفصل العاشر
(1) See: https://www.acrai.at/en/.
(2) The resolution can be found here: http://www.europarl.europa.eu/
doceo/document/TA-8-2017-0051_EN.html?redirect#title1.
(3)

See:

https://www.scu.edu/ethics-in-technology-practice/

conceptual-frameworks/.
(4) See: https://www.partnershiponai.org/.
(5) See: https://www.blog.google/technology/ai/ai-principles/.
(6) See: https://www.microsoft.com/en-us/ai/our-approach-to-ai.
(7) See: https://www.accenture.com/t20160629T012639Z_w_/us-en/
_acnmedia/PDF-24/Accenture-Universal-Principles-Data-Ethics.pdf.
أخلاقيات الذكاء الاصطناعي
(8)

See: https://www.businessinsider.de/apple-ceo-tim-cook-on

-privacy-the-free-market-is-not-working-regulations-2018-11?r=
US&IR=T.
(9) See: https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?
bill_id=201720180SB1001.
(10) See: https://www.stopkillerrobots.org/.
(11) See: https://futureoflife.org/ai-principles/.
(12) Consider people such as Batya Friedman and Helen Nissenbaum
in the United States, and later Jeroen van den Hoven and others in the
Netherlands, who have been championing the ethical design of technology
for some time.
(13) See: https://www.tuev-sued.de/company/press/press-archive/
tuv-sud-and-dfki-to-develop-tuv-for-artificial-intelligence.

 التحديات التي تُواجه صانعي السياسات:الفصل الحادي عشر
(1) See: https://ec.europa.eu/digital-single-market/en/european-aialliance.

 تحد ِّي ُّ:الفصل الثاني عشر
 حول الأولويات وحقبة التأثري البشري:تغري املناخ
(1) See: https://hai.stanford.edu/ and https://hcai.mit.edu.
(2) See: https://sustainabledevelopment.un.org/post2015/transform
ingourworld.
(3) See: https://www.theguardian.com/science/2018/feb/07/spaceoddity-elon-musk-spacex-car-mars-falcon-heavy.
(4) See: https://cosmosmagazine.com/space/why-we-need-to-send
-artists-into-space.
قراءات إضافية

Alpaydin, Ethem, 2016, Machine Learning, Cambridge, MA: MIT Press.
Arendt, Hannah, 1958, The Human Condition, Chicago: Chicago University
Press.
Aristotle, 2002, Nichomachean Ethics, Translated by Christopher Rowe,
with commentary by Sarah Broadie, Oxford: Oxford University Press.
Boddington, Paula, 2017, Towards a Code of Ethics for Artificial Intelligence,
Cham: Springer.
Boden, Margaret A., 2016, AI: Its Nature and Future, Oxford: Oxford University Press.
Bostrom, Nick. 2014, Superintelligence, Oxford: Oxford University Press.
Brynjolfsson, Erik, and Andrew McAfee, 2014, The Second Machine Age,
New York: W. W. Norton.
Coeckelbergh, Mark, 2012, Growing Moral Relations: Critique of Moral
Status Ascription, New York: Palgrave Macmillan.
Crutzen, Paul J., 2006, “The ‘Anthropocene,’” In Earth System Science in
the Anthropocene, edited by Eckart Ehlers and Thomas Krafft, 13–18.
Cham: Springer.

أخلاقيات الذكاء الاصطناعي
Dignum, Virginia, Matteo Baldoni, Cristina Baroglio, Maruiyio Caon, Raja
Chatila, Louise Dennis, Gonzalo Génova, et al. 2018, “Ethics by Design: Necessity or Curse?” Association for the Advancement of Artificial Intelligence. http://www.aies-conference.com/2018/contents/
papers/main/AIES_2018_paper_68.pdf.
Dreyfus, Hubert L., 1972, What Computers Can’t Do, New York: Harper &
Row.
Floridi, Luciano, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice
Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo
Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, and Effy
Vayena, 2018, “AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.” Minds
and Machines 28, no. 4: 689–707.
Frankish, Keith, and William M. Ramsey, eds. 2014. The Cambridge
Handbook of Artificial Intelligence. Cambridge: Cambridge University
Press.
European Commission AI HLEG (High-Level Expert Group on Artificial Intelligence). 2019. “Ethics Guidelines for Trustworthy AI.” April 8, 2019.
Brussels: European Commission. https://ec.europa.eu/futurium/en/
ai-alliance-consultation/guidelines#Top.
Fry, Hannah. 2018. Hello World: Being Human in the Age of Algorithms.
New York and London: W. W. Norton.
Fuchs, Christian. 2014. Digital Labour and Karl Marx. New York: Routledge.
Gunkel, David. 2012. The Machine Question. Cambridge, MA: MIT Press.
Harari, Yuval Noah. 2015. Homo Deus: A Brief History of Tomorrow. London: Hervill Secker.
Haraway, Donna. 1991. “A Cyborg Manifesto: Science, Technology, and
Socialist-Feminism in the Late Twentieth Century.” In Simians,
قراءات إضافية
Cyborgs and Women: The Reinvention of Nature, 149–181. New
York: Routledge.
IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. 2017. “Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems,” Version 2. IEEE, 2017. http://standards.Ieee.org/develop/indconn/ec/
autonomous_systems.html.
Kelleher, John D. and Brendan Tierney. 2018. Data Science. Cambridge, MA:
MIT Press.
Nemitz, Paul Friedrich, 2018. “Constitutional Democracy and Technology in the Age of Artificial Intelligence.” Philosophical Transactions of
the Royal Society A 376, no. 2133. https://doi.org/10.1098/rsta.2018
.0089.
Noble, David F. 1997. The Religion of Technology. New York: Penguin Books.
Reijers, Wessel, David Wright, Philip Brey, Karsten Weber, Rowena Rodrigues, Declan O’Sullivan, and Bert Gordijn. 2018. “Methods for Practising Ethics in Research and Innovation: A Literature Review, Critical
Analysis and Recommendation.” Science and Engineering Ethics 24, no.
1437–1481.
Shelley, Mary. 2017. Frankenstein. Annotated edition. Edited by David H.
Guston, Ed Finn, and Jason Scott Robert. Cambridge, MA: MIT Press.
Turkle, Sherry. 2011. Alone Together: Why We Expect More from Technology
and Less from Each Other. New York: Basic Books.
Wallach, Wendell, and Colin Allen. 2009. Moral Machines: Teaching Robots
Right from Wrong. Oxford: Oxford University Press.
المراجع

Accessnow. 2018. “Mapping Regulatory Proposals for Artificial Intelligence in Europe.” https://www.accessnow.org/cms/assets/uploads/
/11/mapping_regulatory_proposals_for_AI_in_EU.pdf.
ACRAI (Austria Council on Robotics and Artificial Intelligence). 2018. “Die
Zukunft Österreichs mit Robotik und Künstlicher Intelligenz positive gestalten: White paper des Österreichischen Rats für Robotik und
Künstliche Intelligenz.”
“Algorithm and Blues.” 2016. Nature 537:449.
AlgorithmWatch. 2019. “Automating Society: Taking Stock of Automated
Decision Making in the EU.” A report by AlgorithmWatch in cooperation with Bertelsmann Stiftung. January 2019. Berlin: AW AlgorithmWatch GmbH. http://www.algorithmwatch.org/automatingsociety.
Alpaydin, Ethem. 2016. Machine Learning. Cambridge, MA: MIT Press.
Anderson, Michael and Susan Anderson. 2011. “General Introduction.” In
Machine Ethics, edited by Michael Anderson and Susan Anderson, 1–4.
Cambridge: Cambridge University Press.
Arendt, Hannah. 1958. The Human Condition. Chicago: Chicago University
Press.

أخلاقيات الذكاء الاصطناعي
Arkoudas, Konstantine, and Selmer Bringsjord. 2014. “Philosophical Foundations.” In The Cambridge Handbook of Artificial Intelligence, edited
by Keith Frankish and William M. Ramsey. Cambridge: Cambridge University Press.
Armstrong, Stuart. 2014. Smarter Than Us: The Rise of Machine Intelligence.
Berkeley: Machine Intelligence Research Institute.
Awad, Edmond, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-François Bonnefon, and Iyad Rahwan. 2018.
“The Moral Machine Experiment.” Nature 563:59–64.
Bacon, Francis. 1964. “The Refutation of Philosophies.” In The Philosophy
of Francis Bacon, edited by Benjamin Farrington, 103–132. Chicago:
University of Chicago Press.
Boddington, Paula. 2016. “The Distinctiveness of AI Ethics, and Implications for Ethical Codes.” Paper presented at the workshop
Ethics for Artificial Intelligence, July 9, 2016, IJCAI-16, New York.
https://www.cs.ox.ac.uk/efai/2016/11/02/the-distinctiveness-ofai-ethics-and-implications-for-ethical-codes/.
Boddington, Paula. 2017. Towards a Code of Ethics for Artificial Intelligence.
Cham: Springer.
Boden, Margaret A. 2016. AI: Its Nature and Future. Oxford: Oxford University Press.
Borowiec, Steven. 2016. “AlphaGo Seals 4–1 Victory Over Go Grandmaster
Lee Sedol.” Guardian, March 15. https://www.theguardian.com/
technology/2016/mar/15/googles-alphago-seals-4-1-victoryover-grandmaster-lee-sedol.
Bostrom, Nick. 2014. Superintelligence. Oxford: Oxford University Press.
Brynjolfsson, Erik, and Andrew McAfee. 2014. The Second Machine Age.
New York: W. W. Norton.
املراجع
Bryson, Joanna. 2010. “Robots Should Be Slaves.” In Close Engagements
with Artificial Companions: Key Social, Psychological, Ethical and
Design Issues, edited by Yorick Wilks, 63–74. Amsterdam: John
Benjamins.
Bryson, Joanna. 2018. “AI & Global Governance: No One Should Trust AI.”
United Nations University Centre for Policy Research. AI & Global
Governance, November 13, 2018. https://cpr.unu.edu/ai-globalgovernance-no-one-should-trust-ai.html.
Bryson, Joanna, Mihailis E. Diamantis, and Thomas D. Grant. 2017. “Of, For,
and By the People: The Legal Lacuna of Synthetic Persons.” Artificial
Intelligence & Law 25, no. 3: 273–291.
Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. 2017. “Semantics
Derived Automatically from Language Corpora Contain Human-like
Biases.” Science 356:183–186.
Castelvecchi, Davide. 2016. “Can We Open the Black Box of AI?” Nature
, no. 7623: 21–23.
CDT (Centre for Democracy & Technology) 2018. “Digital Decisions.”
https://cdt.org/issue/privacy-data/digital-decisions/.
Coeckelbergh, Mark. 2010. “Moral Appearances: Emotions, Robots, and
Human Morality.” Ethics and Information Technology 12, no. 3: 235–
Coeckelbergh, Mark. 2011. “You, Robot: On the Linguistic Construction of
Artificial Others.” AI & Society 26, no. 1: 61–69.
Coeckelbergh, Mark. 2012. Growing Moral Relations: Critique of Moral
Status Ascription. New York: Palgrave Macmillan.
Coeckelbergh, Mark. 2013. Human Being @ Risk: Enhancement, Technology,
and the Evaluation of Vulnerability Transformations. Cham: Springer.
Coeckelbergh, Mark. 2017. New Romantic Cyborgs. Cambridge, MA: MIT
Press.
أخلاقيات الذكاء الاصطناعي
Crawford, Kate, and Ryan Calo. 2016. “There Is a Blind Spot in AI Research.”
Nature 538:311–313.
Crutzen, Paul J. 2006. “The ‘Anthropocene.’” In Earth System Science in
the Anthropocene edited by Eckart Ehlers and Thomas Krafft, 13–18.
Cham: Springer.
Darling, Kate, Palash Nandy, and Cynthia Breazeal. 2015. “Empathic Concern and the Effect of Stories in Human-Robot Interaction.” In 2015
th IEEE International Symposium on Robot and Human Interactive
Communication (RO-MAN), 770–775. New York: IEEE.
Dennett, Daniel C. 1997. “Consciousness in Human and Robot Minds. In
Cognition, Computation, and Consciousness, edited by Masao Ito, Yasushi Miyashita, and Edmund T. Rolls, 17–29. New York: Oxford University Press.
Digital Europe. 2018. “Recommendations on AI Policy: Towards a Sustainable and Innovation-friendly Approach.” Digitaleurope.org, November
, 2018.
Dignum, Virginia, Matteo Baldoni, Cristina Baroglio, Maruiyio Caon, Raja
Chatila, Louise Dennis, Gonzalo Génova, et al. 2018. “Ethics by Design: Necessity or Curse?” Association for the Advancement of Artificial Intelligence. http://www.aies-conference.com/2018/contents/
papers/main/AIES_2018_paper_68.pdf.
Dowd, Maureen. 2017. “Elon Musk’s Billion-Dollar Crusade to Stop the
A.I. Apocalypse.” Vanity Fair, March 26, 2017. https://www.vanityfair
.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stopai-space-x.
Dreyfus, Hubert L. 1972. What Computers Can’t Do. New York:
HarperCollins.
املراجع
Druga, Stefania and Randi Williams. 2017. “Kids, AI Devices, and Intelligent Toys.” MIT Media Lab, June 6, 2017. https://www.media.mit.edu/
posts/kids-ai-devices/f.
European Commission. 2018. “Ethics and Data Protection.” http://
ec.europa.eu/research/participants/data/ref/h2020/grants_manual/
hi/ethics/h2020_hi_ethics-data-protection_en.pdf.
European Commission Directorate-General of Employment, Social Affairs
and Inclusion. 2018. “Employment and Social Developments in Europe
” Luxembourg: Publications Office of the European Union. http://
ec.europa.eu/social/main.jsp?catId=738&langId=en&pubId=8110.
European Commission AI HLEG (High-Level Expert Group on Artificial Intelligence). 2018. “Draft Ethics Guidelines for Trustworthy AI: Working
Document for Stakeholders.” Working document, December 18, 2018.
Brussels: European Commission. https://ec.europa.eu/digital-singlemarket/en/news/draft-ethics-guidelines-trustworthy-ai.
European Commission AI HLEG (High-Level Expert Group on Artificial Intelligence). 2019. “Ethics Guidelines for Trustworthy AI.” April 8, 2019.
Brussels: European Commission. https://ec.europa.eu/futurium/en/
ai-alliance-consultation/guidelines#Top.
EGE (European Group on Ethics in Science and New Technologies). 2018.
“Statement on Artificial Intelligence, Robotics and ‘Autonomous’ Systems.” Brussels: European Commission.
European Parliament and the Council of the European Union. 2016. “General Data Protection Regulation (GDPR).” https://eur-lex.europa.eu/
legal-content/EN/TXT/?uri=celex%3A32016R0679.
Executive Office of the President, National Science and Technology Council
Committee on Technology. 2016. “Preparing for the Future of Artificial
Intelligence.” Washington, DC: Office of Science and Technology Policy
(OSTP).
أخلاقيات الذكاء الاصطناعي
Floridi, Luciano, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice
Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo
Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, and Effy
Vayena. 2018. “AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.” Minds
and Machines 28, no. 4: 689–707.
Floridi, Luciano, and J. W. Sanders. 2004. “On the Morality of Artificial
Agents.” Minds and Machines 14, no. 3: 349–379.
Ford, Martin. 2015. Rise of the Robots: Technology and the Threat of a
Jobless Future. New York: Basic Books.
Frankish, Keith, and William M. Ramsey. 2014. “Introduction.” In The
Cambridge Handbook of Artificial Intelligence, edited by Keith Frankish and William M. Ramsey, 1–14. Cambridge: Cambridge University
Press.
Frey, Carl Benedikt, and Michael A. Osborne. 2013. “The Future of Employment: How Susceptible Are Jobs to Computerisation?” Working paper,
Oxford Martin Programme on Technology and Employment, University
of Oxford.
Fry, Hannah. 2018. Hello World: Being Human in the Age of Algorithms.
New York: W. W. Norton.
Fuchs, Christian. 2014. Digital Labour and Karl Marx. New York: Routledge.
Goebel, Randy, Ajay Chander, Katharina Holzinger, Freddy Lecue, Zeynep
Akata, Simone Stumpf, Peter Kieseberg, and Andreas Holzinger. 2018.
“Explainable AI: The New 42?” Paper presented at the CD-MAKE 2018,
Hamburg, Germany, August 2018.
Gunkel, David. 2012. The Machine Question. Cambridge, MA: MIT Press.
Gunkel, David. 2018. “The Other Question: Can and Should Robots Have
Rights?” Ethics and Information Technology 20:87–99.
املراجع
Harari, Yuval Noah. 2015. Homo Deus: A Brief History of Tomorrow. London: Hervill Secker.
Haraway, Donna. 1991. “A Cyborg Manifesto: Science, Technology, and
Socialist-Feminism in the Late Twentieth Century.” In Simians,
Cyborgs and Women: The Reinvention of Nature, 149–181. New
York: Routledge.
Haraway, Donna. 2015. “Anthropocene, Capitalocene, Plantationocene,
Chthulucene: Making Kin.” Environmental Humanities 6:159–165.
Herweijer, Celine. 2018. “8 Ways AI Can Help Save the Planet.” World
Economic Forum, January 24, 2018. https://www.weforum.org/
agenda/2018/01/8-ways-ai-can-help-save-the-planet/.
House of Commons. 2018. “Algorithms in Decision-Making.” Fourth Report of Session 2017-19, HC351. May 23, 2018.
ICDPPC (International Conference of Data Protection and Privacy Commissioners). 2018. “Declaration on Ethics and Data Protection in Artificial Intelligence.” https://icdppc.org/wp-content/uploads/2018/10/
_ICDPPC-40th_AI-Declaration_ADOPTED.pdf.
IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. 2017. “Ethically Aligned Design: A Vision for Prioritizing Human Well-Being with Autonomous and Intelligent Systems,” Version
IEEE. http://standards.Ieee.org/develop/indconn/ec/autonomous_
systems.html.
Ihde, Don. 1990. Technology and the Lifeworld: From Garden to Earth.
Bloomington: Indiana University Press.
Jansen, Philip, Stearns Broadhead, Rowena Rodrigues, David Wright, Philp
Brey, Alice Fox, and Ning Wang. 2018. “State-of-the-Art Review.”
Draft of the D4.1 deliverable submitted to the European Commission
on April 13, 2018. A report for The SIENNA Project, an EU H2020 research and innovation program under grant agreement no. 741716.
أخلاقيات الذكاء الاصطناعي
Johnson, Deborah G. 2006. “Computer Systems: Moral Entities but not
Moral Agents.” Ethics and Information Technology 8, no. 4: 195–204.
Kant, Immanuel. 1997. Lectures on Ethics. Edited by Peter Heath and J. B.
Schneewind. Translated by Peter Heath. Cambridge: Cambridge University Press.
Kelleher, John D., and Brendan Tierney. 2018. Data Science. Cambridge,
MA: MIT Press.
Kharpal, Arjun. 2017. “Stephen Hawking Says A.I. Could Be ‘Worst Event
in the History of Our Civilization.’” CNBC. November 6, 2017.
https://www.cnbc.com/2017/11/06/stephen-hawking-ai-couldbe-worst-event-in-civilization.html.
Kubrick, Stanley, dir. 1968. 2001: A Space Odyssey. Beverly Hills, CA:
Metro-Goldwyn-Mayer.
Kurzweil, Ray. 2005. The Singularity Is Near. New York: Viking.
Leta Jones, Meg. 2018. “Silencing Bad Bots: Global, Legal and Political Questions for Mean Machine Communication.” Communication Law and
Policy 23, no. 2: 159–195.
Lin, Patrick, Keith Abney, and George Bekey. 2011. “Robot Ethics: Mapping
the Issues for a Mechanized World.” Artificial Intelligence 175:942–
MacIntyre, Lee C. 2018. Post-Truth. Cambridge, MA: MIT Press.
Marcuse, Herbert. 1991. One-Dimensional Man. Boston: Beacon Press.
Marr, Bernard. 2018. “27 Incredible Examples of AI and Machine Learning in Practice.” Forbes, April 30. https://www.forbes.com/sites/
bernardmarr/2018/04/30/27-incredible-examples-of-ai-and-ma
chine-learning-in-practice/#6b37edf27502.
McAfee, Andrew, and Erik Brynjolfsson. 2017. Machine, Platform, Crowd:
Harnessing Our Digital Future. New York: W. W. Norton.
املراجع
Miller, Tim. 2018. “Explanation in Artificial Intelligence: Insights from the
Social Sciences.” arXiv, August 15. https://arxiv.org/pdf/1706.07269
.pdf.
Mouffe, Chantal. 2013. Agonistics: Thinking the World Politically. London:
Verso.
Nemitz, Paul Friedrich, 2018. “Constitutional Democracy and Technology in the Age of Artificial Intelligence.” Philosophical Transactions of
the Royal Society A 376, no. 2133. https://doi.org/10.1098/rsta.2018
.0089.
Noble, David F. 1997. The Religion of Technology. New York: Penguin Books.
Reijers, Wessel, David Wright, Philip Brey, Karsten Weber, Rowena Rodrigues, Declan O’ Sullivan, and Bert Gordijn. 2018. “Methods for Practising Ethics in Research and Innovation: A Literature Review, Critical
Analysis and Recommendation.” Science and Engineering Ethics 24, no.
1437–1481.
Royal Society, the. 2018. “Portrayals and Perceptions of AI and Why They
Matter.” December 11, 2018. https://royalsociety.org/topics-policy/
projects/ai-narratives/.
Rushkoff, Douglas. 2018. “Survival of the Richest.” Medium, July 5.
https://medium.com/s/futurehuman/survival-of-the-richest9ef6cddd0cc1.
Samek, Wojciech, Thomas Wiegand, and Klaus-Robert Müller. 2017. “Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models.” https://arxiv.org/pdf/1708.08296
.pdf.
Schwab, Katharine. 2018. “The Exploitation, Injustice, and Waste
Powering Our AI.” Fast Company. September 18, 2018. https://
www.fastcompany.com/90237802/the-exploitation-injustice-andwaste-powering-our-ai.
أخلاقيات الذكاء الاصطناعي
Seseri, Rudina. 2018. “The Problem with ‘Explainable AI.’” Tech Crunch.
June 14, 2018. https://techcrunch.com/2018/06/14/the-problemwith-explainable-ai/?guccounter=1.
Searle, John. R. 1980. “Minds, Brains, and Programs.” Behavioral and Brain
Sciences 3, no. 3: 417–457.
Shanahan, Murray. 2015. The Technological Singularity. Cambridge, MA:
The MIT Press.
Siau, Keng, and Weiyu Wang. 2018. “Building Trust in Artificial Intelligence,
Machine Learning, and Robotics.” Cutter Business Technology Journal
, no. 2: 46–53.
State Council of China. 2017. “New Generation Artificial Intelligence Development Plan.” Translated by Flora Sapio, Weiming Chen, and Adrian
Lo.

https://flia.org/notice-state-council-issuing-new-generation-

artificial-intelligence-development-plan/.
Stoica, Ion. 2017. “A Berkeley View of Systems Challenges for AI.” Technical Report No. UCB/EECS-2017-159. http://www2.eecs.berkeley.edu/
Pubs/TechRpts/2017/EECS-2017.
Sullins, John. 2006. “When Is a Robot a Moral Agent?” International Review
of Information Ethics 6: 23–30.
Surur. 2017. “Microsoft Aims to Lie to Their AI to Reduce Sexist Bias.”
August 25, 2017. https://mspoweruser.com/microsoft-aims-lie-aireduce-sexist-bias/.
Suzuki, Yutaka, Lisa Galli, Ayaka Ikeda, Shoji Itakura, and Michiteru Kitazaki. 2015. “Measuring Empathy for Human and Robot Hand Pain
Using Electroencephalography.” Scientific Reports 5, article number
https://www.nature.com/articles/srep15924.
Tegmark, Max. 2017. Life 3.0: Being Human in the Age of Artificial
Intelligence. Allen Lane/Penguin Books.
املراجع
Turkle, Sherry. 2011. Alone Together: Why We Expect More from Technology
and Less from Each Other. New York: Basic Books.
Turner, Jacob. 2019. Robot Rules: Regulating Artificial Intelligence. Cham:
Palgrave Macmillan.
Université de Montréal. 2017. “Montréal Declaration Responsible AI.”
https://www.montrealdeclaration-responsibleai.com/the-declara
tion.
Vallor, Shannon. 2016. Technology and the Virtues. New York: Oxford University Press.
Vigen, Tyler. 2015. Spurious Correlations. New York: Hachette Books.
Villani, Cédric. 2018. For a Meaningful Artificial Intelligence: Towards a
French and European Strategy. Composition of a parliamentary mission from September 8, 2017, to March 8, 2018, and assigned by the
Prime Minister of France, Èdouard Philippe.
Von Schomberg, René, ed. 2011. “Towards Responsible Research and Innovation in the Information and Communication Technologies and Security Technologies Fields.” A report from the European Commission
Services. Luxembourg: Publications Office of the European Union.
Vu, Mai-Anh T., Tülay Adalı, Demba Ba, György Buzsáki, David Carlson,
Katherine Heller, et al. 2018. “A Shared Vision for Machine Learning in
Neuroscience.” Journal of Neuroscience 38, no. 7: 1601–607.
Wachter, Sandra, Brent Mittelstadt, and Luciano Floridi. 2017. “Why a Right
to Explanation of Automated Decision-Making Does Not Exist in the
General Data Protection Regulation.” International Data Privacy Law,
http://dx.doi.org/10.2139/ssrn.2903469.
Wallach, Wendell and Colin Allen. 2009. Moral Machines: Teaching Robots
Right from Wrong. Oxford: Oxford University Press.
Weld, Daniel S. and Gagan Bansal. 2018. “The Challenge of Crafting Intelligible Intelligence.” https://arxiv.org/pdf/1803.04263.pdf.
أخلاقيات الذكاء الاصطناعي
Winfield, Alan F.T. and Marina Jirotka. 2017. “The Case for an Ethical Black
Box.” In Towards Autonomous Robotic Systems, edited by Yang Gao,
Saber Fallah, Yaochu Jin, and Constantina Lekakou (proceedings of
TAROS 2017, Guildford, UK, July 2017), 262–273. Cham: Springer.
Winikoff, Michael. 2018. “Towards Trusting Autonomous Systems.”
In Engineering Multi-Agent Systems, edited by Amal El Fallah
Seghrouchni, Alessandro Ricci, and Son Trao, 3–20. Cham: Springer.
Yampolskiy, Roman V. 2013. “Artificial Intelligence Safety Engineering:
Why Machine Ethics Is a Wrong Approach.” In Philosophy and Theory
of Artificial Intelligence edited by Vincent C. Müller, 289–296. Cham:
Springer.
Yeung, Karen. 2018. “A Study of the Implications of Advanced Digital
Technologies (Including AI Systems) for the Concept of Responsibility within a Human Rights Framework.” A study commissioned for the
Council of Europe Committee of experts on human rights dimensions
of automated data processing and different forms of artificial intelligence. MSI-AUT (2018)05.
Zimmerman, Jess. 2015. “What If the Mega-Rich Just Want Rocket Ships
to Escape the Earth They Destroy?” Guardian, September 16, 2015.
https://www.theguardian.com/commentisfree/2015/sep/16/megarich-rocket-ships-escape-earth.
Zou, James, and Londa Schiebinger. 2018. “Design AI So That It’s Fair.”
Nature 559:324–326.