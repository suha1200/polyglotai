{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تمهيد السلسلة", "section_path": ["تمهيد السلسلة"], "page": 1, "content": "تمهيد السلسلة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "شكر وتقدير", "section_path": ["شكر وتقدير"], "page": 2, "content": "-1ايتها املراة علي الحايط -2الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي -3كل ما له علاقة بالبشر -4اهي حقا مجرد الات؟ -5التكنولوجيا -6لا تنس )علم( البيانات -7الخصوصية وغريها من القضايا لامسيولية الالات والقرارات غري ا ملبررة -8 -9التحيز ومعني الحياة -10السياسات املقترحة -11التحديات التي تواجه صانعي السياسات -12تحد ي تغري املناخ :حول الاولويات وحقبة التاثري البشري مسرد املصطلحات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "قراءات إضافية", "section_path": ["قراءات إضافية"], "page": 3, "content": "املراجع"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تمهيد السلسلة", "section_path": ["تمهيد السلسلة"], "page": 4, "content": "تمهيد السلسلة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تمهيد السلسلة", "section_path": ["تمهيد السلسلة"], "page": 5, "content": "تقد م »سلسلة املعارف الاساسية« التي تنشرها موسسة »ام اي تي بريس« كتبا موجز ة وشكل انيق ،وحج م صغري يلايم الجيب ،تناق ش املوضوعات التي بلغة ج زلة سهلة الفهم، تثري الاهتمام في الوقت الحالي .و ملا كانت كتب هذه السلسلة من تاليف مف كرين بارزين، اضافة موضوعات تتنو ع بني املجالات الثقافية والتاريخية، فانها تقد م اراء الخبراء بشان الي الع لمية والتقنية. اشباع لحظي للمعلومات ،اضحي لدي الجميع في ظل ما يشيع في هذا العصر من بسرعة وسهولة ،واصبح من القدر ة علي الوصول الي الاراء والافكار والشروح السطحية بمكان ان يحظي املرء باملعرفة الاساسية التي ت صادقا للعا لم؛ وما يسر فهم ا الصعوبة تفعله كتب هذه السلسلة هو انها ت حقق ذلك الغرض .وك ل كتاب من هذه الكتب ا مل ختصرة يسرة للوصول الي الافكار ا مل وسيلة م عقدة ،من خلال تبسيط املواد ا مل تخصصة يقد م للقاري لغري ا مل طريقة ممكنة. وشرح املوضوعات املهمة بابسط ختصني ، بروس تيدور استاذ الهندسة البيولوجية وعلوم الكمبيوتر »معهد ماساتشوستس للتكنولوجيا«"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "شكر وتقدير", "section_path": ["شكر وتقدير"], "page": 6, "content": "شكر وتقدير"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "شكر وتقدير", "section_path": ["شكر وتقدير"], "page": 7, "content": "لا يعتمد هذا الكتاب علي عملي الخاص في موضوع اخلاقيات الذكاء الاصطناعي فحسب، بل يعكس املعرفة والخبرة في هذا املجال باكمله .وسيكون من ا ملستحيل ادراج جميع الاشخاص الذين ناقشتهم وتع ل مت منهم علي مدار السنوات املاضية ،لكن املجتمعات ذات الصلة والسريعة النمو التي اعرفها تضم باحثني في مجال الذكاء الاصطناعي مثل جوانا بريسون ولوك ستيلز ،وزملايي الفلاسفة في مجال التكنولوجيا مثل شانون فالور ولوتشيانو فلوريدي ،واكاديميني يسع ون الي الابتكار املسيول في هولندا واململكة املتحدة، مثل بريند ستال في جامعة دي مونتفورت ،وبعض الاشخاص الذين ا لت قيت بهم في فيينا، مثل روبرت ترابل ،وسارة سبيكرمان ،وولفجانج )بيل( برايس ،وزملايي الاعضاء في عني بالذكاء الهييات الاستشارية ذات التوج هات السياسية ،فريق الخبراء الرفيع املستوي ا مل الاصطناعي )املفوضية الاوروبية( واملجلس النمساوي للروبوتات والذكاء الاصطناعي ،ومن ضمنهم علي سبيل املثال لا الحصر راجا شاتيلا ،وفريجينيا ديج نوم ،وجريوين فان دين هوفن ،وسابني كوسيجي ،وماتياس شوتز .او د ايضا ان اشكر بحرارة زاكاري ستورمز للمساعدة في التدقيق اللغوي للكتاب وتنسيقه ،ولينا ستاركل وايزابيل والتر علي دعمهما في البحث عن الادبيات."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 8, "content": "ايتها المراة علي الحايط"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 9, "content": "الضجة واملخاوف التي يثريها الذكاء الاصطناعي :ايتها املراة علي الحايط: م ن الاذكي في العا لم؟ عندما اعلنت النتايج ،اغرورقت عينا اللاعب لي سيدول بالدموع . حقق »الفا جو« ،وهو برنامج ذكاء اصطناعي ط و رته شركة »ديب مايند« التابعة الي جوجل ،فو زا 1-4في لعبة »جو« )لعبة »جو« هي لعبة استراتيجية قديمة ظهرت في الصني ويشارك فيها لاعبان اثنان( .تاريخ الحدث :مارس .2016قبل عقدين من الزمان ،خسر لاعب الشطرنج جاري كاسباروف الحاصل علي لقب »جراند ماستر« )الاستاذ الكبري( امام الالة »ديب بلو« ،والان فاز برنامج كمبيوتر علي بطل العالم لثماني عشرة مرة؛ لي سيدول ،في لعبة م عقدة كان ين حدسهم ظر اليها علي انها لعبة لا يمكن ان يلعبها الا البشر ،باستخدام وتفكريهم الاستراتيجي .الادهي من ذلك ان الكمبيوتر لم يفز باتباع القواعد ا ملعطاة له من ق بل ا ملبرمجني ،وانما عن طريق تع لم الالة القايم علي امللايني من مباريات »جو« السابقة وعلي اللعب ض د نفسه .في مثل هذه الحالة ،يع د املبرمجون مجموعات البيانات وي نشيون الخوارزميات ،ولكن لا يمكنهم معرفة التح ركات التي سياتي بها البرنامج. فالذكاء الاصطناعي يتع لم من تلقاء نفسه .وبعد عدد من التح ركات غري املعتادة واملفاجية، اض ط ر بطل العالم لي الي الانسحاب ).(Borowiec 2016 انه انجاز رايع حق قه الذكاء الاصطناعي .ولكنه ،مع ذلك ،يثري املخاوف في قلوبنا .اننا معجبون بجمال الحركات ،ولكننا ايضا حزاني ،وربما حتي خايفون .نامل في ان تساعدنا حلول انظمة الذكاء الاصطناعي الاكثر ذكاء في احداث ثورة في الرعاية الصحية او في ايجاد"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 10, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 11, "content": "لجميع انواع املشكلات املجتمعية ،ولكن يراودنا القلق من ان تسيطر الالات علي زمام امورنا .فهل تستطيع الالات ان تتفو ق علينا وتتح كم فينا؟ هل لا يزال الذكاء الاصطناعي مجرد اداة ،ام انه سيصبح رويدا رويدا سيدنا لا محالة؟ تذ كرنا هذه املخاوف بكلمات »هال« كمبيوتر الذكاء الاصطناعي في فيلم الخيال العلمي الذي اخرجه ستانلي كوبريك: » :2001ملحمة الفضاء« ) :2001سبيس اوديسي( ،حني قال ردا علي الامر البشري »افتح ابواب املركبة الصغرية«» :اخشي انني لا استطيع ان افعل ذلك يا ديف «.واذا لم ي كن هناك خوف ،فقد يكون هناك شعور بالحزن او خيبة الامل .لقد اطاح داروين وفرويد بايماننا بتمي زنا ،وباحساسنا بالتفو ق ،واطاحا باوهام السيطرة التي يعيش فيها البشر؛ والان جاء ضربة اخري الي صورة البشر عن ذواتهم .اذا كانت الالة دور الذكاء الاصطناعي ليوج ه تستطيع القيام بذلك ،فماذا تبقي لنا؟ ماذا نحن؟ هل نحن مج رد الات؟ هل نحن الات رديية ،بها الكثري من العيوب والاخطاء؟ وماذا سيحدث لنا؟ هل سنصبح عبيدا للالات؟ او ما هو اسوا ،مجرد مصدر للطاقة ،كما في فيلم »املصفوفة« )ذا ماتريكس(؟ التاثري الحقيقي والواسع النطاق للذكاء الاصطناعي ولكن انجازات الذكاء الاصطناعي لا تقتصر علي الالعاب او عا لم الخيال العلمي .فالذكاء الاصطناعي يحدث الان وهو م توغل في كل ما حولنا ،وغالبا ما يكون مضم نا علي نحو غري مريي في ادواتنا اليومية وبكونه جزءا من الانظمة التكنولوجية املعقدة )Boddington .(2017ونظ را الي النمو الهايل لقدرة الكمبيوتر ،واتاحة البيانات )الضخمة( بسبب وسايل التواصل الاجتماعي والاستخدام الهايل ملليارات الهواتف الذكية ،وشبكات املحمول السريعة ،اح ر ز الذكاء الاصطناعي ،وخاصة تع لم الالة ،تقد م ا كبريا .وقد م ك ن هذا الخوارزميات من تولي العديد من انشطتنا ،بما في ذلك التخطيط والكلام والتع رف علي تطبيقات في العديد من املجالات ،بما الوجوه واتخاذ القرار .يمتلك الذكاء الاصطناعي في ذلك النقل والتسويق والرعاية الصحية والتمويل والتامني والامن والجيش والعلوم والتعليم والعمل املكتبي واملساعدة الشخصية )مثل جوجل دوبلكس 1والترفيه والفنون )مثل استرجاع املوسيقي وتاليفها( والزراعة ،وبالطبع التصنيع. تت م عمليات انشاء الذكاء الاصطناعي واستخدامه لدي شركات تكنولوجيا املعلومات والانترنت .علي سبيل املثال ،لطاملا استخدمت جوجل الذكاء الاصطناعي في مح رك البحث الخاص بها .كما يستخدم فيسبوك الذكاء الاصطناعي في الاعلانات املستهدفة واشارات ايتها املراة علي الحايط"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 12, "content": "الصور .كذلك تستخدم مايكروسوفت وا بل الذكاء الاصطناعي في تشغيل مساعديهما الرقميني .لكن الذكاء الاصطناعي لا يقتصر علي قطاع تكنولوجيا املعلومات بمعناه الضي ق. فهناك ،علي سبيل املثال ،الكثري من الخطط امللموسة ،والتجارب في مجال السيارات الذاتية القيادة .فهذه التقنية تعتمد ايضا علي الذكاء الاصطناعي .كما تستخدم الطايرات دون طيار الذكاء الاصطناعي ،مثلها مثل الاسلحة الذاتية التشغيل التي يمكن ان تقتل دون تدخ ل بشري .بل ان الذكاء الاصطناعي قد استخدم بالفعل في اتخاذ القرار في املحاكم. ففي الولايات املتحدة ،علي سبيل املثال ،استخدم نظام »كومباس« للتنب و بالذين يحتم ل ان يعاودوا ارتكاب الجرايم .يدخل الذكاء الاصطناعي نعتبرها عموم ا ايضا في املجالات التي اكثر شخصية او حميمية .علي سبيل املثال ،يمكن للالات الان قراءة وجوهنا ،ليس فقط للتع رف علينا ،ولكن ايضا لقراءة انفعالاتنا واسترداد جميع املعلومات املرتبطة بنا. الذكاء الاصطناعي يحدث الان وهو م نحو غري توغل في ك ل ما حولنا ،وغالبا ما يكون مضم نا علي مريي في ادواتنا اليومية."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 13, "content": "الحاجة الي مناقشة املشكلات الاخلاقية واملجتمعية يمكن ان يكون للذكاء الاصطناعي العديد من الفوايد .ويمكن استخدامه لتحسني الخدمات العامة والتجارية .علي سبيل املثال ،يعد التع رف علي الصور شييا مفيدا في الطب؛ اذ ربما امراض مثل السرطان ومرض الزهايمر .ولكن مثل هذه التطبيقات يساعد في تشخيص ظهر ايضا كيف تثري التقنيات الجديدة تخو فات اخلاقية. اليومية للذكاء الاصطناعي ت اسيلة حول اخلاقيات الذكاء الاصطناعي. واسمحوا لي ان اقد م بعض الامثلة علي هل يجب ان تحتوي السيارات الذاتية القيادة علي قيو د اخلاقية مضم نة؟ واذا كان الامر كذلك ،فما نوع هذه القيود وكيف ينبغي تحديدها؟ علي سبيل املثال ،اذا واجهت بطفل او تصطدم يتعني عليها فيه الاختيار بني ان تصطدم موقفا سيارة ذاتية القيادة بجدار لانقاذ حياة الطفل ،ولكن مع احتمال قتل را كبها ،فماذا تختار؟ وهل ينبغي ترخيص الاسلحة الفت اكة الذاتية التشغيل من الاساس؟ كم عدد القرارات التي نريد تفويضها الي الذكاء الاصطناعي ،وما القدر الذي نفو ضه منها؟ وم ن سيكون املسيول عندما يحدث خطا ما؟ في احدي القضايا ، وض ع القضاة ثقتهم في خوارزمية »كومباس« اكثر من ثقتهم في اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 14, "content": "الاتفاقات التي توصل اليها الدفاع والادعاء 2 .فهل سنعتمد كثريا علي الذكاء الاصطناعي؟ تعد خوارزمية »كومباس« ايضا مثرية للجدل الي ح د كبري؛ نظ را الي ان الابحاث اظهرت ان الاشخاص الذين تنب ات الخوارزمية بانهم سيعيدون ارتكاب الجرايم ولكنهم لم يفعلوا كانت النسبة الكبري منهم من السود ) .(Fry 2018وبالتالي يمكن للذكاء الاصطناعي ان يع زز التحي ز والتمييز غري العادل .ويمكن ان تنشا مشكلات مماثلة مع الخوارزميات التي بقرارات بشان طلبات الرهن العقاري وطلبات التقد م للوظايف .او فلنفكر فيما توصي يسمي بالشرطة التنب وية :تستخدم الخوارزميات للتنبو باملكان ا ملحتم ل لارتكاب الجرايم )علي سبيل املثال ،اي منطقة في املدينة( وم ن قد يرتكبها ،ولكن قد تكون النتيجة ان بدرجة اكبر تستهدف مجموعات اجتماعية واقتصادية او ع رقية معي نة للمراقبة الشرطية من غريهم من املجموعات .وقد ج رت الاستعانة بالفعل بالشرطة التنب وية في الولايات املتحدة ،وكما يظهر تقرير حديث ملنظمة »الجوريذم ووتش« ) ،(2019فقد استعني بها ايضا في اوروبا 3 .وغالبا ما تستخدم تقنية التع رف علي الوجوه القايمة علي الذكاء الاصطناعي لاغراض ا ملراقبة ،ومن ثم يمكن ان تش كل انتها كا لخصوصية الافراد .كما بشكل او باخر التنبو بامليول الجنسية لدي الافراد .الامر لا يتط لب اي معلومات يمكنها من هاتفك او اي بيانات بيومترية )بيانات املقاييس الحيوية( .وتقوم الالة بعملها عن بعد. ومن ثم فاننا باستخدام الكامريات املوجودة في الشوارع والاماكن العامة الاخري ،يمكن التع رف علينا و»قراءتنا« ،بما في ذلك التعرف علي حالتنا املزاجية .وعن طريق تحليل بياناتنا ،يمكن التنبو بصح تنا العقلية والجسدية؛ دون ع لمنا بذلك .ويمكن لاصحاب العمل استخدام التكنولوجيا ملراقبة اداينا .ويمكن للخوارزميات النشطة علي وسايل التواصل الاجتماعي ان تنشر خطاب الكراهية او املعلومات الخطا؛ علي سبيل املثال ،يمكن ان تظهر وتنشر محتوي سياسيا .احدي الحالات اشخاص حقيقي ني الروبوتات السياسية في هيية املعروفة هي برنامج الدردشة الالي من مايكروسوفت لعام 2016ا ملسمي »تاي« ا ملصم م لاجراء محادثات م رحة علي تويتر ،ولكن عندما اصبح اكثر ذكاء ،بدا في نشر تغريدات دلالات عنصرية .يمكن لبعض خوارزميات الذكاء الاصطناعي انشاء خطابات فيديو تحمل بشكل مض لل خطابا لباراك اوباما. كاذبة ،مثل الفيديو الذي جري انشاوه ليشبه غالبا ما تكون النوايا طيبة .ولكن هذه املشكلات الاخلاقية عاد ة ما تكون نتايج غري مقصودة للتكنولوجيا :فمعظم هذه التاثريات ،مثل التحي ز او خطاب الكراهية ،لم يقصدها مطورو التكنولوجيا او مستخدموها .علاو ة علي ذلك ،هناك سوال مهم يجب طرحه دايم ا: ايتها املراة علي الحايط"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 15, "content": "من اجل م ن يتم التحسني؟ من اجل الحكومة ام من اجل املواطنني؟ من اجل الشرطة ام من اجل م ن تستهدفهم الشرطة؟ من اجل بايع التجزية ام من اجل الزبون؟ من اجل القضاة ام من اجل ا ملتهمني؟ كما تظهر الاسيلة املتعلقة بالسلطة والهيمنة ،كالحال علي سبيل املثال عندما يقتصر تشكيل التكنولوجيا علي عدد قليل من الشركات الضخمة )Nemitz .(2018فم ن الذي يشكل مستقبل الذكاء الاصطناعي؟ يلقي هذا السوال الضوء علي الاهمية الاجتماعية والسياسية للذكاء الاصطناعي .تتع لق بالتغري التكنولوجي وتاثريه علي حياة الافراد ،ولكنها تتعلق اخلاقي ات الذكاء الاصطناعي ايضا بالتحولات التي تحدث في املجتمع وفي الاقتصاد .وتد ل قضايا التحي ز والتمييز بالفعل غري ايضا الاقتصاد ،وبالتالي ربما ي علي ان الذكاء الاصطناعي مرت بط باملجتمع .ولكنه ي غري ووفقا ملكافي وبرينجولفسون ) ،(2014فقد دخلنا عصر الالة الهيكل الاجتماعي ملجتمعاتنا. الثاني ،الذي لا تكون فيه الالات مكملة للبشر فحسب ،كما في الثورة الصناعية ،ولكنها ايضا بدايل للبشر .ونظ را الي ان امل هن والاعمال من جميع الانواع ستتاثر بالذكاء الاصطناعي، يتغري مجتمعنا تغريا جذريا مع دخول التقنيات التي وصفت في يو م املتوقع ان فمن من الايام في روايات الخيال العلمي حي ز العالم الحقيقي )McAfee and Brynjolfsson .(2017فما هو مستقبل العمل؟ وما نوع الحياة التي سنعيشها نحن عندما يتولي الذكاء الاصطناعي القيام بالوظايف؟ وم ن »نحن«؟ وم ن الذي سيستفيد من هذا التحو ل ومن سيخسر؟ هذا الكتاب استنادا الي الانجازات ا ملذهلة التي تم تحقيقها ،فهناك الكثري من الضجة ا ملثارة حول الذكاء مجموعة واسعة من مجالات املعرفة الاصطناعي .ويستخدم الذكاء الاصطناعي بالفعل في واملمارسات البشرية .وقد اثارت الاولي تكه نات جامحة حول مستقبل التكنولوجيا ،كما احساسا فلسفية مهم ة حول معني ان تكون انسانا .بينما خلقت الثانية مناقشات اثارت بالالحاح من جانب الاخلاقيني وصانعي السياسات لضمان ان تفيدنا هذه التكنولوجيا بدلا من ان تخلق امام الافراد واملجتمعات تحديات لا يمكنهم التغ لب عليها .وتعد هذه املخاوف عملية والحاح ا. الاخرية اكثر اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 16, "content": "ريه علي حياة الافراد ،ولكنها تتعلق تتعلق اخلاقيات الذكاء الاصطناعي بالتغري التكنولوجي وتاث ايضا بالتحو لات التي تحدث في املجتمع وفي الاقتصاد."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أيتها المرآة على الحائط", "section_path": ["الفصل الأول", "أيتها المرآة على الحائط"], "page": 17, "content": "يتناول هذا الكتاب ،الذي كتبه فيلسوف اكاديمي لديه ايضا خبرة في تقديم املشورة من اجل وضع السياسات ،كلا الجانبني؛ فهو يتعامل مع الاخلاقيات علي هذه املستويات كافة .ويهدف الي اعطاء القاري نظر ة عامة جيدة علي املشكلات الاخلاقية التي يثريها الذكاء الاصطناعي ،بدءا من السرديات املوثرة حول مستقبل الذكاء الاصطناعي والاسيلة الفلسفية وانطلاقا الي القضايا الاخلاقية ا ملتعلقة باملسيولية والتحي ز حول طبيعة الانسان ومستقبله، وكيفية التعامل مع املسايل العملية الواقعية التي اثارتها التكنولوجيا عن طريق وضع السياسات؛ لا سيما اذا كان ذلك قبل فوات الاوان. لكن ماذا سيحدث اذا »فات الاوان«؟ بعض السيناريوهات متشايمة ومتفايلة في الوقت نفسه .اسمحوا لي ان ابدا ببعض الاحلام والكوابيس حول مستقبل التكنولوجيا ،والسرديات املوثرة التي تبدو ،ولو للوهلة الاولي علي الاقل ،ذات ص لة بتقييم الفوايد واملخاطر ا ملحتم لة للذكاء الاصطناعي."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 18, "content": "بالذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 19, "content": "الذكاء الفايق وتجاوز الانسانية اد ت الضجة ا ملحيطة بالذكاء الاصطناعي الي ظهور جميع انواع التكه نات حول مستقبل الذكاء الاصطناعي ومستقبل ما سيكون عليه الانسان .ان احدي الافكار الشايعة ،والتي تتك رر كثريا في وسايل الاعلام وفي النقاشات العامة حول الذكاء الاصطناعي ،بل ينشرها ايضا خبراء التكنولوجيا املوث رون الذين يطو رون تقنية الذكاء الاصطناعي مثل ايلون وبشكل اكثر عمومية ،فكرة ان الالات ماسك وراي كورزوايل ،هي فكرة الذكاء الفايق، ستسيطر علينا ،وتستع بدنا وليس العكس .بالنسبة الي البعض ،هذا حلم؛ وبالنسبة الي الكثريين ،هذا كابوس .وهناك م ن ي رون انه حلم وكابوس في الوقت نفسه. فكرة الذكاء الفايق هي ان الالات ستتفو ق علي الذكاء البشري .وهي غالبا ما ترتبط ووفقا لنيك بوستروم )،(2014 بفكرة انفجار الذكاء الاصطناعي والتف رد التكنولوجي. مازق يماثل ذلك الذي وقعت فيه الغوريلا ،التي يعتمد مصريها اليوم علينا سنقع في طريقني علي الاقل لبلوغ الذكاء الفايق وما يسم ي احيانا بانفجار بشكل كامل .انه يري الذكاء الاصطناعي .احدهما ان الذكاء الاصطناعي سوف يطو ر تحسينا ذاتيا تكراريا؛ نسخة م حسنة من نفسه ،والتي بدورها تصم م اذ يستطيع الذكاء الاصطناعي تصميم نسخة اكثر ذكاء من نفسها ،وهكذا دواليك .اما الطريق الاخر فهو محاكاة الدماغ بالكامل او تحميله :دماغ بيولوجي يمكن مسحه ضوييا انتاجه في وصنع نموذج له ،ثم اعادة مكونات برمجية ذكي ة ومن خلالها .يتم بعد ذلك توصيل هذه ا ملحاكاة للدماغ البيولوجي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 20, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 21, "content": "انفجار في الذكاء غري البشري .حتي بجسم انسان الي .وستودي مثل هذه التطو رات الي فريقا ما يمكنه انشاء ذكاء اصطناعي يصبح ان ماكس تجمارك ) (2017يتخيل ان في منتهي القوة بحيث يستطيع ادارة الكوكب .ويكتب يوفال هراري عن عا ل م لم يع د فيه البشر يسيطرون ،ولكنهم يعبدون البيانات ويثقون في قدرة الخوارزميات علي اتخاذ قراراتهم .وبعد انهيار ك ل اوهام الانسانيني واملوسسات الليبرالية ،لن يبقي للبشر الا ان يحلموا بالاندماج في تدفق البيانات .يسري الذكاء الاصطناعي في مساره الخاص» ،الذهاب انسان ان يتبعه« )Harari انسان من قبل؛ والي حيث لا يمكن لاي الي حيث لم يذهب اي .(2015, 393 طا ترتبط فكرة انفجار الذكاء الاصطناعي ارتبا وثيقا بفكرة »التف رد التكنولوجي«: لحظة في تاريخ البشرية سيحدث فيها التقد م التكنولوجي الهايل تغيريا دراماتيكيا بحيث لا نعود نستوعب ما يحدث و»تنتهي الشيون الانسانية كما نفهمها اليوم« )Shanahan .(2015, xvفي عام ،1965تكه ن عالم الرياضيات البريطاني ايرفينج جون جود بالة فايقة الذكاء تصم م الات افضل؛ وفي التسعينيات ،راي مولف الخيال العلمي وعالم الكمبيوتر فرينور فينج ان هذا سيعني نهاية عصر الانسان .وقد اقترح رايد علم الكمبيوتر جون فون نيومان بالفعل الفكرة في خمسينيات القرن العشرين .وتبن ي راي كورزوايل جنب مع اجهزة وتوقع ان الذكاء الاصطناعي ،جنبا الي ) (2005مصطلح »التف رد« نقطة يكون فيها الكمبيوتر وعلم الوراثة وتكنولوجيا النانو وعلم الروبوتات ،سيودي الي ذكاء الالة اقوي من ك ل الذكاء البشري مجتمع ا ،ويندمج عندها الذكاء البشري وذكاء الالة في النهاية .وسوف يتجاوز البشر حدود اجسامهم البيولوجية .وكما جاء في عنوان كتابه: »التف رد قريب« .وهو يعتقد ان هذا سيحدث حوالي عام .2045 ليس لهذه القصة بالضرورة نهاية سعيدة :ففي راي بوستروم وتجمارك واخرين، ثم ة »مخاطر وجودية« مرتبطة بالذكاء الفايق .وقد تكون نتيجة هذه التطو رات ان الذكاء ويتولي زمام الامور ويهد د حياة الانسان الذكية .وسواء الاصطناعي الفايق سوف يسيطر اكان هذا الكيان واعيا ام لا ،وبصورة اعم مهما كانت حالته او كيفية نشويه ،فان القلق هنا يتع لق بما سيفعله هذا الكيان )او ما لا يفعله( .قد لا يهت م الذكاء الاصطناعي باهدافنا البشرية .ونظ را لعدم امتلاكه جسدا بيولوجيا ،فانه لن يفهم حتي املعاناة البشرية .ويقدم تجربة فكرية لذكاء اصطناعي يحد د له هدف م عني وهو تصنيع مشابك الورق بوستروم باكبر ك م ممكن ،فما كان منه الا ان حو ل كوكب الارض والبشر الذين يعيشون عليه الي الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 22, "content": "موارد لانتاج مشابك الورق .اذن التحد ي الذي يواجهنا اليوم هو التا كد من اننا نبني بطريقة ما مشكلة السيطرة هذه؛ بمعني انه يفعل ما نريد وياخذ ذكاء اصطناعيا لا يثري بطريقة ما من قدرات الذكاء حقوقنا في الاعتبار .علي سبيل املثال ،هل يجب ان نح د الاصطناعي؟ وكيف يمكننا احتواء الذكاء الاصطناعي؟ ثم ة افكار اخري مترابطة وذات صلة؛ الا وهي الافكار املتع لقة بتجاوز الانسانية. في ضوء الذكاء الفايق والاحباط من الضعف البشري و»الاخطاء« ،يجادل انصار تجاوز بحاجة الي تعزيز الانسان :جعله اكثر ذكاء ،واقل ع رضة الانسانية مثل بوستروم باننا للمرض ،واطول عم را ،وربما حتي خالدا ،مما يودي الي ما يسم يه هاراري »الانسان الاله«: ترقية البشر الي الهة .وكما قال فرانسيس بيكون في »دحض الفلسفات« :البشر »الهة فانية« ) .(Bacon 1964, 106ملاذا لا نحاول تحقيق الخلود؟ ولكن حتي لو لم نستطع تحقيق ذلك ،فان الالة البشرية ، بحاجة الي ترقية .فنحن وفقا ملناصري تجاوز الانسانية، اذا لم نفعل ذلك ،فسيخاطر البشر بان يظلوا »الجزء ا ملتخلف غري الكفء بشكل متزايد« بحاجة الي اعادة من الذكاء الاصطناعي ) .(Armstrong 2014, 23ان البيولوجيا البشرية تصميم ،ولذا يتساءل بعض مويدي تجاوز الانسانية ،ملاذا لا نتخ لص تمام ا من الاجزاء كاينات ذكية غري عضوية؟ البيولوجية ونصم م علي الرغم من ان معظم الفلاسفة والعلماء الذين يرو جون لهذه الافكار يحرصون علي تمييز ارايهم عن الخيال العلمي والدين ،فان العديد من الباحثني ي فسرون افكارهم بهذه املصطلحات بالضبط .بادي ذي بدء ،ليس من الواضح مدي ارتباط افكارهم بالتطو رات التكنولوجية الحالية وعلوم الذكاء الاصطناعي ،وما اذا كان هناك فرصة حقيقية للوصول الي الذكاء الفايق في ا ملستقبل القريب ،هذا ان امكن الوصول اليه من الاساس .اذ يرفض البعض تمام ا امكانية الوصول اليه )انظر الفصل التالي( ،وحتي هولاء الذين علي استعداد لقبول امكانية الوصول اليه من حيث املبدا ،مثل العالمة مارجريت بودن ،فانهم لا يعتقدون انه من ا ملرج ح الوصول اليه عمليا .ان فكرة الذكاء الفايق تفترض اننا سنطو ر »الذكاء الاصطناعي العام« ،او الذكاء الذي يكافي الذكاء البشري او يتفو ق عليه ،وهناك العديد من العقبات التي يجب التغ لب عليها قبل تحقيق ذلك. وتري بودن ) (2016ان الذكاء الاصطناعي ليس واعدا كما تقرير يتوقع الكثريون .وفي صادر عن البيت الابيض عام ،2016تم التاكيد علي اتفاق خبراء القطاع الخاص علي يتحقق علي الاقل قبل عقود .كما يرفض العديد من ان الذكاء الاصطناعي العام لن اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 23, "content": "الباحثني في مجال الذكاء الاصطناعي الروي ا ملظلمة املتشايمة التي يرو ج لها بوستروم بشكل ايجابي ،كمساع د او زميل. ويحضون علي استخدام الذكاء الاصطناعي واخرون، ولكن املسالة لا تتعلق بما سيحدث فعليا في املستقبل .بل يوج د شيء اخر يثري القلق وهو ان هذه املناقشة حول تاثريات الذكاء الاصطناعي في املستقبل )البعيد( تشت ت الانتباه عن املخاطر الحقيقية واملوجودة حاليا للانظمة التي تم نشرها فعليا )Crawford and Calo ذكية .(2016يبدو ان هناك خط را حقيقيا انه في املستقبل القريب ،لن تكون الانظمة بشكل غري كاف ،ومع ذلك بما فيه الكفاية واننا سنفهم اثارها الاخلاقية والاجتماعية فرط علي الذكاء ،بوصفه سمة رييسية سنستخدمها علي نطاق واسع .كما ان التركيز ا مل وهدفا نهاييا وحيدا ،هو ايضا امر مشكوك فيه ).(Boddington 2017 للانسانية، مع ذلك ،تستمر الافكار مثل الذكاء الفايق في التاثري علي املناقشة العامة .ومن ا ملحتمل ان توث ر ايضا علي تطو ر التكنولوجيا .علي سبيل املثال ،لا يعتبر راي كورزوايل من دعاة املستقبلية فحسب .بل انه يشغل منصب مدير الهندسة في شركة جوجل منذ عام .2012كما يبدو ان ايلون ماسك ،الرييس التنفيذي لشركة تيسلا وشركة سبيس اكس، وهو شخصية عامة معروفة جدا ،يويد سيناريوهات الذكاء الفايق واملخاطر الوجودية )سيناريوهات الهلاك؟( التي وضعها بوستروم وكورزوايل .وقد حذ ر مرا را من خطورة واعتبره تهديدا وجوديا وزعم اننا لا يمكننا التح كم في الشيطان الذكاء الاصطناعي، ) .(Dowd 2017ويعتقد ماسك ان البشر سينقرضون علي الارجح ،ما لم يدم ج الذكاء البشري والذكاء الالي او نتم كن من الهروب الي املريخ. ربما تكون هذه الافكار موثرة للغاية لانها عميقة تتع لق بالبشر وامالا تمس مخاوف والالات داخل وع ينا الجمعي .وسواء ق بلنا هذه الافكار املحد دة او رفضناها ،فان هناك ص لات واضحة بالسرديات الخيالية في الثقافة البشرية والتاريخ التي تحاول ان تفهم الانسان وعلاقته بالالات .ويجدر بنا ان ن وضح هذه السرديات لكي نفهم بعض هذه وبشكل عام ،فانه من ا ملهم ان نحو افضل ونضعها في سياقها الصحيح. الافكار علي ندمج بحث السرديات في اخلاقيات الذكاء الاصطناعي ،علي سبيل املثال ،لكي نفهم الاسباب التي تجعل بعض السرديات منتشرة ،وم ن انشاها ،وم ن الذي يستفيد منها ) .(Royal Society 2018كما يمكن ان يساعدنا في انشاء سردي ات جديدة حول مستقبل الذكاء الاصطناعي. الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 24, "content": "وحش فرانكنشتاين الجديد من السبل التي يمكننا اتخاذها لتجاوز الضجة املثارة ان نف كر في بعض السرديات ذات الصلة من تاريخ الثقافة البشرية التي تشكل املناقشة العامة الحالية حول الذكاء الاصطناعي .فليست هذه هي املرة الاولي التي يتساءل فيها الناس عن مستقبل البشرية ومستقبل التكنولوجيا .ومهما كانت بعض الافكار املتعلقة بالذكاء الاصطناعي تبدو غريبة ،فاننا يمكننا استكشاف صلتها بافكار وسرديات اكثر شهرة توج د في وعينا بشكل ادق ،في الوعي الجماعي للغرب. الجمعي ،او اولا ،هناك تاريخ طويل للتفكري في البشر والالات او املخلوقات الاصطناعية في الثقافات الغربية وغري الغربية علي ح د سواء .يمكن العثور علي فكرة انشاء كاينات حية من مادة غري حية في قصص الخلق في الثقافات السومرية والصينية واليهودية واملسيحية والاسلامية .فقد كانت لدي الاغريق فكرة انشاء بشر اصطناعيني ،وخاصة النساء الاصطناعيات .علي سبيل املثال ،في الالياذة ،يقال ان هيفايستوس يقوم علي خدمته خدم مصنوعون من الذهب يشبهون النساء .وفي اسطورة بيجماليون الشهرية، يقع النح ات في ح ب تمثال امراة صنع ه من العاج .ويتمن ي ان تدب فيه الروح ويصبح امراة حقيقية ،فت حقق له الالهة افروديت امنيته :فتصبح شفتاها دافيتني وجسدها ناعم ا. ويمكننا بسهولة هنا ملاحظة الصلة بني ذلك وبني الروبوتات الجنسية املعاصرة. هذه السردي ات لا تاتي فقط من الاساطري :ففي كتابه »الاوتوماتا« ،قد م عالم اكتشفت في البحر، الرياضيات واملهندس الاغريقي هريون السكندري )ولد عام (10اداة ظري اغريقي يعتمد علي الية م وهي الية »انتيكيثريا« ،التي تحدد انها كمبيوتر تنا عقدة من التروس وا ملسن نات .ولكن القصص الخيالية التي تجعل الالات تش به البشر تسلب بشكل خاص .فلناخذ ،علي سبيل املثال ،اسطورة الجوليم :وحش مصنوع من البابنا نواج ه نسخة الطني صنع ه حاخام في القرن السادس عشر ،ثم فق د السيطرة عليه .هنا مب كرة من مشكلة التح كم .ويمكن تفسري اسطورة بروميثيوس بهذه الطريقة ايضا؛ اذ يسرق النار من الالهة ويعطيها الي البشر ،لكنه ي عاقب بعد ذلك .وعقوبته الابدية هي ان يربط بصخر ة بينما ياكل النسر ك بده ك ل يوم .وقد كان الدرس القديم من هذه الاسطورة هو التحذير من الغطرسة :فهذه القدرات ليست مقد رة للبشر. ومع ذلك ،في رواية ماري شيلي »فرانكنشتاين« — التي تحمل العنوان الفرعي الدال »بروميثيوس الحديث« — يصبح انشاء حياة ذكية من مادة غري حي ة مشروع ا اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 25, "content": "علميا حديثا .حيث ينشي العالم فيكتور فرانكنشتاين كاينا شبيه ا بالانسان من اجزاء الجثث ،لكنه يفقد السيطرة عليه .ومع ان الحاخام استطاع ان يسيطر علي الجوليم في النهاية ،فان الامر ليس كذلك في هذه الحالة .ويمكن اعتبار فرانكنشتاين رواية رومانسية تحذ ر من التكنولوجيا الحديثة ،ولكنها تستند الي العلم في زمنها .علي سبيل املثال ،يلعب استخدام الكهرباء — وهي تقنية جديدة جدا في ذلك الوقت — دو را مهم ا؛ اذ تستخدم لاحياء الجثة .كما انها تشري الي املغناطيسية وعلم التشريح .في ذلك الوقت ،كان املف كرون والكت اب يناقشون طبيعة الحياة واصلها .ما قوة الحياة؟ لقد تاثرت ماري شيلي بعلوم ري عصرها .وتظهر القصة كيف كان الرومانسيون في القرن التاسع عشر مفتونني في كث ظ فضلا عن املهم في ان يح ررنا الشعر والادب من الجوانب الاكثر لمة من الاحيان بالعلم، في الحداثة ) .(Coeckelbergh 2017يجب الا نعتبر هذه الرواية بالضرورة ضد العلم والتكنولوجيا؛ اذ يبدو ان الرسالة الرييسية التي تحرص علي توصيلها هي ان العلماء ينبغي ان يتحملوا مسيولية اختراعاتهم .يهرب الوحش ،ولكنه يفعل ذلك لان صانعه يرفضه .يجب ان نتذ كر هذا الدرس فيما يتع لق باخلاقيات الذكاء الاصطناعي .ومع ذلك، تو كد الرواية بوضوح خطر التكنولوجيا التي تخرج عن السيطرة ،وعلي وجه الخصوص خطر البشر الاصطناعيني الذين يصيبهم الجنون .تعود هذه املخاوف للظهور علي السطح في القلق ا ملعاصر من ان يخرج الذكاء الاصطناعي عن السيطرة. في رواية ماري شيلي »فرانكنشتاين« — التي تحمل العنوان الفرعي الدال »بروميثيوس الحديث« — يصبح انشاء حياة ذكية من مادة غري حية مشروع ا علميا حديثا."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 26, "content": "وعلاو ة علي ذلك ،كما هو الحال في رواية »فرانكنشتاين« واسطورة »الجوليم« ،تظهر سردية املنافسة :فاملخلوقات الاصطناعية تتنافس مع الانسان .وتستم ر هذه السردية في تشكيل خيالنا العلمي حول الذكاء الاصطناعي ،ولكنها ايضا توث ر علي تفكرينا ا ملعاصر فلناخذ مسرحية »روبوتات روسوم في التكنولوجيا مثل الذكاء الاصطناعي والروبوتات. العاملية« التي كتبت عام 1920 مثالا ،وهي تتناول قصة الروبوتات العبيد التي تتم رد علي سيدها وتثور عليه ،او فيلم » :2001سبيس اوديسي« ) :2001اوديسة الفضاء( الذي انتج عام 1968والذي ذكرناه من قب ل ،ويتحد ث عن ذكاء اصطناعي يبدا في قتل طاقم املركبة الفضايية لتحقيق مهم ته ،او فيلم »اكس ماكينا« الذي انتج عام 2015 الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 27, "content": "ويروي قصة روبوت الذكاء الاصطناعي »افا« التي تنقلب علي صانعها .كما يندرج تحت سردية الالات التي تتم رد علينا مجموعة افلام »ا ملدم ر« )ترمينيتور( .وقد وصف كاتب الخيال العلمي ايزاك اسيموف هذا الخوف ب »عقدة فرانكنشتاين« :الخوف من الروبوتات. ويرتبط هذا يتعني علي العلماء وا ملستثمرين ايضا بالذكاء الاصطناعي اليوم .وهو امر التعامل معه .فبعضهم يحاربون هذا الخوف؛ وبعضهم يساعد في خلقه والحفاظ عليه. اشرت بالفعل الي مثال »ماسك« .وثم ة مثال اخر علي شخصية موثرة ساهمت في وقد نشر الخوف من الذكاء الاصطناعي وهو عالم الفيزياء ستيفن هوكينج ،الذي صر ح في عام 2017بان خلق الذكاء الاصطناعي يمكن ان يكون اسوا حد ث في تاريخ حضارتنا ) .(Kharpal 2017ان »عقدة فرانكنشتاين« منتشرة وعميقة الجذور في الثقافة والحضارة الغربية. التسامي ونهاية العالم بسبب الذكاء الاصطناعي ثمة مقدمات لافكار مثل »تجاوز الانسانية« و»التف رد التكنولوجي« في تاريخ التفكري الديني والفلسفي الغربي او علي الاقل توج د افكار مشابهة لها ،ولا سيما في التقاليد اليهودية املسيحية وفي الفكر الافلاطوني .وعلي عكس ما يعتقده الكثريون ،فان الدين والتكنولوجيا كانا دايم ا متراب طني في تاريخ الثقافة الغربية .ودعوني احصر نقاشي هنا في التسامي ونهاية العالم. في الدين اللاهوتي ،يقصد بالت سامي ان الاله »فوق« العالم املادي والجسدي ومستقل عنه ،وهي فكرة مناقضة لفكرة انه موجود في العا لم وانه جزء منه )الحلولية( .في التقليد اليهودي املسيحي الاحادي اللاهوتي ،يري الله علي انه يتسامي فوق خلقه .ويمكن في الوقت نفسه ايضا ان يري علي انه متغلغل في كل مخلوقاته وفي كل الكاينات )اي انه يتجلي من خلال يح ل فيها( ،وعلي سبيل املثال ،في اللاهوت الكاثوليكي ،يفهم الله كما ابنه )املسيح( والروح القدس .ويبدو ان سرديات الذكاء الاصطناعي التي تتجلي فيها انفصالا او فجوة بني الخالق »عقدة فرانكنشتاين« توكد فكرة التسامي بمعني ان هناك واملخلوق )بني الانسان الاله والذكاء الاصطناعي( ،دون اعطاء الكثري من الامل في امكانية تجاوز هذه الفجوة. اخلاقيات الذكاء الاصطناعي علي عكس ما يعتقده الكثريون ،فان الدين والتكنولوجيا كانا دايم ا متراب طني في تاريخ الثقافة الغربية."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 28, "content": "ايضا ان يشري الي تجاوز الحدود ،او تخ التسامي يمكن طي شيء ما .في التاريخ ري من الاحيان شك ل السمو فوق الديني والفلسفي الغربي ،اتخذت هذه الفكرة في كث املتوسط في العالم املادي والجسدي وتجاوز حدوده .علي سبيل املثال ،في منطقة البحر القرن الثاني امليلادي ،كانت الغنوصية تنظر الي املاد ة جميعها باعتبارها شرا ،وتهدف الي تحرير الشعلة الالهية من الجسد البشري .وفي وقت اسبق ،راي افلاطون الجسد سجنا للروح .وعلي عكس الجسد ،كان ينظر الي الروح علي انها خالدة .وفي امليتافيزيقا الخاصة به ،مي ز افلاطون بني الاشكال ،التي هي ابدية ،والاشياء املوجودة في العالم ،التي تتغري؛ فالاولي تتسامي فوق الاخرية وتتجاوزها .وهناك افكار في مبدا تجاوز الانسانية تذ كرنا بهذا .فهي تحافظ علي هدف التسامي بمعني تجاوز القيود البشرية ،وليس هذا فحسب، بل ان الطرق الخاصة التي يفترض ان يحدث بها هذا التسامي تستحضر افلاطون والغنوصية :لتحقيق الخلود ،يجب التسامي فوق الجسد البيولوجي عن طريق تحميل بشكل اكثر عمومية ،عندما يستخدم الذكاء الاصطناعي ادوات اصطناعية وتطويرها. اشكال اكثر نقاء من العا لم والعلوم والتكنولوجيا ذات الصلة الرياضيات لاستخلاص يتحقق بواسطة وسايل املادي الفوضوي ،يمكن تفسري ذلك علي انه برنامج افلاطوني تكنولوجية .ومن هنا يتبني ان خوارزمية الذكاء الاصطناعي هي الة افلاطونية تستخلص شكلا )او نموذج ا( من عا لم الظواهر )البيانات(. التسامي يمكن ايضا ان يعني تجاوز الحالة الانسانية .في التقليد املسيحي ،يمكن ان ياخذ هذا شكل محاولة راب الفجوة بني الله والبشر من خلال تحويل البشر الي الهة، ربما عن طريق استعادة تشابههم مع الالهة وكمالهم الاصلي ) .(Noble 1997ولكن سع ي مويدي تجاوز الانسانية للخلود ليس جديدا ،بل يمكن تتب عه الي العصور القديمة. اذ يمكننا ان نجده في امليثولوجيا امليزوبوتامية )الاساطري التي تاتي من منطقة ما بني النه رين( :تحكي لنا قصة »ملحمة جلجامش« ،وهي واحدة من اقدم القصص املكتوبة عن البشرية ،عن ملك اوروك )جلجامش( ،الذي يبحث عن الخلود بعد وفاة صديقه انكيدو. ولكنه يفشل في العثور عليه :ومع ذلك ،ينجح في الحصول علي نبتة يقال انها تعيد الشباب ،ولكن تسرقها افعي ،وفي النهاية ، يتعني عليه ان يتع لم الدرس بان عليه مواجهة الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 29, "content": "حقيقة موته هو شخصيا؛ اذ ان سعيه الي الخلود بلا جدوي .علي م ر التاريخ ،كان الناس علاجات مضاد ة للشيخوخة .ومن يبحثون عن اكسري الحياة .واليوم ،تبحث العلوم عن هذا املنطلق ،فان سعي مويدي مبدا تجاوز الانسانية الي الخلود او الي اطالة العمر ليس جديدا او غريبا؛ بل هو واحد من اقدم احلام البشرية واهداف العلم ا ملعاصر .وفي ايدي مويدي تجاوز الانسانية ،يصبح الذكاء الاصطناعي هو اداة التجاوز التي تع دنا بالخلود. من املفاهيم القديمة الاخري التي تساعدنا علي وضع افكار تجاوز الانسانية في سياقها ،ولا سيما فكرة التف رد التكنولوجي ،مفهوم نهاية العالم )ابوكاليبس( والاخروية. ومصطلح »ابوكاليبس« عند الاغريق القدماء ،الذي يلعب ايضا دو را في الفكر اليهودي واملسيحي ،يشري الي كشف الحجاب .وفي الوقت الحاضر ،يشري هذا املصطلح غالبا الي نوع معني من الكشف :وهو كشف سيناريو نهاية الزمان او نهاية العالم .وفي السياقات الدينية ،نجد مصطلح »الاخروية« :وهو جزء من علم اللاهوت يتع لق بالاحداث النهايية للتاريخ واملصري النهايي للبشرية .وتنطوي معظم الافكار الاخروية وتلك التي تتع لق بنهاية العالم علي تخريب او تدمري جذري وغالبا عنيف للعالم ،والاتجاه نحو مستوي اعلي من الواقع والكينونة والوعي .ويذكرنا ذلك ايضا بالطوايف والجماعات املتطرفة املتشايمة التي كانت وما تزال تتنب ا بالكوارث ونهاية العالم .ورغم ان مويدي تجاوز الانسانية في العادة ليس لهم علاقة بمثل هذه الطوايف واملمارسات الدينية ،فان فكرة التفرد التكنولوجي تشبه الي ح د ما سرديات نهاية العا لم والاخروية والتنبو بالكوارث، وهذا امر واضح. بالتالي ،بينما يستند تطوير الذكاء الاصطناعي الي عل م من ا ملفترض انه لا خيالي ولا اقتراح ديني ،وبينما يناي مويدو تجاوز الانسانية بانفسهم عاد ة عن الدين ويرفضون اي بان اعمالهم تستند الي الخيال ،الا ان الخيال العلمي والافكار الدينية والفلسفية القديمة تلعب بالضرورة دو را مهم ا عندما نناقش مستقبل الذكاء الاصطناعي من هذا املنطلق. كيفية تجاوز سرديات املنافسة وتجاوز الضج ة ا ملثارة حول الذكاء الاصطناعي يمكن للمرء ان يتساءل الان :هل هناك سبل للنجاة؟ هل يمكننا تجاوز سرديات املنافسة رسوخا لفهم مستقبل الذكاء الاصطناعي والتكنولوجيا ا ملماثلة؟ ام طرق اكثر وايجاد ان التفكري الغربي حول الذكاء الاصطناعي محكوم عليه بالبقاء في سجن هذه املخاوف اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 30, "content": "العصرية وجذورها القديمة؟ هل يمكننا تجاوز الضجة املثارة حول الذكاء الاصطناعي؟ نصب ة علي الذكاء الفايق؟ اعتقد ان لدينا ام ستظ ل املناقشة م سبلا للنجاة. رغم ان مويدي تجاوز الانسانية في العادة ليس لهم علاقة بمثل هذه الطوايف وا ملمارسات الدينية، فان فكرة التف رد التكنولوجي تشبه الي ح د ما سرديات نهاية العالم والاخروية والتنبو بالكوارث."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 31, "content": "اولا ،يمكننا تجاوز الثقافة الغربية للعثور علي انواع مختلفة من السردي ات غري ا ملبنية علي »عقدة فرانكنشتاين« فيما يخص التكنولوجيا وطرق التفكري غري الافلاطونية. علي سبيل املثال ،في اليابان حيث تتاثر ثقافة التكنولوجيا بديانات الطبيعة اكثر من الغرب ،وتحديدا بديانة الشنتو ،وحيث صو رت الثقافة الشعبية الالات كمساعدين ،نجد موقفا اكثر ودا تجاه الروبوتات والذكاء الاصطناعي .هنا ،لا نجد عقدة فرانكنشتاين. وتنطوي طريقة التفكري التي يطلق عليها احيانا »الارواحية« علي ان الذكاء الاصطناعي يمكن نفسا ،ويمكن ان ي ايضا من حيث املبدا ان يمتلك روح ا او مقدسا .وهذا يعني عتبر عدم وجود سردية تنافسية؛ وعدم وجود رغبة افلاطونية في تجاوز املادية والدفاع ا ملستمر اختلافا جوهريا. عن الانسان بوصفه كاينا يسمو فوق الالة ويتجاوزها ،او يختلف عنها تشتمل الثقافة الشرقية علي افكار حول نهاية الزمان .وعلي عكس في حدود معرفتي ،لا الديانات التوحيدية ،تحمل ديانات الطبيعة فهم ا دوريا للزمن .وبالتالي ،يمكن ان يساعد النظر الي ما هو ابعد من الثقافة الغربية )او في واقع الامر الي املاضي القديم للغرب ،حيث نجد ايضا ديانات طبيعة( في التقييم النقدي للسرديات السايدة حول مستقبل الذكاء الاصطناعي. ثانيا :لتجاوز الضجة ا ملثارة حول الذكاء الاصطناعي وتجن ب حصر مناقشة اخلاقيات الذكاء الاصطناعي في احلام املستقبل البعيد وكوابيسه ،يمكننا ) (1استخدام الفلسفة والعلم لفحص ومناقشة الافتراضات املتع لقة بالذكاء الاصطناعي والانسان الذي يلعب دو را في هذه السيناريوهات واملناقشات )مثل :هل الذكاء العام ممكن؟ ما الفارق بني الانسان والالة؟ ما العلاقة بني الانسان والتكنولوجيا؟ ما الوضع الاخلاقي للذكاء بتفصيل اكثر الي ماهية الذكاء الاصطناعي املوجود وما الاصطناعي؟(؛ و) (2النظر يفعله اليوم في التطبيقات املختلفة؛ و) (3مناقشة املشكلات الاخلاقية والاجتماعية الاكثر واقعية والحاح ا التي يثريها الذكاء الاصطناعي كما يطبق اليوم؛ و) (4التفكري في سياسة الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي", "section_path": ["الفصل الثاني", "الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي"], "page": 32, "content": "الذكاء الاصطناعي للمستقبل القريب؛ و) (5طرح تساول عما اذا كان التركيز علي الذكاء الاصطناعي في الخطاب الجماهريي الحالي مفيدا في ضوء املشكلات الاخري التي تواجهنا، وما اذا كان تركيزنا ينبغي ان ينصب علي الذكاء الاصطناعي وحده .وسوف نتبع هذه املسارات في الفصول القادمة من الكتاب."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 33, "content": "كل ما له علاقة بالبشر"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 34, "content": "هل الذكاء الاصطناعي العام ممكن؟ هل هناك فروق جوهرية بني الانسان والالة؟ تفترض روية انصار تجاوز الانسانية للمستقبل التكنولوجي ان الذكاء الاصطناعي العام )او الذكاء الاصطناعي القوي( ممكن ،ولكن هل هو كذلك؟ بعبار ة اخري ،هل يمكننا انشاء الات تتمت ع بقدرات معرفية تشبه تلك الخاصة بالبشر؟ اذا كانت الاجابة لا ،فان روية الذكاء الفايق بالكامل تصبح غري ذات صلة باخلاقيات الذكاء الاصطناعي .فاذا كان من ا ملستحيل ان تتمت ع الالات بالذكاء البشري العام ،فاننا غري مضطرين الي ان نقلق يعتمد علي فهمنا بشكل عام ،يبدو ان تقييمنا للذكاء الاصطناعي بشان الذكاء الفايق. ملاهية الذكاء الاصطناعي في الوقت الحالي وما يمكن ان يصبح عليه في املستقبل ،كما يعتمد علي رويتنا للفروق بني الانسان والالة .علي الاقل منذ منتصف القرن العشرين ،ناقش الفلاسفة والعلماء ما تستطيع اجهزة الكمبيوتر ان تقوم به وما يمكن ان تصبح عليه، والفروق بني الانسان والالة الذكية .دعونا نلقي نظر ة علي بعض هذه النقاشات ،التي تتناول ماهية الانسان وما يجب ان يكون عليه ،بقدر ما تتناول ماهية الذكاء الاصطناعي وما يجب ان يكون عليه. هل يمكن لاجهزة الكمبيوتر ان تتمت ع بالذكاء والوعي والابداع؟ هل يمكنها فهم الاشياء وادراك املعاني؟ هناك تاريخ من النقد والشك في امكانية وجود ذكاء اصطناعي مشا ب ه لذكاء الانسان .في عام ،1972نشر هيوبرت دريفوس ،فيلسوف ذو خلفية في علم الظواهر ،كتابا بعنوان »ما لا تستطيع اجهزة الكمبيوتر فعله« 1 .منذ الستيني ات ،كان دريفوس يظهر انتقادا شديدا للاساس الفلسفي للذكاء الاصطناعي وش كك في وعوده: وقال ان برنامج الذكاء الاصطناعي البحثي محكوم عليه بالفشل .وقبل ان ينتقل الي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 35, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 36, "content": "بريكلي ،كان يعمل في معهد ماساتشوستس للتكنولوجيا ،وهو مكان مهم لتطوير الذكاء اساسا في ذلك الوقت علي ا ملعالجة الرمزية .راي دريفوس الاصطناعي ،والذي كان يعتمد ان الدماغ ليس جهاز كمبيوتر وان العقل لا يعمل عن طريق ا ملعالجة الرمزية .ان لدينا خلفية لا واعية من املعرفة املشتركة القايمة علي الخبرة وما يمكن ان يطلق عليه هايدجر »كينونتنا في العالم« ،وهذه املعرفة ضمنية ولا يمكن تشكيلها .وتعتمد خبرة الانسان، حسب راي دريفوس ،علي ا ملمارسة بدلا من املعرفة .ولا يستطيع الذكاء الاصطناعي ا لتقاط هذا املعني واملعرفة الضمنية؛ واذا كان هذا هو هدف الذكاء الاصطناعي ،فهذا محض اساطري .فالبشر وحدهم قادرون علي روية ما هو ذو صلة لانهم ،بوصف هم كاينات م تجسدة ووجودية ،يشاركون في العالم وقادرون علي الاستجابة ملتطلبات الوضع. هناك تاريخ من النقد والشك في امكانية وجود ذكاء اصطناعي مشا ب ه لذكاء الانسان."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 37, "content": "في ذلك الوقت ،واج ه دريفوس الكثري من املعارضة ،ولكن في وقت لاحق ،لم يع د الكثريون من باحثي الذكاء الاصطناعي يع دون بتحقيق الذكاء الاصطناعي العام او يتوقعون تحقيقه .وانتقلت ابحاث الذكاء الاصطناعي من الاعتماد علي معالجة الرموز الي نماذج جديدة ،ومنها تع لم الالة القايم علي الاحصاء .وفي حني كانت هناك فجوة هايلة في وقت دريفوس بني ع لم الظواهر والذكاء الاصطناعي ،فان العديد من باحثي الذكاء املتجسدة واملوجودة ،التي تد عي انها الاصطناعي اليوم يعتنقون مناهج العلوم املعرفية اقرب الي علم الظواهر. صايبة وتظهر كيف يمكن ان تتعا رض ومع ذلك ،فان اعتراضات دريفوس لا تزال وجهات نظر الانسان غالبا مع الاراء العلمية ،خاصة — ولكن ليس حصريا — فيما يسم ي بالفلسفة القارية .يشد د الفلاسفة القاريون عاد ة علي ان البشر والعقول البشرية مختلفة اختلافا جوهريا عن الالات ،وير كزون علي التجربة الانسانية الواعية والوجود الانساني، الذي لا يمكن ولا ينبغي اختزاله في اوصاف شكلية او تفسريات علمية .من جهة اخري، يويد بعض الفلاسفة — غالبا من منطلق التقليد التحليلي للفلسفة — روية للانسان تدعم الباحثني في مجال الذكاء الاصطناعي الذين يعتقدون ان الدماغ والعقل البشري يشبهان ويعملان حقا مثل نماذج الكمبيوتر الخاصة بهم .ومن امثلة هولاء الفلاسفة كل ما له علاقة بالبشر"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 38, "content": "بول تشريشلاند ودانييل دنيت .يعتقد تشريشلاند ان العلم ،وخاصة ع لم الاحياء التطو ري كاملا .ويعتقد وعلم الاعصاب ،والذكاء الاصطناعي يمكنهما تفسري الوعي البشري تفسريا شبكة عصبية متك ررة .وينكر وجود افكار او تجارب غري ماد ية فيما ان الدماغ عبارة عن يط لق عليه املادية الاقصايية .فما نسم يه افكا را وتجارب ما هو الا حالات للدماغ .وينكر دنيت ايضا وجود اي شيء بخلاف ما يحدث في الجسم :ويري اننا »نحن انفسنا نوع من الروبوتات« ) .(Dennett 1997واذا كان الانسان في الاساس الة واعية ،فان مثل هذه الالات ممكنة ،وليس فقط من حيث املبدا ولكن في الواقع .يمكننا ان نحاول صنعها .ومن بمكان ان كلا من الفلاسفة القاريني والتحليليني يعارضان الثنايية الديكارتية الاهمية لاسباب مختلفة :فالفلاسفة القاريون يعتقدون ان التي تفصل بني العقل والجسم ،ولكن وجود الانسان يتع لق بكونه في العا لم الذي لا يفصل فيه العقل عن الجسم ،اما الفلاسفة ستقلا عن الجسم. لاسباب مادية ان العقل ليس شييا م القاريون فيعتقدون ولكن ليس جميع الفلاسفة التحليلي ني ي رون ان الذكاء الاصطناعي العام او القوي ممكن .من وجهة نظر الفيلسوف فيتجنشتاين )في وقت لاحق( ،يمكن للشخص ان يجادل ملجموعة من القواعد ان تصف ظاهر ة معرفية ،فان ذلك لا يعني بانه في حني يمكن بالضرورة ان لدينا فعليا قواعد في رءوسنا ) .(Arkoudas and Bringsjord 2014كما لنوع واحد من انواع الذكاء الاصطناعي، هو الحال مع انتقاد دريفوس ،يثري هذا مشكلة وهو الذكاء الاصطناعي الرمزي ،اذا افترض ان هذه هي الطريقة التي يف كر بها البشر. ثم ة انتقاد فلسفي اخر للذكاء الاصطناعي ياتي من جون سريل ،الذي يعارض فكرة ان برامج الكمبيوتر يمكن ان تكون لديها حالات معرفية حقيقية او فهم للمعني )Searle .(1980وفيما يلي التجربة الفكرية التي يقد مها ،والتي تع رف باسم حج ة الغرفة الصينية :يحبس سريل في غرفة ويعطي كتابات صينية ولكنه لا يعرف الصينية .ومع اشخاص خارج الغرفة يتحدثون بالصينية ذلك ،يستطيع الرد علي الاسيلة التي يطرحها لانه يستخدم كتي ب القواعد الذي يم كنه من انتاج الاجابات الصحيحة )مخرجات( استنادا الي املستندات )املدخلات( التي بنجاح دون فهم اللغة يتلقاها .وهو يستطيع القيام بذلك الصينية .وباملثل ،يجادل سريل ،يمكن لبرامج الكمبيوتر انتاج مخرج ات استنادا الي مدخلات بالاستعانة بالقواعد التي تزو د بها ،ولكنها لا تفهم شييا .بمصطلحات فلسفية تخص صا :لا تمتلك برامج الكمبيوتر قصدية ،ولا يمكن خلق فهم حقيقي بواسطة اكثر الحوسبة الشكلية .او كما يقول بودن ) ،(2016الفكرة هي ان املعني ياتي من البشر. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 39, "content": "علي الرغم من ان برامج الكمبيوتر الحالية للذكاء الاصطناعي غالبا ما تختلف عن تلك التي انتقدها دريفوس وسريل ،فان النقاش لا يزال مستم را .يعتقد العديد من فروقا حاسمة بني طريقة تفكري البشر واجهزة الكمبيوتر .علي سبيل الفلاسفة ان هناك املثال ،يمكن للمرء اليوم ان يجادل باننا كاينات قادرة علي خلق املعني ،وواعية وم تجسدة وحية ،ولا يمكن تفسري طبيعتنا وعقولنا ومعرفتنا باملقارنة بالالات .ومع ذلك ،عليك ان تلاحظ انه حتي العلماء والفلاسفة الذين يعتقدون ان هناك الكثري من التشابه بني البشر ري من والالات من حيث املبدا ،وان الذكاء الاصطناعي العام ممكن نظريا ،يرفضون في كث عتبر ان الذكاء الاصطناعي ا ملشابه الاحيان روية بوستروم للذكاء الفايق وافكار مماثلة ت التحقق .فبودن ودنيت كلاهما يعتقدان لذكاء الانسان قد اصبح قاب قوسني او ادني من ان الذكاء الاصطناعي العام صعب جدا تحقيقه عمليا ،وبالتالي ليس شييا يجب القلق بشانه في الوقت الحالي. نحن كاينات قادرة علي خ لق املعني ،وواعية ومتجسدة وحية ،ولا يمكن تفسري طبيعتنا وعقولنا ومعرفتنا باملقارنة بالالات."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 40, "content": "وبناء عليه يمكننا القول ان هناك ،في خلفية النقاش حول الذكاء الاصطناعي ،تباين عميق في الاراء حول طبيعة الانسان والذكاء البشري والعقل والفهم والوعي والابداع واملعني واملعرفة البشرية والعلوم ،وهكذا .فاذا كان ثمة »معركة« من الاساس ،فهي معركة تتع لق بالانسان بقدر ما تتع لق بالذكاء الاصطناعي. الحداثة و)ما بعد( الانسانية وما بعد الظاهرية نظر اوسع في العلوم الانسانية ،من املهم ان نضع هذه النقاشات حول من وجهة سياق اوسع للوقوف علي ماهيتها وما تنطوي عليه .فهذه الذكاء الاصطناعي والانسان في انقسامات عميقة في النقاشات لا تتع لق بالتكنولوجيا والانسان فحسب ،ولكنها تعكس بشكل غري مباشر في الحداثة .دعوني ام ر مرور الكرام علي ثلاثة انقسامات تساهم تشكيل املناقشات الاخلاقية حول الذكاء الاصطناعي .الانقسام الاول هو انقسام ظه ر في مسته ل عصر الحداثة بني حركتي التنوير والرومانسية .اما الاخران فهما تطو رات حديثة كل ما له علاقة بالبشر"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 41, "content": "نسبيا :الاول بني الانسانية وتجاوز الانسانية ،ويبقي حبيس توترات الحداثة ،والثاني بني الانسانية وما بعد الانسانية ،والذي يحاول تخ طي الحداثة. احدي وسايل فهم النقاش حول الذكاء الاصطناعي والانسان هي ان نضع في الاعتبار التوت ر القايم بني التنوير والرومانسية في الحداثة .في القرنني الثامن عشر والتاسع عشر، تحدي العلماء وا ملفكرون التنويريون الاراء الدينية التقليدية وزعموا ان العقل والشك ظهر لنا ماهية الانسان والعالم الحقيقية ،علي عكس ا ملعتقدات ا ملس لم بها غري والعلم ت ا ملبررة بالحجج او غري املدعومة بالادلة .وكانوا متفايلني حيال ما يمكن ان يقد مه العلم لصالح الانسانية .ردا علي ذلك ،قال الرومانسيون ان العقل املج رد والعلم الحديث قد افقدا العا لم سحره واننا في حاجة الي اعادة الغموض والسحر اللذين يريد العلم القضاء عليهما .عند النظر الي النقاش حول الذكاء الاصطناعي ،يبدو لنا اننا لم نبتع د كثريا عن ذلك .علي سبيل املثال ،يستهدف عمل دنييت حول الوعي وعمل بودين حول الابداع تفسريات لكل شيء ،او كما يقول دنييت »فك السحر« .فهذان الفيلسوفان متفايلان تقديم بان العلم يمكنه كشف غموض الوعي والابداع وغريهما .انهما يعارضان كل م ن يقاوم جهود فك سحر الانسان ،مثل الفلاسفة القاريني الذين يسريون في ركب ما بعد الحداثة ويشد دون علي غموض معني ان تكون انسانا؛ بعبارة اخري :الرومانسيني الج دد .يبدو ان سوال »هل نف ك السحر ام نحتفظ بغموض الانسان؟« هو السوال الرييسي في املناقشات التي تتناول الذكاء الاصطناعي العام ومستقبله. اما التوتر الثاني فهو بني مويدي الانسانية ومويدي تجاوز الانسانية .ما هو يتعني »الانسان« ،وماذا يجب ان يكون؟ هل من ا ملهم الدفاع عن الانسان كما هو ،ام علينا تعديل تصو رنا له؟ يحتفي دعاة الانسانية بالانسان كما هو .ومن الناحية الاخلاقية، يشد دون علي القيمة الجوهرية واملتفو قة للبشر .ويمكننا العثور علي افكار دعاة الانسانية في النقاش الداير عن الذكاء الاصطناعي في الحجج التي تدافع عن حقوق الانسان وكرامته كاساس لاخلاقيات الذكاء الاصطناعي ،او في الحجة املويدة لان يكون البشر و قيمهم في قلب وفي مركز مسالة تطوير الذكاء الاصطناعي ومستقبله .هنا غالبا ما تت فق الانسانية اشكالا اكثر تحف مع التفكري التنويري .ولكن يمكن ان تاخذ ظا او رومانسية .كذلك ايضا يمكننا ان نعثر علي الانسانية في مقاومة مشروع دعاة تجاوز الانسانية .فبينما يعتقد دعاة تجاوز الانسانية ان علينا ا مل ضي قدم ا نحو نوع جدي د من الانسان يتم تحسينه بواسطة العلم والتكنولوجيا ،يدافع الانسانيون عن الانسان كما هو ،ويشددون علي قيمته وكرامته ،التي يقال انها مهد دة من ق بل علوم دعاة تجاوز الانسانية وفلسفتهم. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 42, "content": "ردود الفعل الدفاعية تجاه التكنولوجيا الجديدة لها تاريخها الخاص .ففي العلوم الاجتماعية والانسانية ،كثريا ما ت نتقد التكنولوجيا باعتبارها تهديدا للانسانية واملجتمع. علي سبيل املثال ،كان كثري من فلاسفة القرن العشرين شديدي التشاوم حيال العلم، وحذروا من سيطرة التكنولوجيا علي املجتمع .ولكن الصراع الان لا يتع لق فقط بحياة الانسان واملجتمع ،بل يتع لق بالانسان نفسه :هل نحن بصدد تحسينه وتطويره ام لا؟ هذا هو السوال .فمن جهة ،يصبح الانسان نفسه مشروع ا علميا تكنولوجيا ، قابلا للتحسني والتطوير .وبمج رد ان ي فك سحر الانسان — من خلال داروين وعلم الاعصاب والذكاء الاصطناعي — يمكننا ان نبدا في تحسينه .ويمكن للذكاء الاصطناعي ان يساعدنا في نحتضن الانسان كما هو .وربما يقول تحسني الانسان .ومن جهة اخري ،يجب علينا ان البعض :دايم ا ما يفوتنا ان ندرك ماهية الانسان .فنحن لا نستطيع ان نفهمه فهم ا تام ا بواسطة العلم. تستمر هذه التوت رات في تقسيم العقول والقلوب في هذا النقاش .فهل يمكننا تخ طيها؟ يتخلي عن هدف انشاء ذكاء اصطناعي شبيه بالانسان .ولكن حتي عمليا ،يمكن للمرء ان في هذه الحالة ،تظ ل هناك خلافات بشان وضع »الات الذكاء الاصطناعي كنماذج للبشر« ا ملستخدم في علم الذكاء الاصطناعي .هل تع لمنا حقا شييا عن كيفية تفكري البشر؟ ام نوع معني من التفكري ،علي سبيل املثال تفكري يمكن صياغته انها تع لمنا فقط شييا عن بواسطة الرياضيات ،او تفكري يهدف الي السيطرة والتلاع ب؟ الي اي مدي يمكننا حقا التع لم من هذه التقنيات عن الانسان؟ هل البشرية اكبر مما يستطيع العلم ان يدرك؟ اعتدالا ،تظهر الصراعات بشان الحداثة. حتي في املناقشات الاكثر نهج دارسي العلوم الاجتماعية والانسانية للخروج من هذا املازق ،يمكن للمرء اتباع طرقا »غري حديثة« للتفكري خلال الخمسني عام ا املاضية .اوضح كت اب الذين استكشفوا امثال برونو لاتور وتيم انجولد انه يمكننا العثور علي طرق اقل ميلا للمقارنة بني ثناييات واكثر ميلا ل لجوء الي اللاحداثة عند التعامل مع العا لم من اجل تجاوز الخلاف ما بني التنوير والرومانسية .يمكننا عندي ذ ان نحاول اجتياز الفجوة الحديثة بني البشر وغري البشر ليس من خلال الع لم الحديث او من خلال تجاوز الانسانية ،التي تري من وجهة صراع اساسي ،ولكن من خلال الفكر ما بعد الانساني نظرها ان البشر والالات ليسا في من وجهة النظر )ما بعد( الانسانية .وهذا يودي الي التوتر الثالث :بني الانسانية وما بعد الانسانية .يش كك مويدو ما بع د الانسانية ،الذين يعارضون الانسانيني ا ملتهمني بالع نف كل ما له علاقة بالبشر"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 43, "content": "مع غري البشر ،مثل الحيوانات ،تحت مسم ي القيمة الفايقة للانسان ،يش ككون في مركزية الانسان في الانظمة الانطولوجية والاخلاقية الحديثة .فهم ي رون ان غري البشر مهم ون ايضا ،واننا يجب الا نخاف من عبور الحدود بني البشر وغري البشر .وهذا اتجاه مثري للاستكشاف لانه ياخذنا خارج سردية املنافسة بني البشر والالات. روية تصو ر ان العيش يقدم مناصرو ما بعد الانسانية ،من امثال دونا هاراواي، مع الالات ،بل ربما الاندماج معها ،لم يع د يري كتهدي د او ككابوس ،كما كان يري من يتحقق ملناصري تجاوز الانسانية ،ولكنه وسيلة يمكن من قبل دعاة الانسانية ،او كحل م خلالها عبور الحدود الانطولوجية والسياسية بني البشر وغري البشر .ومن ثم يمكن ان يكون الذكاء الاصطناعي جزءا ليس من مشروع دعاة تجاوز الانسانية ،ولكن من مشروع دعاة ما بعد الانسانية ا ملهم ،الذي يدخل من جانب العلوم الانسانية والفنون بدلا من العلم .يتم عبور الحدود ليس باسم العلم والتقد م العاملي ،كما قد يرغب بعض مناصري تجاوز الانسانية التنويريني في القول ،ولكن باسم سياسة مناصري ما بعد الانسانية ايضا ان تقد م شييا وايديولوجية عبور الحدود .ويمكن ملا بعد الانسانية اخر يتع لق بالذكاء الاصطناعي :يمكنها ان تح ث نا علي الاعتراف بانه »ليس ثمة حاجة لان يكون غري البشر مماثلني لنا ويجب عدم جعلهم مماثلني لنا« .يبدو ان الذكاء الاصطناعي يمكنه، بالاستناد الي اراء ما بعد الانسانية ،ان يح رر نفسه من عبء تقليد الانسان او اعادة اشكال مختلفة من الوجود والذكاء والابداع ،وما الي ذلك .ليس بنايه ويمكنه استكشاف هناك حاجة لان يصن ع الذكاء الاصطناعي علي صورتنا .فالتقد م هنا يعني تجاوز الانسان وقبول غري البشر لكي نتع لم منهم .وعلاو ة علي ذلك ،يمكن ان يتفق ك ل من دعاة تجاوز الانسانية وما بعد الانسانية علي انه التنافس مع الذكاء الاصطناعي لاداء مهمة بدلا من معي نة ،يمكننا التوصل اليه من خلال التعاون وحشد هدف مشترك ،يتم ايضا تحديد افضل ما يمكن ان يقد مه البشر والذكاء الاصطناعي من اجل التوج ه نحو تحقيق ذلك الهدف املشترك. وسيلة اخري لتجاوز سردية املنافسة — وهي وسيلة تقترب في بعض الاحيان من مفاهيم ما بعد الانسانية — هي نهج في فلسفة التكنولوجيا يسم ي ما بعد الظاهرية. يستند دريفوس الي علم الظواهر او الظاهرية ،ولا سيما اعمال هايدجر .ولكن الافكار ما بعد الظاهرية ،التي بداها الفيلسوف دون ايده ،تتجاوز فلسفة التكنولوجيا الظاهرية التي ابتكرها هايدجر بالتركيز علي كيفية تفاعل البشر مع تقنيات بع ينها ولا سيما اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 44, "content": "ري من الاحيان مع دراسات العلوم املصنوعات املادية .ير كز هذا النهج ،الذي يتعاون في كث والتكنولوجيا ،علي البعد املادي للذكاء الاصطناعي .قد ين ظر الي الذكاء الاصطناعي في بمصنوعات مادية و بنيات طابع مج رد او شكلي ،غري متصل بعض الاحيان علي انه ذو سابقا اساسية محد دة .ولكن جميع الشكليات والتجريدات والعمليات الرمزية املذكورة ادوات مادية و بنيات اساسية مادية .علي سبيل املثال ،كما سنري في الفصل تعتمد علي التالي ، بشكل كبري علي الشبكات وانتاج كمي ات ضخمة يعتمد الذكاء الاصطناعي الحالي من البيانات باستخدام الاجهزة الالكترونية .تلك الشبكات والاجهزة ليست مجرد اشياء »افتراضية« ولكن بشكل مادي .وعلاو ة علي ذلك ،يتحد ث ما بعد يتعني انتاجها وصيانتها الظاه ري ني ،مثل بيتر بول فريبيك ،عكس التقسيم الحديث بني املوضوع واملحمول ،عن التشكيل ا ملتبادل بني البشر والتكنولوجيا ،او علي الاحري التشكيل ا ملتبادل بني املوضوع وبدلا من روية التكنولوجيا كتهديد ،يو كدون ان البشر م ي الون الي التكنولوجيا واملحمول. )بمعني انهم كانوا دايم ا يستخدمون التكنولوجيا؛ اي انها جزء من وجودنا وليست شييا خارجيا يهد د هذا الوجود( ،وان التكنولوجيا تساعد البشر علي التعامل مع العالم. بالنسبة الي الذكاء الاصطناعي ،يبدو ان هذه الروية تعني ان املعركة الانسانية للدفاع وبدلا من ذلك ، وفقا لهذا النهج ،كان عن الانسان ضد التكنولوجيا هي معركة مضل لة. الانسان دايم ا مي الا الي التكنولوجيا ،ولهذا علينا ان نسال كيف يساعد الذكاء الاصطناعي بشكل تفاع لي بينما لا يزال البشر في التعامل مع العالم ونحاول تشكيل هذه ا ملساعدات بامكاننا :اننا نستطيع مناقشة الاخلاقيات في مرحلة تطوير الذكاء الاصطناعي ،بل يتعني علينا ذلك ، بدلا من ان نشكو فيما بع د من املشكلات التي يسب بها. يبدو ان الذكاء الاصطناعي يمكنه ،بالاستناد الي اراء ما بعد الانسانية ،ان يح رر نفسه من عبء اشكال مختلفة من الوجود والذكاء والابداع ،وما تقليد الانسان او اعادة بنايه ويمكنه استكشاف الي ذلك."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 45, "content": "ومع ذلك ،ربما يشع ر املرء بالقلق من ان روي مناصري ما بعد الانسانية وما بعد الظاهرية ليست ناقد ة بما فيه الكفاية؛ لانها شديدة التفاول وشديدة البعد عن املمارسة العلمية والهيكلية ،وبالتالي فهي ليست حساسة بما فيه الكفاية تجاه الاخطار الحقيقية والعواقب الاخلاقية وا ملجتمعية للذكاء الاصطناعي .ان عبور الحدود التي لم يسبق عبورها كل ما له علاقة بالبشر"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "كل ما له علاقة بالبشر", "section_path": ["الفصل الثالث", "كل ما له علاقة بالبشر"], "page": 46, "content": "لا يكون بالضرورة من دون مشكلات ،وفي املمارسة العملية قد لا تفيد افكار ما بعد الانسانية وما بعد الظاهرية في حمايتنا من التس لط والاستغلال الذي قد نعاني منه ج راء استخدام تقنيات كالذكاء الاصطناعي .يمكن للمرء ايضا ان يدافع عن روية اكثر تقليدية بنوع جديد من الانسانية ، بدلا من ان يدعم ما بع د الانسانية .وهكذا للانسان او يطالب يستمر النقاش."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 47, "content": "اهي حقا مجرد الات؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 48, "content": "التشكيك في املكانة الاخلاقية للذكاء الاصطناعي: الوكالة الاخلاقية واكتساب املكانة الاخلاقية احدي القضايا التي اثريت في الفصل السابق تتع لق بما اذا كان غري البشر مهم ني ايضا. يعتقد الكثريون اليوم ان الحيوانات مهم ة من الناحية الاخلاقية .ولكن لم ي كن الامر كذلك دايم ا .علي ما يبدو ،كن ا مخطيني في املاضي بشان الحيوانات .فاذا كان الكثريون اليوم يعتقدون ان الالات املدعومة بالذكاء الاصطناعي مجرد الات ،فهل يرتكبون خطا م ماثلا؟ مكانة اخلاقية؟ هل ينبغي هل تستح ق الالات املدعومة بالذكاء الاصطناعي الفايقة الذكاء بمكان ان نف كر حتي في مسالة ما اذا كانت الالات حقوقا؟ ام انه من الخطورة ان نعطيها بمكانة اخلاقية؟ يمكن ان تحظي احدي الطرق ملناقشة ما هو الذكاء الاصطناعي وما يمكن ان يصبح عليه هي اسيلة فلسفية السوال عن املكانة الاخلاقية للذكاء الاصطناعي .ونحن هنا نتط رق الي متع لقة بالذكاء الاصطناعي ،ليس عبر امليتافيزيقا او الابستمولوجيا او تاريخ الافكار، ولكن عبر فلسفة الاخلاق .يمكن ان يشري مصطلح »املكانة الاخلاقية« )ويسمي احيانا »الاهمية الاخلاقية«( الي نوع ني من الاسيلة .الاول يتع لق بما يمكن للذكاء الاصطناعي القيام به من الناحية الاخلاقية؛ بعبار ة اخري ،ما اذا كان يمكن ان يتمت ع بما يطلق عليه الفلاسفة »الوكالة الاخلاقية« ،واذا كان الامر كذلك ،فهل يتمت ع بالوكالة الاخلاقية الكاملة؟ ماذا يعني هذا؟ يبدو ان افعال الذكاء الاصطناعي اليوم لها بالفعل عواق ب »ضعيفا« من اشكال شكلا اخلاقية .سيت فق معظم الناس علي ان لدي الذكاء الاصطناعي الوكالة الاخلاقية بهذا املعني ،والذي يش به ،علي سبيل املثال ،معظم السيارات اليوم؛ اذ"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 49, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 50, "content": "يمكن ان يكون للاخرية ايضا عواق ب اخلاقية .ولكن اذا س لمنا بان الذكاء الاصطناعي بشكل اقوي من اشكال الوكالة الاخلاقية؟ واستقلالا ،فهل يمكن ان يتمت ع يزداد ذكاء يجب ان يتم منح ه او سيتطو ر لديه بعض القدرة علي التفكري الاخلاقي والقدرة هل علي اصدار الاحكام واتخاذ القرارات؟ علي سبيل املثال :هل يمكن وهل يجب ان نعتبر السيارات الذاتية القيادة التي تستخدم الذكاء الاصطناعي ذات وكالة اخلاقية؟ هذه الاسيلة تتع لق باخلاقيات الذكاء الاصطناعي ،بمعني انها تتط رق الي ماهية القدرات الاخلاقية التي يمكن او ينبغي ان يتمت ع بها الذكاء الاصطناعي؟ ولكن الاسيلة ا ملتعلقة ب »املكانة الاخلاقية« يمكن ايضا ان تشري الي كيف ينبغي ان نعامل الذكاء الاصطناعي .هل شكلا من اشكال الاحترام الاخلاقي؟ هل الذكاء الاصطناعي »مجرد الة« ،ام انه يستحق بطريقة مختلفة عن الطريقة التي نتعامل بها مثلا مع الة التحميص يجب علينا معاملته لكيان صناعي ذكي للغاية ،اذا تم تطوير مثل او املغسلة؟ هل يجب ان نمنح حقوقا هذا الكيان يوم ا ما ،حتي لو لم ي كن بشريا؟ هذا ما يطلق عليه الفلاسفة السوال املتعلق ب »اكتساب املكانة الاخلاقية« .هذا السوال يتعلق باخلاقيات الذكاء الاصطناعي بذاته، ولكنه يتع لق باخلاقياتنا تجاهه .هنا يكون الذكاء الاصطناعي موض ع اهتما م من الناحية وكيلا اخلاقيا م الاخلاقية ، حتملا في ح د ذاته. بدلا من كونه هل الذكاء الاصطناعي »مجرد الة«؟ هل يجب علينا معاملته بطريقة مختلفة عن الطريقة التي نتعامل بها مثلا مع الة التحميص او املغسلة؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 51, "content": "الوكالة الاخلاقية لنبدا بالتحد ث عن سوال الوكالة الاخلاقية .اذا كان الذكاء الاصطناعي يمكن ان يصبح اكثر ذكاء مما هو عليه اليوم ،فيمكننا ان نفترض انه يستطيع ان يطو ر قدرته علي التفكري الاخلاقي وانه يستطيع ان يتع لم كيف يت خ ذ البشر القرارات بشان القضايا الاخلاقية. ولكن هل سيكون هذا كافيا لكي يحظي بالوكالة الاخلاقية الكاملة؛ اي الوكالة الاخلاقية خيالا علميا بالكامل .فاذا كنا نعتمد اليوم علي التي يتمت ع بها الانسان؟ هذا السوال ليس الخوارزميات في اتخاذ بعض قراراتنا ،علي سبيل املثال في السيارات او املحاكم ،فيبدو سليمة من الناحية الاخلاقية .ولكن ليس انه سيكون من ا مله م ان تكون تلك القرارات اهي حقا مجرد الات؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 52, "content": "من الواضح ما اذا كانت الالات يمكن ان تتمت ع بنفس القدرات الاخلاقية التي يتمت ع بها بافعال في العا لم ،وهذه الافعال لها البشر .انها تتمت ع بالوكالة الاخلاقية بمعني انها تقوم عواقب اخلاقية .علي سبيل املثال ،قد تتسب ب سيارة ذاتية القيادة في حادث ،او قد يوصي الذكاء الاصطناعي بسجن شخص معني .هذه السلوكيات والخيارات ليست حيادية من الناحية الاخلاقية؛ اذ ان لها عواقب اخلاقية واضحة علي الاشخاص ذوي الصلة .ولكن للتعامل مع هذه املشكلة ،هل يجب منح الوكالة الاخلاقية للذكاء الاصطناعي؟ وهل يمكن ان يتمت ع بوكالة اخلاقية كاملة؟ هناك مواقف فلسفية متنو عة حيال هذه الاسيلة .يقول بعض الاشخاص ان الالات لا يمكن ان تتمت ع ابدا بالوكالة الاخلاقية .ويري هولاء ان الالات ليس لديها القدرات اللازمة للوكالة الاخلاقية ،مثل الحالات العقلية او الانفعالات او الارادة الحرة .ولذلك هناك خطورة نعتمد عليها في اتخاذ قرارات سليمة اخلاقيا وان نفترض انها تستطيع اتخاذ في ان كاملا .علي سبيل املثال ،قالت ديبورا جونسون ) (2006ان مثل هذه القرارات اعتمادا بوكالة اخلاقية خاصة بها :انها من انتاج البشر وتستخدم من انظمة الكمبيوتر لا تتمت ع ق بلهم ،والبشر وحدهم لديهم الحرية والقدرة علي التصر ف واتخاذ القرارات من الناحية الاخلاقية .وبالطريقة نفسها ،يمكن للمرء ان يقول ان الذكاء الاصطناعي من انتاج البشر، وبالتالي يجب ان يكون اتخاذ القرارات الاخلاقية في املمارسات التكنولوجية من اختصاص بوكالة البشر .علي النقيض من ذلك ،هناك اوليك الذين يعتقدون ان الالات يمكن ان تتمت ع اخلاقية كاملة تمام ا مثل البشر .ويزعم الباحثون مثل مايكل وسوزان اندرسون ،علي سبيل املثال ،انه من حيث املبدا يمكن ،بل يجب ،ان تمنح الالات نوع ا من الاخلاق البشرية ) .(Anderson and Anderson 2011ويمكننا تزويد الذكاء الاصطناعي باملبادي ،وربما تكون الالات حتي افضل من البشر في الوصول الي القرارات الاخلاقية نظ را لانها اكثر عقلانية ولا تنجرف وراء عواطفها .وقد جادل البعض ،لدحض هذه الفكرة ،بان القواعد الاخلاقية كثريا ما تتضارب )علي سبيل املثال ،انظر الي قصص الروبوتات لاسيموف، حيث تتسب ب القوانني الاخلاقية للروبوتات دايم ا في مشكلات للبشر والروبوتات( ،وان افتراضات خاطية مشروع انشاء »الات اخلاقية« من خلال تغ ذيتها بالقواعد يستند الي بخصوص طبيعة الاخلاق .فالاخلاق لا يمكن اختزالها في ات باع القواعد ،كما انها ليست مسالة عواطف بشرية فحسب؛ ولكن هذه العواطف قد تكون ضرورية للغاية للح كم الاخلاقي .فاذا كان الذكاء الاصطناعي العام ممكنا علي الاطلاق ،فاننا لا نريد نوع ا من اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 53, "content": "»الذكاء الاصطناعي املريض نفسيا« اي الذي يتمت ع بالعقلانية الكاملة ولكن ه لا يهت م باهتمامات الانسان لانه يفتقر الي املشاعر ).(Coeckelbergh 2010 لهذه الاسباب ،يمكن ان نرفض فكرة تمت ع الذكاء الاصطناعي بوكالة اخلاقية كاملة موقفا وس طا :يجب ان نمنح الذكاء الاصطناعي نوع ا من رفضا تام ا ،او يمكن ان نت خ ذ القواعد الاخلاقية ،ولكن ليس كل القواعد الاخلاقية .يستخدم وينديل فالاخ وكولني الني مصطلح »القواعد الاخلاقية الوظيفية« ) .(39 ،2009تحتاج انظمة الذكاء الاصطناعي الي بعض القدرة علي تقييم العواقب الاخلاقية لافعالها .واملنطق وراء هذا القرار واضح في حالة السيارات ذاتية القيادة :ستتو رط السيارة علي الارجح في مواقف تتط لب اتخاذ التدخل خيار اخلاقي ولكن لا يوج د وقت للاستعانة بالبشر لاتخاذ القرار او انتظار البشري .وفي بعض الاحيان ،تكون هذه الخيارات عبارة عن معضلة .يتحد ث الفلاسفة عن معضلة عربة الترام ،وهي تجربة فكرية تتعلق بسري عربة ترام علي مسار سكك حديدية ويجب عليك الاختيار بني عدم ف عل اي شيء ،الامر الذي سيود ي الي م وت خمسة اشخاص مسار اخر ،حيث يكون هناك مقي دين باملسار ،او سحب الرافعة وارسال العربة الي تعرفه .ما هو الشيء السليم اخلاقيا الذي يتوج ب شخص واحد مقي د به ولكنه شخص عليك القيام به؟ باملثل ،يقول انصار هذا النهج ان السيارة الذاتية القيادة قد تض ط ر الي اتخاذ خيار اخلاقي ،علي سبيل املثال ،بني قتل املشاة العابرين علي الطريق والاصطدام يجب ان تت خ ذه السيارة؟ يبدو انه بحايط ،مما يودي الي موت السايق .ما الخيار الذي سيتعني علينا اتخاذ هذه القرارات الاخلاقية )م سبقا( والتا كد من تغذية السيارات بها من ق بل ا ملطو رين .او ربما نحتاج الي بناء سيارات مزو دة بالذكاء الاصطناعي تتع لم من اختيارات البشر .ومع ذلك ،قد يثار سوال عما اذا كان اعطاء الذكاء الاصطناعي قواعد هو وسيلة جيدة لتمثيل الاخلاق البشرية ،هذا ان كان من ا ملمكن »تمثيل« الاخلاق من الاساس، واذا كانت معضلة عربة الترام تبني شييا جوهريا في الحياة والتجربة الاخلاقية .او ،من منظور مختلف تمام ا ،يمكن للمرء ان يتساءل عما اذا كان البشر في الواقع قاد رين علي اتخاذ قرارات اخلاقية بكفاءة .وملاذا نقلد اخلاق البشر من الاساس؟ ان مناصري تجاوز باخلاق فايقة لانه الانسانية ،علي سبيل املثال ،ي رون ان الذكاء الاصطناعي سوف يتمتع سيكون اكثر ذكاء من ا. موقف وكالة اخلاقية اخر ،لا يتط لب هذا التشكيك في التركيز علي الانسان يوج هنا الي تمحور حول الانسان .وقد دافع لوتشيانو فلوريدي كاملة ويحاول ترك املوقف الاخلاقي ا مل اهي حقا مجرد الات؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 54, "content": "اخلاق لا عقل لها وغري مستندة الي خصايص يمتلكها وجيه دبليو ساندرز ) (2004عن كاف من التفاعل تعتمد علي التمت ع بمستوي البشر .ويمكننا جعل الوكالة الاخلاقية والاستقلال والقدرة علي التكي ف وكذلك القدرة علي القيام بتصر فات ذات طابع اخلاقي. ووفقا لهذه املعايري ،فان كلب البحث والانقاذ يتمت ع بالوكالة الاخلاقية ،ولكن كذلك روبوت يتولي تصفية الرسايل البريدية غري املرغوب فيها .وبامل ثل ،يمكن الذكاء الاصطناعي الذي تطبيق معايري لا تتمحور حول الانسان ملنح الروبوتات الوكالة الاخلاقية ،كما اقترح جون ستقلا عن ا ملبرمجني ويمكننا تفسري سلوكه سالينز ) :(2006اذا كان الذكاء الاصطناعي م بان نعزو اليه القصد الاخلاقي )مثل قصد فعل الخري او الشر( ،واذا ن م سلوكه عن اخرين ،فان هذا الذكاء الاصطناعي يتمت ع بالوكالة فهم مسيوليته تجاه وكلاء اخلاق ي ني الاخلاقية .ومن ثم ،فان هذه الاراء لا تتط لب الوكالة الاخلاقية الكاملة اذا كان ذلك يعني بطريقة تكون من حيث املبدا الوكالة الاخلاقية البشرية ،ولكنها تع رف الوكالة الاخلاقية ستقلة عن الوكالة الاخلاقية الكاملة للبشر والقدرات البشرية املطلوبة لذلك .ومع ذلك، م هل ستكون مثل هذه الوكالة الاخلاقية الاصطناعية كافية اذا ح ك م عليها وفقا للمعايري الاخلاقية البشرية؟ عمليا ،يكمن القلق ،علي سبيل املثال ،في ان السيارات ذاتية القيادة قد لا تطبق القواعد الاخلاقية الكافية .اما من حيث املبدا ،فيكمن القلق في اننا نبتع د كثريا عن الاخلاق البشرية هنا .ويعتقد الكثريون ان الوكالة الاخلاقية مرتبطة ويجب ان تكون مرتبطة بالانسانية والشخصية .وهولاء لا يميلون الي اعتناق افكار موي دي ما بعد الانسانية او مويدي تجاوز الانسانية. اكتساب املكانة الاخلاقية ثمة موضوع ملكانة اخلاقية .تخي ل اخر مثري للجدل ويتع لق باكتساب الذكاء الاصطناعي ان لدينا ذكاء اصطناعيا فايقا .هل من ا ملقبول اخلاقيا ايقاف تشغيل ه ،او »قتله«؟ واذا كلب الي مزود ما نظرنا عن كثب الي الذكاء الاصطناعي الحالي :هل من املقبول ركل بالذكاء الاصطناعي؟ 1اذا كانت الالات املدعومة بالذكاء الاصطناعي ستكون جزءا من الحياة اليومية ،كما يتوقع العديد من الباحثني ،فان مثل هذه الحالات ستظهر بالضرورة يجب علي البشر التصر ف تجاه هذه الكيانات الاصطناعية .ومع ذلك، وتثري مسالة كيف ليس ع لينا ان نن ظر الي ا ملستقبل البعيد او الي الخيال العلمي .فقد اظهرت الابحاث ان الناس في الوقت الحالي يتعاطفون مع الروبوتات ويترد دون في »قتلها« او »تعذيبها« اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 55, "content": ") ،(Suzuki et al. 2015; Darling, Nandy, and Breazeal 2015حتي اذا لم ت كن مزو دة بالذكاء الاصطناعي .ويبدو ان البشر لا يحتاجون من الكيانات الاصطناعية سوي القليل جدا من اجل اضفاء الانسانية او الشخصية عليهم والتعا طف معهم .فاذا اصبحت هذه الكيانات الان مزود ة بالذكاء الاصطناعي ،مما يجعلها اشبه بالانسان )او بالحيوان(، يبدو ان هذا يجعل مسالة اكساب املكانة الاخلاقية اكثر الحاح ا .علي سبيل املثال ،ماذا ينبغي ان يكون ر د فعلنا تجاه الاشخاص الذين يتعاطفون مع الذكاء الاصطناعي؟ هل هم مخطيون؟ ربما يكون قول ان الالات املدعومة بالذكاء الاصطناعي هي مجرد الات وان الاشخاص ببساطة مخطيون في تقديرهم للامور وفي عواطفهم وتجربتهم الذين يتعاطفون معها الاخلاقية هو الاقرب الي البديهة .اذ يبدو لنا ،عند النظرة الاولي ،اننا لا ندين بشيء اشخاصا .ويفكر الكثري من الباح ثني في مجال الذكاء الي الالات .فهي اشياء ،وليست الاصطناعي بهذا املنطق .علي سبيل املثال ،تري جوانا برايسون ان الروبوتات هي ادوات التزامات تجاهها ) .(Bryson 2010قد يتفق الذين يتبن ون وممتلكات وانه ليس لدينا اي هذا املوقف بشد ة علي انه اذا كان لدي الالات املدعومة بالذكاء الاصطناعي القدرة علي مكانة اخلاقية. الوعي ،ولديها حالات عقلية ،وما الي ذلك ،فاننا مطالبون بان نمنحها يتحقق اليوم .وكما راينا في الفصول السابقة ،قد ولكنهم سيقولون ان هذا الشرط لا يتحقق ابدا؛ ويقول تحقيقه من حيث املبدا ،ولكن اخرون انه يمكن يقول البعض انه لن هذا لن يحدث في املستقبل القريب .ولكن النتيجة املترتبة علي السوال املتعلق باملكانة الاخلاقية هي انه في الوقت الحالي وفي املستقبل القريب ،يفترض ان نتعام ل مع الالات املدعومة بالذكاء الاصطناعي كاشياء ،الا اذا ثبت خلاف ذلك. تواجهنا عند اتخاذ هذا املوقف ،وهي انه علي الرغم من ذلك ،فثم ة مشكلة واحدة لا يفسر ولا يبرر احساسنا البديهي الاخلاقي ولا تجاربنا الاخلاقية التي تخبرنا بان ثم ة شييا خاطيا في »اساءة معاملة« الذكاء الاصطناعي ،حتي اذا لم ت كن لديه خصايص شبيهة بالبشر او الحيوانات مثل الوعي او الاحساس .للعثور علي مثل هذه التبريرات، يمكن للمرء اللجوء الي كانط ،الذي اعتبر انه من الخطا اطلاق النار علي كلب؛ ليس لان التزامات تجاه هذا الكلب ،ولكن لان مثل هذا الشخص كلب ينتهك اي اطلاق النار علي »يضر بصفات الرحمة والانسانية في نفسه ،والتي يجب ان يمارسها بناء علي واجباته بطريقة مختلفة تجاه تجاه البشر« ) .(Kant 1997اما اليوم فنحن نميل الي التفكري اهي حقا مجرد الات؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 56, "content": "الكلاب )علي الرغم من ان هذا ليس حال الجميع وليس الحال في كل مكان( .ولكن يبدو انه يمكن تطبيق الحج ة نفسها علي الالات املدعومة بالذكاء الاصطناعي :يمكننا ان نقول اننا لا ندين بشيء الي الالات املدعومة بالذكاء الاصطناعي ،ولكن نا مع ذلك ينبغي لنا عدم ر كل او »تعذيب« الة مزو دة بالذكاء الاصطناعي؛ لان ذلك يجعلنا غري رحماء ايضا استخدام حج ة اخلاقيات الفضيلة ،وهي ح ج ة غري مباشرة تجاه البشر .يمكن ايضا بالبشر وليس بالذكاء الاصطناعي» :اساءة معاملة« الذكاء الاصطناعي خطا لانها تتع لق ليس لان ثم ة ضر را سيلحق بالذكاء الاصطناعي ،ولكن لان طابعنا الاخلاقي سيتاذ ي اذا اشخاصا افضل .وعلي النقيض من هذا النهج يمكننا ان ما فعلنا ذلك .وهذا لا يجعلنا بقيمة جوهرية نقول انه في ا ملستقبل قد تتمت ع بعض الالات املزو دة بالذكاء الاصطناعي وتستحق اهتمامنا الاخلاقي ،بشرط ان تكون لديها خصايص مثل الاحساس .ولا يبدو »الاخر« من العلاقة الاخلاقية ان النهج غري املباشر للواجب او الفضيلة ياخذ هذا الجانب علي محمل الجد .فهو يعني فقط بالبشر .فماذا عن الالات املزو دة بالذكاء الاصطناعي؟ ولكن هل يمكن للالات املزو دة بالذكاء الاصطناعي او الروبوتات ان تكون هي »الاخر« كما سال ديفيد جنكل )(2018؟ مرة اخري ،يبدو ان املنطق يقول :لا ،الالات املزو دة بالذكاء الاصطناعي ليست لديها الخصايص املطلوبة. »اساءة معاملة« الذكاء الاصطناعي خطا؛ ليس لان ثمة ضر را سيلحق بالذكاء الاصطناعي ،ولكن لان طابعنا الاخلاقي سيتاذ ي اذا ما فعلنا ذلك."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 57, "content": "ثمة نهج مختلف تمام ا يري ان طريقة تعاملنا مع مسالة املكانة الاخلاقية هي نفسها تنطوي علي اشكالية .يعتمد التفكري الاخلاقي الشايع بشان املكانة الاخلاقية علي ما تملكه الكيانات من خصايص ذات صلة بالاخلاق؛ علي سبيل املثال ،الوعي او الاحساس. ولكن كيف نع لم ما اذا كان لدي الذكاء الاصطناعي صلة فعلا خصايص معينة ذات بالاخلاق ام لا؟ وهل نحن متا كدون من ذلك في حالة البشر؟ يقول ا ملتش ككون اننا لسنا مكانة متا كدين .ومع ذلك ،حتي دون هذا اليقني ا ملعرفي ،فاننا لا نزال نضفي علي الانسان اخلاقية علي اساس املظهر .ومن ا ملرج ح ان يحدث الشيء نفسه اذا قد ر للالات املزو دة بمظهر وسلوك شبيه ني بالبشر في املستقبل .يبدو انه بغض بالذكاء الاصطناعي ان تتمت ع اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 58, "content": "النظر عم ا يعتبره الفلاسفة من الصواب اخلاقيا ،سيضفي البشر ،باية حال ،علي هذه حقوقا ،علي سبيل املثال .علاوة علي ذلك ،اذا نظرنا عن الالات مكانة اخلاقية ،ويمنحونها املكانة الاخلاقية »في الواقع« ،فانه يت ضح علي الطريقة ا لتي يضفي بها البشر كثب الي سبيل املثال ان كلا من العلاقات الاجتماعية القايمة وال لغة تلعب دو را .علي سبيل املثال، ري اخلاقي بشان ق اذا عام لنا ق طتنا ،ولكن لان طتنا بلطف ،فهذا ليس لاننا ننخرط في تفك لدينا بالفعل نوع ا من العلاقة الاجتماعية معها .انها بالفعل حيوا ن اليف ومرافق لنا قبل ان نقوم بالعمل الفلسفي الذي ن كسبها بموج به مكانة اخلاقية؛ هذا اذا شعرنا من الاساس خاصا علي كلبنا ،فاننا — علي عكس بحاجة الي مثل هذه املمارسة .واذا اطلقنا اسم ا الحيوانات التي لا خاصة، مكانة اخلاقية تحمل اسم ا التي نا كلها — قد منحناه بالفعل بصرف النظر عن خصايصه املوضوعية .باستخدام مثل هذا النهج العلاقاتي والنقدي وغري ا ملتزم ت ) ،(Coeckelbergh 2012يمكننا القول ان البشر سوف يمنحون الالات مكانة اخلاقية بناء علي كيفية تضمينها في حياتنا الاجتماعية املزو دة بالذكاء الاصطناعي وفي لغتنا وفي ثقافتنا البشرية. علاو ة علي ذلك ،نظ را الي ان مثل هذه الظروف متغرية تاريخيا — فكر مرة اخري في كيفية معاملتنا وتفكرينا بشان الحيوانات — ربما تكون هناك حاجة الي اتخاذ سبل بشكل عام او لالة الحيطة الاخلاقية قبل »تحديد« املكانة الاخلاقية للذكاء الاصطناعي بشكل عام معي نة مزو دة بالذكاء الاصطناعي .وملاذا حتي نتحد ث عن الذكاء الاصطناعي بشكل مجرد؟ يبدو ان هناك شييا خاطيا في الاجراء الاخلاقي ملنح املكانة الاخلاقية: او كيان ما ،نخرج هذا الكيان من سياق علاقاته ،وقبل ان نحصل علي فمن اجل الح كم علي ككيان نتخذ بطريقة رتبوية ،سلطوية ،مهيمنة، نتيجة اجراينا الاخلاقي ،نتعام ل معه نحن البشر ا ملتفو قني قرا را بشانه .ويبدو اننا قبل حتي ان نفكر في مكانته الاخلاقية ،قد منزلة معي نة وربما ككاين نت خذ ايضا ما ر سنا عليه العنف بمعاملته وضعناه بالفعل في ونصبنا انفسنا الهة محورية قوية عاملة علي الارض قرارات بشانه ، يحق لها منح املكانة للكاينات الاخري .لقد جعلنا ايضا جميع السياقات وامللابسات الاجتماعية غري الاخلاقية م ريية .كما في حالة معضلة عربة الترام ،لقد اختزلنا الاخلاق في صورة كاريكاتريية. الفلاسفة املويدون باستخدام مثل هذا التفكري ،يبدو ان فلاسفة الاخلاق يفعلون ما ات هم لدريفوس الباحثني في مجال الذكاء الاصطناعي الرمزي ب فعله :تشكيل وتجريد ثروة من التخلي عما يجعلنا بشرا ،وليس ذلك التجربة الاخلاقية واملعرفة الاخلاقية علي حساب اهي حقا مجرد الات؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 59, "content": "فحسب ،بل وعلي حساب التضحية بمسالة املكانة الاخلاقية لغري البشر .وبصرف النظر عن املكانة الاخلاقية الفعلية للالات املزو دة بالذكاء الاصطناعي ،كما لو كان هذا يمكن بمكان ان نفحص توج هنا بشكل مستقل تمام ا عن ذاتية الانسان ،فمن الاهمية تحديده الاخلاقي ومشروع التفكري الاخلاقي املجرد نفسه ،باسلوب نقدي. »اساءة معاملة« الذكاء الاصطناعي خطا؛ ليس لان ثمة ضر را سيلحق بالذكاء الاصطناعي ،ولكن لان طابعنا الاخلاقي سيتاذ ي اذا ما فعلنا ذلك."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 60, "content": "نحو قضايا اخلاقية اكثر عملية كما تظهر املناقشات في هذا الفصل والفصل السابق ،فان التفكري في الذكاء الاصطناعي يع لمنا اشياء اخري الي جانب ما نتع لمه بشان الذكاء الاصطناعي .انه يعلمنا ايضا اشياء عن انفسنا :عن طريقة تفكرينا ،وطريقة تصر فنا في الواقع ،والطريقة التي ينبغي ان لاخلاقيات الذكاء الاصطناعي، نتعام ل بها مع غري البشر .فاذا نظرنا الي الاسس الفلسفية عميقة حول طبيعة ومستقبل الانسانية والعلم والحداثة .ان التشكيك في نري خلافات الاصطناعي يكشف اللثام عن عا لم مظلم من الاسيلة النقدية حول املعرفة البشرية الذكاء وا ملجتمع البشري وطبيعة الاخلاق البشرية. هذه املناقشات الفلسفية اقل بعدا واقل »اكاديمية« مما قد يعتق د البعض .وستظ ل لاحقا في هذا الكتاب ،املزي د من املسايل الاخلاقية تعاود الظهور امامنا عندما نتناول، عملية التي يثريها الذكاء الاصطناعي .وسرعان ما ستواجهنا والقانونية والسياسية الاكثر موضوعات مثل املسيولية والسيارات ذاتية القيادة، من جدي د بمج رد ان نحاول التط رق الي او شفافية تع لم الالة ،او الذكاء الاصطناعي ا ملتحيز ،او اخلاقيات الروبوتات الجنسية .اذا كانت اخلاقيات الذكاء الاصطناعي تريد ان تكون اكثر من مج رد قايمة بالقضايا ،فيجب ان يكون لديها ما تقوله حول مثل هذه املسايل. بعد ك ل ما قيل ،حان الوقت الان للتحو ل الي قضايا اكثر عملية .هذه القضايا لا تتع لق با ملشكلات الفلسفية التي يطرح ها الذكاء الاصطناعي العام ا ملفترض ،او باملخاطر املت صلة بالذكاء الفايق في املستقبل البعيد ،او بالوحوش املخيفة الاخري التي يخلقها الخيال العلمي .انها تتعلق بحقايق الذكاء الاصطناعي القايمة بالفعل ،والتي هي اق ل اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "أهي حقا مجرد آلات؟", "section_path": ["الفصل الرابع", "أهي حقا مجرد آلات؟"], "page": 61, "content": "وضوح ا وربما اقل جاذبية ،ولكنها لا تزال شديدة الاهمية .ان الذكاء الاصطناعي في الوقت الحالي لا ياخذ دور وحش فرانكنشتاين او الروبوتات ا ملذهلة املزو دة بالذكاء الاصطناعي التي تهد د الحضارة ،كما انه اكثر من مجرد تجرب ة فكرية فلسفية .الذكاء بتقنيات سري ة غري مريية ولكنها متغلغلة ومنتشرة وقوية ومتزايدة الاصطناعي يتع لق الذكاء ،تلك التقنيات التي تش كل بالفعل حياتنا اليوم .ومن ثم ،فان اخلاقيات الذكاء الاصطناعي تتع لق بالتحديات الاخلاقية التي يثريها الذكاء الاصطناعي في الوقت الحالي وفي ا ملستقبل القريب ،كما تتعلق بتاثري هذه التحد يات علي مجتمعاتنا وديمقراطياتنا الهشة. ان اخلاقيات الذكاء الاصطناعي تتع لق بحياة الناس وبالسياسة .انها تتعلق بحاجتنا، كافراد وكمجتمعات ،الي التعامل مع القضايا الاخلاقية الان."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 62, "content": "التكنولوجيا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 63, "content": "قبل مناقشة القضايا الاخلاقية الواقعية ا ملتعلقة بالذكاء الاصطناعي بمزي د من التفاصيل، مهمة اخري علينا انجازها لتمهيد الطريق :بعيدا عن الضج ة ا ملثارة حول لدينا الذكاء الاصطناعي ،علينا ان نفهم هذه التكنولوجيا وتطبيقاتها .فلننح جانبا الخيال العلمي لتجاوز الانسانية والتط لعات الفلسفية للذكاء الاصطناعي العام ،ولن ل ق نظر ة علي ماهية تكنولوجيا الذكاء الاصطناعي وكيفية استخدامها اليوم .وبما ان تعريفات الذكاء الاصطناعي وغريها من ا ملصط لحات هي نفسها غري مت فق عليها ،فانني لن اتعم ق في نقاشات فلسفية او سياقات تاريخية .ان هدفي الرييسي هنا هو ان اعطي القاري فكر ة عن التكنولوجيا املعنية وكيفية استخدامها .وسوف ابدا بالتحد ث عن الذكاء الاصطناعي بشكل عام؛ اما الفصل التالي ،فسيتناول تقنيات تع لم الالة وعلم البيانات وتطبيقاتهما. ما هو الذكاء الاصطناعي؟ يمكن تعريف الذكاء الاصطناعي بانه الذكاء الذي تظهره او تحاكيه الرموز البرمجية سوالا حول كيفية تعريف الذكاء .من )الخوارزميات( او الالات .ويثري هذا التعريف الناحية الفلسفية ،ي غامضا .ويمكن القول بانه ذكاء شبيه بالذكاء عتبر الذكاء مفهوم ا البشري .علي سبيل املثال ،يع رف فيليب جانسن واخرون الذكاء الاصطناعي بانه »علم ذكية وفقا ملعايري الذكاء البشري« )،2018 وهندسة الالات ذات القدرات التي تعتبر .(5 وفقا لهذا التعريف ،يتعلق الذكاء الاصطناعي بانشاء الات ذكي ة تفكر او تتفاعل مثل البشر .ومع ذلك ،يعتقد العديد من الباحثني في مجال الذكاء الاصطناعي انه ليس تعريفا اكثر حيادا ص يغ داع لان يكون الذكاء شبيه ا بالذكاء البشري ،ويفضلون هناك"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 64, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 65, "content": "بشكل مستقل عن الذكاء البشري واهداف الذكاء الاصطناعي العام او القوي ذات الصلة. ويسردون جميع انواع الوظايف املعرفية واملهام مثل التع لم والادراك والتخطيط ومعالجة اللغة الطبيعية والتفكري واتخاذ القرارات وح ل املشكلات؛ وغالبا ما يعادل ذلك الذكاء نفسه .علي سبيل املثال ،تزعم مارجريت بودين ان الذكاء الاصطناعي »يسعي الي جعل اجهزة الكمبيوتر تقوم بالاشياء التي يمكن للعقول البشرية القيام بها« .يبدو الامر في البداية وكان البشر هم النموذج الوحيد .الا انها ،تسرد بعد ذلك كل انواع املهارات النفسية مثل الادراك والتنب و والتخطيط ،التي تشكل جزءا من »الفضاء الغني بقدرات معالجة املعلومات املتنوعة« ) .(1 ،2016ويمكن ان تكون معالجة املعلومات هذه ليست حك را علي الانسان .فالذكاء العام ، وفقا ملارجريت بودين ،لا يكون بالضرورة بشريا .فهناك بعض بعقول مستقبلية لا الحيوانات التي يمكننا اعتبارها ذكية .ويحلم مويدو تجاوز الانسانية تكون مضمنة بيولوجيا مثلما هو الحال الان .ومع ذلك ،كان هدف تحقيق قدرات شبيهة بقدرات البشر وربما ذكاء عام شبيه بذكاء البشر جزءا من الذكاء الاصطناعي منذ البداية. طا يرتبط تاريخ الذكاء الاصطناعي ارتبا والتخصصات وثيقا بتاريخ علوم الكمبيوتر ذات الصلة مثل الرياضيات والفلسفة ،ومن ث م فهو يمت د علي الاقل الي العصور الحديثة الباكرة )مثل جوتفريد فيلهلم لايبنيتس ورينيه ديكارت( ان لم يكن الي العصور القديمة، والات ذكية يمكنها كاينات اصطناعية تنتشر فيها قصص عن حرفي ني يصنعون التي خداع الناس )تذ كر الشخصيات املتحركة في اليونان القديمة او الشخصيات الالية الشبيهة بالبشر في الصني القديمة( .ولكن علي العموم يعتبر الذكاء الاصطناعي قد بدا تخص مستقلا ،بعد اختراع الكمبيوتر صا في الخمسينيات من القرن العشرين بوصفه تخصص علم التح كم الالي الرقمي القابل للبرمجة في اربعيني ات القرن العشرين وولادة )السيبرانية( ،الذي ع رفه نوربرت وينر في عام 1948علي انه الدراسة العلمية »للتح كم والتواصل في الحيوان والالة« ) .(Wiener 1948وكان نشر ورقة الان تورينج البحثية لعام 1950بعنوان »الالات الحاسبة والذكاء« في مجلة »مايند« ،والتي قدمت اختبار بشكل عام سوال ما اذا كانت الالات قادر ة علي تورينج الشهري ولكن كانت تتناول التفكري ،وسبقت بالفعل في التكه ن بالالات التي يمكنها التع لم واداء مهام مج ردة ،كانت لحظة هامة في تاريخ الذكاء الاصطناعي .ومع ذلك ،تعتبر ورشة العمل التي ع قدت في بشكل عام هي محل جامعة دارتموث في صيف عام 1956في هانوفر ،نيو هامبشاير، ميلاد الذكاء الاصطناعي ا ملعاصر .وقد صاغ منظمها جون مكارثي فيها مصطلح الذكاء التكنولوجيا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 66, "content": "الاصطناعي ،وشاركت فيها اسماء مهمة مثل مارفن مينسكي ،وكلود شانون ،والن نيويل، وهريبرت سايمون .وفي حني كان ينظر الي علم التح كم الالي علي انه شديد الانشغال بالالات التناظرية ،اهتم ت ورشة عمل الذكاء الاصطناعي في دارتموث بالالات الرقمية. كانت الفكرة هي »محاكاة« الذكاء البشري )وليس اعادة خلق ه :فالعملية مختلفة عما وظن الكثري من املشاركني في ورشة العمل هذه ان انشاء الة تتمت ع بنفس يحدث في البشر(. جيل واحد. ذكاء البشر امر وشيك الحدوث :توقعوا انها لن تستغرق في ظهورها اكثر من هذا هو هدف »الذكاء الاصطناعي القوي« .الذكاء الاصطناعي »القوي« او »العام« قادر علي اداء اي مهام معرفية يمكن للبشر اداوها ،في حني ان الذكاء الاصطناعي مجالات محددة مثل الشطرنج، »الضعيف« او »املحدود« يمكن ان يودي فقط في وتصنيف الصور ،وما الي ذلك .حتي اليوم ،لم ن حقق الذكاء الاصطناعي العام ،وكما راينا في الفصول السابقة ،فان الشكوك تح وم حول ما اذا كن ا سن حققه علي الاطلاق .وعلي الرغم من ان بعض الباحثني والشركات يحاولون تطوير الذكاء الاصطناعي العام ،ولا سيما هولاء الذين يومنون بنظرية حاسوبية العقل ،فانه لن يتم تطويره في ا ملستقبل القريب .ولذا ،تركز الاسيلة الاخلاقية والسياسية في الفصل التالي علي الذكاء الاصطناعي الضعيف او املحدود ،املوجود بالفعل حاليا والذي من ا ملرج ح ان يصبح اكثر قو ة وانتشا را في املستقبل القريب. يمكن تعريف الذكاء الاصطناعي باعتباره علم ا وكذلك باعتباره تكنولوجيا .يمكن ان يكون الهدف من الذكاء الاصطناعي هو تفسري الذكاء والوظايف املعرفية املذكورة تفسريا علميا ادق .ويمكن ان يساعدنا في فهم البشر وغريهم من الكاينات التي تمتلك ذكاء وتخص صا يدرس طبيعيا فهم ا افضل .وبهذه الطريقة ،يكون الذكاء الاصطناعي علم ا بشكل منهجي ) ،(Jansen et al. 2018واحيانا يدرس العقل او الدماغ. ظاهرة الذكاء ومن هذا املنطلق ،يرتبط الذكاء الاصطناعي بعلو م اخري مثل العلوم املعرفية وعلم النفس وعلم البيانات )انظر القسم اللاحق( ،واحيانا ايضا ع لم الاعصاب ،الذي يسعي حثيثا الي فهم الذكاء الطبيعي .ولكن قد يكون الهدف من الذكاء الاصطناعي ايضا هو تطوير لاغراض عملية مختلفة ،او كما يقول بودن »لانجاز اشياء مفيدة« :يمكن ان ياخذ تقنيات لاغراض عملية .ويمكن شك ل ادوات ،صم مها البشر ،وتخلق مظهر الذكاء والسلوك الذكي للالات املدعومة بالذكاء الاصطناعي ان تفعل ذلك عن طريق تحليل البيية )في صورة بدرجة كبرية من الاستقلالية .في بعض الاحيان ،تلتقي الاهتمامات بيانات( والتصر ف اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 67, "content": "العلمية-النظرية والاغراض التكنولوجية ،علي سبيل املثال في ع لم الاعصاب الحوسبي، مشروعات محددة ادوات من علوم الكمبيوتر لفهم الجهاز العصبي ،او في الذي يستخدم وايضا الروبوتات مثل »مشروع الدماغ البشري« الاوروبي ،الذي يشمل العلوم العصبية والذكاء الاصطناعي؛ وتجمع بعض مشروعاته ما بني ع لم الاعصاب وتع لم الالة فيما يع رف بعلم اعصاب البيانات الضخمة )مثل فو واخرين .(2018 التخصصات ويرتبط بها ،بما بشكل اعم ،يعتمد الذكاء الاصطناعي علي العديد من في ذلك الرياضيات )علي سبيل املثال ،الاحصاء( ،والهندسة ،واللغويات ،والعلوم املعرفية، وعلوم الكمبيوتر ،وعلم النفس ،وحتي الفلسفة .وكما راينا ،يهتم الفلاسفة والباحثون في مجال الذكاء الاصطناعي علي ح د سواء بفهم العقل وظواهر مثل الذكاء والوعي والادراك والفعل والابداع .وقد اث ر الذكاء الاصطناعي علي الفلسفة والعكس صحيح .وقد اق ر كيث فرانكيش وويليام رامزي بهذا الارتباط بني الذكاء الاصطناعي والفلسفة ،وشد دا علي تخصصات الذكاء الاصطناعي ،وجمعا الجانبني العلمي والتكنولوجي في تعريفهما تعد د التخصصات لفهم ونمذجة ومحاكاة الذكاء للذكاء الاصطناعي باعتباره »نهج ا متعد د والعمليات املعرفية عن طريق الاستناد الي مبادي واجهزة حوس بي ة ورياضية ومنطقية وميكانيكية وحتي بيولوجية متنوعة« ) .(1 ،2014لذلك ،يعتبر الذكاء الاصطناعي نظريا وعمليا ،علم ا وتكنولوجيا .ويركز هذا الكتاب علي الذكاء الاصطناعي باعتباره تكنولوجيا، علي الجانب الاكثر عملية :ليس فقط لان التركيز داخل الذكاء الاصطناعي قد تحو ل في هذا الاتجاه ،ولكن ،علي وجه الخصوص ،لان الذكاء الاصطناعي في هذه الصورة له عواقب اخلاقية واجتماعية؛ علي الرغم من ان البحث العلمي ايضا ليس خاليا تمام ا من العواقب الاخلاقية. باعتباره تكنولوجيا ،يمكن للذكاء الاصطناعي ان ياخذ اشكالا مختلفة وعادة ما يكون جزءا من نظم تكنولوجية اكبر :الخوارزميات ،والالات ،والروبوتات ،وما الي ذلك. لذلك ،في حني قد يتع لق الذكاء الاصطناعي ب »الالات« ،فان هذا املصطلح لا يشري الي شكلا بشريا .يمكن ان يضم ن الذكاء الروبوتات وحدها ،ناهيك عن الروبوتات التي تت خ ذ الاصطناعي في العديد من انواع الانظمة والاجهزة التكنولوجية الاخري .ويمكن لانظمة الذكاء الاصطناعي ان برنامج يعمل علي الويب )مثل الدردشة الالية ومحركات تاخذ شك ل البحث وتحليل الصور( ،ولكن يمكن ان يضم ن ايضا الذكاء الاصطناعي في الاجهزة امللموسة مثل الروبوتات او السيارات او تطبيقات »انترنت الاشياء« .بالنسبة الي انترنت التكنولوجيا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 68, "content": "الاشياء ،يستخدم احيانا مصطلح »الانظمة الالكترونية-املادية« ،وهي عبارة عن اجهزة تعمل في العا لم املادي وتتفاعل معه .وتع د الروبوتات نوع ا من الانظمة الالكترونية-املادية، التي توث ر تاثريا مباشرا علي العالم ).(Lin, Abney, and Bekey 2011 اذا ت م تضمني الذكاء الاصطناعي في روبوت ،فانه يطلق عليه احيانا الذكاء »املتجسد« .وتعتمد الروبوتات في تاثريها علي العا لم املادي تاثريا مباشرا الاصطناعي علي مكو نات مادية .ولكن كل نظام ذكاء اصطناعي ،بما في ذلك البرامج النشطة علي الويب» ،يفعل« شييا ولديه ايضا مكو نات مادية مثل الكمبيوتر الذي يعمل عليه ،وا ملكونات املادية للشبكة وال بنية الاساسية التي يعتمد عليها ،وما الي ذلك .وهذا يجعل التفرقة ما بني تطبيقات الويب »الافتراضية« والتطبيقات »البرمجية« من ناحية ،والتطبيقات املادية او مسالة صعبة وم حرية .ان برامج الذكاء الاصطناعي تطبيقات »الاجهزة« من ناحي ة اخري تحتاج الي مكو نات مادية و بنية اساسية مادية لكي تعمل ،والانظمة الالكترونية-املادية لا يمكن اعتبارها ذكاء اصطناعيا الا اذا تم توصيلها بالبرامج املناسبة .علاو ة علي ذلك ،من وجهة نظر الظاهرية ،قد تندمج املكونات املادية والبرمجية احيانا في تجربتنا واستخدامنا شكلا بشريا ويعمل بواسطة للاجهزة :فنحن لا نشعر بان الروبوت التفاع لي الذي ياخذ الذكاء الاصطناعي ،او ان جهاز املحادثة بالذكاء الاصطناعي مثل اليكسا ،عبارة عن مكونات برمجية او مكونات مادية ،ولكننا نشعر انهما جهاز تكنولوجي واحد )واحيانا نشعر انهما شبه اشخاص ،مثل دمية »هالو باربي«(. من ا ملرج ح ان يكون للذكاء الاصطناعي تاثري كبري علي علم الروبوتات ،وذلك علي والتواصل الشبيه بتواصل الانسان. سبيل املثال من خلال التقد م في معالجة اللغة الطبيعية ري من الاحيان يط لق علي هذه الروبوتات اسم »الروبوتات الاجتماعية«؛ لانها مصم مة في كث كرفاق او مساع دين، بهدف املشاركة في الحياة الاجتماعية اليومية للبشر ،علي سبيل املثال، بطريقة طبيعية .ومن ثم ،يمكن ان يعزز الذكاء الاصطناعي من خلال التفاع ل مع البشر مزيدا من التطورات في الروبوتات الاجتماعية. ومع ذلك ،بغض النظر عن املظهر والسلوك الكلي للنظام وتاثريه علي البيية ا ملحيطة به ،وهو ما يعتبر مهم ا جدا من الناحية الظاهرية والاخلاقية ،فان اساس »الذكاء« في الذكاء الاصطناعي هو برنامج» :خوارزمية« او مجموعة من الخوارزميات .والخوارزمية وتسلسل من التعليمات ،مثل الوصفة ،تخبر الكمبيوتر او الهاتف الذكي او هي مجموعة الالة او الروبوت او اي شيء اخر يتم تضمينها فيه بما يجب ان يفعل .وهي تودي الي اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 69, "content": "مشكلة مخرجات معي نة بناء علي املعلومات املتاحة )املدخلات( .وتطب ق الخوارزمية لح ل ما .ولكي نفهم اخلاقيات الذكاء الاصطناعي ،علينا اولا ان نفهم كيفية عمل خوارزميات الذكاء الاصطناعي وما تقوم به .وسوف اتحد ث اكثر عن هذا املوضوع هنا وفي الفصل القادم. املناهج واملجالات الفرعية ا ملختلفة هناك انواع مختلفة من الذكاء الاصطناعي .يمكن القول ايضا ان هناك مناهج او نماذج بحث مختلفة .كما راينا في انتقاد دريفوس ،غالبا ما كان الذكاء الاصطناعي علي مدار التاريخ ذكاء اصطناعيا رمزيا .وكان هذا هو النموذج السايد حتي اواخر الثمانينيات. ويعتمد الذكاء الاصطناعي الرمزي علي التمثيلات الرمزية للمها م املعرفية العالية ا ملستوي مثل التفكري التجريدي واتخاذ القرارات .علي سبيل املثال ،قد يت خ ذ قرا را استنادا الي نموذج للقرارات وعواق بها ا ملمكنة ،ويمث ل الهيكل الشجري لاتخاذ القرار؛ وهو عبارة عن بشكل رسومي يشبه ا ملخطط الانسيابي .وتحتوي الخوارزمية التي تفعل ذلك علي غالبا عبارات شرطية :قواعد لاتخاذ القرار علي صورة ... ،if ... thenبحيث يلي ifالشرط ويلي بيانات تمث ل thenالنتيجة .وهذه العملية حاسمة وغري عشوايية .وبالاستناد الي قاعدة املعرفة الخبرية البشرية ،يمكن مل ثل هذا الذكاء الاصطناعي اتخاذ القرار ،معتمدا علي ك م قرارات حكيمة او يصل هايل من املعلومات ،والتصر ف كنظا م خبري .ويستطيع ان يت خذ الي توصيات استنادا الي كتلة ضخمة من املعرفة ،قد يكون من الصعب او من ا ملستحيل بالنسبة الي البشر الاطلاع عليها .علي سبيل املثال ،تستخدم هذه الانظمة الخبرية في القطاع خطة العلاج .وقد ظ لت هذه الانظمة هي الانجح في مجال الطب ي لتشخيص املرض ووضع الذكاء الاصطناعي لفتر ة طويلة. ولا يزال الذكاء الاصطناعي الرمزي مفيدا حتي اليوم ،ولكن ظهرت ايضا انواع جديدة من الذكاء الاصطناعي ،يمكن دمجها او عدم دمجها مع الذكاء الاصطناعي الرمزي ،وهي قادرة علي التع لم ذاتيا من البيانات ،علي عكس الانظمة الخبرية .ويتم نهج مختلف تمام ا .ويعتمد نموذج البحث »التشابكي« ،الذي تم ذلك من خلال استخدام كبديل ملا اطلق عليه اسم »الذكاء الاصطناعي تطويره في الثمانينيات من القرن العشرين القديم« ويعرف اختصا را ب ،GOFAIوتكنولوجيا »الشبكات العصبية« علي فكرة اننا بدلا التكنولوجيا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 70, "content": "وحدات من تمثيل الوظايف املعرفية الع ليا ،يجب علينا بناء شبكات مترابطة بالاستناد الي بسيطة .ويدعي مويدو هذا النهج ان هذا يشبه الطريقة التي يعمل بها الدماغ البشري؛ وحدات املعالجة البسيطة ا ملسم اة »الخلايا العصبية« اذ ينشا الادراك من تفاع لات بني )ومع ذلك ،فهي لا تشبه الخلايا العصبية البيولوجية( .ويستخدم العديد من الخلايا العصبية ا ملترا بطة .يستخدم هذا النهج وهذه التكنولوجيا كثريا في »تع لم الالة« )انظر الفصل التالي( ،والذي يطلق عليه بعد ذلك »التع لم العميق« اذا كانت الشبكات العصبية طبقات من الخلايا العصبية .وت عتبر بعض الانظمة هجينة؛ علي سبيل تتكو ن من عدة املثال ،ي عتبر »الفا جو« الذي ط و رته شركة »ديب مايند« نظام ا هجينا .وقد اد ي التع لم العميق الي حدوث تطو ر في مجالات مثل روية الالة ومعالجة اللغة الطبيعية .ويمكن ان يكون تع لم الالة الذي يستخدم شبكة محايدة بمنزلة »صندوق اسود«؛ بمعني انه في حني ان ا ملبرمجني يعرفون تصميم الشبكة ،فانه ليس واضح ا للاخرين ماذا يحدث بالضبط في طبقاتها الوسيطة )بني املدخلات واملخرجات( وبالتالي كيف تت خ ذ قرا را .وهذا عكس وقابلا للتفسري ،ومن ثم ما يحدث في الهيكل الشجري لاتخاذ القرار ،الذي يكون واضح ا فحصه وتقييمه من ق بل البشر. يمكن ثم ة نموذج مهم اخر في مجال الذكاء الاصطناعي وهو ذلك الذي يستخدم مناهج اكثر تجسيدية واكثر اعتمادا علي املواقف ،مرك زا علي التفاع ل واملهام الحركية بدلا مما نطلق عليه املهام املعرفية الع ليا .والروبوتات التي صنعها باحثون في مجال الذكاء الاصطناعي تمثيلات رمزية ولكن مثل رودني بروكس من »ام اي تي« لا تح ل املشكلات باستخدام عن طريق التفاع ل مع البيية ا ملحيطة .علي سبيل املثال ، صم م الروبوت »كوج« الشبيه بالبشر ،الذي ت م تطويره في التسعينيات من القرن العشرين ،بحيث يتع لم من خلال التفاعل مع العالم ،كما يفعل الاطفال .وعلاو ة علي ذلك ،يعتقد بعض الاشخاص ان العقل يمكن ان ينشا فقط من الحياة؛ وبالتالي ،لانشاء الذكاء الاصطناعي ،يجب ان نحاول انشاء حيا ة اصطناعية .ويتبع بعض املهندسني نهج ا اق ل ميتافيزيقية واكثر عملية؛ اذ تطبيقات تكنولوجية عملية .وهناك ايضا الات تطو رية ياخذون الاحياء نموذج ا لتطوير مزودة بالذكاء الاصطناعي تستطيع ان تتطو ر .ويمكن لبعض البرامج ،باستخدام ما يسم ي بخوارزميات الوراثة ،تغيري نفسها. هذا التن وع في مناهج الذكاء الاصطناعي ووظايفه يشري الي ان الذكاء الاصطناعي اليوم له العديد من املجالات الفرعية :تع لم الالة ،وروية الكمبيوتر ،ومعالجة اللغة اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 71, "content": "الطبيعية ،والانظمة الخبرية ،والحوسبة التطو رية ،وهل م ج را .وغالبا ما يكون التركيز مجال واحد من مجالات الذكاء الاصطناعي، اليوم علي تع لم الالة ،ولكن هذا ليس سوي حتي وان كانت هذه املجالات الاخري م تصلة غالبا بتع لم الالة .وقد تم تحقيق تطورات هايلة موخ را في روية الكمبيوتر ومعالجة اللغة الطبيعية وتحليل البيانات الضخمة عن طريق تع لم الالة .علي سبيل املثال ،يمكن استخدام تع لم الالة ملعالجة اللغة الطبيعية استنادا الي تحليل الكلام واملصادر املكتوبة مثل النصوص املوجودة علي الانترنت .وقد اثمر هذا العمل عن انشاء اجهزة املحادثة الحديثة .مثال اخر هو التع رف علي الوجوه استنادا الي روية الكمبيوتر والتع لم العميق ،ويمكن استخدامه ،علي سبيل املثال ،في مجال املراقبة. التطبيقات والتاثري مجالات مختلفة )لها تطبيقات متنوعة(، يمكن تطبيق تكنولوجيا الذكاء الاصطناعي في تتراوح ما بني التصنيع والزراعة والنقل ،والرعاية الصحية والتمويل والتسويق والجنس التواصل الاجتماعي .في مجال البيع بالتجزية والتسويق، والترفيه والتعليم ووسايل اعلانات مستهدفة .اما في تستخدم انظمة التوصية للتاثري في قرارات الشراء ولتقديم يشغل الذكاء الاصطناعي الروبوتات :وهي التواصل الاجتماعي ،يمكن ان مجال وسايل اشخاص حقيقيون ولكنها في الواقع حسابات مستخدمني تظهر علي انها عبارة عن برامج .ويمكن مل ثل هذه الروبوتات ان تنشر محتوي سياسيا او تجري دردشة مع مستخدمني من البشر .وفي مجال الرعاية الصحية ،يستخدم الذكاء الاصطناعي لتحليل بيانات من ملايني املرضي .وما زالت الانظمة الخبرية تستخدم ايضا في هذا املجال. مجموعات ضخمة من البيانات في مجال التمويل ،يستخدم الذكاء الاصطناعي لتحليل لتحليل السوق واتم ت ة التعاملات املالية .وغالبا ما يتم تضمني نوع من الذكاء الاصطناعي مرافقا للانسان .والطيار الالي والسيارات ذاتية القيادة في الروبوتات ا ملصم مة لتكون تستخدم الذكاء الاصطناعي .ويمكن لاصحاب العمل استخدام الذكاء الاصطناعي ملراقبة شخصيات مدعومة بالذكاء الاصطناعي. املوظفني .كما ان العاب الفيديو تحتوي علي وتستطيع الالات املزو دة بالذكاء الاصطناعي تاليف املوسيقي او كتابة مقالات الاخبار. كما تستطيع تقلي د اصوات الاشخاص وحتي انشاء مقاطع فيديو مزيفة لخطابات. التكنولوجيا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 72, "content": "نظ را الي تنو ع تطبيقات الذكاء الاصطناعي ،من ا ملرج ح ان يكون له تاثري واسع النطاق ،سواء اليوم او في ا ملستقبل القريب .فاذا ف ك رنا مثلا في الشرطة التنب وية وامكانية التع رف علي الكلام ،اللذين يخلقان امكانيات جديدة للامان واملراقبة ،ووسايل النقل بني مدن باكملها ،والتداول الافراد والسيارات ذاتية القيادة التي يمكن ان تحدث تحو لا في الخوارزمي العالي الترد د الذي يش كل بالفعل الاسواق املالية ،او التطبيقات التشخيصية في القطاع الطبي التي توثر في اتخاذ القرارات السليمة .يجب ايضا الا ننسي العلوم كاحد املجالات الرييسية التي تاث رت الي ح د كبري بالذكاء الاصطناعي :عن طريق تحليل مجموعات ضخمة من البيانات ،يمكن للذكاء الاصطناعي مساعدة العلماء في اكتشاف ارتباطات لم يكونوا ليدركوها لولاه .وهذا ينطبق علي العلوم الطبيعية مثل الفيزياء ،ولكن ايضا علي العلوم الاجتماعية والعلوم الانسانية .ومن ا ملو كد ان يوثر الذكاء الاصطناعي في مجال العلوم الانسانية الرقمية الناشي ،علي سبيل املثال ،عن طريق تعليمنا املزيد عن البشر وعن ا ملجتمعات البشرية. يوثر الذكاء الاصطناعي ايضا علي العلاقات الاجتماعية ،كما ان له تاثريا اجتماعيا واقتصاديا وبيييا اوسع ) .(Jansen et al. 2018ومن ا ملرج ح ان يشكل الذكاء الاصطناعي التفاعلات البشرية ويوثر علي الخصوصية .ويقال انه قد يزيد من التحي ز والتمييز .ومن املتوقع ان يودي الي فقدان الوظايف وربما الي احداث تحو ل اقتصادي كامل .فمن ا ملمكن معجلا الظلم ان يزيد الفجوة بني الاغنياء والفقراء وبني اصحاب النفوذ وا ملستضع فني، والتفاوت الاجتماعي .اما التطبيقات العسكرية ،فقد ت غري الطريقة التي يتم بها تنفيذ يجب ان الحروب ،علي سبيل املثال ،عند استخدام الاسلحة القاتلة ذاتية التشغيل .كذلك ناخذ في اعتبارنا التاثري البييي للذكاء الاصطناعي ،والذي يشمل زيادة استهلاك الطاقة لاحقا بعض الاثار الاخلاقية والاجتماعية بمزي د من التفصيل، والتلو ث .وسوف اناقش مرك زا علي مشكلات الذكاء الاصطناعي وم خاطره .ولكن يمكن ان يكون للذكاء الاصطناعي ايضا اثار ايجابية؛ علي سبيل املثال ،يمكن ان يخلق مجتمعات جديدة عن طريق وسايل التواصل الاجتماعي ،ويق لل املهام املتك ررة والخطرية عن طريق تكليف الروبوتات بها، وي حسن سلاسل الامداد ،ويق لل استهلاك املياه ،وهكذا. فيما يتع لق بالتاثري — ايجابي او سلبي — يجب الا نسال فقط عن طبيعة التاثري ومداه؛ بل ان نسال ايضا »م ن« هم املتاثرون وكيف سيتاث رون .قد يكون التاثري اكثر ايجابية بالنسبة الي البعض منه بالنسبة الي الاخرين .فهناك العديد من الاطراف ا ملعنية، اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 73, "content": "بدءا من العمال واملرضي وا ملستهلكني ،الي الحكومات وا ملستثمرين والشركات ،وجميعهم قد يتاثرون بط رق مختلفة .وتنشا هذه الاختلافات في املكاسب والخساير من تاثريات الذكاء الاصطناعي ليس فقط داخل البلدان ولكن ايضا بني البلدان واجزاء العا لم .فهل سيعود الذكاء الاصطناعي بالن فع علي البلدان املتقد مة وا ملتطورة في املقام الاول؟ وهل من ا ملمكن ان يكون مفيدا ايضا للاشخاص ذوي التعليم ا ملنخف ض والدخل ا ملنخفض، علي سبيل املثال؟ م ن ستكون لديه القدرة علي الوصول الي التكنولوجيا ويكون قاد را علي جني فوايدها؟ م ن سيتمكن من تمكني نفسه باستخدام الذكاء الاصطناعي؟ وم ن سيكون مستبعدا من هذه الفوايد؟ م ن ستكون لديه القدرة علي الوصول الي التكنولوجيا ويكون قاد را علي جني فوايدها؟ م ن سيتم كن من تمكني نفسه باستخدام الذكاء الاصطناعي؟ وم ن سيكون مستبعدا من هذه الفوايد؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 74, "content": "الذكاء الاصطناعي ليس التكنولوجيا الرقمية الوحيدة التي تثري مثل هذه الاسيلة. فهناك تقنيات رقمية اخري خاصة باملعلومات والاتصالات ،وهي ايضا توثر تاثريا كبريا علي حياتنا ومجتمعاتنا .وكما سنري ،بعض املشكلات الاخلاقية التي يثريها الذكاء الاصطناعي ليست حك را علي الذكاء الاصطناعي وحده .علي سبيل املثال ،هناك مشكلات موازية في تكنولوجيا الاجهزة الذاتية التشغيل .تذ كر مثلا الروبوتات الصناعية التي تم ت برمجتها ولا ت عتبر ذكاء اصطناعيا ،ولكنها لا تزال لها تاثريات اجتماعية عندما تودي الي البطالة .وبعض مشكلات الذكاء الاصطناعي مرتبطة بالتقنيات التي يت صل بها الذكاء بتحديات جديدة التواصل الاجتماعي والانترنت ،التي تواجهنا الاصطناعي ،مثل وسايل منصات عندما يتم دمج ها مع الذكاء الاصطناعي .علي سبيل املثال ،عندما تستخدم لتعرف املزيد عن مستخدميها، التواصل الاجتماعي مثل »فيسبوك« الذكاء الاصطناعي فان هذا يثري مخاوف تتع لق بالخصوصية. هذا الاتصال مع التقنيات الاخري يعني ايضا ان الذكاء الاصطناعي يكون غري ملحوظ في كثري من الاحيان .ويرجع هذا في املقام الاول الي كونه اصبح بالفعل جزءا لا يتجزا من حياتنا اليومية .فالذكاء الاصطناعي كثريا ما يستخدم في تطبيقات جديدة يجب الا ننسي الذكاء الاصطناعي الذي يشغل بالفعل ومذهلة مثل »الفا جو« .ولكننا التواصل الاجتماعي ،ومحركات البحث ،وغريها من الوسايط والتقنيات التي منصات التكنولوجيا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 75, "content": "اضحت جزءا من تجربتنا اليومية .ان الذكاء الاصطناعي م توغل في كل شيء .ويمكن غامضا، واشكال اخري من التكنولوجيا ان يكون الفارق بني الذكاء الاصطناعي الفعلي مم ا يجعل الذكاء الاصطناعي غري مريي :اذا تم تضمني انظمة الذكاء الاصطناعي في نعرف بالفعل انه مضم ن ،فانه من الصعب التكنولوجيا ،فاننا عاد ة لا نلاحظها .واذا كنا ان نقول ما اذا كان الذكاء الاصطناعي هو الذي يسب ب املشكلة او التاثري ،او اذا كانت التكنولوجيا الاخري ا ملت صلة به هي املسيولة عن ذلك .بعبارة اخري ،لا يوجد »ذكاء اصطناعي« في ح د ذاته :فالذكاء الاصطناعي يعتمد دايم ا علي تقنيات اخري ويتم تضمينه في ممارسات واجراءات علمية وتكنولوجية اوسع .وفي حني ان الذكاء الاصطناعي ايضا مشكلات اخلاقية خاصة به ،فان »اخلاقيات الذكاء الاصطناعي« تحتاج الي ان يثري تكون مرتبطة بالاخلاقيات العامة للمعلومات الرقمية وتكنولوجيا الاتصالات ،واخلاقيات الكمبيوتر ،وما الي ذلك. يجب الا ننسي الذكاء الاصطناعي الذي يشغل بالفعل منصات التواصل الاجتماعي ،ومحركات البحث، وغريها من الوسايط والتقنيات التي اضحت جزءا من تجربتنا اليومية .ان الذكاء الاصطناعي م توغل في ك ل شيء."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 76, "content": "ثم ة منطق اخر يوكد انه لا يوجد شيء يعرف باسم الذكاء الاصطناعي في ح د ذاته، وهو ان التكنولوجيا اجتماعية وانسانية :فالذكاء الاصطناعي لا يتعلق ايضا دايم ا ما تكون فقط بالتكنولوجيا ولكن ايضا بما يفعله البشر بها ،وكيف يستخدمونها ،وكيف يدركونها بييات اجتماعية وتقنية اوسع .وهذا امر مهم للاخلاقيات ويعيشونها ،وكيف يضم نونها في ايضا بقرارات الانسان — ويعني — التي تتعلق منظور تاريخي ايضا انه يجب تضمني واجتماعي ثقافي .الضجة الاعلامية املثارة حاليا حول الذكاء الاصطناعي ليست الضج ة الاولي التي تثار حول التقنيات املتقدمة .قبل الذكاء الاصطناعي ،كانت »الروبوتات« او »الالات« هي الكلمات الرييسية .كما شهدت تقنيات متقدمة اخري مثل التكنولوجيا النووية ،وتكنولوجيا النانو ،والانترنت ،والتكنولوجيا الحيوية الكثري من الجدل .ومن ا ملفيد ان نضع ذلك في اعتبارنا خلال مناقشاتنا حول اخلاقيات الذكاء الاصطناعي؛ اذ ربما يمكننا ان نستفيد من هذه النقاشات والجدالات .ان استخدام التكنولوجيا وتطويرها اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التكنولوجيا", "section_path": ["الفصل الخامس", "التكنولوجيا"], "page": 77, "content": "يحدث في سياق اجتماعي .وكما يع لم الاشخاص ا ملهتمون بتقييم التكنولوجيا ،عندما تكون التكنولوجيا جديدة ،يميل الناس الي ان يثريوا حولها الكثري من الجدل ،ولكن بمجرد ان تصبح جزءا من الحياة اليومية ،تنخف ض الضجة ا ملثارة حولها والجدل بشانها بشكل كبري .ومن ا ملرجح ان يحدث هذا ايضا مع الذكاء الاصطناعي .وفي حني ان مثل التوقع ليس سببا وجيه ا لترك مهمة تقييم الجوانب الاخلاقية والعواقب الاجتماعية هذا للذكاء الاصطناعي ،فانه يساعدنا في روية الذكاء الاصطناعي في سياقه ،ومن ث م يساعدنا في نحو افضل. فهمه علي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 78, "content": "تع لم الالة بما ان العديد من الاسيلة الاخلاقية حول الذكاء الاصطناعي تتعلق بتقنيات تعتمد كليا او جزييا علي تع لم الالة وعلم البيانات ذي الصلة ،فانه يجدر بنا ان نلقي الضوء علي هذه التقنية والعلم. يشري »تع لم الالة« الي البرامج التي يمكنها »التع لم« .واملصطلح مثري للجدل :فالبعض يقولون ان ما تقوم به ليس تع لم ا حقيقيا لانها لا تتمت ع بادراك حقيقي؛ والتع لم مقصور علي ضييلا او منعدم ا مع البشر فحسب .علي اي حال ،يحمل تع لم الالة الحديث »تشابه ا ما قد يحدث في عقول البشر« ) .(Boden 2016, 46وهو يعتمد علي الاحصاءات؛ اذ انه عملية احصايية .ويمكن استخدامه ملها م متنوعة ،ولكن املهمة الاساسية غالبا ما تكون هي التع رف علي الانماط .ويمكن للخوارزميات التع رف علي الانماط او القواعد املوجودة وتوقع البيانات ا ملستقبلية. في البيانات واستخدام تلك الانماط او القواعد لتفسري البيانات تعليمات وقواعد مباشرة يعطيها املبرمج. يحدث ذلك ذاتيا؛ بمعني انه يحدث دون تعتمد علي خبراء بشريني في املجال يشرحون القواعد وعلي عكس الانظمة الخبرية التي للمبرمجني الذين يتو لون بعد ذلك برمجة هذه القواعد ،تبحث خوارزمية تع لم الالة عن انماط لم يحد دها املبرمج .كل ما عليك هو تحديد الهدف او املهمة فقط .وسوف قواعد او يستطيع البرنامج ان يكي ف سلو كه بما يتوافق مع متطلبات املهمة .علي سبيل املثال، يمكن لتع لم الالة املساعدة في التمييز بني البريد الالكتروني العشوايي غري املرغوب فيه عتبر عشواييا .مثال والبريد ا ملهم من خلال فحص عدد كبري من الرسايل وتع لم ما ي اخر:"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 79, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 80, "content": "مجموعة من لانشاء خوارزمية تتع رف علي صور القطط ،لا يقد م املبرمجون للكمبيوتر خاص بها نموذج القواعد تع رف فيها ما هي القطط ،ولكنهم يتيحون للخوارزمية انشاء حسن الخوارزمية من ادايها ذاتيا لتحقيق اعلي لصور القطط .وت دقة تنبو بالاستناد الي مجموعة من صور القطط وغري القطط .وبالتالي ،تهدف الي تع لم ما هي صور القطط. بتعليمات او قواعد محددة. ويقد م البشر تقارير ،ولكنهم لا يغذ ونها نظريات لتفسري البيانات والتنب و بها؛ في حني ينشي كان العلماء في السابق ينشيون الكمبيوتر في تع لم الالة نماذج خاصة به تتناسب مع البيانات .اذن فنقطة البداية هي البيانات ،وليس النظريات .ومن هذا ا ملنطلق ،لم تع د البيانات »سلبية« بل »نشطة«: »فالبيانات نفسها هي التي تحد د ما يجب القيام به بعد ذلك« )Alpaydin 2016, .(11يد رب الباحثون الخوارزمية باستخدام مجموعات البيانات املوجودة )علي سبيل املثال ،رسايل البريد الالكتروني القديمة( ،وعندي ذ تستطيع الخوارزمية التنب و بالنتايج من البيانات الجديدة )علي سبيل املثال ،البريد الالكتروني الوارد الجديد( ) .(CDT 2018يشار كميات كبرية من املعلومات )البيانات الضخمة( باسم احيانا الي التع رف علي الانماط في »التنقيب عن البيانات« ،تشبيه ا له باستخراج املعادن القي مة من الارض .ومع ذلك ،فان انماط من البيانات ،وتحليل البيانات ،وليس املصطلح مض لل لان الهدف هو استخراج استخراج البيانات نفسها. متغري م عني يمكن ان يكون تع لم الالة »موج ه ا« ،مما يعني ان الخوارزمية تر كز علي يع رف باسم هدف التنبو .علي سبيل املثال ،اذا كان الهدف هو تقسيم الاشخاص الي فيتني )علي سبيل املثال ،خطورة امنية عالية او منخفضة( ،فان ا ملتغريات التي تتنبا بهاتني الفيتني معروفة بالفعل ،وبالتالي تتع لم الخوارزمية التنب و بالانتماء الي احدي الفيتني )الخطورة الامنية العالية او الخطورة الامنية املنخفضة( .يد رب املبرمج النظام عن طريق توفري امثلة وغريها ،علي سبيل املثال ،صور للاشخاص الذين يش كلون خطورة امنية عالية وامثلة للاشخاص الذين لا يشكلون خطورة امنية .يكون الهدف ان يتع لم النظام التنب و بم ن ينتمي الي كل فية ،اي م ن يشكل خطور ة امنية عالية وم ن لا يشكل بناء علي البيانات الجديدة .اذا ا عطي النظام ما يكفي من الامثلة ،فانه سيكون قاد را علي التعميم لراكب يم ر من هذه الامثلة ومعرفة كيفية تصنيف البيانات الجديدة ،مثل صور ة جديدة ع بر امن املطار .اما تع لم الالة »غري ا ملوج ه« فيعني عدم تقديم هذا النوع من التدريب، خاصة بها .علي سبيل املثال، فيات وان الفيات غري معروفة :ومن ثم تنشي الخوارزميات لا تنس )علم( البيانات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 81, "content": "خاصة به استنادا الي ا ملتغريات التي يحددها؛ لا امنية فيات ينشي الذكاء الاصطناعي انماط لم يحد دها خبراء التي يقدمها اليه املبرمج .وربما يعثر الذكاء الاصطناعي علي املجال )في هذا السياق :الخبراء الامنيون( .ويمكن ان تبدو الفيات التي انشاها الذكاء الاصطناعي من منظور البشر عشوايية للغاية .وربما لا يكون لها معني .ولكنها موجودة من الناحية الاحصايية .وفي بعض الاحيان يكون لها معني ،وفي هذه الحالة يمكن لهذه معرفة جديدة حول الفيات في العالم الواقعي .اما التع لم »ا ملع زز«، الطريقة ان تعطينا فانه يتطلب تقييم ا للمخرجات ان كانت جيدة ام سيية .وهذا يشبه فكرة الثواب والعقاب. خبر اي الاجراءات يجب ان ي فالبرنامج لا ي تخذ ،ولكنه »يتعلم« من خلال عملية تكرارية اي الاجراءات التي تودي الي الثواب .ففي املثال الامني السابق ،يتلقي النظام تقري را )او بعمل جيد عندما يجري بيانات( من الخبراء الام ني ني بحيث »يعرف« ما اذا كان قد قام تنب وا معينا .فاذا لم يسبب الشخص الذي تنبا النظام بانه ذو خطورة امنية منخفضة مشكلات امنية ،فان النظام يتلقي تقري را بان مخرجاته كانت جيدة ومن ثم »يتعلم« اي دقيقا بنسبة 100في نسبة من الخطا :فالنظام ليس منه .يجب ملاحظة ان هناك دايم ا املاية .يجب ايضا ملاحظة ان ا ملصط لح ني الفن ي ني »موج ه« و»غري موج ه« لا علاقة لهما التدخل البشري في استخدام التكنولوجيا :ففي حني ان الخوارزمية تتمت ع ببعض بمدي بطرق مختلفة. يتدخلون الاستقلالية ،فان البشر في جميع انواع تع لم الالة هذا صحيح يخص البيانات في مجال الذكاء الاصطناعي ،بما في ذلك ايضا فيما ما يسم ي ب »البيانات الضخمة« .اكتسب تع لم الالة القايم علي البيانات الضخمة الكثري من الاهتمام بسبب توفر كميات كبرية من البيانات وزيادة قدرة الكمبيوتر )الارخص(. يتحد ث بعض الباحثني عن »زلزال البيانات« ) .(Alpaydin 2016, xنحن جميع ا ننتج بيانات من خلال انشطتنا الرقمية ،مثلما يحدث علي سبيل املثال عندما نستخدم وسايل منتجات عبر الانترنت .هذه البيانات مهمة بالنسبة التواصل الاجتماعي او عندما نشتري وايضا بالنسبة الي الحكومات والعلماء .لقد صار جمع البيانات الي الجهات التجارية وتخزينها ومعالجتها اسهل بكثري علي املوسسات ).(Kelleher and Tierney 2018 وليس ذلك بسبب تع لم الالة فقط :فالبيية الرقمية الاوسع وتقنيات الوسايط الرقمية التواصل الاخري تلعب دو را مهم ا في هذا الصدد .اذ تيسر التطبيقات عبر الانترنت ووسايل الاجتماعي جمع البيانات من الافراد .كما ان تخزين البيانات اصبح اق ل تكلفة ،واصبحت اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 82, "content": "بشكل امكانيات اكبر .كل هذا كان مهم ا لتطوير الذكاء الاصطناعي اجهزة الكمبيوتر ذات عام ،وعلم البيانات بشكل خاص. علم البيانات نستنتج مما سبق ان تع لم الالة يرتبط ب »علم البيانات« .اذ يهدف علم البيانات الي انماط مفيدة وذات معني من مجموعات البيانات ،وفي الوقت الحالي هذه استخراج املجموعات كبرية جدا .يستطيع تع لم الالة تحليل هذه املجموعات الكبرية من البيانات اليا. ويعتمد تع لم الالة وعلم البيانات علي الاحصاءات ،او علي الانتقال من امللاحظات الفردية ارتباطات في البيانات من خلال توصيفات عامة .فعلماء الاحصاء يهتم ون بالعثور علي الي التحليل الاحصايي .وتبحث عمليات انشاء النماذج الاحصايية عن العلاقات الرياضية بني املدخلات واملخرجات .وهذا هو ما تساعد فيه خوارزميات تع لم الالة. نحن جميع ا ننتج بيانات من خلال انشطتنا الرقمية ،كما يحدث علي سبيل املثال عندما نستخدم التواصل الاجتماعي او عندما نشتري منتجات عبر الانترنت. وسايل"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 83, "content": "ولكن علم البيانات ينطوي علي اكثر من مجرد تحليل البيانات بواسطة تع لم الالة .اذ يجب جمع البيانات واعدادها قبل تحليلها ،وبعد ذلك يجب تفسري نتايج التحليل .وينطوي علم البيانات علي تحد يات مثل كيفية الحصول علي البيانات وتنقيتها )علي سبيل املثال، من وسايل التواصل الاجتماعي والويب( ،وكيفية الوصول الي كمي ة كافية من البيانات، وكيفية جمع مجموعات البيانات مع ا ،وكيفية اعادة هيكلة مجموعات البيانات ،وكيفية اختيار مجموعات البيانات ذات الصلة ،واي نوع من البيانات يتم استخدامه .لذلك لا يزال البشر يلعبون دو را مهم ا في جميع املراحل وفيما يتعلق بجميع هذه الجوانب ،بما في ذلك صياغة املشكلة ،والحصول علي البيانات ،واعداد البيانات )مجموعة البيانات التي تتد رب عليها الخوارزمية ومجموعة البيانات التي ستطبق عليها( ،وانشاء خوارزمية التع لم او اختيارها ،وتفسري النتايج ،واتخاذ قرار حول الاجراء الذي يجب اتخاذه )Kelleher and"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 84, "content": ".(Tierney 2018 لا تنس )علم( البيانات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 85, "content": "تظهر التحد يات العلمية في كل مرحلة من هذه العملية ،وعلي الرغم من ان البرامج قد تكون سهلة الاستخدام ،فان مواجهة هذه التحديات تتط لب وجود املعرفة البشرية تخصصة .وعاد ة ما يكون التعاون بني البشر ام را ضروريا الخبرية ا مل ايضا ،علي سبيل املثال ،بني علماء البيانات واملهندسني .ومن الوارد حدوث اخطاء طوال الوقت ،لذا فان الاختيار البشري واملعرفة البشرية والتفسري البشري امر حاسم الاهمية .فالبشر مهم ون في نحو معقول وتوجيه التكنولوجيا نحو البحث عن عوامل هذا السياق لتفسري الامور علي وعلاقات مختلفة .والذكاء الاصطناعي ،من وجهة نظر بودن ) ،(2016يفتقر الي فهمنا للصلات والعلاقات .ويمكننا ان نضيف انه يفتقر ايضا الي الفهم والتجربة والحساسية والحكمة .وهذه حجة جيدة تدعم نظريا ومبدييا ضرورة مشاركتنا نحن البشر في الامر .ولكن ثمة حجة عملية ايضا تدعم عدم خروج البشر من املشهد؛ وهي ان البشر يشاركون بالفعل عمليا في الامر .فدون املبرمجني وعلماء البيانات ،لن تستطيع التكنولوجيا القيام بوظيفتها ببساطة .علاو ة علي ذلك ،كثريا ما يتم دمج الخبرة البشرية مع الذكاء الاصطناعي ،علي سبيل املثال ،عندما يستخدم الطبيب استراتيجية علاج سرطان يوصي بها الذكاء الاصطناعي ،ولكنه في الوقت نفسه يعتمد علي تجاربه وحدسه كخبري .فاذا الغي التدخل البشري ،يمكن ان تسوء الامور او تفقد معناها او ببساطة تصبح غري منطقية. ولنضرب مثلا باملشكلة املعروفة التالية من الاحصاء ،والتي توثر بدورها علي علاقات سببية .يقدم تايلر فيجني في استخدام تع لم الالة :الارتباطات لا تعني بالضرورة كتابه »الارتباطات الزايفة« ) (2015بعض الامثلة الجيدة علي ذلك .في الاحصاء ،الارتباط بعلاقات سببية الزايف هو الارتباط الذي تكون فيه ا ملتغريات غري مرتبطة فيما بينها عامل ثالث غري مريي .من بني ولكنها قد تبدو كذلك؛ ويكون الارتباط ناجم ا عن وجود الامثلة التي يقد مها فيجني الارتباط بني معدل الطلاق في ولاية مني ومعدل استهلاك السمن النباتي للفرد الواحد ،او الارتباط بني معدل استهلاك جبن املوتزاريلا للفرد الواحد والحصول علي دكتوراه في الهندسة ا ملدنية 1 .ربما يعثر الذكاء الاصطناعي علي مثل هذه تستحق مزيدا من يتدخل البشر لتقرير الارتباطات التي الارتباطات ،ولكن يجب ان علاقات سببية. الدراسة من اجل العثور علي فضلا عن ذلك ،في املرحلة التي يتم فيها جمع البيانات وتصميم او انشاء مجموعة يخص كيفية التجريد عن الواقع )Kelleher and Tierney اختيارات فيما البيانات ،نجري .(2018والتجريد عن الواقع لا يكون محايدا ابدا ،والتجريد نفسه ليس واقع ا؛ وانما هو اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 86, "content": "تمثيل للواقع .وهذا يعني انه يمكننا مناقشة مدي جودة هذا التمثيل وملاءمته ،فيما يتعلق بغ رض معني .قارن هذا باية خريطة :الخريطة نفسها ليست هي الاقليم ،وقد اختار البشر طريقة تصميم الخريطة لغ ر ض معني )علي سبيل املثال ،خريطة مللاحة السيارات مقابل خريطة طوبوغرافية للتن زه سريا علي الاقدام( .في تع لم الالة ،يعمل التجريد باستخدام الاساليب الاحصايية علي انشاء نموذج للواقع؛ انه ليس الواقع الفعلي .كما يتضم ن ذلك اختيارات :اختيارات بشان الخوارزمية نفسها التي ت وفر العملية الاحصايية التي تاخذنا من البيانات الي النمط/القاعدة ،ولكن ايضا اختيارات بشان تصميم مجموعة البيانات التي تتد رب عليها الخوارزمية .يعني هذا الجانب الاختياري ،ومن ثم الجانب البشري ،في اسيلة نقدية حول الاختيارات التي تت خذ ،بل يجب علينا تع لم الالة انه يمكننا ان نطرح ان نفعل ذلك .علي سبيل املثال ،هل مجموعة البيانات التي سيتم التدريب عليها تمثل تمثيلا جيدا؟ هل هناك اي تحي زات في البيانات؟ كما سنري في الفصل القادم، السكان هذه الاختيارات والقضايا ليست مجرد اسيلة فنية ولكن لها ايضا جانب اخلاقي شديد الاهمية. التطبيقات تطبيقات عديدة ،ذ كرت بعضها بالفعل تحت العنوان الاعم لتع لم الالة وعلم البيانات ا ملتمثل في الذكاء الاصطناعي .هذه التقنيات يمكن استخدامها للتع رف علي الوجوه )بل للتع رف علي الانفعالات بناء علي تحليل الوجوه( ،او تقديم اقتراحات بحث ،او قيادة السيارة ،او اجراء توقعات شخصية ،او التنب و بم ن سيعاود ارتكاب الجريمة، او التوصية بموسيقي معينة للاستماع اليها .وتستخدم في مجال املبيعات والتسويق، للتوصية بمنتجات وخدمات .علي سبيل املثال ،عندما تشتري شييا علي موقع امازون، بيانات عنك ثم يقدم توصيات علي اساس نموذج احصايي يستند الي سيجمع املوقع بيانات من جميع العملاء .استخدمت شركة ووملارت في متاجرها تقنية التع رف علي الوجوه للتصدي للسرقة؛ وقد تستخدم في املستقبل التقنية نفسها لتحديد ما اذا كان ا ملتسوقون سعداء ام محبطني .كما ان للتقنيات تطبيقات مختلفة في مجال التمويل. تعاونت وكالة اكسبريان للمرجعية الايتمانية مع الذكاء الاصطناعي املدعوم بتع لم الالة لتحليل البيانات ا ملتعلقة با ملعاملات والقضايا املنظورة في املحاكم من اجل التوصية بما قرض ملقد م طلب لرهن عقاري .وتستخدم امريكان اكسبريس تع لم اذا كان يجب تقديم لا تنس )علم( البيانات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 87, "content": "الالة لتوقع املعاملات الاحتيالية .وفي مجال النقل ،يستخدم الذكاء الاصطناعي والبيانات الضخمة لانشاء سيارات ذاتية القيادة .علي سبيل املثال ،تستخدم شركة بي ام دبليو نوع ا من تقنية التع رف علي الصور لتحليل البيانات الواردة من اجهزة الاستشعار والكامريات في السيارة .وفي مجال الرعاية الصحية ،يمكن ان يساعد الذكاء الاصطناعي املدعوم بتع لم الالة في تشخيص السرطان )علي سبيل املثال ،في تحليل صور الاشعة لتشخيص مرض السرطان( او اكتشاف الامراض ا ملعدية .علي سبيل املثال ،اجري نظام الذكاء الاصطناعي تحليلا ملليون صورة من صور اشعة العيون وبيانات املرضي ،مدربا لشركة ديب مايند نفسه علي تشخيص اعراض حالات العيون املرضية ا ملتدهورة .وقد تجاوز نظام واتسون توصيات بشان الذي انشاته شركة اي بي ام ممارسة لعبة »جيوباردي« ويستخدم لتقديم علاج السرطان .كما تزو د اجهزة الرياضة والصحة التي يمكن ارتداوها تطبيقات تع لم الالة بالبيانات .وفي مجال الصحافة ،يمكن لتع لم الالة كتابة تقارير اخبارية .علي سبيل املثال ،في اململكة املتحدة ،تستخدم وكالة انباء »بريس اسوسييشن« الروبوتات في كتابة تقارير الاخبار املحلية .ويدخل الذكاء الاصطناعي ايضا الي املنزل واملجال الشخصي ،علي تتولي جمع البيانات واجهزة تفاع لية مساعدة مت صلة سبيل املثال ،في شكل روبوتات بمعالجة اللغة الطبيعية .تتحد ث دمية »هالو باربي« الي الاطفال باستخدام معالجة اللغة الطبيعية التي تحلل املحادثات املسجلة .فك ل ما يقوله الاطفال يتم تسجيله وتخزينه وتحليله في وحدات الخدمة الخاصة ب »توي توك« .ثم يرسل ردا الي الجهاز :وتجيب دمية »هالو باربي« علي اساس ما »تعلمته« عن مستخدمها .ويستخدم فيسبوك تقنيات التع لم العميق والشبكات العصبية لهيكلة وتحليل البيانات الاتية مما يق رب من مليا ري مستخدم بيانات غري مهيكلة .وهذا يساعد الشركة في تقديم اعلانات مستهدفة. للمنصة ينتجون ويح لل انستجرام صور 800مليون مستخدم بهدف بيع الاعلانات الي الشركات .ويستخدم نتفليكس محركات التوصية التي تح لل بيانات العملاء ،لكي يحو ل نفسه من موزع الي منتج محتوي :فاذا كنت تستطيع التنب و بما يرغب الناس في مشاهدته ،فيمكنك انتاجه بنفسك وتحقيق ربح منه .بل ان علم البيانات استخدم في مجال الطهي .علي سبيل املثال، بناء علي تحليل نحو 10000وصفة ،ينشي نظام شيف واتسون الذي انتجته شركة اي بي ام وصفاته الخاصة التي تقترح توليفات جديدة للمكونات 2 .ويمكن ايضا استخدام الذكاء الاصطناعي املدعوم بتع لم الالة في التعليم ،والتوظيف ،والعدالة الجنايية ،والامن اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تنس)علم(البيانات لا َ تع ُّلم الآلة", "section_path": ["الفصل السادس", "تنس)علم(البيانات لا َ تع ُّلم الآلة"], "page": 88, "content": ")علي سبيل املثال ،الشرطة التنبوية( ،واسترجاع املوسيقي ،والاعمال املكتبية ،والزراعة، والاسلحة العسكرية ،وما الي ذلك. في املاضي ،كانت الاحصاء من املجالات غري الجذابة .اما اليوم ،فبعد ان اصبحت جزءا شكل يدم ج فيه الذكاء الاصطناعي مع البيانات الضخمة ،اصبحت من ع لم البيانات وفي الاحصاء شديدة الجاذبية .انها السحر الجديد .انها املجال الذي ت فضله وسايل الاعلام. نوع جديد من التنقيب عن كما انها تعتبر مجا ل اعمال ضخم ا .فالبعض يتحد ثون عن خيالا الذهب؛ والتوقعات هايلة .علاو ة علي ذلك ،فهذا النوع من الذكاء الاصطناعي ليس محض نبوءة ،كما تبني الامثلة التي ضربناها ان ما يسم ي بالذكاء الاصطناعي علميا او املحدود او الضعيف موجود بالفعل وواسع الانتشار .وفيما يتعلق بتاثريه ا ملحتم ل ،فليس هناك ما يمكننا ان نصفه بانه محدود او ضعيف .لذلك ،فانه من الضروري جدا ان نح لل ونناقش العديد من القضايا الاخلاقية التي اثارتها تقنيات تع لم الالة وغريها من تقنيات الذكاء الاصطناعي وتطبيقاتها .وهذا هو موضوع الفصول القادمة. في املاضي ،كانت الاحصاء من املجالات غري الجذ ابة .اما اليوم ،فبعد ان اصبحت جزءا من علم شكل يدمج فيه الذكاء الاصطناعي مع البيانات الضخمة ،اصبحت الاحصاء شديدة البيانات وفي الجاذبية .انها السحر الجديد."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 89, "content": "الخصوصية وغيرها من القضايا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 90, "content": "ان العديد من املشكلات الاخلاقية ا ملتعلقة بالذكاء الاصطناعي معروفة من مجال اخلاقيات بشكل اعم ،من مجال اخلاقيات التكنولوجيا الرقمية وتكنولوجيا الروبوتات والاتمتة او، الاتصالات .ولكن هذا في ح د ذاته لا يق لل من اهميتها .وعلاو ة علي ذلك ،فان هذه القضايا بتقنيات اخري — تكتسب بعدا جديدا وتصبح — بسبب التكنولوجيا وطريقة ارتباطها اكثر اهمية والحاح ا. الخصوصية وحماية البيانات فلنفكر ،علي سبيل املثال ،في مسالة الخصوصية وحماية البيانات .ينطوي الذكاء الاصطناعي ،ولا سيما تطبيقات تع لم الالة التي تتعام ل مع البيانات الضخمة ،غالبا علي جمع املعلومات الشخصية واستخدامها .ويمكن ايضا استخدام الذكاء الاصطناعي وايضا في مكان العمل وفي كل مكان ،وذلك من خلال الهواتف الذكية للمراقبة ،في الشارع ري من الاحيان ،لا يعلم الناس حتي ان البيانات ووسايل التواصل الاجتماعي .وفي كث سياق سياق ما تستخدم بواسطة اطراف اخري في تجم ع ،او ان البيانات التي قدموها في اخر .كما ان البيانات الضخمة غالبا ما تعني ان )مجموعات( البيانات التي تحصل عليها املنظمات املختلفة يتم دمجها مع ا. يتط لب الاستخدام الاخلاقي للذكاء الاصطناعي جمع البيانات ومعالجتها ومشاركتها وحقهم في معرفة ما يحدث لبياناتهم ،والوصول الي بطريقة تحترم خصوصية الافراد بياناتهم ،والاعتراض علي جمع بياناتهم او علي معالجتها ،ومعرفة ان بياناتهم تجمع لقرارات يتخذها الذكاء الاصطناعي )في حالة حدوث ذلك وتعالج وانهم بعدي ذ يخضعون"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 91, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 92, "content": "بالفعل( .وتثار العديد من هذه القضايا ايضا في سياقات تكنولوجيا املعلومات وتكنولوجيا طا مهم ا الاتصالات الاخري ،وكما سنري فيما بع د في هذا الفصل ،تعتبر الشفافية شر ايضا في تلك الحالات )انظر لاحقا في هذا الفصل( .كما تثار قضايا حماية البيانات في اخلاقيات البحث ،علي سبيل املثال ،في اخلاقيات جمع البيانات لابحاث العلوم الاجتماعية. ومع ذلك ،عند النظر الي السياقات التي يستخدم فيها الذكاء الاصطناعي اليوم، تصبح قضايا الخصوصية وحماية البيانات اكثر تعقيدا .فان احترام هذه الق يم والحقوق استبيان كعالم اجتماع :اذ يمكن للباحث ابلاغ املشاركني سهلا الي ح د ما عند اجراء يكون بشكل صريح ،ومن ثم سيكون من املعروف نسبيا ما في الاستبيان وطلب موافقتهم سيحدث للبيانات .ولكن البيية التي يستخدم فيها الذكاء الاصطناعي وعلم البيانات اليوم مختلفة تمام ا .فلنتناول مثلا وسايل التواصل الاجتماعي :علي الرغم من عاد ة ما تكون معلومات الخصوصية والتطبيقات التي تطلب من ا ملستخدمني املوافقة ،فان ا ملستخدمني لا يعرفون بوضوح ما يحدث لبياناتهم او حتي اي بيانات يتم جمعها؛ واذا كانوا يرغبون ري من الاحيان ،لا في استخدام التطبيق والاستمتاع بفوايده ،فعليهم ان يوافقوا .وفي كث يعلم ا ملستخدمون حتي ان الذكاء الاصطناعي ي شغل التطبيق الذي يستخدمونه .وغالبا ما ت نطاق اخر واستخدامها لاغراض مختلفة )اعادة سياق ما الي نقل البيانات ا ملعطاة في اغراض اخري( ،علي سبيل املثال ،عندما تبيع الشركات بياناتها الي استخدام البيانات في شركات اخري او تنقل البيانات بني اجزاء مختلفة من نفس الشركة دون ع لم املستخدمني بهذا. التلاع ب والاستغلال وا ملستخدمني ا ملستهدفني تشري هذه الظاهرة الاخرية ايضا الي احتمالية التلاع ب با ملستخدمني واستغلالهم .يستخدم الذكاء الاصطناعي للتحكم فيما نشتريه ،وفي الاخبار التي نتابعها ،وفي الاراء التي نثق بها ،وغري ذلك .وقد اشار الباحثون في النظرية النقدية الي السياق الراسمالي الذي يحدث فيه استخدام وسايل التواصل الاجتماعي .علي سبيل املثال ،يمكن القول ان مستخدمي »عملا رقميا« مجانيا ) (Fuchs 2014من خلال انتاج وسايل التواصل الاجتماعي يود ون البيانات لصالح الشركات .ويمكن ان يشمل هذا الشكل من اشكال الاستغلال ايضا الذكاء الاصطناعي .فبوصفنا مستخدمني لوسايل التواصل الاجتماعي ،نحن نتعرض لخطر ان نصبح القوة العاملة ا ملستغ لة غري املاجورة ،التي تنتج البيانات لصالح الذكاء الاصطناعي الخصوصية وغريها من القضايا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 93, "content": "الذي يحلل بياناتنا بعد ذلك لصالح الشركات التي تستخدم البيانات ،والتي عاد ة ما ايضا .وهذا يذ كرنا اطرافا اخري ايضا بتحذير هريبرت ماركوزه في ستينيات تتضم ن القرن العشرين بانه حتي في املجتمعات ا ملسم اة مجتمعات »حرة« ،و»غري شمولية« ،هناك اشكال خاصة من السيطرة ،وخاصة استغلال ا ملستهلكني ) .(Marcuse 1991يكمن اشكال الخطر هنا في ان الذكاء الاصطناعي قد يودي حتي في الديمقراطيات الحديثة الي جديدة من التلاع ب واملراقبة والاستبداد ،ليس بالضرورة في شكل سياسات استبدادية ولكن بطريقة اكثر خفاء وفعالية :من خلال تغيري الاقتصاد بطريقة تحو لنا جميع ا — في استخدامنا للهواتف الذكية والتفاعلات الرقمية الاخري — الي ما يشبه الابقار التي يتم حلبها للحصول علي بياناتها .ولكن يمكن ايضا استخدام الذكاء الاصطناعي للتلاع ب في التواصل بشكل اكثر مباشرة ،علي سبيل املثال ،من خلال تحليل بيانات وسايل السياسة الاجتماعي لدعم حملات سياسية معينة )كما في الحالة الشهرية لشركة كامبريدج اناليتيكا، التي استخدمت بيانات مستخدمي فيسبوك — دون موافقتهم — لاغراض سياسية في انتخابات الرياسة الامريكية عام ،(2016او عن طريق استخدام روبوتات لنشر رسايل التواصل الاجتماعي استنادا الي تحليل بيانات الافراد من حيث سياسية علي وسايل تفضيلاتهم السياسية للتاثري علي عمليات التصويت .كما ان البعض يساورهم القلق من نيابة عن البشر ،قد يحو ل ان يحو ل الذكاء الاصطناعي ،من خلال تو ليه املهام املعرفية مستخدميه الي اطفال علي املستوي العقلي عن طريق »تقليل قدرتهم علي التفكري بمحض انفسهم او اتخاذ قراراتهم الخاصة بما يجب فعله« ) .(Shanahan 2015, 170علاو ة علي ذلك ،لا يكمن خطر الاستغلال في جانب املستخدم فحسب :فالذكاء الاصطناعي يعتمد علي اجهزة صنعها اشخاص ،وقد ينطوي انشاء هذه الاجهزة علي استغلال هولاء الاشخاص. وقد يدخل الاستغلال ايضا في تدريب الخوارزميات وانتاج البيانات التي تستخدم لصالح الذكاء الاصطناعي وعن طريقه .ان الذكاء الاصطناعي ربما يجعل الحياة ايسر بالنسبة الي مستخدميه ،ولكن ليس بالضرورة بالنسبة الي اوليك الذين ي نقبون عن املعادن ،او بالنسبة الي م ن يتعاملون مع ا ملخلفات الالكترونية ،او الي م ن يدربون الذكاء الاصطناعي. علي سبيل املثال ،لا يقتصر ما يقوم به تطبيق »اليكسا« الذي طو رته امازون اكو علي انشاء مستخدمني يود ون عملا مجانيا ويصبحون مصادر للبيانات ويباعون كمنتجات؛ بل هناك عا لم من العمل البشري يكمن خلف الكواليس :فع م ال التنقيب عن املعادن، والعمال علي السفن ،والعمال الذين يصنفون مجموعات البيانات ،كل هولاء في خدمة تجميع رءوس الاموال وترا كمها لدي عدد قليل جدا من الاشخاص ).(Schwab 2018 اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 94, "content": "اشكال جديدة من التلاع ب واملراقبة والاستبداد ،ليس بالضرورة في قد يودي الذكاء الاصطناعي الي سياسات استبدادية ولكن بطريقة اكثر خفاء وفعالية. شكل"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 95, "content": "بعض مستخدمي الذكاء الاصطناعي اكثر تع ر ضا للخطر من غريهم .ونظريات الخصوصية والاستغلال غالبا ما تفترض ان املستخدم شخص بالغ سليم الجسم ،صغري السن نسبيا ،في كامل قواه العقلية . لكن العا لم الحقيقي مليء بالاطفال وكبار السن والاشخاص الذين لا يتمتعون بقوي عقلية »طبيعية« او »كاملة« ،وغريهم .مثل هولاء ا ملستخدمني الضعفاء اكثر ع رضة للخطر .ويمكن انتهاك خصوصيتهم او التلاعب بهم فرصا جديدة لهذه الانتهاكات وعمليات التلاعب .ف كر ويوفر الذكاء الاصطناعي بسهولة، مثلا في الاطفال الصغار الذين يتحدثون مع دمي ة متصلة بنظام تكنولوجي مدعوم بالذكاء الاصطناعي :علي الارجح ،هولاء الاطفال لا يعلمون شييا عن الذكاء الاصطناعي ا ملستخدم او عن جمع بياناتهم ،فما بالك بما يفع ل بمعلوماتهم الشخصية .ان روبوت الدردشة او الدمية الذكية املدعومة بالذكاء الاصطناعي لا تستطيع فقط ان تجمع الكثري من املعلومات الشخصية عن الطفل وابويه بهذه الطريقة ،بل يمكنها ايضا التلاع ب بالطفل باستخدام واجهة اللغة والصوت .ومع تحو ل الذكاء الاصطناعي الي جزء من »انترنت الالعاب« ) (Druga and Williams 2017وانترنت الاشياء )الاخري( ،تصبح هذه مشكلة اخلاقية وسياسية .ان شبح الشمولية والاستبداد يعاود الظهور مجددا :ليس في قصص الخيال العلمي ا ملتشايمة او في كوابيس ما بعد الحروب القديمة ،ولكن في التكنولوجيا الاستهلاكية املوجودة بالفعل في الاسواق. الاخبار الكاذبة ،وخطر الشمولية ،وتاثريها علي العلاقات الشخصية يمكن ان يستخدم الذكاء الاصطناعي ايضا في انتاج خطاب الكراهية واملعلومات الزايفة، كاشخاص ولكنها في الواقع مجرد برامج مدعومة بالذكاء او في انشاء روبوتات تبدو الاصطناعي .وقد سبق واشرت بالفعل الي روبوت الدردشة »تاي« وخطاب اوباما الزايف. قد يودي ذلك الي عا ل م لا يمكن فيه التمييز بوضوح بني ما هو حقيقي وما هو زايف، يجب تسميتها »ما بعد الحقيقة« عالم تتداخل فيه الحقايق مع الخيال .وسواء كان بشكل واضح في ام لا ) ،(McIntyre 2018تساهم هذه التطبيقات للذكاء الاصطناعي الخصوصية وغريها من القضايا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 96, "content": "املشكلة .بالطبع ،كان يوج د تلاعب ومعلومات كاذبة قبل ظهور الذكاء الاصطناعي. فالافلام ،علي سبيل املثال ،كانت دايم ا تخلق اوهام ا ،والصحف كانت تنشر الدعاية جنب مع امكانيات وبيية الانترنت الكاذبة .ولكن بعد ظهور الذكاء الاصطناعي ،جنبا الي ووسايل التواصل الاجتماعي الرقمية ،يبدو ان املشكلة تزداد تعقيدا وح د ة .ويبدو ان هناك املزيد من الف رص للتلاع ب ،مما يعرض التفكري النقدي للخطر .وكل هذا يذكرنا مرة اخري بخطورة الشمولية ،التي تستفيد من ا لتباس الحقيقة وتنتج اخبا را زايفة لاغراض ايديولوجية. ومع ذلك ،حتي في اليوتوبيا الليبرالية قد لا تكون الحياة غاية في الاشراق والبهاء .اذ ان املعلومات الكاذبة تنخر في جدار الثقة ومن ثم تفسد النسيج الاجتماعي .ويمكن ان التواصل ،او علي الاقل التواصل الهادف، يودي الاستخدام ا ملفرط للتكنولوجيا الي تقليل بني الافراد .في عام ،2011قدمت شريي تريكل ادعاء يتعلق بالتكنولوجيا مثل اجهزة الكمبيوتر والروبوتات :لقد انتهي بنا الامر الي توقع املزيد من التكنولوجيا ،والقليل من انفسنا .ويمكن ايضا استخدام هذه الحج ة فيما يتعلق بالذكاء الاصطناعي :تكمن املشكلة في ان الذكاء الاصطناعي ،في شكل وسايل التواصل الاجتماعي او في شكل »الرفاق« الرقميني ،يعطينا وهم الرفقة ولكنه يزعزع استقرار العلاقات الحقيقية مع الاصدقاء والاحباء والعايلات .وعلي الرغم من ان هذه املشكلة كانت موجود ة بالفعل قبل الذكاء وسيط جديد من الوسايط )قراءة الصحف او الاصطناعي وتزداد تفاقم ا مع ظهور كل مشاهدة التلفيزيون بدلا من التحد ث وادارة حوار( ،فانه يمكن القول ان التكنولوجيا ري في خلق وهم الرفقة، الان ،في وجود الذكاء الاصطناعي وتطبيقه ،قد اصبحت افضل بكث وان هذا يزيد من خطر الوحدة او تدهور العلاقات الشخصية. السلامة والامان هناك ايضا مخاطر اوضح .فالذكاء الاصطناعي ،لا سي ما في حال تضمينه في انظمة ايضا الي ان يكون امنا .ولنضرب الاجهزة التي تعمل في العا لم الفعلي ،يحتاج مثلا علي ذلك بالروبوتات الصناعية :يفترض الا تلح ق هذه الروبوتات الاذي بالعمال .ومع ذلك، تحدث احيانا حوادث في املصانع .ويمكن للروبوتات ان تقتل ،حتي لو كان ذلك ناد را نسبيا .ومع ذلك ،في الروبوتات التي تعتمد علي الذكاء الاصطناعي ،تصبح مشكلة السلامة جنب مع البشر ،وقد تتم كن اكثر تح ديا :فهذه الروبوتات قد تتم كن من العمل جنبا الي اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 97, "content": "نحو ذكي« .ولكن ماذا يعني ذلك بالضبط؟ هل يجب من تجن ب الحاق الاذي بالبشر »علي قريبة من البشر ،مما يبطي العملية ،ام انه من املقبول ان تتحرك ببطء اكبر عندما تكون بسرعة عالية من اجل انجاز العمل بكفاءة وسرعة؟ هناك دايم ا احتمالات لحدوث التحرك خطا من نوع ما .فهل يجب ان تنطوي اخلاقيات السلامة علي الوصول الي حلول وسط؟ تثري الروبوتات املدعومة بالذكاء الاصطناعي في بيية املنزل او في الاماكن العامة ايضا قضايا تتع لق بالسلامة .علي سبيل املثال ،هل يجب علي الروبوت دايم ا تجن ب الاصطدام شخصا من اجل الوصول الي هدفه؟ بالبشر ام انه من املقبول احيانا ان يعرقل الروبوت هذه ليست مسايل تقنية بحتة ولكن لها جانب اخلاقي :انها مسالة حياة بشرية و قيم مثل مشكلات تتع لق باملسيولية )سنتحدث عن هذا بتفصيل الحرية والكفاءة .كما انها تثري اكثر لاحقا(. ثم ة مشكلة اخري كانت موجودة بالفعل قبل ظهور الذكاء الاصطناعي في املشهد، تستحق تجديد اهتمامنا بها؛ الا وهي مشكلة الامان .في عالم متصل بالشبكات، ولكنها يمكن اختراق اي جهاز الكتروني او برنامج واختراقه والتلاع ب به من قبل اشخاص لديهم نوايا خبيثة .فك لنا نعلم بشان فريوسات الكمبيوتر ،علي سبيل املثال ،التي يمكن ان تخ رب جهاز الكمبيوتر الخاص بك .ولكن عند تزويد اجهزتنا وبرامجنا بالذكاء الاصطناعي، بوكالة اخلاقية اكبر ويكون لهذا يمكن ان تزيد امكانياتها وقدراتها ،وعندما تحظي عواقب مادية في العالم الفعلي ،تصبح مشكلة الامان اكبر بكثري .علي سبيل املثال ،اذا اختر قت سيارتك الذاتية القيادة التي تعمل بالذكاء الاصطناعي ،فسوف تعاني مما هو اكثر من مجرد »مشكلة في الكمبيوتر« او »مشكلة في البرنامج«؛ قد تلقي حتفك .واذا اخترق برنامج احدي البني التحتية املهمة )مثل الانترنت ،او املياه ،او الطاقة ... الخ( او اضطراب قدرات مدمرة ،فمن املرج ح ان يتعرض املجتمع باكمله الي جهاز عسكري ذي كبري وسوف يتعرض الكثري من الاشخاص للضرر .في التطبيقات العسكرية ،يش كل استخدام الاسلحة الفتاكة الذاتية التشغيل خطورة امنية واضحة ،لا سي ما علي ا ملستهدفني بالطبع بهذه الاسلحة )وعادة ما لا يكونون من الغرب( ولكنه يش كل خطورة ايضا علي اوليك الذين ينشرونها :اذ يمكن دايم ا اختراقها وتحويلها ضدهم .علاو ة علي ذلك ،قد حرب عاملية جديدة .ولا يلزمنا ان ننظر يودي سباق التس لح الذي يشمل هذه الاسلحة الي بعيدا في ا ملستقبل :فاذا كانت الطايرات دون طيار )غري ا ملزودة بالذكاء الاصطناعي( مطار كبري في لندن ،فانه ليس من الصعب تخي ل مدي يمكنها بالفعل حاليا السيطرة علي الخصوصية وغريها من القضايا"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 98, "content": "هشاشة منشات بنيتنا الاساسية اليومية وكيف يمكن للاستخدام املوذي او لاختراق الذكاء تدمريية هايلة .لاحظ ايضا انه ،علي وعمليات اضطرابات جسيمة الاصطناعي ان يسبب عكس التكنولوجيا النووية علي سبيل املثال ،فان استخدام تكنولوجيا الذكاء الاصطناعي طويلا؛ ومن ثم فالعايق امام استخدام الحالية لا يتط لب معد ات باهظة الثمن او تدريبا لاغراض خبيثة منخفض نسبيا. الذكاء الاصطناعي تذكرنا ايضا املشكلات العادية املتعلقة بالامان مع السيارات ومنشات البنية التحتية عرضة للخطر من غريهم، مثل املطارات بانه علي الرغم من ان بعض الاشخاص اكثر تقنيات مثل الذكاء الاصطناعي لاننا ،مع زيادة فاننا »جميع ا« مع رضون للخطر في ظ ل تمت ع هذه التقنيات بالوكالة وزيادة تفويضنا لها لتادية املزيد من املهام ،نصبح جميع ا اكثر اعتمادا عليهم .وهناك احتما ل دايم ان تسري الامور علي غري ما نروم .ومن ثم ،يمكننا القول ان املخاطر التكنولوجية الجديدة ليست مجرد مخاطر تكنولوجية ،وانما تتجاوز ذلك لتصبح مخاطر تهد د وجودنا بصفتنا بشرا ) .(Coeckelbergh 2013يمكن روية املشكلات الاخلاقية املطروحة هنا علي انها مخاطر انسانية :فاملخاطر التكنولوجية تهدد كبشر في نهاية املطاف .وبقدر ما نعتمد علي الذكاء الاصطناعي ،وبقدر ما يكون وجودنا الذكاء الاصطناعي اكثر من مجرد ادا ة نستخدمها؛ فانه يصبح جزءا من هويتنا ومن املخاطر التي تحيق بنا في العالم. في عال م متصل بالشبكات ،يمكن اختراق اي جهاز الكتروني او برنامج واختراقه والتلاع ب به من قبل اشخاص لديهم نوايا خبيثة."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الخصوصية وغيرها من القضايا", "section_path": ["الفصل السابع", "الخصوصية وغيرها من القضايا"], "page": 99, "content": "كذلك يثري تمت ع الذكاء الاصطناعي بالوكالة الاخلاقية ،لا سيما اذا كانت تح ل مح ل اهمية مع مرور الوقت :الا وهي الوكالة الاخلاقية البشرية ،مشكلة اخلاقية اخري تزداد املسيولية .وهذا هو موضوع الفصل القادم."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 100, "content": "كيف يمكن ان نسند املسيولية الاخلاقية وما الكيفية الواجبة لذلك؟ نواج ه عند استخدام الذكاء الاصطناعي لاتخاذ قرارات وللقيام باشياء بالنيابة عن ا ،فاننا اهمية عندما يم كننا مشكلة مشتركة في جميع تقنيات الاتمتة ،غري ان هذه املشكلة تزداد ري مما كنا الذكاء الاصطناعي من تفويض املزيد واملزيد من القرارات الي الالات اكثر بكث نفعل في املاضي :وهذه املشكلة هي اسناد املسيولية 1 .اذا منح الذكاء الاصطناعي وكالة اكبر واخذ علي عاتقه ما كان يتولاه البشر في املاضي ،فكيف نسند املسيولية الاخلاقية عن افعاله؟ م ن املسيول عن الاضرار والفوايد التي تنشا عن التكنولوجيا عندما يفوض البشر يخص املخاطر تحديدا :م ن املسيول عند الوكالة والقرارات الي الذكاء الاصطناعي؟ وفيما حدوث خطا ما؟ عندما يقوم البشر باداء مها م واتخاذ قرارات ،فنحن عاد ة ما نربط الوكالة باملسيولية الاخلاقية .فانت مسيول عما تفعله وعن القرارات التي تت خذها .واذا كان لديك تاثري علي العالم وعلي الاخرين ،فانت مسيول عن عواقب افعالك . وفقا لارسطو ،هذا هو الشرط الاول للمسيولية الاخلاقية ،املعروف باسم الشرط التح كمي :في الاخلاقيات النيقوماخية ،يقول ارسطو ان الفعل يجب ان ينشا من الفاعل .ولهذا الراي ايضا جانب تقييمي :اذا كان لديك وكالة واذا كنت قاد را علي اتخاذ قرارات ،فينبغي ان تتحم ل املسيولية عن افعالك. وما نريد تجن به من الناحية الاخلاقية هو ان يوج د شخص يتمتع بالوكالة والقدرة ولكنه طا ايضا شر لا يتحمل املسيولية .اضاف ارسطو اخر فيما يخص املسيولية الاخلاقية :انت مسيول اذا كنت تعلم ما تفعله .وهذا شرط ادراكي :يجب ان تكون واعيا بما تفعل وعلي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 101, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 102, "content": "دراية بعواقبه املحتملة .وما نحتاج الي تجن به هنا هو شخص تصدر عنه افعال لا يدري ماهيتها ،وهو ما قد يودي في النهاية الي عواقب وخيمة. وكالة اكبر واخذ علي عاتق ه ما كان يتولاه البشر في املاضي ،فكيف نسند اذا منح الذكاء الاصطناعي املسيولية الاخلاقية عن افعاله؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 103, "content": "تتحقق هذه الشروط عند تفويض القرارات والاعمال الي الذكاء الان دعونا نري هل افعالا قرارات ويودي الاصطناعي .املشكلة الاولي هي ان الذكاء الاصطناعي يمكن ان يت خذ لها عواقب اخلاقية ،ولكنه لا يدرك ما يفعله وغري قادر علي التفكري الاخلاقي وبالتالي لا مسيولا من الناحية الاخلاقية عما يفعله .يمكن ان تتمت ع الالات بالوكالة يمكن اعتباره ولكن ليس بالوكالة الاخلاقية؛ لانها تفتق ر الي الوعي والارادة الحرة والعواطف والقدرة علي تكوين النوايا وما شاب ه ذلك .علي سبيل املثال ، وفقا لروية ارسطو ،يمكن للبشر فقط اداء الافعال التطو عية والتفكري في افعالهم .اذا كان هذا صحيح ا ،فان الح ل الوحيد هو جع ل البشر مسيولني عما تفعله الالة .ومن ثم فان البشر يفو ضون الوكالة الي الالة، ولكنهم يحتف ظون باملسيولية .ونحن نفعل ذلك بالفعل في انظمتنا القانونية؛ اذ اننا لا عتبر الكلاب او الاطفال الصغار مسيولني عن افعالهم ،ولكننا نضع املسيولية القانونية ن شخص ما مهمة معينة الي موسسة ما ،قد نفو ض علي عاتق م ن يتو لون رعايتهم .وفي ولكننا نحم ل املسيولية للمدير املسيول عن املشروع العام ،علي الرغم من ان الشخص ا ملفوض في هذه الحالة يتحم ل جزءا من املسيولية 2 .اذن ملاذا لا نسمح للالة باداء الاعمال ونحتفظ باملسيولية علي الجانب البشري؟ يبدو ان هذه هي افضل وسيلة نمضي بها قدم ا، حيث ان الخوارزميات والالات بلا مسيولية. يواجه هذا الح ل عدة مشكلات في حالة الذكاء الاصطناعي . اولا ،يمكن ومع ذلك، للنظام املزو د بالذكاء الاصطناعي ان يتخذ قراراته ويودي افعاله بسرعة كبرية للغاية، علي سبيل املثال ،في التداول العالي الترد د او في السيارات الذاتية القيادة ،مما يحرم التدخل في الفعل .فكيف يمكن للبشر الانسان من الوقت الكافي لاتخاذ القرار النهايي او ان يتحم لوا املسيولية عن مثل هذه الافعال والقرارات؟ ثانيا ،لانظمة الذكاء الاصطناعي تطبيق معني ،فربما يصبح من تواريخ .عندما يقوم الذكاء الاصطناعي باشياء في سياق لامسيولية الالات والقرارات غري ا ملبررة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 104, "content": "غري الواضح م ن انشاه ،وم ن استخدمه اولا ،والكيفية التي يجب بها توزيع املسيولية بني هذه الاطراف املختلفة املعنية .علي سبيل املثال ،في حالة انشاء خوارزمية ذكاء اصطناعي مشروع علمي في الجامعة ،ثم تطبيق هذه الخوارزمية للمرة الاولي في ا ملختبر في في سياق الجامعة ،ثم في قطاع الرعاية الصحية ،وفي سياق عسكري .فم ن يتحم ل وقت لاحق في املسيولية؟ قد يكون من الصعب تتب ع جميع البشر املتو رطني في تاريخ هذه الخوارزمية نتيجة معي نة ت حمل اشكالية اخلاقية .فنحن لا بالذات ،بل في التاريخ السببي الذي اد ي الي نعرف دايم ا جميع الاشخاص ا ملعني ني في اللحظة التي تثار فيها مشكلة تتعلق باملسيولية. فخوارزمية الذكاء الاصطناعي غالبا ما يكون لها تاريخ طويل يشارك فيه العديد من الاشخاص .وهذا يفضي بنا الي مشكلة نمطية في اسناد املسيولية عن الافعال التكنولوجية؛ اذ غالبا ما يكون هناك الكثري من الاطراف ويمكنني ان اضيف ،الاشياء. هناك الكثري من الاطراف بمعني ان الكثري من الاشخاص يشاركون في الفعل التكنولوجي .في حالة الذكاء الاصطناعي ،يبدا الامر باملبرمج ،ولكن لدينا ايضا املستخدم النهايي واخرون .دعونا نفكر مثلا في السيارة الذاتية القيادة :هناك املبرمج ،ومستخ د م السيارة ،واصحاب شركة السيارات ،واملستخدمون الاخرون للطريق ،وهكذا .في مارس حادث في اريزونا اد ي الي وفاة احد ،2018تسب بت سيارة ذاتية القيادة لشركة اوبر في ا ملشاة .فم ن املسيول عن هذه النتيجة املاساوية؟ يمكن ان يكون املسيولون هم م ن برمجوا السيارة ،والاشخاص املسيولني عن تطوير املنتج في الشركة ،وشركة اوبر نفسها، ومستخدم السيارة ،والشخص الساير ،واملشرع )علي سبيل املثال ،ولاية اريزونا( ،وهكذا. اذن فليس من الواضح علي م ن تقع املسيولية .قد يكون الامر هو ان املسيولية لا يمكن شخص واحد؛ وربما تقع علي اكثر من شخص .ولكن هذا يعني ولا يجب اسنادها الي انه ليس من الواضح كيفية توزيع املسيولية .فقد تقع املسيولية علي بعضهم اكثر من الاخرين. هناك ايضا الكثري من الاشياء ،بمعني ان النظام التكنولوجي يتالف من العديد من العناصر املتصلة؛ وعاد ة ما يكون هناك العديد من املكونات التي تدخل في النظام. هناك خوارزمية الذكاء الاصطناعي ،ولكن هذه الخوارزمية تتفاعل مع اجهزة استشعار، وتستخدم جميع انواع البيانات ،وتتفاعل مع جميع انواع املكونات املادية والبرمجية. كل هذه الاشياء لها تاريخها ومتصلة بالاشخاص الذين برمجوها او انتجوها .وعندما يحدث خطا ،لا يكون واضح ا لنا بالضرورة ما اذا كان »الذكاء الاصطناعي« هو الذي اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 105, "content": "سب ب املشكلة ام مكو ن اخر من مكونات النظام؛ بل اننا لا نعرف بالضرورة اين تنتهي مسيولية الذكاء الاصطناعي وتبدا مسيولية بقية املكونات التكنولوجية .وهذا يجعل من الصعب اسناد املسيولية وتوزيعها .دعونا نفكر ايضا في تعلم الالة وعلم البيانات :كما راينا ،ليس هناك فقط خوارزمية ،ولكن ايضا عملية تشمل مراحل مختلفة مثل جمع البيانات ومعالجتها ،وتدريب الخوارزمية ،وهكذا؛ وجميع هذه املراحل يدخل فيها عناصر تقنية مختلفة وتتط لب قرارات بشرية .مرة اخري ،هناك تاريخ سببي يشترك فيه الكثري من البشر والاجزاء ،وهذا يجعل اسناد املسيولية ام را صعبا. لكي نحاول التعامل مع هذه القضايا ،يمكننا ان نتعلم من الانظمة القانونية او نلقي نظرة علي كيفية عمل التامني؛ وسوف اتحد ث عن بعض املفاهيم القانونية في الفصول املتعلقة بالسياسة .ولكن ثم ة اسيلة اكثر عمومية تلوح لنا من وراء هذه الانظمة القانونية وانظمة التامني حول وكالة الذكاء الاصطناعي واملسيولية عنه :الي اي مدي نريد ان نعتمد علي تقنية الاتمتة ،وهل يمكننا ان نتحمل املسيولية عما يقوم به الذكاء الاصطناعي ،وكيف يمكننا اسناد املسيوليات وتوزيعها؟ علي سبيل املثال ،مفهوم الاهمال في القانون يتع لق بما اذا كان الشخص قد اد ي ما عليه من واجب العناية .ولكن ماذا يعني خاصة انه من الصعب التنب و بجميع العواقب هذا الواجب في حالة الذكاء الاصطناعي، الاخلاقية ا ملحتملة؟ وهذا يقودنا الي القضية التالية .حتي اذا ت م ح ل مشكلة التحكم ،فهناك الشرط الثاني للمسيولية الاخلاقية ،والذي يتع لق بمشكلة املعرفة .لكي تتحم ل املسيولية ،يجب ان تعرف ما تفعله والنتايج ا ملترت بة علي فعلك ،وفيما بعد ،تعرف ما قمت به .وبالاضافة نتوقع ان يتمكن الشخص من الي ذلك ،هذه املسالة لها جانب سردي :في حالة البشر، شرح ما قام به او ق ر ره .املسيولية اذن تعني القدرة علي الرد والتفسري .فاذا حدث خطا ما ،فنحن نريد ردا وتفسريا .علي سبيل املثال ،نطلب من القاضي ان ي فسر قراره ،او اشكالية للغاية في حالة الذكاء نسال الجاني ملاذا فعل ما فع له .وهذه الشروط تصبح الاصطناعي . اولا ،من حيث املبدا ،لا »يعرف« الذكاء الاصطناعي في الوقت الحاضر ما يفعله ،بمعني انه ليس واعيا وبالتالي لا يدرك ما يقوم به ولا يدرك نتايج افعاله .يمكنه تخزين ما يفعله وتسجيله ،ولكنه لا »يعرف ما يقوم به« كما يفعل البشر ،الذين يدركون، بوصفهم كاينات واعية ،ما يفعلون ويمكنهم — وفقا لارسطو مرة اخري — التفكري والتامل في افعالهم وعواقب تلك الافعال .وعندما لا تلب ي هذه الشروط في حالة البشر ،علي لامسيولية الالات والقرارات غري ا ملبررة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 106, "content": "سبيل املثال ،في حالة الاطفال الصغار جدا ،فاننا لا نحم لهم املسيولية .وكذلك عاد ة ما لا نحم ل الحيوانات املسيولية ايضا 3 .واذا لم يلب الذكاء الاصطناعي هذه الشروط ،فاننا لا نستطيع ان نحم له املسيولية .والحل مرة اخري هو تحميل املسيولية للبشر عن اعمال الذكاء الاصطناعي ،علي افتراض انهم يعرفون ما يقوم به الذكاء الاصطناعي وما يفعلونه باستخدام الذكاء الاصطناعي — وبمراعاة الجانب السردي — وانهم قادرون علي الر د عن افعاله ويمكنهم تفسري ما قام به الذكاء الاصطناعي. ومع ذلك ،فان مدي صحة هذا الافتراض ليس ام را من السهل تقريره كما قد يبدو للوهلة الاولي .عاد ة ما يعرف املبرمجون واملستخدمون ما الذي يرغبون في القيام به باستخدام الذكاء الاصطناعي ،او بدقة اكبر :يعرفون ما يريدون من الذكاء الاصطناعي ان يفعله لهم .انهم يعرفون الهدف النهايي؛ ولهذا السبب يفو ضون املهمة الي الذكاء الاصطناعي .وقد يكونون بشكل عام .ولكن، ايضا علي دراية بكيفية عمل التكنولوجيا كما سنري ،هم لا يعرفون بدق ة دايم ا ما يفعله الذكاء الاصطناعي )في اي لحظة( ولا يمكنهم دايم ا تفسري ما فعله او كيف وصل الي قراره. الشفافية والقابلية للتفسري نحن نواجه هنا مشكلة الشفافية والقابلية للتفسري .في بعض انظمة الذكاء الاصطناعي، تكون الطريقة التي يستخدمها الذكاء الاصطناعي لاتخاذ قراره واضحة .علي سبيل املثال، اذا كان الذكاء الاصطناعي يستخدم شجرة اتخاذ القرارات ،فان الطريقة التي يصل بها الي قراره تكون واضحة .فقد تم ت برمجته بطريقة تحد د القرار ،بناء علي مدخلات معي نة .وبالتالي يمكن للبشر تفسري كيف وصل الذكاء الاصطناعي الي قراره ،ويمكن ان »نطلب« من الذكاء الاصطناعي ان »يفسر« قراره .بعد ذلك ،يمكن للبشر تحم ل مسيولية القرار او ،علي الاحري ،اتخاذ قرار بناء علي التوصية التي قد م ها الذكاء الاصطناعي. ومع ذلك ،مع بعض انظمة الذكاء الاصطناعي الاخري ،ولا سيما تلك التي تستخدم تع لم الالة وخاصة التع لم العميق الذي يستخدم الشبكات العصبية ،لم يع د من املمكن للانسان قرارات من هذا النوع .حيث لم يع د واضح ا كيف يصل تقديم هذا التفسري او اتخاذ الذكاء الاصطناعي الي قراره ،وبالتالي لا يمكن بشكل كامل .انهم للبشر تفسري القرار قرار معني. يعرفون كيف يعمل النظام الخاص بهم، بشكل عام ،ولكن لا يمكنهم تفسري ولنضرب مثلا بلعبة الشطرنج املزودة بالتع لم العميق :يعرف املبرمجون كيف يعمل الذكاء اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟", "section_path": ["الفصل الثامن", "ُ لامسئولية الآلات والقرارات غير المُبررة كيف يمكن أن نسند املسئولية الأخلاقية وما الكيفية الواجبة لذلك؟"], "page": 107, "content": "حركة معي نة )اي الاصطناعي ،ولكن الطريقة الدقيقة التي يصل من خلالها الجهاز الي ما يحدث في طبقات الشبكة العصبية( ليست واضحة ولا يمكن تفسريها .وهذه مشكلة يخص تحم ل املسيولية ،حيث لا يستطيع البشر الذين ينشيون الذكاء الاصطناعي او فيما يستخدمونه تفسري قرار معني ،وبالتالي يفشلون في معرفة ما يقوم به الذكاء الاصطناعي ولا يمكنهم تبرير افعاله . فمن ناحية ،يعرف البشر ما الذي يقوم به الذكاء الاصطناعي )علي سبيل املثال ،يعرفون الرموز البرمجية الخاصة بالذكاء الاصطناعي ويعرفون كيف بشكل عام( ،ولكن من ناحية اخري ،هم لا يعرفون )لا يمكنهم تفسري قرار يعمل معني( ،وتكون نتيجة ذلك ان البشر الذين يتاثرون بالذكاء الاصطناعي لا يمكن اعطاوهم التوقع .وبالتالي ،علي الرغم معلومات دقيقة حول ما الذي دفع الالة الي الوصول الي هذا مشكلة من ان كل تكنولوجيا الاتمتة تثري مشكلات فيما يتعلق باملسيولية ،فاننا هنا نواجه تخص بعض انواع الذكاء الاصطناعي؛ وهي ما يط لق عليها مشكلة الصندوق الاسود. بمعرفة حول علاوة علي ذلك ،حتي الافتراض بان البشر في مثل هذه الحالات يتمتعون بشكل عام وحول رموزه البرمجية ليس دايم ا صحيح ا .فعلي الارجح الذكاء الاصطناعي يعرف املبرمجون الاصليون الرموز البرمجية وكيفية عمل كل شيء )او علي الاقل يعرفون"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين", "section_path": ["الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين"], "page": 108, "content": "لتطبيقات محد دة يعرفون تمام ا ما يفعله الذكاء يغريون الخوارزمية او يستخدمونها الاصطناعي .علي سبيل املثال ،قد لا يفهم الشخص الذي يستخدم خوارزمية التداول الذكاء الاصطناعي تمام املعرفة ،او قد لا يعرف مستخدمو وسايل التواصل الاجتماعي حتي ان الذكاء الاصطناعي يستخدم ،فما بالك بان يفهموه .ومن جهة املبرمجني )الاصليني(، نحو دقيق الاستخدام »ا ملستقبلي« للخوارزمية التي يطورونها فهم قد لا يعرفون علي او مختلف مجالات التطبيق التي يمكن استخدامها فيها ،فما بالك بك ل الت بعات غري بغض النظر عن املشكلة املقصودة للاستخدام ا ملستقبلي لهذه الخوارزمية .لذلك ،حتي الخاصة بتع لم الالة )التعلم العميق( ،هناك مشكلة تتع لق باملعرفة لدرجة ان الكثريين مم ن يستخدمونه لا يعرفون ما يفعلون؛ لانهم لا يعرفون ما الذي يفعله الذكاء الاصطناعي، وما هي تاثرياته ،او حتي انه مستخدم من الاساس .وهذه يخص جانب ايضا مشكلة فيما املسيولية ،وبالتالي فهي مشكلة اخلاقية خطرية. في بعض الاحيان ،يتم تسليط الضوء علي هذه املشكلات في سياق الثقة :فغياب الشفافية يودي الي غياب الثقة في التكنولوجيا وفي الاشخاص الذين يستخدمون هذه لامسيولية الالات والقرارات غري ا ملبررة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين", "section_path": ["الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين"], "page": 109, "content": "التكنولوجيا .لذلك يسال بعض الباحثني كيف يمكننا زيادة الثقة في الذكاء الاصطناعي، كعامل من العوامل التي يمكن ان تزيد من ويحد دون الشفافية والقابلية للتفسري فضلا عن تجن ب التحي ز ) (Winikoff 2018او صور الذكاء الاصطناعي ا ملرعبة الثقة، )»ترمينيتور«( ) .(Siau and Wang 2018وكما سنري في الفصل القادم ،غالبا ما تهدف سياسات الذكاء الاصطناعي ايضا الي بناء الثقة .ومع ذلك ،فان مصطلحات مثل الذكاء يجب ان نحتفظ الاصطناعي »الجدير بالثقة« مثرية للجدل؛ اذ تجعلنا نتساءل هل بمصطلح »الثقة« للحديث عن العلاقات الانسانية ،ام يمكن استخدامه للحديث عن الالات ايضا؟ تقول جوانا برايسون ) ،(2018الباحثة في مجال الذكاء الاصطناعي ،ان الذكاء الاصطناعي ليس شييا يمكن الوثوق به ولكنه مجموعة من تقنيات تطوير البرامج؛ ومن ثم فهي تعتقد ان مصطلح »الثقة« يجب ان ي حتفظ به للحديث عن البشر وموسساتهم تساولات حول نوع الاجتماعية .وعلاو ة علي ذلك ،يثري موضوع الشفافية والقابلية للتفسري املجتمع الذي نرغب في العيش فيه .فهنا لا يكمن الخطر في مجرد تلاع ب الراسماليني او النخب التكنوقراطية وهيمنتهم ،مما يخلق مجتمع ا يعاني من الانقسام الي ح د كبري .وانما مجتمع عالي التقنية، يتمثل الخطر الاكبر وربما الاعمق الذي يحيق بنا في ان نعيش في مجتمع لا تعود فيه حتي هذه النخب قادر ة علي معرفة ما تفعله ،مجتمع لا يستطيع فيه اح د ان ي فسر ما يحدث. كما سنري ،يقترح صانعو السياسات في بعض الاحيان »الذكاء الاصطناعي القابل للتفسري« و»حق التفسري« .الا اننا لا ندري ان كان من ا ملمكن ان يكون الذكاء الاصطناعي ستحيلا شفافا طوال الوقت .يبدو هذا سه ل التحقيق في الانظمة الكلاسيكية .ولكن اذا بدا م من حيث املبدا شرح ك ل خطوة في عملية اتخاذ القرار وشرح القرارات ا ملتعلقة بافراد محد دين مع تطبيقات تعلم الالة ا ملعاصرة ،فلدينا مشكلة اذن .هل من املمكن »فتح الصندوق الاسود«؟ قد يكون هذا شييا جيدا ،ليس فقط للاخلاق ولكن ايضا لتحسني النظام )اي ،النموذج( والتع لم منه .علي سبيل املثال ،اذا كان النظام اكثر قابلية للتفسري، سمات غري ملايمة ،عندي ذ يمكن للبشر واذا كان الذكاء الاصطناعي يستخدم ما نعتبره اكتشاف هذه املشكلات واملساعدة في القضاء علي الارتباطات الزايفة .واذا كان الذكاء الاصطناعي يحدد استراتيجيات جديدة ملمارسة لعب ة ويجعل هذه الاستراتيجيات اكثر شفافية للبشر ،عندي ذ يمكن للبشر تع لمها من الالة لتحسني ادايهم في اللعبة .وهذا مفيد ليس فقط في مجال الالعاب ،ولكن ايضا في مجالات مثل الرعاية الصحية والعدالة الجنايية اخلاقيات الذكاء الاصطناعي والعلوم .لذلك ،يحاول بعض الباحثني تطوير تقنيات لفتح الصندوق الاسود )Samek,"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين", "section_path": ["الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين"], "page": 110, "content": ".(Wiegand, and Müller 2017ولكن اذا لم يكن ذلك ممكنا بع د او كان ممكنا بدرجة محدودة ،فكيف لنا ان نمضي قدم ا؟ هل تتع لق املشكلة الاخلاقية هنا بالاختيار بني الاداء وامكانية التفسري )(Seseri 2018؟ واذا كانت تكلفة انشاء نظام ذي اداء جيد هي نقص يجب علينا استخدام مثل هذا النظام ،ام لا؟ ام يجب ان نحاول تجن ب في الشفافية ،فهل هذه املشكلة والبحث عن حلول تقنية اخري ،بحيث تكون حتي انظمة الذكاء الاصطناعي الاكثر تقدم ا قادر ة علي تبرير افعالها للبشر؟ هل يمكننا تدريب الالات علي القيام بذلك؟ علاو ة علي ذلك ،حتي اذا كانت الشفافية مرغوبة وممكنة ،فقد يكون من الصعب تحقيقها عمليا .علي سبيل املثال ،ربما لا تكون الشركات الخاصة علي استعداد للكشف عن خوارزمياتها؛ لانها ترغب في حماية مصالحها التجارية .كذلك قد تح ول قوانني امللكية الفكرية التي تحمي تلك املصالح دون ذلك .وكما سنري في فصول لاحقة ،اذا كان الذكاء الاصطناعي في ايدي الشركات القوية ،فان هذا يثري السوال حول م ن يصنع قوانني الذكاء الاصطناعي وم ن يجب ان يصنعها. ومع ذلك ،يجب مراعاة ان الشفافية والقابلية للتفسري من الناحية الاخلاقية لا تتع لق بالضرورة بالكشف عن الرموز البرمجية ،وهي بالتاكيد لا تقتصر علي ذلك فحسب. اساسا بتفسري القرارات للبشر .انها لا تتع لق في املقام الاول بتفسري »كيف املسالة تتع لق مسيولا املتوقع منه ان يكون يعمل« وانما تتع لق بكيف يمكنني انا ،بوصفي انسانا من ويتصر ف بمسيولية ،تفسري قراري .ويمكن ان تكون كيفية عمل الذكاء الاصطناعي، وكيفية وصوله الي هذه التوصية ،جزءا من ذلك التفسري .علاو ة علي ذلك ،فان الكشف عن معرفة حول كيفية عمل الذكاء الاصطناعي. الرموز البرمجية بمفردها لا يعطي بالضرورة فهذه املعرفة تعتمد علي الخلفية التعليمية للانسان ومهاراته .فاذا كان يفتقر الي الخبرة نوع اخر من التفسري .وهذا لا يذ كرنا فحسب بمشكلة التقنية ذات الصلة ،فاننا نحتاج الي سوال حول نوع التفسري الذي نحتاج ه ،ثم ماهية التفسري في التعليم ولكنه يود ي بنا الي ح د ذاته. وهكذا تط رح قضية الشفافية والقابلية للتفسري ايضا اسيلة فلسفية وعلمية مثرية للاهتمام ،مثل الاسيلة املتعلقة بطبيعة التفسري ) .(Weld and Bansal 2018ومما يتالف التفسري الجيد؟ وما الفرق بني التفسريات والاسباب ،وهل يمكن للالات تقديم اي منها؟ وكيف يت خذ البشر القرارات في الواقع؟ وكيف يبر رون قراراتهم؟ هناك ابحاث حول هذا لامسيولية الالات والقرارات غري ا ملبررة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين", "section_path": ["الجزء الذي برمجوه( ،ولكن ذلك لا يعني أن املبرمِجني وا ُملستخدمني اللاحقِ ني الذين"], "page": 111, "content": "املوضوع في علم النفس املعرفي والعلوم املعرفية ،والتي يمكن استخدامها للتفكري في الذكاء سببية كاملة؛ الاصطناعي القابل للتفسري .علي سبيل املثال ،لا يقدم الناس عموم ا سلاسل تفسريات ويجيبون عما يعتقدون انها معتقدات الشخص الذي ي فسر لهم: وانما يختارون التفسريات اجتماعية ) .(Miller 2018وربما نتوقع ايضا ان تكون تفسريات الالات مختلفة ري من الاحيان بانها نتيجة للعواطف. عن تفسريات البشر ،الذين يبررون افعالهم في كث ولكن اذا فعلنا ذلك ،فهل يعني هذا اننا نعتبر طريقة اتخاذ الالات للقرارات افضل من طريقة اتخاذ البشر لها ) ،(Dignum et al. 2018واذا كان الامر كذلك ،فهل يجب ان نفعل؟ يتحدث بعض الباحثني عن الاستدلال بدلا من التفسري .بل ان وينيكوف )(2018 يطلب »الاستدلال بناء علي الق يم« من الذكاء الاصطناعي وغريه من الانظمة ا ملستقلة ،التي يجب ان تكون قادر ة علي تمثيل القيم البشرية والاستدلال باستخدام تلك الق يم .ولكن هل يمكن للالة ان تقوم بالاستدلال ،وكيف يمكن للنظام التكنولوجي »استخدام« الق يم او »تمثيلها« من الاساس؟ اي نوع من املعرفة يمتلكها هذا النظام؟ وهل يمتلك معرفة من الاساس؟ وهل يستطيع الفهم من الاساس؟ وكما يسال بودينجتون ) ،(2017هل يمكن للبشر ان ي بشكل كامل عن قي مهم الجوهرية؟ عبروا مثل هذه املشكلات مثرية للاهتمام من منظور الفلاسفة ،ولكنها صلة ايضا ذات مباشرة بالاخلاقيات ،كما انها واقعية وعملية للغاية .وكما يقول كاستيلفيتشي ):(2016 ان فتح »الصندوق الاسود« مشكلة في العا لم الحقيقي .علي سبيل املثال ،يجب علي البنوك ان ت قرض ما؛ ويجب علي القضاة تفسري سبب اصدار الاوامر بحبس فسر سبب رفض شخص ما )مر ة اخري( .ان تفسري القرارات ليس فقط جزءا من طبيعة البشر عندما يتواصلون ) ،(Goebel et al. 2018بل هو ايضا مطلب اخلاقي .ان القدرة علي التفسري شرط ضروري للسلوك واتخاذ القرارات بشكل مسيول وقابل للمساءلة .ويبدو انه ضروري لاي مجتمع يرغب في احترام البشر بوصفهم افرادا مستقلني اجتماعي ني يحاولون بشكل مسيول وفي الوقت نفسه يطالبون ،عن استحقاق، التصرف واتخاذ القرارات اسباب للقرارات التي توثر عليهم وتفسريات لها .وسواء اكان بامكان بالحصول علي الذكاء الاصطناعي توفري تلك الاسباب والتفسريات »مباشر ة« ام لا ،فان البشر لا بد ان يواجه الباحثني يكونوا قادرين علي الاجابة عند سوالهم عن الاسباب .ان التحدي الذي في مجال الذكاء الاصطناعي هو ضمان انه في حال استخدام الذكاء الاصطناعي لاغراض اتخاذ القرارات من الاساس ،فيجب تصميم التكنولوجيا بحيث يتمكن البشر قدر الامكان من الاجابة عند سوالهم عن اسباب اتخاذ تلك القرارات."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 112, "content": "مشكلة اخري من املشكلات ذات الجوانب الاخلاقية والاجتماعية في الوقت يعد التحي ز نفسه ،وهي ايضا تتعلق بالذكاء الاصطناعي القايم علي ع لم البيانات بعيدا عن غريه من تقنيات الاتمتة الاخري .عندما يت خذ الذكاء الاصطناعي — او علي الاحري ،عندما يوصي منصفة او غري عادلة تجاه باتخاذ — قرارات ،قد يظهر التحي ز؛ اذ قد تكون القرارات غري افراد او مجموعات بعينها .وعلي الرغم من ان التحي ز قد يظهر ايضا عند استخدام الذكاء الاصطناعي التقليدي — علي سبيل املثال ،نظام خبري يستخدم شجرة اتخاذ قرارات او مرتبطة بتطبيقات تع لم قاعدة بيانات تتسم بالتحيز — فان قضية التحيز غالبا ما تكون الالة .وبينما كانت مشكلات التحيز والتمييز موجودة دايم ا في املجتمع ،الا ان القلق يكمن وتفاقم اثارها. في ان يودي الذكاء الاصطناعي الي استمرار هذه املشكلات بينما كانت مشكلات التحي ز والتمييز موجود ة دايم ا في املجتمع ،الا ان القلق يكمن في ان يودي وتفاقم اثارها. الذكاء الاصطناعي الي استمرار هذه املشكلات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 113, "content": "غالبا ما يكون التحي ز غري مقصود؛ فا ملطو رون واملستخدمون ،وغريهم من اطراف ري من الاحيان ،اثار التمييز ض د مجموعات او معنية مثل ادارة الشركة ،لا يتوقعون ،في كث افراد معينني .ويمكن ان يكون السبب في ذلك هو عدم فهمهم نظام الذكاء الاصطناعي بشكل كاف بمشكلة التحي ز او حتي بتحي زاتهم الشخصية، كما ينبغي ،او عدم وع يهم"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 114, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 115, "content": "بشكل عام عدم تصو رهم وعدم تفكريهم بما فيه الكفاية في العواقب ا ملحتم لة غري او تواصلهم مع بعض الاطراف ذات الصلة .يع د هذا ام را املقصودة للتكنولوجيا وعدم اشكاليا نظ را الي ان القرارات ا ملتحي زة يمكن ان تكون لها عواقب وخيمة ،علي سبيل املثال ،من حيث الوصول الي املوارد والتمت ع بالحريات )(CDT 2018؛ اذ قد لا يحصل الافراد علي وظيفة ،او لا يتم كنون من الحصول علي ايتمان ،او قد ينتهي بهم الحال في تقتصر علي الافراد فحسب؛ اذ قد تتاثر السجن ،او حتي يتع رضون للعنف .وا ملعاناة لا باسرها بالقرارات ا ملتحيزة ،علي سبيل املثال ،عندما تصن ف منطقة كاملة في مجتمعات املدينة او جميع الاشخاص مم ن لهم خلفية عرقية معي نة بواسطة الذكاء الاصطناعي علي انهم يشكلون خطور ة امنية عالية. ولنع د م رة اخري الي مثال خوارزمية كومباس الذي تحد ثنا عنه في الفصل الاول، تلك الخوارزمية التي تتنب ا بمدي احتمالية ان يقوم ا ملد عي عليه باعادة ارتكاب الجريمة وكان القضاة في فلوريدا يستخدمونها في اتخاذ قراراتهم بشان امكانية منح السجني طا . افراج ا مشرو لدراسة اج رتها »بروبابليكا« ،وهي غرفة اخبارية عبر الانترنت، وفقا كانت النتايج الايجابية الكاذبة للخوارزمية )ا ملد عي عليهم الذين توقعت الخوارزمية ان فرط الي الاشخاص يعيدوا ارتكاب الجرايم ولكنهم في الواقع لم يفعلوا( تميل بشكل م من ذوي البشرة السمراء ،وكانت النتايج السلبية الكاذبة )ا ملد عي عليهم الذين توقعت بشكل مفرط الي الخوارزمية الا يعيدوا ارتكاب الجرايم ولكنهم في الواقع فعلوا( تميل الاشخاص ذوي البشرة البيضاء ) .(Fry 2018ومن ثم راي النقاد ان هناك تحي زا ضد ا ملد عي عليهم من ذوي البشرة السمراء .مثال اخر علي ذلك هو اداة »بريدبول« ،وهي اداة للتنب و بالجرايم وقد استخدم ت في الولايات املتحدة جريمة لتوقع احتمالية حدوث في مناطق معي نة من املدن وللتوصية بتخصيص موارد الشرطة )علي سبيل املثال ،اين التوقعات. يجب ان يجري ضباط الشرطة عمليات التفتيش والتجوال( استنادا الي هذه وتركزت املخاوف في هذا الصدد في ان يكون النظام متحي زا ضد الاحياء الفقرية واحياء ا مللو نني او ان تودي املراقبة الامنية ا ملفرطة الي كسر الثقة بني الناس في تلك املناطق ،مما تتحقق ذاتيا ).(Kelleher and Tierney 2018 يح و ل توقع حدوث الجريمة الي نبوء ة يقتصر علي العدالة الجنايية او ا ملراقبة الامنية؛ بل يمكن ان يعني ايضا، ولكن التحي ز لا لتحيزات ضد هم اذا صن فهم الذكاء علي سبيل املثال ،تع رض مستخدمي خدمات الانترنت تصنيفا سييا. الاصطناعي التحيز ومعني الحياة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 116, "content": "قد ينشا التحي ز بعد ة ط ر ق في جميع مراحل التصميم والاختبار والتطبيق .واذا ما ر كزنا علي مرحلة التصميم ،فسنجد ان الت حي ز قد يظهر في اختيار مجموعة البيانات التي سيتم التدريب عليها؛ وفي مجموعة البيانات التي سيتم التدريب عليها نفسها، والتي قد تكون غري ممثلة او غري كاملة ،وفي الخوارزمية ،وفي مجموعة البيانات التي يتم ادخالها الي الخوارزمية بعد تدريبها ،وفي القرارات القايمة علي الارتباطات الزايفة الاوسع .علي )انظر الفصل السابق( ،وفي املجموعة التي تنشي الخوارزمية ،وفي املجتمع رجال سبيل املثال ،قد لا تكون مجموعة البيانات ممث لة للسكان )كان تكون م بنية علي امريكيني بيض( ولكنها تستخدم للتنبو مع السكان كك ل )الرجال والنساء من خلفيات عرقية متنو عة( .يمكن ايضا ان يكون التحي ز متع ل قا بالاختلافات بني البلدان .فكثري من الشبكات العصبية العميقة ا ملستخدمة في التع رف علي الصور تد رب علي مجموعة البيانات ا ملح د دة »ايمدجنت« ،ImageNetالتي تحتوي علي كمي ة غري متكافية من البيانات من ري من الولايات املتحدة ،في حني ان بلدان مثل الصني والهند ،ال لتني تمثلان جزءا اكبر بكث سكان العالم ،تسهمان بنسبة صغرية فقط ) .(Zou and Schiebinger 2018وهذا قد وبشكل عام ،يمكن ان تكون مجموعات البيانات يودي الي تحي ز مجموعة البيانات ثقافيا. كاملة او ذات جودة رديية ،مما قد يودي الي وجود تحي ز .كذلك قد يكون التنب و م بنيا غري علي قد ر ضييل من البيانات ،علي سبيل املثال في حالة التنب و بجرايم القتل :حيث لا يوج د كمثال اخر ،يشعر هذا الكم الكبري من جرايم القتل ،مما يجعل التعميم ام را اشكاليا. بعض الباح ثني بالقلق ازاء نقص التنو ع في ف رق تطوير الذكاء الاصطناعي وعلم البيانات؛ رجالا ب يضا من البلدان الغربية حيث يكون معظم علماء الكمبيوتر ومهندسي الكمبيوتر تتراوح اعمارهم ما بني 20عام ا و 40عام ا ،وقد تنعكس تجاربهم الشخصية واراوهم، وبالتاكيد تحي زاتهم في العملية ،وهو ما قد يوثر سلبا علي الاشخاص الذين لا تنطبق عليهم هذه الاوصاف ،مثل النساء ،والاشخاص ذوي الاعاقة ،وكبار السن ،والاشخاص ا مللونني ،والاشخاص من البلدان النامية. قد تكون البيانات متحيزة مارسة مجموعات معينة؛ لان هناك تحي زا في م ايضا ضد بشكل عام .علي سبيل املثال ،ثمة ادعاءات بان مجال بشكل خاص او في املجتمع معينة بيانات من املرضي الذكور ،وبالتالي فانه متحي ز ،كذلك بشكل رييسي الطب يستخدم بشكل اوسع .اذا كانت هناك التحي ز ضد الاشخاص ا مللو نني وهو يعتبر سايدا في املجتمع الخوارزمية تستخدم مثل هذه البيانات ،فان النتايج ستكون ايضا متحيزة .وكما ورد اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 117, "content": "في مقال مجلة »نيتشر« الافتتاحي عام :2016التحي ز في املدخلات يودي الي تحي ز في ا ملخرجات .وقد تبني سمات التحي ز من خلال يكتسب ايضا ان تع لم الالة يمكن ان استخدام البيانات النصي ة من شبكة الويب العاملية ،حيث تعكس هذه البيانات اللغوية الثقافة الانسانية اليومية ،بما فيها من تحيزات )Caliskan, Bryson, and Narayanan .(2017علي سبيل املثال ،قد تحتوي متون اللغات نفسها علي تحيزات جنسية .وا ملثري للقلق في هذه الحالة ان الذكاء الاصطناعي ربما يساعد في استمرار هذه التحي زات ،مما بشكل اكبر الجماعات التي كانت تعاني من التهميش دايم ا .يمكن ايضا ان يظهر يضر التحيز اذا كان هناك ارتباط ولكن لا يوجد سبب .علي سبيل املثال ،في مجال العدالة الجنايية مرة اخري :قد تستنتج الخوارزمية انه اذا كان احد والدي ا ملد عي عليه قد اودع السجن ،فان هذا ا ملد عي عليه من ا ملرج ح ان يودع السجن ايضا .حتي لو كان هذا الارتباط قايم ا وحتي لو كان الاستنتاج تنبويا ،يبدو انه من غري العدل ان يحصل هذا ا ملد عي عليه علي عقوبة اشد؛ نظ را الي عدم وجود علاقة سببية ).(House of Commons 2018 واخريا ،يمكن ايضا ان ينشا التحي ز بسبب ان صانعي القرارات من البشر يثقون في دقة توصيات الخوارزميات اكثر مما ينبغي ) (CDT 2018ويتجاهلون املعلومات الاخري او لا يعتمدون علي ح كمهم الشخصي بما فيه الكفاية .علي سبيل املثال ،قد يعتمد القاضي اعتمادا كليا علي الخوارزمية ولا ياخذ في اعتباره العناصر الاخري .وكما هو الحال دايم ا مع الذكاء الاصطناعي وغريه من تقنيات الاتمتة ،تلعب القرارات والتفسريات البشرية دو را مهم ا ،وهناك دايم ا خطر الاعتماد الزايد علي التكنولوجيا. ومع ذلك ،ليس من الواضح ما اذا كان من ا ملمكن تجن ب التحي ز من الاساس ،او حتي ما اذا كان يجب تجن به ،فاذا كان من الواجب تجن به ،فما التكلفة التي يمكن تحم لها في سبيل ذلك .علي سبيل املثال ،اذا كان تغيري خوارزمية تعلم الالة لتقليل احتمالات التحي ز سيكون علي حساب جعل توقعاتها اقل دقة ،فهل يجب علينا تغيريها؟ قد نضطر الي الاختيار ما بني فعالية الخوارزمية من ناحية ومكافحة التحي ز من ناحي ة اخري .هناك ايضا مشكلة في انه اذا ت م تجاهل سمات معينة او تجاهلها مثل العرق ،فان انظمة تع لم الالة قد تحدد ما يعرف بموشرات هذه السمات ،مما يودي ايضا الي التحي ز .علي سبيل املثال ،في حالة الع رق ،قد يكون من ا ملمكن ان تختار الخوارزمية متغريات اخري مرتبطة بالع رق مثل الرمز البريدي .وهل من املمكن وجود خوارزمية خالية تمام ا من التحيز؟ لا يوج د توافق بني الفلاسفة او حتي في املجتمع بشان العدالة الكاملة او الانصاف الكامل. التحيز ومعني الحياة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 118, "content": "علاو ة علي ذلك ،وكما اشر نا في الفصل السابق ،فان مجموعات البيانات ا ملستخدمة من ق بل الخوارزميات هي تجريدات عن الواقع وهي نتاج اختيارات بشرية ،ومن ث م فهي لا تكون يتوغل التحيز في عا لمنا ومجتمعاتنا؛ محايدة ابدا ).(Kelleher and Tierney 2018 وبالتالي ،علي الرغم من انه يمكن القيام بالكثري ويجب القيام بالكثري لتقليل التحيز ،فان نماذج الذكاء الاصطناعي لن تخل و تمام ا من التحيز ).(Digital Europe 2018 علاو ة علي ذلك ،يبدو بالتاكيد ان الخوارزميات ا ملستخدمة في اتخاذ القرار دايم ا ما تكون متحيزة من منطلق كونها تمييزية؛ اذ انها مصممة للتمييز بني مختلف الاحتمالات. علي سبيل املثال ،في عملية التوظيف ،يفترض ان يكون فحص الس ري الذاتية ذا طابع متحيز وتمييزي تجاه سمات املرشحني التي تناسب الوظيفة .ويكمن السوال الاخلاقي والسياسي فيما اذا كان هناك تمييز معني غري منصف وغري عادل .ولكن مرة اخري، تختلف وجهات النظر بشان ما هو منصف وما هو عادل .وهذا يجعل قضية التحي ز تقنية ولكنها ايضا مرتبطة باملناقشات السياسية حول الانصاف والعدالة .علي ليست فقط سبيل املثال ،هل من العدل ممارسة التمييز الايجابي او التدابري الايجابية ،التي تحاول يجب محو اثر التحي ز عن طريق التحيز الايجابي مع الافراد او الجماعات املحرومة؟ هل ان تكون العدالة عمياء ومحايدة — وبالتالي هل يجب ان تكون الخوارزميات عمياء ازاء الع رق ،علي سبيل املثال — ام ان العدالة تعني تمييز اوليك ا ملحرومني بالفعل من اي ميزات ،مما يصل بنا في النهاية الي نوع من التحي ز والتمييز )التصحيحي(؟ وهل يجب علي السياسة في السياق الديمقراطي ان تعطي الاولوية لحماية مصالح الاغلبية ام تركز علي تعزيز مصالح الاقلية ،حتي وان كانت اقلية محرومة قديم ا او حاليا؟ يجب ان تكون العدالة عمياء ومحايدة ام ان العدالة تعني تمييز اوليك املحرومني بالفعل من هل اي ميزات؟"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 119, "content": "وهذا يقودنا الي السوال حول الاجراءات .حتي اذا اتفقنا علي وجود تحي ز ،فهناك طرق مختلفة للتعامل مع املشكلة .وتشمل هذه الطرق التكنولوجية وكذلك الاجراءات يجب علينا اتخاذها؛ ا ملجتمعية والسياسية والتعليم .وثمة خلاف حول الاجراءات التي اذ انها تعتمد مرة اخري علي مفهومنا للعدالة والانصاف .علي سبيل املثال ،تثري قضية يجب ان نقبل العالم كما هو ام التدابري الايجابية قضية اكثر عمومية حول ما اذا كن ا اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 120, "content": "بطريقة من شانها تجن ب استمرار نحو فع ال اننا يجب ان نش كل عاملنا ا ملستقبلي علي يجب ان نستخدم مجموعة الظلم الذي كان مستشريا في املاضي .بعض الناس ي رون اننا بيانات تعكس العالم الواقعي .وقد تمثل البيانات التحيزات املوجودة في املجتمع وقد تنشي الخوارزمية نموذج ا من التحي زات املوجودة لدي الناس الان ،ولكن هذه ليست مشكلة يجب ان يقلق بشانها ا ملطورون .بينما يري اخرون ان مثل هذه املجموعة من قرون من التحيز ،وان هذا التحي ز والتمييز غري عادل البيانات موجودة فقط بسبب يجب تغيري تلك املجموعة من البيانات او الخوارزمية من اجل تعزيز وظالم ،وعليه فانه التدابري الايجابية .علي سبيل املثال ،في استجاب ة الي نتايج خوارزمية البحث في جوجل التي ببساطة تبدو متحيز ة ضد اساتذة الرياضيات الاناث ،يمكن للمرء ان يقول ان هذا يعكس حقيقة العالم )وان هذا هو بالضبط ما يجب ان تفعله خوارزمية البحث(؛ او يمكن ان اولوية لصور اساتذة الرياضيات الاناث من اجل تغيري التصور نجعل الخوارزمية تعطي وربما تغيري العا لم ) .(Fry 2018ويمكن ايضا ان نحاول انشاء ف رق تطوير تكون اكثر بشكل افضل الفيات التي من املحتم ل تنوع ا من حيث الخلفية والراي والتجربة ،وتمثل ان تتاثر بالخوارزمية ).(House of Commons 2018 لن يصح الراي القايل بانها تعكس الواقع اذا كانت مجموعة البيانات التي سيتم بيانات قديمة لا تعكس الوضع التدريب عليها لا تعكس العالم الواقعي وتحتوي علي الحالي .كما ان القرارات املبنية علي هذه البيانات تساعد بالفعل في استمرار التمييز الذي كان موجودا في املاضي بدلا من الاستعداد للمستقبل .وعلاو ة علي ذلك ،ثم ة اعتراض اخر علي الراي القايل بانها تعكس الواقع وهو انه حتي اذا كان النموذج يعكس العالم واضرار اخري قد تقع علي افراد او الواقعي ،فان هذا يمكن ان يودي الي تدابري تمييزية مجموعات بعينها .علي سبيل املثال ،قد ترفض شركات الايتمان منح قروض الي ا ملتقدمني علي اساس مح ل الاقامة ،او قد تفرض املواقع الالكترونية رسوم ا اكبر علي بعض العملاء مقارنة بغريهم استنادا الي ملفات العملاء التعريفية التي انشاها الذكاء الاصطناعي. كذلك يمكن ان تتبع امللفات التعريفية الافراد عبر النطاقات املختلفة )Kelleher and شكل .(Tierney 2018ويمكن ان تربط وظيفة الاكمال التلقايي البسيطة في ظاهرها ب بجريمة ما )الامر الذي قد يود ي الي عواقب وخيمة( ،حتي اذا كانت خوارزمية خطا اسم ك بشكل صحيح؛ بمعني ان معظم الناس يريدون البحث الكامنة وراءها تعكس العا لم البحث عن اسم املجرم وليس عن اسمك .وثم ة مثال اخر علي التحي ز ،ولكنه ربما ليس التحيز ومعني الحياة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 121, "content": "واضح ا بالقدر نفسه :فنظام استرجاع املوسيقي ا ملستخدم في خدمات مثل »سبوتيفاي«، توصيات بناء علي السلوك الحالي )املسارات املوسيقية التي ينقر عليها معظم الذي يقد م الناس( ،قد يتحي ز ضد املوسيقي واملوسيقيني الذين هم اق ل شيوع ا .وحتي اذا كان النظام العيش وضع لا يستطيع فيه بعض املوسيقيني يعكس العا ل م الواقعي ،فان هذا يودي الي من موسيقاهم ويجعل بعض املجتمعات تشع ر بعدم التقدير وعدم الاحترام. حني ان هذه حالات واضحة من التمييز الذي ينطوي علي مشكلات ،الا مرة اخري ،في يجب ان نسال دايم ا :هل يمكن ان يكون التمييز في عادلا ام لا؟ واذا كان حالة معينة اننا غري عادل ،فما الاجراء الذي سيت خذ حياله وم ن الذي سيتخ ذه؟ علي سبيل املثال ،ما الذي يمكن ان يفعله علماء الكمبيوتر حياله؟ هل يجب ان يجعلوا مجموعات البيانات التي يتم بيانات ومجموعات بيانات »مثالية« كما اقترح التدريب عليها اكثر تنوع ا ،وربما ينشيون اريك هورفيتز من شركة مايكروسوفت )(Surur 2017؟ ام يجب ان تعكس مجموعات البيانات العا لم؟ هل يجب علي املطو رين تضمني التمييز الايجابي في خوارزمياتهم ،ام يجب عليهم انشاء خوارزميات »عمياء«؟ ان كيفية التعامل مع التحيز في الذكاء الاصطناعي ليست مسالة تقنية فحسب؛ بل هي مسالة سياسية وفلسفية .ان املسالة تتع لق بنوع الواجب علينا ان نحاول تغيريه ،واذا كان الامر املجتمع والعا لم الذي نريده ،واذا كان من كذلك ،فما هي الطرق املقبولة والعادلة لتغيريه .انها ايضا مسالة تتع لق بالبشر بقدر ما تتعلق بالالات :هل نعتقد ان اتخاذ القرارات البشرية عادل ومنصف ،واذا لم يكن الامر كذلك ،فما دور الذكاء الاصطناعي؟ ربما يمكن ان يع لمنا الذكاء الاصطناعي شييا عن البشر ومجتمعاتهم من خلال الكشف عن تحي زاتنا .وقد تكشف مناقشة اخلاقيات الذكاء الاصطناعي الاختلال الكبري في موازين القوي الاجتماعية واملوسسية. وهكذا تصل املناقشات حول اخلاقيات الذكاء الاصطناعي الي ع مق قضايا مجتمعية وسياسية باسيلة فلسفية حول العدالة والانصاف ،واسيلة فلسفية وعلمية حساسة ترتبط حول البشر ومجتمعاتهم .واحدة من هذه القضايا هي مستقبل العمل. مستقبل العمل ومعني الحياة املتوقع ان تحو ل الاتمتة التي تعتمد علي الذكاء الاصطناعي اقتصاداتنا ومجتمعاتنا من فضلا عن مستقبل الحياة تساولات حول مستقبل العمل ومعناه، بشكل جذري ،مما يثري البشرية ومعناها. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 122, "content": "اولا ،هناك م خاوف من ان يودي الذكاء الاصطناعي الي تدمري الوظايف ،الامر الذي قد يودي الي البطالة الشاملة .وهناك ايضا سوال حول نوع الوظايف التي يستطيع الذكاء ستقتصر علي وظايف ذوي الياقات الزرقاء )العمالة اليدوية(، الاصطناعي تو ليها :وهل كما يط لق عليها ،ام ان هناك وظايف اخري يمكن ان يتولاها؟ يتنب ا تقرير شهري لك ل من بنيديكت فري ومايكل اوزبورن ) (2013بان 47في املاية من جميع الوظايف في الولايات املتحدة يمكن اتمتتها .وتحمل تقارير اخري ارقام ا اق ل اثار ة للجدل ،ولكن معظمها يتنبا بان فقدان الوظايف سيكون كبريا .ويتفق العديد من الكت اب علي ان الاقتصاد قد تاثر بشكل كبري ) ،(Brynjolfsson and McAffee 2014بما في ذلك التغريات وسيظ ل يتاثر امللحوظة التي حدثت في التوظيف الان والتي ستحدث في املستقبل .ومن ا مل توقع ان يودي العاملني ،ليس فقدان الوظايف بسبب الذكاء الاصطناعي الي التاثري علي جميع انواع بشكل متزايد علي اداء فقط ذوي الياقات الزرقاء ،حيث اصبح الذكاء الاصطناعي قاد را املهام ا ملعرفية ا ملعقدة .اذا كان هذا صحيح ا ،فكيف يمكننا ان نع د الاجيال الجديدة لهذا املستقبل؟ ماذا يجب ان يتع لموا؟ وماذا يجب ان يفعلوا؟ وماذا لو كان الذكاء الاصطناعي يفيد بعض الاشخاص اكثر من غريهم؟ بهذا السوال الاخري ،نعود مر ة اخري الي قضايا العدالة والانصاف ،التي شغلت سيوسع تفكري الفلاسفة السياسيني لعصور .علي سبيل املثال ،اذا كان الذكاء الاصطناعي عادلا ،فما الذي يمكن الفجوة بني الاثرياء والفقراء ،فهل هذا امر عادل؟ واذا لم يكن القيام به حيال ذلك؟ يمكن ايضا صياغة املشكلة من حيث عدم املساواة )هل سيزيد الذكاء الاصطناعي من عدم املساواة في املجتمعات وفي العالم؟( او من حيث التع رض الي التاثريات السلبية :هل سيحظي اصحاب الوظايف والاثرياء وا ملتع لمون في الدول املتقدمة تكنولوجيا بفوايد الذكاء الاصطناعي بينما سيكو ن العاطلون عن العمل والفقراء والاقل عرضة لتاثرياته السلبية )(Jansen et al. 2018؟ وللتعامل تعليم ا في الدول النامية اكثر مع قضية اخلاقية وسياسية اخري اكثر حداثة :ماذا عن العدالة البييية؟ ما هو تاثري الذكاء الاصطناعي علي البيية وعلاقتنا بالبيية؟ ماذا يعني »الذكاء الاصطناعي ا ملستدام«؟ هناك ايضا سوال حول ما اذا كانت اخلاقيات الذكاء الاصطناعي وسياساته مرتبطة ب قيم البشر ومصالحهم فقط ام لا) .انظر الفصل الثاني عشر(. التحيز ومعني الحياة بشكل املتوقع ان تحو ل الاتمتة التي تعتمد علي الذكاء الاصطناعي اقتصاداتنا ومجتمعاتنا من جذري ،مما يثري اسيلة حول مستقبل العمل ومعناه ،فضلا عن مستقبل الحياة البشرية ومعناها."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 123, "content": "ثمة سوال تفترض اخر ذو طابع وجودي يتع لق بمعني العمل والحياة البشرية . املخاوف من فقدان الوظايف ان العمل هو القيمة الوحيدة واملصدر الوحيد للدخل واملعني. ولكن اذا كانت الوظايف هي الشيء الوحيد ذو القيمة ،فربما علينا عندي ذ خلق املزيد من الامراض العقلية ،ورفع معدل التدخني ،وزيادة معدلات السمنة؛ لان هذه املشكلات هي التي تودي الي خلق وظايف 1 .ونحن لا نريد ذلك .اذن فمن الواضح اننا نومن بان هناك قيم ا اخري اهم من خلق الوظايف في ح د ذاته .وملاذا نعتمد علي الوظايف لتحقيق الدخل بطريقة مختلفة .يمكننا ان نفصل بني واملعني؟ يمكننا تنظيم مجتمعاتنا واقتصاداتنا ودخلا .فهناك الكثريون يقومون بالعمل »عملا« العمل والدخل ،او بالاحري ما نعتبره مج انا ،علي سبيل املثال في املنزل ورعاية الاطفال واملسنني .فلماذا لا يعتبر هذا »عملا«؟ قيمة واهمية من غريه من الاعمال؟ وملاذا وملاذا يكون القيام بذلك النوع من العمل اق ل لا نجعله مصد را للدخل؟ علاو ة علي ذلك ،يعتقد بعض الاشخاص ان الاتمتة يمكن ان متعة وابداع ا ،ليس تتيح لنا املزيد من الرفاهية والراحة .ربما يمكننا القيام باشياء اكثر بالضرورة في شكل وظيفة .يمكننا ،بعبار ة اخري ،الاعتراض علي فكرة ان الحياة ذات عمل مدفوع الاجر ومنظم م املعني هي فقط حياة ت سبقا من ق بل الاخرين او قضي في اداء عمل يتم في اطار ما يط لق عليه »التوظيف الذاتي« .ربما يمكننا فرض تدابري معي نة مثل تحديد »دخل اساسي« لنسمح للجميع بفعل ما ي رونه ذا معني وقيمة .وبالتالي ،ردا علي مشكلة مستقبل العمل ،يمكننا ان نفكر فيما يجعل العمل ذا معني ،وفي نوع العمل الذي ينبغي للبشر عمله )او بالاحري يسم ح لهم بعمله( ،وفي كيفية اعادة تنظيم مجتمعاتنا واقتصاداتنا بحيث لا يرتبط الدخل بالوظايف والتوظيف. علي الرغم من ك ل ما قيل ،فان الافكار اليوتوبية حول املجتمعات ا مل رفهة وغريها موجات من تتحقق حتي الان .لقد شهدنا بالفعل عدة من الجنان ما بعد الصناعية لم الاتمتة بدءا من القرن التاسع عشر حتي الان ،ولكن الي اي مدي ح ر رتنا الالات واعتقت بعض الاعمال ا ملضجرة والخطرية ،ولكنها استخدمت ايضا نيابة عنا رقابنا؟ ربما تو لت للاستغلال ولم ت بشكل جذري الهيكل اله رمي للمجتمع .وقد استفاد بعض الناس غري اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 124, "content": "استفاد ة هايلة من الاتمتة ،بينما لم يفعل اخرون .وربما تكون الاوهام حول عدم وجود فضلا عن وظايف هي رفاهية محفوظة فقط لاوليك الذين كانوا في جانب ا ملستفيدين. ذلك ،هل ح ر رتنا الالات لنعيش حيا ة ذات معني اكثر من ذي قبل؟ ام انها تهد د امكانية هذه الحياة نفسها؟ هذا نقاش طويل ولا توج د اجابات سهلة عن هذه الاسيلة ،ولكن املخاوف التي لدينا تعد اسبابا وجيهة لان نتش كك علي الاقل في العالم الجديد الجميل نبوءات الذكاء الاصطناعي. الذي رسم ته لنا استغلالا يجب علاو ة علي ذلك ،قد لا يكون العمل بالضرورة شقاء يجب تجن به او مقاومته؛ فثمة وجهة نظر اخري تشري الي ان العمل له قيمة في ح د ذاته ،وانه يمنح العامل التواصل الاجتماعي مع الاخرين ،والانتماء هدفا ومعني ،وان له فوايد متنوعة مثل الي شيء اكبر ،والتمت ع بالصحة ،والحصول علي ف رص ملمارسة املسيولية )Boddington .(2016فاذا كان هذا هو الحال ،فلربما كان علينا ان نحتف ظ بالعمل للبشر؛ او علي الاقل ببعض انواع العمل ،كالعمل ذي ا ملغزي الذي ي فرصا لتحقيق هذه الفوايد .او وفر ربما علينا ان نحتف ظ علي الاقل ببعض املهام .وليس علي الذكاء الاصطناعي ان ياخذ يتولي بعض املهام ذات القيمة الاقل .ويمكننا علي عاتقه وظايف باكملها ،ولكن يمكن ان ان نتعاون مع الذكاء الاصطناعي .علي سبيل املثال ،يمكننا اختيار عدم تفويض العمل يقترحه بوستروم( او يمكننا اختيار التعاون الابداعي الي الذكاء الاصطناعي )وهو ما مع الذكاء الاصطناعي للقيام باشياء ابداعية .ما يثري القلق في هذا الصدد هو انه اذا ستتولي القيام بك ل ما نقوم به في حياتنا الان ،فلن يتبقي لنا شيء نقوم كانت الالات به ،وسنجد حياتنا بلا معني .ومع ذلك ،فنحن نقول »اذا«؛ ويجب ان نضع في اعتبارنا الش ك فيما يمكن ان يقوم به الذكاء الاصطناعي )انظر الفصل الثالث( وحقيقة ان العديد »عملا« ولكنها ذات مغ زي كبري ،وبالتالي فاننا سنحتفظ علي الارجح من انشطتنا ليست بالكثري لنقوم به .علي هذا ،يمكننا ان نقول ان السوال الان ليس ماذا سيفعل البشر تتولي الالات القيام بجميع اعمالهم وانشطتهم ،ولكن اي املهام نريد او نحتاج الي عندما الاحتفاظ بها للبشر ،وما هي الادوار التي يمكن ان يتولاها الذكاء الاصطناعي ،ان كان سيتولي اي ادوار ،لدعمنا في هذه املها م بطرق اخلاقية ومقبولة اجتماعيا. ختام ا ،تدعونا اخلاقي ات الذكاء الاصطناعي الي التفكري في ماهية املجتمع الخ ري والعادل ،وماهية الحياة البشرية ذات املعني ،وماهية الدور الذي تضطلع به التكنولوجيا والذي يمكن ان تضطلع به فيما يتع لق بك ل ذلك .ويمكن ان تكون الفلسفة ،بما فيها التحيز ومعني الحياة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 125, "content": "الفلسفة القديمة ،مصدر الها م للتفكري في تقنيات اليوم واملشكلات التي تجلبها بالفعل والتي يحتم ل ان تجلبها من الناحية الاخلاقية وا ملجتمعية .فاذا كان الذكاء الاصطناعي يثري هذه الاسيلة القديمة حول الحياة الجيدة ذات املعني ،فلدينا مصادر في مختلف التقاليد الفلسفية والدينية يمكن ان تساعدنا في التعامل مع هذه الاسيلة .علي سبيل املثال، كما اقترحت شانون فالور ) ،(2016فان تقليد اخلاقيات الفضيلة الذي وضعه ارسطو وكونفوشيوس وفلاسفة قدماء اخرون ربما ما زال يستطيع ان يساعدنا اليوم للتفكري في معني ازدهار الانسان وكيف ينبغي ان يكون في عصر التكنولوجيا .وبعبار ة اخري ،قد توج د لدينا بالفعل اجابات عن هذه الاسيلة ،ولكن علينا القيام ببعض العمل للتفكري في معني الحياة الجيدة في سياق التكنولوجيا الحديثة ،بما في ذلك الذكاء الاصطناعي. واجه فكرة تطوير »اخلاقيات الذكاء الاصطناعي للحياة الجيدة« ومع ذلك ،ت بشكل عا م عدة مشكلات .تتمث ل املشكلة واخلاقيات الذكاء الاصطناعي للعا لم الواقعي الاولي في السرعة .يفترض نموذج اخلاقيات الفضيلة الذي ورثته الفلسفة الغربية من يتغري ببطء ولا ارسطو مجتمع ا بسرعة كبرية ،ويمتلك فيه الناس تتغري فيه التكنولوجيا وقتا لتع لم الحكمة العملية؛ ولذا ،فانه من غري الواضح كيف يمكن استخدامه للتعامل التغري ) (Boddington 2016ومع التطو ر السريع للتقنيات مثل الذكاء مجتمع سريع مع الاصطناعي .هل ما زال لدينا الوقت الكافي للاستجابة ولتطوير الحكمة العملية ونقلها فيما يتع لق باستخدام تقنيات مثل الذكاء الاصطناعي؟ هل تاتي الاخلاقيات بعد فوات الاوان؟ عندما تنشر بومة مينريفا جناح يها )التي ترمز للحكمة عند اليونان( ،ربما يكون شكل العالم قد تغري تمام ا ولم يع د بالامكان التعرف عليه .فما هو دور مثل هذه الاخلاقيات ،وماذا ينبغي ان يكون دورها في سياق التطو رات التي تحدث في العالم الواقعي؟ اما املشكلة الثانية ،فنظ را الي تنوع وتعدد وجهات النظر في هذا الامر داخل املجتمعات ،والاختلافات الثقافية بني املجتمعات ،فان الاسيلة الخاصة بماهية الحياة نحو مختلف في الجيدة ذات املعني في ظل وجود التكنولوجيا يمكن الاجابة عنها علي الاماكن والسياقات ا ملختلفة ،وهي تخضع ،من الناحية العملية الي كل انواع العمليات السياسية التي قد تنتهي او لا تنتهي بالتوافق .والاعتراف بهذا التنو ع والتعد د قد يودي الي نهج يميل الي التعد دية .كما يمكن ان ياخذ شكل النسبية .وقد اثارت الفلسفة خاصة ما يع رف بمدرسة ما بعد الحداثة ،الكثري ونظرية املجتمع في القرن العشرين، اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحيز ومعنى الحياة التحيز ً", "section_path": ["الفصل التاسع", "التحيز ومعنى الحياة التحيز ً"], "page": 126, "content": "سياق جغرافي من الشكوك حول الاجابات التي يزع م كونها عاملية في حني انها نشات من وتاريخي وثقافي معني )من »الغرب« ،علي سبيل املثال( وانها مرتبطة بمصالح وعلاقات التوافق من قوة معينة .كما اثريت شكوك حول ما اذا كانت السياسة يجب ان تهدف الي التوافق الاساس )انظر اعمال شانتال موف ،علي سبيل املثال ،موف (2013؛ وما اذا كان مرغوبا فيه دايم ا ،ام ان الصراع الشرس حول مستقبل الذكاء الاصطناعي يمكن ان يكون له بعض الفوايد؟ وعلاو ة علي ذلك ،هناك مشكلة اخري تتعلق بالهيمنة :فالتفكري في الاخلاقيات في العالم الحقيقي يعني التفكري ليس فقط فيما يجب القيام به فيما يتعلق بالذكاء الاصطناعي ولكن ايضا فيم ن سيقرر ،وم ن يجب عليه ان يقرر ،مستقبل الذكاء الاصطناعي وبالتالي مستقبل مجتمعنا .ودعونا نفكر مع ا مرة اخري في قضايا الحكم الشمولي وهيمنة الشركات الكبرية .واذا رفضنا الحكم الشمولي والبلوتوقراطية )حكم الاثرياء( ،فماذا يعني اتخاذ قرار ديموقراطي بشان الذكاء الاصطناعي؟ ما هو نوع املعرفة املتعلق بالذكاء الاصطناعي الذي يحتاجه السياسيون واملواطنون؟ اذا كان هناك فهم ضعيف للغاية للذكاء الاصطناعي ومشكلاته املحتم لة ،فاننا نواجه خطر التكنوقراطية او ببساطة عدم وجود سياسة للذكاء الاصطناعي علي الاطلاق. ومع ذلك ،كما يوضح الفصل التالي ،يبدو ان واحدة علي الاقل من العمليات السياسية املتعلقة بالذكاء الاصطناعي التي ظهرت موخ را جاءت في الوقت املناسب .وتلك هي صنع ظهر سياسات خاصة بالذكاء الاصطناعي ،وهي عملية استباقية ،وتهدف الي التوافق ،وت درجة متزايدة من التقارب ،ويبدو انها تلتزم بنوع من العاملية بلا خجل ،وتعتمد علي املعرفة الخبرية ،وتزعم — ولو علي الاقل شفهيا — احترام مبادي الديمقراطية ،وخدمة الصالح العام واملصلحة العامة ،ومشاركة جميع الاطراف ا ملعنية."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 127, "content": "السياسات المقترحة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 128, "content": "يتعني علي صانعي السياسات الاجابة عنها ما يجب القيام به واسيلة اخري نظ را الي املشكلات الاخلاقية ا ملرتبطة بالذكاء الاصطناعي ،فانه من الواضح ان شييا ما يجب القيام به .ولذا ،تتضم ن معظم مبادرات السياسات ا ملتعلقة بالذكاء الاصطناعي اخلاقيات الذكاء الاصطناعي .وجدير بالذكر ان هناك الكثري من املبادرات في هذا املجال يجب القيام به ،وما املسار الذي في الوقت الحالي .ومع ذلك ،ليس من الواضح بالضبط ما يجب ات خاذه .علي سبيل املثال ،ليس واضح ا كيفية التعامل مع مشكلة الشفافية او التحي ز، نظ را الي التقنيات نفسها ،والتحي ز الذي يعاني منه املجتمع بالفعل ،والاراء ا ملتباينة حول العدالة والانصاف .وهناك ايضا العديد من التدابري ا ملمكن اتخاذها :اذ يمكن ان تعني السياسة التنظي م من خلال اصدار القوانني واللوايح ،علي سبيل املثال ،الانظمة القانونية، ولكن هناك ايضا استراتيجيات اخري قد تكون متصلة او غري متصلة بالانظمة القانونية، مثل التدابري التكنولوجية ،وقواعد الاخلاق ،والتعليم .ولا يقتصر التنظيم علي القوانني ولكنه ايضا معايري مثل معايري الايزو .وعلاوة علي ذلك ،هناك يتضمن ايضا انواع اخري من الاسيلة التي يجب القيام يتعني الاجابة عنها في السياسات املقترحة؛ فالامر ليس فقط ما به ،ولكن يجب القيام به ،وما مقدار ما يجب القيام به، ايضا ملاذا يجب القيام به ،ومتي وم ن يجب عليه ان يقوم به ،وما هي طبيعة املشكلة وم داها ودرجة خطورتها والحاحها. اولا :من ا ملهم تبرير التدابري املقترحة .علي سبيل املثال ،قد تستند السياسة ا ملقترحة تعتمد علي اقتراح بالتقليل من اتخاذ القرارات التي الي مبادي حقوق الانسان لتبرير خوارزميات متحيزة .ثانيا :استجابة الي التطو ر التكنولوجي ،غالبا ما تاتي السياسة بعد فوات الاوان ،عندما تكون التكنولوجيا قد توغلت بالفعل في املجتمع ودخلت في ك ل"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 129, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 130, "content": "شيء . يكتمل تطوير التكنولوجيا بدلا من ذلك ،يمكن ان نحاول وضع سياسة قبل ان يخص الذكاء الاصطناعي ،يمكن القول ان هذا ما زال ممكنا، ويبدا استخدامها .وفيما الي ح د ما ،علي الرغم من ان الكثري من الانظمة املدعومة بالذكاء الاصطناعي موجودة بالفعل حولنا .والبعد الزمني مهم ايضا فيما يتع لق بالنطاق الزمني للسياسة :هل هي م خصصة فقط للسنوات الخمس او العشر املقبلة ،ام تهدف الي ان تكو ن اطار عمل علي املدي البعيد؟ هنا علينا ان نختار .علي سبيل املثال ،يمكن تجاهل التنبوات علي املدي البعيد والتركيز علي املستقبل القريب ،كما تفعل معظم السياسات ا ملقترحة ،او يمكن طرح روية ملستقبل الانسانية .ثالثا :لا يتفق الجميع علي ان ح ل املشكلات يتط لب الكثري من التدابري الجديدة .يزعم بعض الاشخاص واملوسسات ان التشريعات الحالية كافية للتعامل مع الذكاء الاصطناعي .فاذا كان هذا هو الحال ،فانه يبدو ان ا ملشر عني ليسوا في حاجة الي القيام بالكثري ،في حني ان الذين يفسرون القانون والذين يطو رون الذكاء الاصطناعي هم م ن يحتاجون الي العمل الدءوب .ويعتقد اخرون انه يجب ان نعيد التفكري في جوهر املجتمع وموسساته ،بما في ذلك انظمتنا القانونية ،من اجل التعامل مع املشكلات الاساسية واعداد اجيال ا ملستقبل .رابع ا :يجب ان توضح السياسة املقترحة م ن يقتصر هذا علي جهة واحدة وانما اكثر من جهة. الذي يجب ان يتخذ الاجراءات .وقد لا سوالا حول كيفية توزيع عمل تكنولوجي .ويثري هذا فكما راينا ،يشترك الكثريون في اي اساسا هي املسيولة عن اتخاذ اجراءات، املسيولية عن السياسة والتغيري :هل الحكومات اجراءات خاصة بها لضمان ام يجب ،علي سبيل املثال ،علي الشركات والصناعة اتخاذ الذكاء الاصطناعي الاخلاقي؟ وفيما يتع لق بالشركات ،هل يجب مخاطبة الشركات الكبرية فقط ام واملتوسطة الحجم؟ وما هو دور العلماء )ا مل ختصني ايضا الشركات الصغرية بالكمبيوتر( واملهندسني الافراد؟ وما هو دور املواطنني؟ خامسا :تعتمد الاجابة عما يجب القيام به ومقدار ما يجب القيام به ،وعن اسيلة اخري ،علي كيفية تعريف طبيعة املشكلة نفسها وم داها ودرجة خطورتها والحاحها. علي سبيل املثال ،هناك اتجاه في سياسات التكنولوجيا )وفي الواقع ،في اخلاقيات الذكاء مشكلات جديدة في ك ل مكان .ومع ذلك ،كما راينا في الفصل السابق، الاصطناعي( لروية فالعديد من املشكلات قد لا تكون حك را علي التقنيات الجديدة ،ولكنها ربما تكون موجود ة وقت طويل .علاو ة علي ذلك ،كما اظهر النقاش حول التحي ز ، منذ يعتمد ما نقترح القيام به علي كيفية تعريف املشكلة :هل هي مشكلة خاصة بالعدالة ،واذا كانت كذلك ،فما هو السياسات املقترحة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 131, "content": "نوع العدالة ا ملهد دة؟ سيشكل تعريف املشكلة التدابري التي نقترحها .علي سبيل املثال ،اذا تعريف معني للمشكلة .واخريا ،يلعب قد منا تدابري للعمل الايجابي ،فان هذا يستند الي ايضا تعريف الذكاء الاصطناعي دو را في تحديد السياسة املقترحة ونطاقها ،وقد كان هذا ستحسن التعريف دايم ا مثريا للجدل والنقاشات .علي سبيل املثال ،هل من ا ملمكن ومن ا مل ان نميز بوضوح بني الذكاء الاصطناعي والخوارزميات الذكية ا ملستقلة ،او بني الذكاء الاصطناعي وتقنيات الاتمتة؟ جميع هذه الاسيلة تجعل من صنع السياسات ا ملتعلقة بشكل كبري .وبالفعل ،نجد العديد من الاختلافات بالذكاء الاصطناعي ام را قد يثري الجدل والجدالات ،علي سبيل املثال حول مدي الحاجة الي تشريعات جديدة ،وحول املبادي التي يجب الاستناد اليها بالضبط لتبرير التدابري ،وحول مسالة ما اذا كان ينبغي تحقيق توازن بني اخلاقيات الذكاء الاصطناعي والاعتبارات الاخري )مثل تنافسية الشركات والاقتصاد(. درجة ملحوظة من التقا رب. ومع ذلك ،اذا ف كرنا في وثايق السياسة الفعلية ،فسنجد املبادي الاخلاقية والتبريرات لقد اد ي الاحساس الواسع الانتشار بضرورة واهمية التعامل مع التحديات الاخلاقية وا ملجتمعية التي اثارها الذكاء الاصطناعي الي سيل من املبادرات ووثايق السياسات التي لا تع رف فقط بعض املشكلات الاخلاقية ا ملرتبطة بالذكاء الاصطناعي ولكنها تهدف ايضا الي توفري توجيهات معيارية للسياسات .وقد اقترحت سياسات خاصة بالذكاء عنصر اخلاقي من ق بل مجموعة متنوعة من الجهات ،بما في ذلك الاصطناعي تشتمل علي الحكومات والهييات الحكومية مثل اللجان الوطنية للاخلاقيات ،وشركات التكنولوجيا مثل جوجل ،واملهندسني ومنظماتهم املهنية مثل معهد مهندسي الكهرباء والالكترونيات، والهييات الحكومية الدولية مثل الاتحاد الاوروبي ،والجهات غري الحكومية وغري الهادفة للربح ،والباحثني. لقد اد ي الاحساس الواسع الانتشار بضرورة واهمية التعامل مع التحديات الاخلاقية وا ملجتمعية التي اثارها الذكاء الاصطناعي الي سيل من املبادرات ووثايق السياسات."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 132, "content": "اذا راجعنا بعض املبادرات واملقترحات الحديثة ، يتبني ان معظم الوثايق تبدا بتبرير السياسة من خلال توضيح املبادي ،ثم تقدم بعض التوصيات فيما يتعلق باملشكلات اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 133, "content": "الاخلاقية ا ملحددة .وكما سنري ،هذه املشكلات واملبادي شديدة التشابه .وفي كثري من تعتمد املبادرات علي مبادي اخلاقية عامة ومبادي من قانون اخلاقيات املهنة. الحالات، راجع معكم بعض املقترحات. فدعوني ا ترفض معظم املقترحات سيناريو الخيال العلمي الذي تستولي فيه الالات الفايقة وتتولي فيه السيطرة .علي سبيل املثال ،في فترة رياسة اوباما، الذ كاء علي زمام الامور نشرت حكومة الولايات املتحدة تقري را بعنوان »الاستعداد ملستقبل الذكاء الاصطناعي«، صراحة علي ان املخاوف الطويلة الامد بشان الذكاء الاصطناعي الفايق العام تو كد فيه »يجب الا يكون لها تاثري كبري علي السياسة الحالية« )املكتب التنفيذي للرييس ،2016 وبدلا من ذلك ،يتناول التقرير ا ملشكلات الحالية وا مل توقعة في املستقبل القريب التي .(8 يثريها تع لم الالة ،مثل التحي ز ومشكلة انه حتي ا ملطورون قد لا يفهمون نظامهم بما فيه الكفاية لتجن ب مثل هذه العواقب .ويو كد التقرير ان الذكاء الاصطناعي مفيد للابتكار والنمو الاقتصادي ويشد د علي الرقابة الذاتية ،ولكنه يقول ان حكومة الولايات املتحدة لزم الامر. يمكنها مراقبة سلامة التطبيقات وعدالتها ،وتعديل الاطر القانونية اذا علاو ة علي ذلك ،تملك العديد من الدول الاوروبية حاليا استراتيجيات للذكاء هدفا الاصطناعي تتضم ن عنصرا اخلاقيا .ويعد »الذكاء الاصطناعي القابل للتفسري« مشتر كا بني العديد من صانعي السياسات .يقول مجلس عموم اململكة املتحدة )(2018 ان الشفافية وحق التفسري امور اساسية لنتم كن من مساءلة الخوارزميات ،ويجب علي الصناعات والجهات التشريعية التعامل مع مسالة اتخاذ القرارات ا ملتحيزة من ق بل الخوارزميات .كذلك تفحص لجنة مجلس لوردات اململكة املتحدة املختارة ا ملعنية بالذكاء الاصطناعي التداع يات الاخلاقية للذكاء الاصطناعي .وفي فرنسا ،يقترح تقرير تفاقم مشكلات فيلاني العمل نحو تطوير »ذكاء اصطناعي ذي معني« لا يودي الي الاقصاء ،او يزيد من التفاوت الاجتماعي ،او يودي الي مجتمع تح كمنا فيه خوارزميات »صناديق سوداء«؛ اذ يجب ان يكون الذكاء الاصطناعي وصديقا للبيية قابلا للتفسري مجلسا استشاريا وطنيا معنيا بالروبوتات ) .(Villani 2018كما انشات النمسا موخ را لسياسة تستند الي حقوق الانسان ،والعدالة توصيات والذكاء الاصطناعي 1 ،والذي قد م والانصاف ،والاشراك والتضامن ،والديمقراطية واملشاركة ،وعدم التمييز ،واملسيولية، قابل للتفسري و قيم اخري شبيهة .كما توصي ورقتها البيضاء بتطوير ذكاء اصطناعي صراحة ان املسيولية تظ ل علي عاتق البشر؛ ولا يمكن ان يكون الذكاء الاصطناعي وتقول السياسات املقترحة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 134, "content": "مسيولا اخلاقيا ) .(ACRAI 2018كذلك ،فان الهييات واملوتمرات الدولية نشطة للغاية. فقد نشر املوتمر الدولي ملفوضي حماية البيانات والخصوصية اعلانا بشان الاخلاقيات وحماية البيانات في الذكاء الاصطناعي ،ويتضم ن مبادي العدالة ،واملساءلة ،والشفافية والفهم ،والتصميم املسيول ،والخصوصية ا ملتضمنة في التصميم )مفهوم يطالب بمراعاة الخصوصية في جميع مراحل عملية الهندسة( ،وتمكني الافراد ،والح د من التحيز او التمييز وتخفيف اثارهما ).(ICDPPC 2018 يضع بعض صانعي السياسات هدفهم في اطار »الذكاء الاصطناعي الجدير بالثقة«. فعلي سبيل املثال ،تو كد ا ملفوضية الاوروبية ،التي تع د بلا ش ك واحدة من ابرز الهييات العاملية في مجال صنع سياسات الذكاء الاصطناعي ،علي اهمية هذا املصطلح .وفي ابريل مجموعة فريق خبراء رفيع املستوي مع نيا بالذكاء الاصطناعي لوضع ،2018انشات جديدة من ارشادات الذكاء الاصطناعي؛ وفي ديسمبر ،2018اصدر الفريق مسودة نهج في الذكاء الاصطناعي يتمحور حول وثيقة عمل تتضم ن ارشادات اخلاقية تدعو الي الانسان ،والي تطوير ذكاء اصطناعي جدير بالثقة ،يحترم الحقوق الاساسية واملبادي الاخلاقية .وكانت الحقوق املذكورة هي كرامة الانسان ،وحرية الفرد ،واحترام الديمقراطية، والعدالة ،وسيادة القانون ،وحقوق املواطن .اما املبادي الاخلاقية ،فهي الاحسان )فعل الخري( وعدم الحاق الاذي ،والاستقلال )الحفاظ علي وكالة الانسان( ،والعدالة )ان تكون عادلا( ،والقابلية للتفسري )شفافية التنفيذ( .هذه املبادي مالوفة من مجال اخلاقيات علم تفسريات تسلط الضوء علي الاحياء ،ولكن الوثيقة تضيف اليها القابلية للتفسري ،وتتضم ن املشكلات الاخلاقية الخاصة التي يثريها الذكاء الاصطناعي .علي سبيل املثال ،ي فسر مبدا عدم الحاق الاذي علي املطالبة بان خوارزميات الذكاء الاصطناعي يجب ان تتجن ب التمييز، ويجب ان تحمي الفيات الضعيفة مثل الاطفال واملهاجرين. والتلاع ب ،والتوجيه السلبي ، اما مبدا العدالة ،في ومنفذيه فسر علي انه يتضمن مطالبة مطوري الذكاء الاصطناعي بضمان احتفاظ الافراد واملجموعات الاقلية بالتح رر من التحي ز .ويفسر مبدا القابلية للتفسري علي انه يطالب بان تكون انظمة الذكاء الاصطناعي قابلة للتدقيق و»مفهومة من ق بل البشر علي اختلاف مستويات فهمهم وخبرتهم« )European Commission AI خاص بشكل .(HLEG 2018, 10وتحد د النسخة النهايية ،التي صدرت في ابريل ،2019 ان قابلية التفسري لا تتع لق فقط بتفسري العملية التقنية ولكن ايضا بالقرارات البشرية ذات الصلة بها ).(European Commission AI HLEG 2019, 18 اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 135, "content": "في وقت سابق ،اصدرت هيية استشارية اخري تابعة الي الاتحاد الاوروبي ،وهي املجموعة الاوروبية ا ملعنية بالاخلاقيات في العلوم والتقنيات الجديدة بيانا حول الذكاء مقترحة مبادي الكرامة الانسانية ،والاستقلال، الاصطناعي والروبوتات والانظمة ا ملستقلة، واملسيولية ،والعدالة ،واملساواة ،والتضامن ،والديمقراطية ،وسيادة القانون واملساءلة، والامان والسلامة ،وحماية البيانات والخصوصية ،والاستدامة .ويقال ان مبدا الكرامة الانسانية يقتضي اعلام الافراد بما اذا كانوا يتفاعلون م ع الة ام م ع انسان اخر )EGE .(2018كذلك عليك ملاحظة ان الاتحاد الاوروبي لديه بالفعل تشريعات قايمة تتعلق بتطوير الذكاء الاصطناعي واستخدامه .وتهدف لايحة ح ماية البيانات العامة ،التي اعت مدت في مايو ،2018الي حماية جميع مواطني الاتحاد الاوروبي وتمكينهم فيما يتع لق بخصوصية البيانات .وتتضم ن مبادي مثل حق الفرد في نسيان بياناته )يمكن للفرد ان يطلب مسح بياناته الشخصية ووقف معالجة تلك البيانات في املستقبل( وا لخصوصية ا ملتضم نة في التصميم .كما تمنح الافراد املعنيني حق الوصول الي »معلومات ذات معني حول املنطق ا ملضم ن« في اتخاذ القرارات املوتمتة ومعلومات حول »العواقب ا مل توقعة« لمثل هذه املعالجة )البرملان الاوروبي ومجلس الاتحاد الاوروبي .(2016الاختلاف عن وثايق السياسة هو ان هذه املبادي املذكورة هنا تعد متطلبات قانونية .انها بمثابة تشريع املوسسات التي تنتهك لايحة حماية البيانات العامة يمكن تغريمها. مفروض؛ بمعني ان ومع ذلك ،ثمة تساول مطروح عما اذا كانت احكام لايحة حماية البيانات العام ة تكافي الحق الكامل في تفسري القرار ) ،(Digital Europe 2018وبشكل عام ،اذا كانت توفر حماية كافية ضد مخاطر اتخاذ القرار املوتمت )Wachter, Mittelstadt, and Floridi .(2017توفر لايحة حماية البيانات العام ة الحق في الاعلام باتخاذ القرار املوتمت ولكن قرار بع ينه .وهذه ايضا مشكلة فيما يبدو انها لا تطالب بتفسري الاساس املنطقي لاي دراسة اجراها مجلس اوروبا، يتع لق باتخاذ القرار في املجال القانوني .وقد طالبت محاكمة عادلة لجنة من خبراء حقوق الانسان ،بان يكون للافراد الحق في استنادا الي عمل واجراءات قانونية سليمة بشروط يمكنهم فهمها ).(Yeung 2018 تع د املناقشات القانونية ذات اهمي ة بالطبع في املناقشات ا ملتعلقة باخلاقيات الذكاء الاصطناعي وسياسة الذكاء الاصطناعي .وقد ناقش ترينر ) (2019املقارنات بالحيوانات )كيف عوملت وتعامل في القانون وما اذا كانت تتمت ع بحقوق( وراجع عددا من الصكوك القانونية فيما يتعلق بما يمكن ان تعني للذكاء الاصطناعي .علي سبيل املثال ،عند وقوع السياسات املقترحة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 136, "content": "شخص ما ملتزم ا بواجب الرعاية لتجن ب الضرر ،فان مسالة الاهمال تتعلق بما اذا كان وقوع ضرر ،حتي اذا لم يكن الضر ر الواقع مقصودا .يمكن ان ينطبق ذلك علي مصمم او مدرب الذكاء الاصطناعي .ولكن ما مدي سهولة التنبو بعواقب الذكاء الاصطناعي؟ اما القانون الجنايي ،فعلي العكس من ذلك ،فهو يتط لب ني ة ايقاع الضرر .ولكن هذا غالبا ليس الحال مع الذكاء الاصطناعي .من ناحي ة اخري ،لا تتعلق املسيولية عن املنتج بخطا تعويضات عن الاضرار، تفرض علي الشركة التي انتجت التكنولوجيا دفع الافراد ولكنها بغض النظر عن الخطا .ويمكن ان يكون هذا احد الحلول ا ملمكنة للمسيولية القانونية عن الذكاء الاصطناعي .كذلك تت صل قوانني امللكية الفكرية بالذكاء الاصطناعي ،مثل حقوق الطبع والنشر وبراءات الاختراع ،وقد بدات مناقشات حول »الشخصية الاعتبارية« للذكاء افتراضا قانونيا ولكنه ذريعة تطب ق حاليا علي الشركات ومختلف الاصطناعي ،وهو ما يعد ا ملنظمات .فهل يجب ان يطب ق قرار مثري للجدل في عام ايضا علي الذكاء الاصطناعي؟ في ،2017اقترح البرملان الاوروبي ان منح الروبوتات الذاتية التشغيل الاكثر تطو را منزلة الاشخاص الالكترونيني هو ح ل قانوني ممكن لقضية املسيولية القانونية؛ وهذه الفكرة لم يتم الاعتراف بها من ق بل املفوضية الاوروبية في استراتيجيتها للذكاء الاصطناعي 2في عام حقوق وشخصية للالات، اعتراضا حازم ا علي فكرة اعطاء .2018كذلك اعترض اخرون مجاد لني ،علي سبيل املثال ،بانه سيصبح من الصعب ،ان لم ي كن من ا ملستحيل ،محاسبة لاغراض ذاتية )Bryson, شخص لان الناس سيسع ون الي استغلال هذه الفكرة اي .(Diamantis, and Grant 2017كان هناك ايضا الحالة الشهرية لصوفيا ،الروبوت الذي منحته السعودية »الجنسية« في عام .2017تثري مثل هذه الحالة مجددا مسالة املكانة الاخلاقية للروبوتات والذكاء الاصطناعي )انظر الفصل الرابع(. اقترح ت ايضا سياسات ذكاء اصطناعي خارج نطاق امريكا الشمالية واوروبا. فالصني ،علي سبيل املثال ،لديها استراتيجية وطنية للذكاء الاصطناعي .وتقر خطتها التنموية بان الذكاء الاصطناعي هو تكنولوجيا هد امة يمكن ان تضر بالاستقرار الاجتماعي، وتنتهك الخصوصية الشخصية ،وتخلق وتوثر علي القانون والاخلاقيات الاجتماعية، مخاطر امنية؛ ومن ثم توصي الخطة بتعزيز الوقاية املستقبلية وتقليل املخاطر املحتم لة )مجلس الدولة الصيني .(2017وتروي بعض الجهات الفاعلة في الغرب سردية منافسة: حرب عاملية نقترب من اندلاع يخشون ان تتجاوزهم الصني او حتي فكرة اننا انهم جديدة .بينما يحاول اخرون التع لم من استراتيجية الصني .وقد يتساءل الباحثون ايضا اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 137, "content": "عن كيفية تعامل الثقافات املختلفة مع الذكاء الاصطناعي بط رق مختلفة .ويمكن ان يسهم البحث في مجال الذكاء الاصطناعي نفسه في بناء وجهة نظر مقارنة عابرة للثقافات بشان اخلاقيات الذكاء الاصطناعي ،علي سبيل املثال ،عندما يذكرنا بالفروق بني الثقافات الفردية والجماعية فيما يتع لق با ملعضلات الاخلاقية ) .(Awad et al. 2018ويمكن ان يثري مشكلات لاخلاقيات الذكاء الاصطناعي اذا كانت تهدف الي ان تكون عاملية .ويمكن هذا ايضا استكشاف كيف تختلف السرديات حول الذكاء الاصطناعي في الصني او اليابان ،علي سبيل املثال ،عن السرديات الغربية .ومع ذلك ،علي الرغم من الاختلافات الثقافية ، يتبني ان بدرجة كبرية وملحوظة .فبينما توكد خطة سياسات اخلاقيات الذكاء الاصطناعي متشابهة الصني اكثر علي الاستقرار الاجتماعي والصالح العام الجماعي ،الا ان املخاطر الاخلاقية ا ملحددة واملبادي املذكورة ليست مختلفة كثريا عن تلك ا ملقترحة من ق بل الدول الغربية."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 138, "content": "علي الرغم من الاختلافات الثقافية ، يتبني ان سياسات اخلاقيات الذكاء الاصطناعي متشابهة بدرجة كبرية وملحوظة."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 139, "content": "سابقا ،سياسة اخلاقيات الذكاء الاصطناعي ليست مقصور ة ولكن ،كما ذكرنا علي الحكومات ولجانها وهيياتها فقط .فقد اخذ الاكاديميون ايضا زمام املبادرة .علي اقترح اعلان مونتريال بشان الذكاء الاصطناعي املسيول من ق بل جامعة سبيل املثال ، مونتريال وشمل استشارة املواطنني والخبراء وغريهم من اصحاب الشان .ويقول الاعلان ان تطوير الذكاء الاصطناعي يجب ان يع زز رفاه جميع املخلوقات الحية ويع زز استقلال البشر ،ويقضي علي جميع انواع التمييز ،ويحترم الخصوصية الشخصية ،ويحمينا من الدعاية والتلاع ب ،ويع زز النقاش الديمقراطي ،ويجعل مختلف الجهات الفاعلة م سيولني عن مكافحة مخاطر الذكاء الاصطناعي ).(Université de Montréal 2017 وقد اقترح باحثون اخرون مبادي الاحسان ،وعدم التسب ب في الاذي ،والاستقلال ،والعدالة، وقابلية التفسري ) .(Floridi et al. 2018وتعمل الجامعات مثل كامبريدج وستانفورد علي اخلاقيات الذكاء الاصطناعي ،غالبا من وجهة نظر الاخلاق التطبيقية .وكذلك يودي ايضا العاملون في مجال الاخلاق املهنية الاشخاص عملا مفيدا .علي سبيل املثال ،قدم مركز مجموعة من النظريات الاخلاقية كادا ة ماركولا للاخلاق التطبيقية في جامعة سانتا كلارا السياسات املقترحة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 140, "content": "ملمارسة التكنولوجيا والهندسة ،والتي قد تفيد ايضا في اثراء اخلاقيات الذكاء الاصطناعي باملعلومات 3 .كما ابدي فلاسفة التكنولوجيا اهتمام ا كبريا بالذكاء الاصطناعي موخ را. نجد ايضا مبادرات بشان اخلاقيات الذكاء الاصطناعي في عالم الشركات .علي سبيل املثال ،يدخل في الشراكة بشان الذكاء الاصطناعي شركات مثل ديب مايند ،واي بي ام، وانتل ،وامازون ،وابل ،وسوني ،وفيسبوك 4 .وتدرك العديد من الشركات الحاجة الي الذكاء الاصطناعي الاخلاقي .علي سبيل املثال ،نشرت جوجل مبادي اخلاقيات الذكاء الاصطناعي: تقديم فايدة اجتماعية ،وتجن ب التسب ب في التحي ز غري العادل او تعزيزه ،وفرض السلامة، والحفاظ علي تحم ل املسيولية ،والحفاظ علي تصميم الخصوصية ،وتعزيز التمي ز العلمي، وتقييد التطبيقات التي يحتمل كونها ضارة او مسيية مثل الاسلحة او التكنولوجيا تنتهك مبادي القانون الدولي وحقوق الانسان 5 .وتتحد ث شركة مايكروسوفت عن التي فكرة »الذكاء الاصطناعي من اجل الخري« وتقترح مبادي العدالة ،واملوثوقية والسلامة، والخصوصية والامان ،والتضمني ،والشفافية ،واملساءلة 6 .كما اقترحت شركة اكسنتشر مبادي عاملية لاخلاقيات البيانات ،بما في ذلك احترام الاشخاص الكامنة وراء البيانات، والخصوصية ،والتضمني ،والشفافية 7 .وعلي الرغم من ان وثايق الشركات تميل الي التركيز علي الرقابة الذاتية ،فان بعض الشركات تعترف بضرورة اللوايح التنظيمية الخارجية. وقد قال تيم كوك الرييس التنفيذي لشركة ابل ان اللوايح التنظيمية التكنولوجية ،علي سبيل املثال ،لضمان الخصوصية امر لا غ ني عنه لان السوق الحرة التي لا تخضع لرقابة حكومية لا تفيد في هذه الحالة 8 .ومع ذلك ،هناك جدل حول ما اذا كان هذا يتطلب لوايح تنظيمية جديدة .ويدعم البعض مسار اللوايح التنظيمية ،بما في ذلك القوانني الجديدة. فقد قدمت ولاية كاليفورنيا بالفعل مشروع قانون يطالب بالكشف عن الروبوتات: بطريقة تض لل الشخص الاخر حول هويته الاصطناعية امر غري فان استخدام الروبوت موقفا اكثر تحف ظا .فقد جادلت شركة ديجيتال يوروب قانوني 9 .وتتخذ شركات اخري ) ،(2018التي تمثل الصناعة الرقمية في اوروبا ،بان الاطار القانوني الحالي مجه ز ملعالجة املشكلات املتعلقة بالذكاء الاصطناعي ،بما فيها التحي ز والتمييز ،ولكن لبناء الثقة ،فان الشفافية والقابلية للتفسري امران غاية في الاهمية :يجب ان يفهم الافراد والشركات متي معلومات ذات بحاجة الي توفري وكيف تستخدم الخوارزميات في اتخاذ القرارات ،ونحن معني وتيسري عملية تفسري القرارات الخوارزمية. تلعب الجهات غري الهادفة الي الربح دو را ايضا .علي سبيل املثال ،تطرح الحملة الدولية لوقف الروبوتات القاتلة العديد من الاسيلة الاخلاقية بشان التطبيقات العسكرية اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 141, "content": "للذكاء الاصطناعي 10ومن جانب دعاة تجاوز الانسانية ،توج د مبادي الذكاء الاصطناعي التي ات فق عليها املشاركون الاكاديميون والصناعيون في موتمر اسيلومار ،وهو موتمر عقده »معهد مستقبل الحياة« )ماكس تيجمارك واخرون( .وكان الهدف العام هو الحرص علي ان يظل الذكاء الاصطناعي مفيدا ،واحترام املبادي والقيم الاخلاقية مثل السلامة والشفافية واملسيولية ،وتوجيه القيم ،والخصوصية ،والتحكم البشري 11 .هناك ايضا منظمات مهنية تعمل في مجال سياسات الذكاء الاصطناعي .فقد طرح معهد مهندسي الكهرباء والالكترونيات ،الذي يزعم انه اكبر منظمة مهنية فنية في العالم ،مبادر ة عاملية مناقشات بني الخبراء ،اثمرت املبادرة عن حول اخلاقيات الانظمة الذكية وا ملستقلة .وبعد وثيقة تتضم ن روية ل »تصمي م موج ه اخلاقيا« ،تقترح ان يكون تصميم هذه التقنيات وتطويرها وتنفيذها موجه ا بواسطة املبادي العامة لحقوق الانسان والرفاه واملساءلة والشفافية والتوعية بشان سوء الاستخدام .ويمكن ان يكون تضمني الاخلاق في املعايري التكنولوجية العاملية وسيلة فع الة للمساهمة في تطوير الذكاء الاصطناعي الاخلاقي. الحلول التكنولوجية ومسالة الاساليب والتنفيذ تبني املبادرة العاملية التي طرحها معهد مهندسي الكهرباء والالكترونيات انه فيما يتعلق بالتدابري ،تركز بعض وثايق السياسات علي الحلول التكنولوجية .علي سبيل املثال ،كما ذكرنا في الفصل السابق ،دعا بعض الباح ثني الي الذكاء الاصطناعي القابل للتفسري ،الي فتح الصندوق الاسود .وهناك اسباب وجيهة للرغبة في ف عل ذلك؛ اذ ان تفسري املنطق وراء القرار الذي يت خذ ليس مطلبا اخلاقيا فقط ولكنه ايضا جانب مهم من الذكاء البشري ) .(Samek, Wiegand, and Müller 2017اذن فالفكرة وراء الذكاء الاصطناعي القابل الشفاف هي ان يكون من السهل فهم افعال الذكاء الاصطناعي وقراراته. للتفسري او وكما راينا ،فان هذه الفكرة من الصعب تنفيذها في حالة تع لم الالة الذي يستخدم الشبكات العصبية ) .(Goebel et al. 2018ولكن يمكن للسياسات بالطبع دعم البحث في هذا الاتجاه. بشكل عام ،فان فكرة تضمني الاخلاق في تصميم التقنيات الجديدة هي فكرة رايعة. الحساس ويمكن ان تساعدنا الافكار مثل الاخلاقيات ا ملتضمنة في التصميم او التصميم بطريقة تودي الي مزي د للقيم ،التي لها تاريخها الخاص 12 ،في تصميم الذكاء الاصطناعي من املساءلة واملسيولية والشفافية .علي سبيل املثال ،يمكن ان تنطوي الاخلاقيات ا ملتضم نة السياسات املقترحة"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 142, "content": "في التصميم علي ضمان التتب ع في جميع املراحل ) ،(Dignum et al. 2018مما يسهم في امكانية مساءلة الذكاء الاصطناعي .ويمكن تحقيق فكرة التتبع حرفيا ،بمعني تسجيل بيانات حول سلوك النظام .وقد طالب وينفيلد وجريوتكا ) (2017بتنفيذ »صندوق اسود اخلاقي« في الروبوتات والانظمة ا ملستق لة ،ليسجل ما يفعله الروبوت )البيانات من بطريقة تشبه الصندوق الاسود الاجهزة الاستشعارية ومن الوضع »الداخلي« للنظام( ا ملثب ت في الطايرات .ويمكن تطبيق هذه الفكرة ايضا في الذكاء الاصطناعي ا ملستقل: فعندما يحدث خطا ما ،قد تساعدنا مثل هذه البيانات في تفسري ما حدث بالضبط. وهذا بدوره قد يساعد في التحليل الاخلاقي والقانوني للحالة .وعلاو ة علي ذلك ،كما يقول الباحثون ،وهم م حقون في قولهم ،يمكننا ان نتع لم شييا من صناعة الطايرات، للتحقق من السلامة وعمليات مريية التي تخضع الي تنظي م صارم ولديها عمليات دقيقة للتحقيق في الحوادث .فهل يمكن تثبيت بنية اساسية مماثلة تضمن التنظيم والسلامة في حالة الذكاء الاصطناعي؟ وللمقارنة بمجال اخر من مجالات وسايل النقل ،قد اقترحت صناعة السيارات ايضا شهاد ة او نوع ا من »رخصة القيادة« للمركبات الذاتية التشغيل املدعومة بالذكاء الاصطناعي .يذهب بعض الباحثني الي ابع د من ذلك ويهدفون الي انشاء حاولة لتحقيق »اخلاقيات الالة« بمعني ان تستطيع الالات نفسها الات اخلاقية ،في م يجب الاحتفاظ بهذه اتخاذ قرارات اخلاقية .ويجادل اخرون بان هذه فكرة خطرية وانه القدرة للبشر ،وانه من ا ملستحيل خلق الات تتمت ع بالوكالة الاخلاقية الكاملة ،ولا حاجة الي ان تتمت ع الالات بالوكالة الاخلاقية الكاملة ،ويكفي ان تكون الالات امنة وملتزمة بالقانون ) ،(Yampolskiy 2013او قد ت نشا اشكال من »الاخلاق الوظيفية« )Wallach (and Allen 2009التي لا تكافي الوكالة الاخلاقية الكاملة ،ولكنها مع ذلك تجعل الالة م راعية نسبيا لقواعد الاخلاق .تعد هذه املناقشة ،التي تتع لق مجددا بموضوع املكانة الاخلاقية ،ذات صلة ،علي سبيل املثال ،في حالة السيارات الذاتية القيادة :والي اي مدي ستحسن تضمني القواعد الاخلاقية في هذه السيارات ،وما نوع هذه يتعني ويمكن وي القواعد الاخلاقية وكيف يمكن تنفيذها تقنيا؟ الحساس للق يم ،في يمكن ان تساعدنا الافكار مثل الاخلاقيات ا ملتضمنة في التصميم او التصميم انشاء الذكاء الاصطناعي بطريقة تودي الي مزي د من املساءلة واملسيولية والشفافية. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "السياسات المقترحة", "section_path": ["الفصل العاشر", "السياسات المقترحة"], "page": 143, "content": "يميل صانعو السياسات الي دعم العديد من هذه الاتجاهات في البحث والابتكار في وبشكل عام ،تضمني مجال الذكاء الاصطناعي ،مثل الذكاء الاصطناعي القابل للتفسري الاخلاق في التصميم .علي سبيل املثال ،الي جانب الاساليب غري التقنية مثل اللوايح التنظيمية ،ووضع املعايري ،والتعليم ،وحوار الاطراف ا ملعنية وفرق التصميم الشاملة، ذكر تقرير فريق الخبراء الرفيع املستوي عددا من الاساليب التقنية ومنها تضمني القواعد الاخلاقية وسيادة القانون في التصميم ،وهياكل الذكاء الاصطناعي الجدير بالثقة، والاختبار والتحقق ،والتتبع والتدقيق ،والتفسري .علي سبيل املثال ،يمكن ان تشتمل الاخلاقيات ا ملضمنة في التصميم علي الخصوصية ا ملضمنة في التصميم .ويشري التقرير ايضا الي بعض الطرق التي يمكن بها تنفيذ الذكاء الاصطناعي الجدير بالثقة ،مثل التتب ع يجب كطريقة للمساهمة في الشفافية :وفي حالة الذكاء الاصطناعي ا ملستند الي قواعد توضيح كيفية بناء النموذج ،وفي حالة الذكاء الاصطناعي ا ملستند الي التع لم يجب توضيح وسيلة تدريب الخوارزمية ،بما في ذلك كيفية جمع البيانات واختيارها .ومن ا ملفترض ان يضم ن هذا ان يكون نظام الذكاء الاصطناعي قابلا للتدقيق ،ولا سي ما في املواقف الخطرية ).(European Commission AI HLEG 2019 حاسمة الاهمية :حيث ان تحديد عدد من املبادي تع د م سالة الاساليب والتنفيذ الاخلاقية شيء ،واكتشاف طريقة تنفيذ هذه املبادي عمليا شيء مختلف تمام ا .وحتي املفاهيم مثل الخصوصية ا ملضم نة في التصميم ،التي يفترض ان تكون اقرب الي عملية بطريقة مجردة وعامة؛ ومن ثم فاننا ما زلنا لا ندري التطوير والهندسة ،فغالبا ما تصاغ ملناقشة موجزة حول بعض بالتحديد ما ينبغي ان نفعله .ويقودنا هذا الي الفصل التالي سياسات اخلاقيات الذكاء الاصطناعي. تواجه التحديات التي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 144, "content": "التحديات التي تواجه صانعي السياسات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 145, "content": "الاخلاقيات الاستباقية :الابتكار املسيول وتضمني الق يم في التصميم تواجه العديد من ربما لا يدهشنا ان نعرف ان سياسات اخلاقيات الذكاء الاصطناعي روية استباقية لاخلاقيات الذكاء التحد يات .وقد راينا ان بعض السياسات ا ملقترحة تويد بحاجة الي مراعاة الاخلاق في املرحلة ا ملبكرة من تطوير تكنولوجيا الاصطناعي؛ بمعني اننا الذكاء الاصطناعي .وتكمن الفكرة في تجن ب املشكلات الاخلاقية وا ملجتمعية التي يخلقها الذكاء الاصطناعي والتي سيكون من الصعب التعامل معها بمجرد حدوثها .ويتماشي هذا مع افكار الابتكار املسيول ،وتضمني الق يم في التصميم ،وغريها من الافكار ا ملشابهة اقترحت علي مدار السنوات الاخرية .وهذا يحو ل املشكلة من معالجة الاثار السلبية التي للتقنيات ا ملستخدمة علي نطاق واسع بالفعل الي تحمل املسيولية تجاه التقنيات التي يتم تطويرها اليوم. نتوقع العواق ب غري املقصودة للتقنيات الجديدة في ومع ذلك ،ليس من السهل ان مرحلة التصميم .احدي الطرق لتخفيف هذه املشكلة هو بناء سيناريوهات حول العواقب الاخلاقية ا ملستقبلية .وهناك اساليب مختلفة ملمارسة الاخلاقيات في البحث والابتكار ) ،(Reijers et al. 2018احداها ليست فقط دراسة تاثري سرديات الذكاء الاصطناعي الحالية وتقييمها ) (Royal Society, 2018ولكن واقعية ايضا خلق سرديات جديدة اكثر حول تطبيقات معينة للذكاء الاصطناعي."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 146, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 147, "content": "النهج ا ملوج ه للممارسة والنهج التصاعدي :كيف نترجمهما عمليا؟ الابتكار املسيول لا يتعلق فقط بتضمني الاخلاقيات في التصميم ،ولكنه يتط لب ايضا مراعاة اراء مختلف الاطراف ا ملعنية ومصالحهم .وتنطوي الحوكمة الشاملة علي اشراك نقاش عام ،والتدخل ا ملجتمعي ا ملبكر في مرحلة نطاق واسع من الاطراف ا ملعنية ،واجراء البحث والابتكار ) .(Von Schomberg 2011وهذا قد يعني ،مثلا ،تنظيم مجموعات نقاش مركزة واستخدام تقنيات اخري ملعرفة راي الناس في التكنولوجيا. يتعارض هذا النهج التصاعدي في الابتكار املسيول مع نهج الاخلاقيات التطبيقية الذي يتبعه معظم وثايق السياسات ،والذي يميل في الغالب الي ان يكون نهج ا تنازليا ومجردا . اولا ،يتم انشاء السياسات غالبا من ق بل خبراء ،دون ان يشارك فيها نطاق واسع من الاطراف ا ملعنية .ثانيا ،حتي اذا اي دت هذه السياسات مبادي مثل الاخلاقيات ا ملضمنة في التصميم ،فانها تظ ل شديدة الغموض فيما يتعلق بما يعنيه تطبيق هذه جسر بني املبادي عمليا .ولانجاح سياسة الذكاء الاصطناعي ،يظ ل التحدي كبريا لبناء املبادي الاخلاقية والقانونية ا ملجردة والعالية املستوي من ناحية ،وبني ممارسات تطوير سياقات معينة ،والتقنيات ،واصوات اوليك الذين يشاركون التكنولوجيا واستخدامها في في هذه املمارسات ويعملون في هذه السياقات من ناحية اخري .يترك بناء هذا الجسر ملن توج ه اليهم هذه السياسات املقترحة .فهل يمكننا القيام باملزيد في املرحلة الاولي من صنع يجب علينا ذلك؟ نحتاج علي الاقل الي املزيد من العمل علي الاساليب السياسات ،وهل واملوسسات التي نحتاجها لجعل اخلاقيات الذكاء الاصطناعي تنجح عمليا. والاجراءات ويجب علينا ان نولي املزيد من الاهتمام للعملية. الابتكار املسيول لا يتعلق فقط بتضمني الاخلاقيات في التصميم ،ولكنه يتطلب ايضا مراعاة اراء مختلف الاطراف ا ملعنية ومصالحهم."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 148, "content": "فيما يتعلق بالسوال عم ن يشارك في وضع اخلاقيات الذكاء الاصطناعي ،فاننا نحتاج الي تطبيق نهج تصاعدي الي جانب النهج التنازلي ،بمعني الاستماع اكثر الي الباحثني واملهنيني الذين يتعاملون مع الذكاء الاصطناعي عمليا ،بل والي الاشخاص الذين من ا ملحتم ل ان يضر هم الذكاء الاصطناعي .اذا كنا نويد مبدا الديمقراطية واذا كان التحديات التي تواجه صانعي السياسات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 149, "content": "هذا املفهوم يشمل التضمني واملشاركة في صنع القرار بشان مستقبل مجتمعاتنا ،فان سماع صوت الاطراف ا ملعنية ليس ام را اختياريا ولكنه الزامي من الناحيتني الاخلاقية والسياسية .بينما يشارك بعض صانعي السياسات في نوع من التشاور مع الاطراف املعنية )علي سبيل املثال ،لدي املفوضية الاوروبية تحالف الذكاء الاصطناعي الخاص بها( 1 ،لا يزال من املشكوك فيه ما اذا كانت مثل هذه الجهود تصل حقا الي ا ملطورين سيتعني عليهم تحم ل واملستخدمني النهاييني للتكنولوجيا ،والاهم من ذلك ،الي اوليك الذين معظم املخاطر والتعايش مع اثارها السلبية .فهل صنع القرار والسياسات الخاصة بالذكاء الاصطناعي ام ر ديمقراطي ينطوي علي مشاركة حقا؟ ان مفهوم الديمقراطية مهد د ايضا بحقيقة تركز السلطة في ايدي عدد صغري نسبيا من الشركات الكبرية .ويري بول نيميتز ) (2018ان ترا كم السلطة الرقمية في ايدي شركات قليلة ينطوي علي اشكالية :اذا مارست حفنة من الشركات سلطتها ليس فقط علي الافراد — من خلال تكوين ات تعريفية عنا — ولكن ملف ايضا علي البنية الاساسية للديمقراطية ،فان هذه الشركات ،علي الرغم من نواياها الحسنة للمساهمة في الذكاء عقبات امامه .ولذلك ، فمن الضروري وضع لوايح الاصطناعي الاخلاقي ،سوف تضع تنظيمية وحدود لحماية املصلحة العامة ،ولضمان ان هذه الشركات لن تشكل القواعد بمفردها .واشار موراي شاناهان الي ان »ا مليل الي تر كز السلطة والثروة واملوارد في ايدي عدد قليل يت سم بالاستدامة الذاتية« ) ،(166 ،2015مما يجعل من الصعب تحقيق انصافا .كما انه يجعل الافراد ع رضة لجميع انواع املخاطر ،بما في ذلك مجتمع اكثر الاستغلال وانتهاكات الخصوصية ،علي سبيل املثال ،ما تسم يه دراسة اجراها املجلس الاوروبي »التاثري ا ملرو ع لاعادة استخدام البيانات« ).(Yeung 2018, 33 اذا قارن ا الوضع مع سياسة البيية ،يمكن ان نكون متشايمني ايضا بشان امكانية ان فلناخذ ،علي سبيل تت خذ البلدان اجراء فع الا وتعاونيا بشان اخلاقيات الذكاء الاصطناعي. بتغري املناخ في الولايات املتحدة ،حيث يتم في بعض املثال ،العمليات السياسية ا ملتعلقة وتغري املناخ نفسها ،وحيث تعمل بعض القوي الاحيان انكار مشكلة الاحترار العاملي السياسية ذات النفوذ ضد اتخاذ اي اجراء حيال ذلك ،او النجاح املحدود للغاية ملوتمرات يواجه اوليك الذين تغري املناخ الدولية في الاتفاق علي سياسة مناخية مشتركة وفع الة .وقد يسعون الي اتخاذ اجراء عا لمي في ظل املشكلات الاخلاقية واملجتمعية التي اثارها الذكاء اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 150, "content": "الاصطناعي صعوبات مماثلة .فغالبا ما تتفوق املصالح الاخري علي املصلحة العامة، وهناك ندرة في السياسات الحكومية الدولية الخاصة بالتكنولوجيا الرقمية الجديدة ،بما فيها الذكاء الاصطناعي .ومع ذلك ،هناك استثناء واحد لذلك وهو الاهتمام العاملي بحظر الاسلحة القاتلة الذاتية التشغيل ،التي تحتوي ايضا علي جانب ذكاء اصطناعي .ولكن هذا لا يزال استثناء ،ولا يحظي ايضا بدعم جميع البلدان )علي سبيل املثال ،ما زال موضع جدل في الولايات املتحدة(. علاو ة علي ذلك ،ورغم حسن النية ،فان لك ل من اخلاقيات التصميم والابتكار املسيول قيودهما الخاصة . اولا ،تفترض اساليب مثل التصميم الحساس للق يم انه يمكننا التعبري عن ق يمنا ،وتفترض جهود بناء الالات الاخلاقية اننا يمكن ان ن بشكل كامل عن عبر بوضوح اخلاقياتنا .ولكن هذا لا يحدث بالضرورة دايم ا؛ اذ اننا قد لا نستطيع التفكري ولا التعبري عن اخلاقياتنا اليومية .ففي بعض الاحيان ،نستجيب الي مشكلات اخلاقية بطريقة معينة دون ان نتمكن من تبرير استجابتنا بشكل كامل ).(Boddington 2017 شكل من وكما قال فيتجنشتاين :اخلاقياتنا ليست فقط متجسدة ولكنها مضم نة في نحو عميق بطريقة قيامنا بالافعال ككاينات متجسدة اشكال الحياة .انها متصلة علي واجتماعية ،وكمجتمعات وثقافات .وهذا يفرض حدودا علي مشروع التعبري الكامل عن الاخلاق والتفكري الاخلاقي .ويمثل ايضا مشكلة ملشروع تطوير الالات الاخلاقية ،ويتحدي الافتراضات التي تقول ان الاخلاق والديمقراطية يمكن مناقشتهما والتعبري عنهما بالكامل. كما يخلق مشكلة لصانعي السياسات الذين يعتقدون ان اخلاقيات الذكاء الاصطناعي يمكن التعامل معها تمام ا من خلال قايمة من املبادي او من خلال اساليب قانونية وتقنية بحاجة الي اساليب واجراءات وعمليات .ولكن كل هذا ليس كافيا؛ محد دة .نحن بالتاكيد فالاخلاقيات لا تعمل مثل الالة ،وكذلك السياسة والابتكار املسيول. ثانيا ،يمكن ان يكون هذان النهجان عايقا امام الاخلاقيات عندما يكون من الواجب اخلاقيا ايقاف تطوير التكنولوجيا .فغالبا ما تكون وظيفتهما من الناحية العملية هي تيسري عملية الابتكار ،وتعزيز تحقيق الارباح ،وضمان قبول التكنولوجيا .وقد لا يكون هذا بالضرورة سييا .ولكن ماذا لو كانت املبادي الاخلاقية تشري الي انه يجب ايقاف او تعليق التكنولوجيا ،او تطبيق م عني من تطبيقاتها؟ اعتبر كروفورد وكالو ) (2016ان الحساس للق يم والابتكار املسيول تعتمدان علي افتراض ان التكنولوجيا اداتي التصميم سيجري تطويرها؛ وتق ل فعالي تهما عندما يتعلق الامر باتخاذ قرار حول ما اذا كان يجب التحديات التي تواجه صانعي السياسات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 151, "content": "انشاء هذه التكنولوجيا من الاساس .علي سبيل املثال ،في حالة الذكاء الاصطناعي ا ملتقد م مثل تطبيقات تع لم الالة الجديدة ،ربما تكون هذه التكنولوجيا لا تزال غري جديرة بالثقة او لها عيوب اخلاقية خطرية ،وان بعض تطبيقاتها علي الاقل قد يتوجب عدم استخدامها )بعد( .وسواء اكان وقف التكنولوجيا هو الحل الافضل دايم ا ام لا ،فان القضية هي اننا يجب علي الاقل ان نتمت ع بالحق في طرح السوال وتقرير ما ينبغي فعله .فاذا كان هذا الحق غايبا ،فسوف يظ ل الابتكار املسيول ستا را نخفي وراءه مواصلة العمل كاملعتاد. نحو اخلاقيات ايجابية بشكل عا م لا تتع لق علي الرغم من ك ل ما قيل ،فان اخلاقيات الذكاء الاصطناعي عايق اخر يح ول دون ممارسة بالضرورة بمنع الاشياء ) .(Boddington 2017هناك اخلاقيات الذكاء الاصطناعي عمليا ،وهذا العايق هو ان العديد من الجهات الفاعلة في مجال الذكاء الاصطناعي مثل الشركات والباحثني التقني ني لا يزالون يعتبرون الاخلاقيات بشكل كامل؛ اذ غالبا ما يجب علي قيودا ،او اشياء سلبية .هذه الفكرة ليست مضللة الاخلاق ان تقي د ،وتح د ،وتقو ل ان شييا ما غري مقبول .واذا اخذنا اخلاقيات الذكاء الاصطناعي علي م حمل الجد واجه بعض التنا زلات ،ولا سي ما علي ونفذنا توصياتها ،فقد ن املدي القصري .فقد يكون للاخلاقيات ثم ن لا بد من دفعه؛ سواء علي مستوي املال او الوقت او الطاقة .ومع ذلك ، فمن خلال تقليل املخاطر ،تدعم الاخلاقيات والابتكار املسيول التنمية ا ملستدامة للاعمال التجارية واملجتمع علي املدي البعيد .ولا يزال هناك تح د في اقناع جميع الجهات الفاعلة في مجال الذكاء الاصطناعي ،بم ن فيهم صانعي السياسات، فعلا .لاحظ بان هذا هو الحال ايضا ان السياسة واللوايح التنظيمي ة لا تتع لق فقط بحظر صعوبة وتعقيدا؛ بل يمكن ان تكون داعمة ،من خلال تقديم الاشياء او بجعلها اكثر حوافز ،علي سبيل املثال. علاو ة علي ذلك ،الي جانب الاخلاقيات السلبية التي تفرض قيودا ،نحن في حاجة الي توضيح الاخلاقيات الايجابية وشرحها :لوضع روية للحياة الجيدة واملجتمع الجيد. وبينما تلمح بعض املبادي الاخلاقية املقترحة اعلاه الي مثل هذه الروية ،فلا يزال توجيه املناقشة الي هذا الاتجاه تحديا .كما سبق وذكرنا ،لا تتع لق املسايل الاخلاقية الخاصة بالذكاء الاصطناعي بالتكنولوجيا فحسب؛ بل تتع لق بحياة الانسان وازدهاره، وتتع لق بمستقبل املجتمع ،وربما تتعلق ايضا بغري البشر ،وبالبيية ،وبمستقبل الكوكب اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 152, "content": ")انظر الفصل التالي( .وهكذا تعيدنا املناقشات حول اخلاقيات الذكاء الاصطناعي وسياساته من جدي د الي الاسيلة الكبرية التي يجب ان نطرحها علي انفسنا؛ افرادا، جتمعات ،وربما بشرا .ويمكن للفلاسفة ان يساعدونا في التفكري في هذه الاسيلة. وم وبالنسبة الي صانعي السياسات ،يكمن التحد ي في تطوير روية واسعة للمستقبل التكنولوجي تتضم ن افكا را حول ما هو مهم وما هو ذو معني وما هو ذو قيمة .علي بشكل عا م تتعم د تجاهل مثل هذه الاسيلة وتركها الرغم من ان الديمقراطيات الليبرالية تتدخل في مثل هذه املوضوعات العميقة مثل ماهية الحياة الجيدة ومن ثم للافراد ،ولا فهي »سطحية« )ابتكار سياسي اد ي الي تجن ب بعض انواع الحروب علي الاقل وساهم تواجهنا ،فان في الاستقرار والازدهار( ،فانه في ظ ل التحد يات الاخلاقية والسياسية التي »عمقا« يعتبر من قبيل انعدام املسيولية .وينبغي ان تتع لق تجاهل الاسيلة الاخلاقية الاكثر السياسة ايضا ،بما فيها سياسات الذكاء الاصطناعي ،بالاخلاقيات الايجابية. بشكل عام ،لا تتع لق اخلاقيات الذكاء الاصطناعي بالضرورة بمنع الاشياء؛ بل نحن في حاجة الي اخلاقيات ايجابية :لوضع روية للحياة الجيدة وا ملجتمع الجيد."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 153, "content": "ومع ذلك ،فالسبيل الي ذلك من منظور صانعي السياسات ،ليس من خلال العمل وتولي دور امللك الفيلسوف كما في فلسفة افلاطون ،ولكن بالعثور علي بشكل فردي التوازن الصحيح بني التكنوقراطية والديمقراطية التشاركية .الاسيلة التي تواجهنا هي اسيلة تهمنا جميع ا؛ وعلينا ان نتشارك جميع ا في الاجابة عنها .لذلك ،لا يمكننا تركها في ايدي فية قليلة من الاشخاص ،سواء اكانوا في الحكومة ام في الشركات الكبرية .ويعيدنا هذا الي الاسيلة حول كيفية انجاح الابتكار املسيول واملشاركة في سياسات الذكاء الاصطناعي. املشكلة لا تتع لق فقط بالسلطة؛ انها تتع لق ايضا بالخري :الخري للافراد والخري للمجتمع. ان افكارنا الحالية حول الحياة الجيدة واملجتمع الجيد — اذا كنا قاد رين علي التعبري نقاش نقدي اعمق بكثري .ودعوني اقترح انه قد يكون عنها من الاساس — قد تحتاج الي انظمة سياسية اخري من ا ملفيد للغرب ،علي الاقل ان يستكشفوا خيار محاولة التع لم من غري غربية وثقافات سياسية اخري .لا يجوز لسياسة الذكاء الاصطناعي الفع الة وا ملبررة تجن ب املشاركة في مثل هذه النقاشات الاخلاقية الفلسفية والسياسية الفلسفية. التحديات التي تواجه صانعي السياسات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 154, "content": "التخصصات التخصصات وتجاوز تداخل هناك عوايق اخري يجب تجاوزها اذا اردنا جعل اخلاقيات الذكاء الاصطناعي اكثر فعالية واردنا دعم التطوير املسيول للتكنولوجيا ،تجن با ملا يسميه الباحثون التقنيون »شتاء« الذكاء الاصطناعي الجديد :ابطاء عملية تطوير الذكاء الاصطناعي والاستثمار التخصصات الكافي .ما التخصصات وتجاوز تداخل فيه .احد هذه العوايق هو نقص نواجه فجوة شاسعة في الخلفية والفهم بني ا مل ختصني في العلوم الانسانية والعلوم زلنا الاجتماعية من جهة ،وا مل جهة اخري ،داخل ختصني في العلوم الطبيعية والهندسية من املوسسي لس د الفجوة الواسعة ا ملجتمع الاكاديمي وخارجه .حتي الان ،ما زلنا نفتقد الدعم بني هذين »العا ملني« ،سواء في املجتمع الاكاديمي او في املجتمع الاوسع .ولكن اذا كن ا نريد حقا ان نمتلك تكنولوجيا متقدمة اخلاقية مثل الذكاء الاصطناعي الاخلاقي ،فيجب علينا ان نق رب بني هولاء الاشخاص وبني هذين العا ملني ،في اقرب وقت ممكن. فمثلا ،يجب ان ويتط لب هذا احداث تغيري في كيفية اجراء البحث والتطوير — يشارك فيه ليس فقط الاشخاص التقنيون ورجال الاعمال ولكن ايضا م ختصون في العلوم الانسانية — وكذلك تغيري كيفية »تعليم« الاشخاص ،من الشباب وغريهم .يجب ان نحرص علي ان يدرك الاشخاص الذين لديهم خلفية في العلوم الانسانية اهمية التفكري في التقنيات الجديدة مثل الذكاء الاصطناعي ويحاولوا اكتساب بعض املعرفة حول هذه حساسية التقنيات وما تقوم به .ومن ناحي ة اخري ،يجب جعل العلماء واملهندسني اكثر واستخدامها .ومن ثم عندما تجاه الجوانب الاخلاقية وا ملجتمعية لتطوير التكنولوجيا يتع لمون استخدام الذكاء الاصطناعي ،ويساهمون بعد ذلك في تطوير تكنولوجيا الذكاء يمت بص لة الي الاصطناعي الجديدة ،فانهم لن ي روا الاخلاقيات موضوع ا هامشيا لا ممارساتهم التكنولوجية ولكن ي رونها »جزءا اساسيا« من هذه املمارسات .وعنديذ ،في الحالة املثالية ،ستعني »ممارسة الذكاء الاصطناعي« او »ممارسة علم البيانات« ان يت م نطاق اوسع ،يمكننا تضمني الاخلاقيات ببساطة بوصفها جزءا اساسيا لا غ ني عنه .علي التخصصات شكل اكثر تنو ع ا وشمولية من التعليم او السرد تتداخل فيه ان نفكر في وايضا بالوسايط والتقنيات .بعبار ة جذريا فيما يتعلق بالاساليب واملناهج ،وباملوضوعات، اخري اوضح ،اذا تع ل م املهندسون كيفية العمل باستخدام النصوص وتعلم ا ملختصون في العلوم الانسانية كيفية العمل باستخدام اجهزة الكمبيوتر ،فسيزداد الامل في اخلاقيات التكنولوجيا وفي سياسة تصلح للتنفيذ عمليا. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 155, "content": "مخاطر »شتاء« الذكاء الاصطناعي وخطر الاستخدام اللاواعي للذكاء الاصطناعي وبشكل عام، اذا لم يبدا تنفيذ هذه التوجيهات في السياسة والتعليم علي ارض الواقع، واجه فقط مخاطر »شتاء« اذا فشل مشروع الذكاء الاصطناعي الاخلاقي ،فاننا لن ن الذكاء الاصطناعي؛ بل ان الخطر الادهي والام ر سيكمن في الكارثة الاخلاقية والاجتماعية والاقتصادية التي ستل م بنا وسيدفع ثمنها البشر وغري البشر والبيية .هذا لا يتعلق بالتفرد التكنولوجي ،او بالالات التي ستدمر العالم ،او بسيناريوهات نهاية العالم الاخري حول املستقبل البعيد ،ولكنه يتعلق بالزيادة البطيية ولكن املوكدة في تراكم املخاطر التكنولوجية وما ينجم عنها من تفاقم الضعف البشري والاجتماعي والاقتصادي والبييي .هذه الزيادة في املخاطر والضعف مرتبطة باملشكلات الاخلاقية املشار اليها هنا وفي الفصول السابقة، بما فيها الاستخدام الجاهل واملتهور لتقنيات الاتمتة ا ملتقد مة مثل الذكاء الاصطناعي. بشكل عام :حتي ان الفجوة في التعليم ربما تزيد من تاثري مخاطر الذكاء الاصطناعي لو لم تتسب ب دايم ا في مخاطر جديدة مباشرة ،فانها تضاعف املخاطر املوجودة بالفعل نحو استثنايي .حتي الان ،لا يوج د ما يسمي »رخصة قيادة« لاستخدام الذكاء علي الاصطناعي ،ولا يوج د تعليم الزامي لاخلاقيات الذكاء الاصطناعي للباحثني التقني ني، ورجال الاعمال ،ومسيولي الحكومة وغريهم من الاشخاص املشاركني في ابتكار الذكاء الاصطناعي واستخدامه وسياساته .هناك الكثري من الات الذكاء الاصطناعي غري ا ملرو ضة اشخاص لا يعرفون املخاطر واملشكلات الاخلاقية ا ملرتبطة بها ،او الذين قد تكون في ايدي لديهم توقعات خطا بشان التكنولوجيا .ويكمن الخطر ،مرة اخري ،في ممارسة السلطة دون معرفة و)بالتالي( دون مسيولية؛ والاسوا من ذلك ان يخضع الاخرون الي هذه السلطة .واذا كان هناك شر علي الاطلاق ،فانه يقيم حيثما قالت فيلسوفة القرن العشرين حنة ارنت :في غياب الوعي عن القرارات والعمل اليومي ا ململ .وعندما يفترض ان الذكاء الاصطناعي غري متحيز ويستخدم دون فهم ملا يتم القيام به ،فان هذا من شانه ان يسهم في تعميق غياب الوعي ،ثم في النهاية ،في الفساد الاخلاقي للعالم .وتستطيع سياسات التعليم املساع دة في التخفيف من ذلك وبالتالي املساهمة في جعل الذكاء الاصطناعي جيدا وذا معني. لا تزال هناك العديد من الاسيلة ا ملزعجة ،وربما املولمة الي ح د ما ،التي غالبا ما يتم تجاهلها في املناقشات التي تدور حول اخلاقيات الذكاء الاصطناعي وسياساته ،ولكنها التحديات التي تواجه صانعي السياسات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "التحديات التي ُتواجه صانعي السياسات", "section_path": ["الفصل الحادي عشر", "التحديات التي ُتواجه صانعي السياسات"], "page": 156, "content": "كاملا .هل اخلاقيات تحليلا تستحق من ا علي الاقل ان نذ كرها هنا ،حتي وان لم نحللها الذكاء الاصطناعي تتع لق فقط بخري البشر وقيمتهم ،ام ان علينا ان نراعي ايضا ق يم غري البشر وخريهم ومصالحهم؟ وحتي اذا كانت اخلاقيات الذكاء الاصطناعي تتعلق بشكل رييسي بالبشر ،فهل يمكن ان تكون اخلاقيات الذكاء الاصطناعي ليست باملسالة الاهم التي يتعني علي البشرية الاهتمام بها؟ يقودنا هذا السوال الي الفصل الاخري من الكتاب."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 157, "content": "تحدي وحقبة التاثير البشري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 158, "content": "يجب ان تكون اخلاقيات الذكاء الاصطناعي محورها الانسان؟ هل علي الرغم من ان العديد من املو لفات ا ملتعلقة باخلاقيات الذكاء الاصطناعي والسياسات تاتي علي ذ كر البيية او التنمية ا ملستدامة ،فانها تو كد علي الق يم الانسانية وغالبا ما تتمحور حول الانسان بوضوح .علي سبيل املثال ،تقول الارشادات الاخلاقية التي وضعها نهج متمحور فريق الخبراء الرفيع ا ملستوي املعني بالذكاء الاصطناعي انه يجب تبن ي بمكانة اخلاقية فريدة وراسخة حول الانسان للذكاء الاصطناعي »يتمتع فيه الانسان لها اولوية علي جميع الاصعدة املدنية والسياسية والاقتصادية والاجتماعية« )European (Commission AI HLEG 2019, 10وقد صاغت الجامعات مثل ستانفورد ومعهد ماساتشوستس للتكنولوجيا سياسات بحثها في سياق الذكاء الاصطناعي ا ملتمحور حول الانسان. غالبا ما يتم تعريف هذا التمحور حول الانسان فيما يتعلق بالتكنولوجيا باعطاء الاولوية لخري الانسان وكرامته علي حساب ما قد تتط لبه او تفعله التكنولوجيا. فالتكنولوجيا يجب ان تعود بالفايدة علي البشر وان تخدمهم وليس العكس .ومع ذلك ،وكما راينا في الفصول الاولي ،فان مدي مناسبة هذا التركيز علي الانسان في اخلاقيات الذكاء الاصطناعي ليس واضح ا كما قد يبدو للوهلة الاولي ،ولا سي ما اذا اخذنا في الاعتبار املناهج املويدة لتجاوز الانسانية او سرديات املنافسة )ما بني الانسان والتكنولوجيا(. وتبني فلسفة التكنولوجيا ان هناك املزيد من الطرق — الاكثر دقة وتعقيدا — لتحديد العلاقة بني البشر والتكنولوجيا .علاو ة علي ذلك ،يعد النهج ا ملتمحور حول الانسان غري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 159, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 160, "content": "واضح علي اقل تقدير ،ان لم ي كن مثريا للمشكلات ،في ضوء املناقشات الفلسفية حول البيية والكاينات الحية الاخري .في فلسفة البيية واخلاقياتها ،هناك نقاش طويل حول قيمة غري البشر ،خاصة الكاينات الحية ،وحول كيفية احترام تلك القيمة وهذه الكاينات، يخص اخلاقيات وحول املشكلات ا ملحتملة التي قد تنشا نتيجة احترام قيمة البشر .وفيما الذكاء الاصطناعي ،فان هذا يعني ان علينا علي الاقل طرح السوال بشان تاثري الذكاء الاصطناعي علي الكاينات الحية الاخري والنظر في احتمالية وجود تعا رض بني ق يم ومصالح البشر وغري البشر. تحديد الاولويات علي النحو الصحيح يمكن ايضا القول بوجود مشكلات اخري اكثر خطورة من تلك التي يسببها الذكاء بشكل صحيح .وقد ينشا هذا الاعتراض من الاصطناعي ،وانه من ا ملهم تحديد اولوياتنا تغري املناخ ،التي تعد النظر الي املشكلات العاملية مثل وفقا للبعض املشكلة الاهم التي تحتاج البشرية الي التصد ي لها وايلايها الاولوية نظ را الي خطورتها وتاثريها ا ملحتم ل علي الكوكب كلا. واضح علي اقل تقدير ،ان لم ي كن مثريا للمشكلات ،في ضوء يع د النهج ا ملتمحور حول الانسان غري املناقشات الفلسفية حول البيية والكاينات الحية الاخري."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 161, "content": "بالنظر الي جدول اعمال الامم املتحدة للتنمية ا ملستدامة لعام ) 2015الذي يطلق عليه اهداف التنمية ا ملستدامة( 2ونظرته العامة الي القضايا العاملية املتعلقة بما وصفه الامني العام للامم املتحدة بان كي-مون »الانسان والكوكب« ،نري العديد من القضايا العاملية التي تتط لب يقظة اخلاقية وسياسية :التفاوت الاجتماعي ا ملتزايد داخل البلدان وفيما بينها ،والحروب والتط رف العنيف ،والفقر وسوء التغذية ،وصعوبة الوصول الي املياه العذبة ،ونقص املوسسات الفعالة والديمقراطية ،وزيادة نسبة السكان ا ملتقد مني في السن ،والامراض ا ملعدية والوبايية ،ومخاطر الطاقة النووية ،ونقص الفرص للاطفال الجنسني واشكال التمييز والاقصاء ا ملختلفة ،والازمات والشباب ،وعدم املساواة بني الانسانية وجميع انواع انتهاكات حقوق الانسان ،وا ملشكلات املتعلقة بالهجرة واللاجيني، تحد ي تغري املناخ :حول الاولويات وحقبة التاثري البشري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 162, "content": "بتغري املناخ — مثل وتغري املناخ واملشكلات البييية — التي تتع لق في بعض الاحيان الكوارث الطبيعية ا ملتك ررة وا ملتفاقمة واشكال تدهور البيية مثل الجفاف وفقدان التنوع البيولوجي .في ضوء هذه املشكلات الضخمة ،هل يجب ان نعتبر الذكاء الاصطناعي اولويتنا الاولي؟ وهل يشت ت الذكاء الاصطناعي انتباهنا عن قضايا اكثر اهمية؟ من جهة ،يبدو ان التركيز علي الذكاء الاصطناعي وغريه من املشكلات التكنولوجية مشكلات اخري في غري مح له عندما يعاني عدد هايل من البشر ويعاني العالم باسره من كثرية للغاية .ففي حني ان الناس في احد انحاء العالم يكافحون من اجل الوصول الي املياه بييات عنيفة ،يقلق اخرون في جزء اخر من العذبة او من اجل البقاء علي قيد الحياة في العا لم بشان خصوصيتهم علي الانترنت ويتخي لون مستقبلا يحقق فيه الذكاء الاصطناعي الذكاء الفايق .من الناحية الاخلاقية ،يبدو ان شييا مريبا يحدث ،شييا يتعلق بالتفاوت الطرف عن مثل هذه تغض الاخلاق والسياسات الاجتماعي والظلم العا لمي ني .يجب الا املشكلات ،التي لا تتع لق بالضرورة بالذكاء الاصطناعي علي الاطلاق .علي سبيل املثال ،في البلدان النامية ،يمكن احيانا للتكنولوجيا ا ملنخفضة التكلفة — وليس التكنولوجيا ا ملتقدمة — املساعدة في ح ل مشكلات الناس؛ لانهم يستطيعون ان يتحم لوا تكاليفها ويستطيعون تركيبها وصيانتها. وايضا يعمل مشكلات جديدة من جهة اخري ،يمكن ان يسبب الذكاء الاصطناعي تفاقم املشكلات القايمة بالفعل في ا ملجتمعات وفي البيية .علي سبيل املثال ،يخشي علي البعض ان الذكاء الاصطناعي سيوسع الفجوة بني الاغنياء والفقراء ،وانه ،مثل العديد من التقنيات الرقمية ،سيزيد من استهلاك الطاقة ،ويخلق مزيدا من النفايات .من هذا املنظور ،فان مناقشة اخلاقيات الذكاء الاصطناعي والتعامل معها ليس تشتيتا للانتباه ولكنه احدي الطرق التي يمكننا من خلالها املساهمة في معالجة مشكلات العالم ،بما بحاجة ايضا الي ايلاء الاهتمام فيها املشكلات البييية .ومن ثم ،يمكننا ان نستخلص اننا للذكاء الاصطناعي :نعم ،الفقر والحروب وما الي ذلك هي مشكلات خطرية ،ولكن الذكاء الاصطناعي يمكن ايضا ان يود ي الي — او يساعد علي — تفاقم مشكلات خطرية الان وفي ا ملستقبل ،ويجب ان يكون في قايمة املشكلات التي تحتاج منا الي ايجاد الحلول .ومع ذلك، فهذا لا يجيبنا عن السوال املتعلق بالاولويات؛ وهو سوال مهم علي مستوي الاخلاقيات والسياسة علي ح د سواء .ان القضية لا تتمثل في وجود اجابات سهلة عن ذلك السوال؛ بل القضية هي ان هذا السوال لا يط رح حتي في معظم املو لفات الاكاديمية ووثايق السياسات حول الذكاء الاصطناعي. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 163, "content": "ففي حني ان الناس في احد انحاء العالم يكافحون من اجل الوصول الي املياه العذبة او من اجل بييات عنيفة ،يقلق اخرون في جزء اخر من العالم بشان خصوصيتهم علي البقاء علي قيد الحياة في الانترنت."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 164, "content": "وتغري املناخ وحقبة التاثري البشري الذكاء الاصطناعي احدي اصعب الطرق لطرح السوال ا ملتعلق بالاولويات هو التع رض ملناقشة مسالة تغري املناخ واملوضوعات ذات الصلة مثل حقبة التاثري البشري» :ملاذا نقلق بشان الذكاء الاصطناعي اذا كانت املشكلة امللح ة هي تغري املناخ وكون مستقبل الكوكب في خطر؟« او دعونا نستعري عبار ة من الثقافة السياسية الامريكية» :انه املناخ ،ايها الغبي!« وسوف اوضح هنا هذا التحد ي واناقش تداع ياته علي التفكري في اخلاقيات الذكاء الاصطناعي. في حني يرفض بعض املتط رفني النتايج العلمية ،يقر العلماء وصانعو السياسات مشكلة عاملية خطرية ولكنه نطاق واسع بان ايضا »احد اكبر تغري املناخ ليس فقط علي التحد يات في عصرنا« ،كما هو مذكور في نص اهداف التنمية ا ملستدامة للامم املتحدة. مشكلة مستقبلية :فدرجة الحرارة العاملية ومستويات البحر ترتفع بالفعل، وهو ليس مما يوثر علي البلدان واملناطق الساحلية ا ملنخفضة .وقريبا جدا سوف يضطر املزيد من الناس الي التعامل مع عواقب تغري املناخ .ويستنتج الكثريون من هذا انه يجب علينا بشكل عاجل للتخفيف من مخاطر تغري املناخ؛ وانا اقول »التخفيف« لان التصر ف الان التوقف .ان الفكرة هي ان هذا ليس فقط الوقت العملية ربما قد تجاوزت بالفعل نقطة املناسب للقيام بشيء ولكن ربما فات الاوان بالفعل لتجن ب جميع العواقب .وباملقارنة مع بشكل مخاوف مويدي تجاوز الانسانية بشان الذكاء الفايق ،فان هذه املخاوف مدعومة افضل بالادلة العلمية وحازت دعم ا كبريا بني الن خب ا ملثقفة في الغرب — التي ضجرت من النزعة الشكية ما بعد الحداثية وسياسات الهوية البريوقراطية — التي تري الان سببا للتركيز علي مشكلة يبدو انها حقيقية للغاية وواقعية للغاية وعاملية للغاية : تغري املناخ يحدث حقا ويوثر علي ك ل شخص وكل شيء في هذا الكوكب .وتدعو حملة جريتا ثونبرج والاعتصامات املناخية ،علي سبيل املثال ،الي توجيه الاهتمام الي ازمة املناخ. تحد ي تغري املناخ :حول الاولويات وحقبة التاثري البشري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 165, "content": "»ملاذا نقلق بشان الذكاء الاصطناعي اذا كانت املشكلة امللح ة هي تغري املناخ وكون مستقبل الكوكب في خطر؟«"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 166, "content": "يستخدم احيانا مفهوم حقبة التاثري البشري لتاطري املشكلة .وهي فكرة طرحها بول كروتزن الباحث في وتنص علي اننا نعيش في تغري املناخ ويوجني ستورمر عالم الاحياء، حقبة جيولوجية زادت فيها قوة البشر علي الارض وعلي نظمها البييية ،مما جعل البشر قو ة جيولوجية .ف كر في النمو الا سي لاعداد البشر واملاشية ،وفي التوسع العمراني املتزايد، واستنزاف الوقود الاحفوري ،والاستخدام الهايل للمياه العذبة ،وانقراض الانواع ،واطلاق املواد السامة ،وما الي ذلك .يعتقد البعض ان حقبة التاثري البشري قد بدات مع الثورة الزراعية؛ بينما يري اخرون انها انطلقت بانطلاق الثورة الصناعية )(Crutzen 2006 او بعد الحرب العاملية الثانية .علي اي حال ،لقد نشات قصة جديدة وتاريخ جديد، وربما حتي سردية جديدة .وغالبا ما يستخدم هذا املفهوم في الوقت الحاضر لاثارة القلق التخصصات )بما في ذلك العلوم وتغري املناخ ،ولحشد مختلف بشان الاحتباس الحراري الانسانية( للتفكري في مستقبل الكوكب. لا يتبن ي الجميع هذا املصطلح؛ فهو مصطلح مثري للجدل حتي بني الجيولوجيني، وقد شكك البعض في تركيزه علي اهمية البشر .علي سبيل املثال ،قد جادلت هاراواي ) (2015من منظور ما بعد الانسانية بان الانواع الاخري والعوامل »اللاحيوية« تلعب ايضا دو را في البيية املتحولة .ولكن حتي من دون مفهوم مثري للجدل مثل حقبة التاثري البشري ،فان ويجب علي السياسة تغري املناخ واملشكلات البييية )الاخري( ستظ ل باقية ، التعامل معها ،والافضل ان يكون ذلك في اقرب وقت ممكن .فماذا يعني هذا بالنسبة الي سياسة الذكاء الاصطناعي؟ يعتقد العديد من الباحثني ان الذكاء الاصطناعي والبيانات الضخمة يمكن ان تساعدنا ايضا في علاج العديد من مشكلات العالم ،بما في ذلك تغري املناخ .وعلي غرار بشكل عام ،يمكن ان يسهم الذكاء الاصطناعي في املعلومات الرقمية وتقنيات الاتصالات التنمية املستدامة وفي التعامل مع العديد من املشكلات البييية .ومن ا ملرج ح ان يصبح اتجاها ناجح ا في البحث والتطوير .ومع ذلك ،يمكن ان يجعل الذكاء الاصطناعي ا ملستدام يخصنا نحن جميع ا. يخص البيية؛ وبالتالي فيما الذكاء الاصطناعي الامور اسوا فيما اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 167, "content": "ولنتذ كر مجددا زيادة استهلاك الطاقة والنفايات .ومن منظور مشكلة حقبة التاثري البشري ،فان املخاطرة تكمن في ان البشر يمكن ان يستخدموا الذكاء الاصطناعي لاحكام قبضتهم علي الارض ،مما سيزيد من حدة املشكلة بدلا من ح لها. بشكل خاص اذا كنا ننظر الي الذكاء الاصطناعي ليس هذا يعتبر ام را اشكاليا فقط بوصفه حلا ولكن بوصفه الحل الرييسي .ولنفكر في سيناريو الذكاء الفايق لذكاء اصطناعي يعرف افضل منا نحن البشر ما هو جيد لنا :ذكاء اصطناعي »حميد« يخدم البشرية من خلال جعل البشر يتصر فون لصالحهم ولصالح الكوكب؛ علي سبيل املثال، الالة الاله التي تعادل تقنيا امللك الفيلسوف املذكور في فلسفة افلاطون .يحل الذكاء الاصطناعي الاله محل الانسان الاله ) ،(Harrari 2015ويدير نظام دعم الحياة الخاص بنا ويديرنا .فلحل مشكلات توزيع املوارد ،علي سبيل املثال ،يمكن للذكاء الاصطناعي ان يعمل بوصفه »وحدة خدمة« ،يدير امكانية وصول البشر الي املوارد .وستكون قراراته حلول تكنولوجية مستندة الي تحليله لانماط البيانات .ويمكن دمج هذا السيناريو مع مبتكرة مثل الهندسة الجيولوجية .البشر ليسوا الوحيدين الذين يحتاجون الي الادارة؛ فالكون كله في حاجة الي اعادة هندسته .ومن ثم ،يمكننا استخدام التكنولوجيا ل »اصلاح« مشكلاتنا ومشكلات الكوكب. ومع ذلك ،فان هذه السيناريوهات لن تكون فقط مستبدة وتتعد ي علي استقلالية البشر ،بل ستساهم بشكل اساسي في مشكلة حقبة التاثري البشري نفسها :فالوكالة ايضا البشرية ا ملفرطة ،هذه املرة يتم تفويضها من ق بل البشر الي الالات ،ستحول الكوكب باكمله ورد والة للبشر .يتم »حل« مشكلة حقبة التاثري البشري من خلال الوصول الي مجرد م بها الي النقيض التكنوقراطي ،مما يودي الي عا ل م من الالات يعام ل فيه البشر اولا كاطفال يجب رعايتهم وربما في وقت لاحق يتم تجاهلهم تمام ا .وفي هذا النوع من التاثري البشري ا ملتعلق بالبيانات الضخمة والسيناريو املالوف جدا الذي يتم فيه احلال الالات مح ل البشر، نعود م رة اخري الي سيناريوهات الاحلام والكوابيس. جنون الفضاء الجديد والاغراء الافلاطوني تغري املناخ وحقبة التاثري البشري ،والتي هي ثم ة اجابة اخري علي ايضا روية مولعة بالتكنولوجيا وربما ترتبط احيانا بسرديات تجاوز البشرية ،وهي :قد ندمر هذا الكوكب، ولكن يمكننا الهرب من الارض والذهاب الي الفضاء. تحد ي تغري املناخ :حول الاولويات وحقبة التاثري البشري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 168, "content": "كانت الصورة الايقونية لعام 2018هي سيارة ايلون ماسك الرياضية طراز تسلا وهي تطفو في الفضاء 3 .ماسك ايضا لديه خطط لاستعمار املريخ .وهو ليس الشخص راوده هذا الحلم :فهناك اهتمام متزايد بالذهاب الي الفضاء .وهذا ليس الوحيد الذي ي مجرد حلم .اذ تستثمر اموال طايلة في مشروعات الفضاء .وعلي عكس سباق الفضاء الذي حدث في القرن العشرين ،هذه املشروعات يتم دعمها من ق بل الشركات الخاصة. واملليونريات ا ملولعون بالتكنولوجيا ليسوا الوحيدين ا ملهتمني بالفضاء ،بل ان الفنانني ايضا شغوفون به بشدة .تخطط شركة سبيس اكس الخاصة بايلون ماسك لارسال فنانني الي مدار القمر 4 .وتعد السياحة الفضايية فكر ة اخري تزداد شيوع ا .فم ن من ا لا يرغب في غر للغاية. الذهاب الي الفضاء؟ الفضاء م مشكلة في ح د ذاته .بل ان له فوايد محتملة .علي سبيل لا يمثل الذهاب الي الفضاء تطرفا في بييات اكثر املثال ،يمكن ان تساعد الابحاث في كيفية البقاء علي قيد الحياة في التعامل مع املشكلات علي الارض ،وفي اختبار التقنيات ا ملستدامة ،واتخاذ منظور كوكبي. ضع في اعتبارك ناجمة عن ان ايضا ان مشكلة حقبة التاثري البشري يمكن ان تكون تكنولوجيا الفضاء منذ سنوات طويلة اتاحت لنا روية الارض من بعد .وبالنظر الي صورة سيارة ماسك مر ة اخري :يعتقد بعض الناس ان السيارة الكهربايية ح ل من حلول املشكلات البييية ،دون التشكيك في افتراض ان السيارات هي افضل وسيلة للنقل ودون التفكري في كيفية انتاج الكهرباء .علي اي حال ،هناك افكار مثرية للاهتمام. اشكالية اذا كانت نتيجتها هي اهمال املشكلات الارضية، ولكن احلام الفضاء تعد عرضا من اعراض الحالة التي شخصتها حنة ارنت ) (1958بالفعل عندما واذا كانت كتبت عن البشر :الكثري من التجريد والاغتراب .اشارت حنة الي ان الع لم يدعم رغبة دفينة وايضا في مغادرة الارض :حرفيا ،من خلال تكنولوجيا الفضاء )في عصرها ،سبوتنيك( من خلال طرق رياضية تجردنا وتعزلنا مما اصفه بحياتنا الارضية الفوضوية ا مل تجسدة والسياسية .ومن هذا املنظور ،يمكن تفسري احلام مويدي تجاوز البشرية بالذكاء الفايق وبمغادرة الارض علي انها تداع يات لنوع اشكالي من الاغتراب والهروب .انها الفكر الافلاطوني وفكر تجاوز الانسانية في اوضح صوره؛ ان الفكرة هي التغ لب ليس فقط علي قيود الجسد البشري ،ولكن ايضا علي قيود ذلك »النظام الداعم للحياة« :اي الارض نفسها .فالجسد ليس هو السجن الوحيد ،بل الارض نفسها ،ومن ثم علينا ان نه رب منها. اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 169, "content": "بالتالي ،فاحدي مخاطر الذكاء الاصطناعي هي انه يم كن هذا النوع من التفكري ويصبح الة للاغتراب :اداة ملغادرة الارض وانكار حالتنا الوجودية الاعتمادية الضعيفة والجسدية والارضية .بعبار ة اخري :صاروخ .مرة اخري ،لا تمثل الصواريخ مشكلة في ح د ذاتها .انما املشكلة هي مزج تقنيات معينة مع سرديات معينة .فعلي الرغم من ان الذكاء الاصطناعي يمكن ان يكون قوة ايجابية بالنسبة الي حياتنا الشخصية ،واملجتمع، والبشرية ،فان مزيج ا من تعزيز الاتجاهات التجريدية والاغترابية في العلوم والتكنولوجيا مستقبل تكنولوجي مو ذ مع خيالات تجاوز الانسانية و»تجاوز الارض« قد يودي الي للبشر وللكاينات الحية الاخري علي الارض .اذا هربنا من مشكلاتنا بدلا من التعامل معها — كما في مشكلة تغري املناخ ،علي سبيل املثال — فقد نفوز باملريخ )حتي الان( ولكننا سوف نخسر الارض. وكالعادة ،هناك جانب سياسي فرصا اخر لهذا املوضوع :اذ يمتلك بعض الناس مقارنة بالاخرين .املشكلة ليست فقط في ان تكنولوجيا ومالا وقدر ة اكبر علي الهروب الفضاء والذكاء الاصطناعي لهما تكلفة حقيقية بالنسبة الي الارض وان ك ل املال ا ملستثم ر في مشروعات الفضاء لم ي نفق علي مشكلات الارض الحقيقية مثل الحروب والفقر؛ بل املشكلة هي ان الاثرياء سيكونون قاد رين علي الهروب من الارض التي يدم رونها ،في كوكب يستحيل العيش فيه بصورة متزايدة )انظر ،علي حني يجب علي بقيتنا البقاء علي سبيل املثال ،زيمرمان .(2015ومثل الصواريخ والتكنولوجيا الاخري ،يمكن ان يصبح الذكاء الاصطناعي اداة ل »بقاء الاكثر ثراء« ،كما اوضح احد املع لقني ).(Rushkoff 2018 في الوقت الحاضر ،يحدث ذلك بالفعل مع تقنيات اخري :ففي مدن مثل دلهي وبكني، يعاني معظم الناس من تلو ث الهواء ،بينما يطري الاثرياء الي مناطق اقل تلوثا او يشترون هواء نقيا باستخدام تقنيات تنقية الهواء .ليس الجميع يتنفسون الهواء نفسه .والان ،هل سيساهم الذكاء الاصطناعي في توسيع هذه الفجوات بني الاثرياء والفقراء ،مما يودي الي صرفنا الذكاء حياة اكثر كربا وغري صحية للبعض وحياة افضل للبعض الاخر؟ هل سي الاصطناعي عن املشكلات البييية؟ يبدو ان فكرة ان الذكاء الاصطناعي ينبغي ان يسعي الي تحسني الحياة علي الارض ،للجميع وليس لفية معينة ،مع الوضع في الاعتبار ان حياتنا تعتمد علي كوكب الارض ،تعد متطلبا اخلاقيا .وقد تعيق بعض سرديات الفضاء تحقيق هذا الهدف بدلا من ان تساعدنا في تحقيقه. تحد ي تغري املناخ :حول الاولويات وحقبة التاثري البشري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 170, "content": "عودة الي الارض :نحو ذكاء اصطناعي مستدام دعوني اعود الي املشكلة العملية جدا للاولويات واملخاطر الحالية والحقيقية ا ملتعلقة بتغري املناخ .ماذا يجب ان تفعل اخلاقيات الذكاء الاصطناعي وسياساته في ضوء هذه التحديات؟ وعندما تكون هناك خلافات بشان قيمة حياة الكاينات غري البشرية ،فكيف يمكن حلها؟ سيتفق معظم الناس علي ان تسليم السيطرة الي الذكاء الاصطناعي او حلولا جيدة .لكن ما هو الحل الجيد؟ وهل يوج د حل؟ اذا ما الهروب من الارض ليست اجابة نافعة علي هذه الاسيلة ،فستقودنا بالضرورة الي الاسيلة الفلسفية املتعلقة اجبنا بكيفية تعاملنا بوصفنا بشرا مع التكنولوجيا ومع بييتنا .كما تقودنا ايضا الي الفصل املتعلق بالتكنولوجيا :ماذا يمكن ان يفعل الذكاء الاصطناعي وعلم البيانات من اجلنا، وماذا يمكننا ان نتوقع من الذكاء الاصطناعي منطقيا؟ من الواضح ان الذكاء الاصطناعي يمكن ان يساعدنا في التصدي للمشكلات البييية. فلنفكر مثلا في نحو استثنايي ان تغري املناخ .يبدو ان الذكاء الاصطناعي يستطيع علي املعقدة .اذ يمكن للذكاء الاصطناعي مساعدتنا يساعدنا في مواجهة مثل هذه املشكلات في دراسة املشكلة ،علي سبيل املثال ،من خلال اكتشاف الانماط التي لا يمكننا رويتها في البيانات البييية ،نظ را الي كثرة هذه البيانات وتعقيدها .كما يمكن ان يساعدنا في الحلول ،علي سبيل املثال ،من خلال مساعدتنا في التعامل مع تعقيد عمليات التنسيق وفي تنفيذ تدابري مثل تقليل انبعاثات املواد الضارة ،كما اقترح فلوريدي واخرون ).(2018 وعلي نطاق اوسع ،يمكن ان يساعد الذكاء الاصطناعي من خلال مراقبة ونمذجة الانظمة البييية وتمكني حلول مثل الشبكات الذكية للطاقة والزراعة الذكية ،كما اقترحت مدونة املنتدي الاقتصادي العاملي ) .(Herweijer 2018ويمكن للحكومات وللشركات ايضا ان تتولي الامر هنا .علي سبيل املثال ،استخدمت جوجل بالفعل الذكاء الاصطناعي لتقليل استخدام الطاقة في مراكز البيانات. ومع ذلك ،لا يعني هذا بالضرورة »انقاذ الكوكب« .يمكن للذكاء الاصطناعي ايضا ان يسبب مشكلات ويجعل الامور اسوا .ولنفكر مر ة اخري في التاثري البييي السلبي الذي يعتمد يمكن ان يخلفه الذكاء الاصطناعي نظ را الي الطاقة وال بني التحتية واملواد التي عليها .ولنفكر ليس فقط في استخدام الذكاء الاصطناعي ولكن ايضا في انتاجه :قد تكون الكهرباء منتج ة بطرق غري مستدامة ،كما ان انتاج الاجهزة املدعومة بالذكاء الاصطناعي يستهلك الطاقة واملواد الخام وينتج نفايات .او فلنفكر في »الدفع الذاتي« الذي اقترحه اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 171, "content": "بطرق بييية فلوريدي واخرون؛ اذ يقترحون ان الذكاء الاصطناعي قد يساعدنا في التصرف جيدة عن طريق مساعدتنا في الالتزام بخيارنا املفروض ذاتيا .ولكن هذا الامر ينطوي علي م خاطره الاخلاقية الخاصة :فليس من الواضح انه يحترم استقلال البشر وكرامتهم، كما يدعي ال كت اب ،وقد يسري في اتجاه الذكاء الاصطناعي الحميد الذي يعتني بالبشر لكنه يدمر حريتهم ويساهم في مشكلة حقبة التاثري البشري .وهناك علي الاقل خطورة فرض اشكال جديدة من السلطة الابوية والاستبداد .علاو ة علي ذلك ،قد يتماشي استخدام الذكاء الاصطناعي ملواجهة تغري املناخ مع النظرة العاملية التي تحو ل العالم الي مجرد مستودع بيانات ومع الروية التي تختزل ذكاء الانسان الي معالجة البيانات؛ بل ربما نوع ادني من معالجة البيانات يتط لب التحسني بواسطة الالات .ومن غري ا ملرج ح ان تعيد مثل هذه الروي تشكيل علاقتنا بالبيية بطريقة ت خفف التحديات مثل تغري املناخ واملشكلات املشار اليها بمصطلح التاثري البشري. نواجه ايضا خطر النزعة للحلول التكنولوجية بمعني ان الاقتراحات لاستخدام الذكاء الاصطناعي ملعالجة املشكلات البييية يمكن ان تفترض ان هناك حلا نهاييا لجميع املشكلات ،وان التكنولوجيا وحدها يمكن ان تجيب عن اصعب اسيلتنا ،واننا يمكن ان نحل املشكلات بالكامل عن طريق استخدام الذكاء البشري او الاصطناعي .ولكن املشكلات البييية لا يمكن ح لها عن طريق الذكاء التكنولوجي والعلمي؛ فهي مرتبطة ايضا باملشكلات السياسية والاجتماعية التي لا يمكن التصدي لها بالكامل عن طريق التكنولوجيا وحدها. مشكلات بشرية .والرياضيات وذريتها التكنولوجية كما ان املشكلات البييية دايم ا ما تكون هي ادوات مفيدة جدا ،ولكنها محدودة فيما يتعلق بفهم املشكلات البشرية والتعامل معها .علي سبيل املثال ،قد تتعا رض الق يم .ولن يستطيع الذكاء الاصطناعي بالضرورة ان يساعدنا في الاجابة عن السوال حول الاولويات ،وهو سوال اخلاقي وسياسي مهم يجب ان نترك للبشر الاجابة عنه .وتع لمنا العلوم الانسانية والاجتماعية ان نكون حذرين جدا بشان الحلول »النهايية«. علاو ة علي ذلك ،البشر ليسوا الوحيدين الذين تواجههم مشكلات؛ فالكاينات غري البشرية ايضا تواجهها صعوبات ،والتي غالبا ما تهم ل في املناقشات الخاصة بمستقبل يجب ان نهرب من الارض ،او الروية العاملية الذكاء الاصطناعي .واخريا ،الراي القايل باننا التي تقول ان كل شيء عبارة عن بيانات نستطيع نحن البشر التلاع ب بها بمساعدة الالات، نطاقا اشكال اوسع يمكن ان يود يا في النهاية الي توسيع الفجوة بني الاغنياء والفقراء والي تحد ي تغري املناخ :حول الاولويات وحقبة التاثري البشري"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "تغير المناخ :حول الأولويات ِّ تحدي ُّ", "section_path": ["الفصل الثاني عشر", "تغير المناخ :حول الأولويات ِّ تحدي ُّ"], "page": 172, "content": "من الاستغلال والانتهاكات للكرامة الانسانية ،بالاضافة الي تهديد حياة الاجيال القادمة عن طريق املخاطرة بتدمري ظروف الحياة علي كوكبنا .اننا نحتاج الي التفكري العميق في كيفية بناء مجتمعات وبييات مستدامة؛ اننا نحتاج الي التفكري البشري. الذكاء والحكمة ومع ذلك ،فطريقة تفكري البشر لها جوانب متعددة ايضا .والذكاء الاصطناعي مرتبط بنوع واحد من انواع التفكري البشري والذكاء البشري :النوع املعرفي الاكثر تجريدا .هذا النوع من التفكري قد اثبت نجاح ا كبريا ،ولكنه له قيوده وهو ليس النوع الوحيد من التفكري الذي يمكن او يجب علينا ممارسته .والاجابة عن الاسيلة الاخلاقية والسياسية بشكل افضل مع ا ملتعلقة بكيفية العيش ،وكيفية التعامل مع بييتنا ،وكيفية التعامل الكاينات الحية غري البشرية تتط لب ما هو اكثر من الذكاء البشري التجريدي )علي سبيل املثال ،الح جج ،والنظريات ،والنماذج( او التع رف علي الانماط بواسطة الذكاء الاصطناعي. اشخاص اذكياء والات ذكية ،ولكننا بحاجة الي الحدس والخبرة التي لا ايضا نحتاج الي استجابة الي التحلي بالحكمة العملية والفضيلة وصفها بوضوح كامل ،ونحتاج الي يمكن املشكلات واملواقف املادية ومن اجل تحديد اولوياتنا .قد تستنري هذه الحكمة بالعمليات املعرفية التجريدية وبتحليل البيانات ،ولكنها تستند ايضا الي التجارب ا مل تجسدة الخاصة بالعلاقات واملواقف التي نم ر بها في العالم ،والي التعامل مع اشخاص اخرين ،ومع املادية، ومع بييتنا الطبيعية .ومن ا ملحتمل ان يعتمد نجاحنا في التصدي للمشكلات الكبرية التي تواجهنا في عصرنا علي مزيج من الذكاء التجريدي — البشري والاصطناعي — والحكمة العملية امللموسة التي تم تطويرها علي اساس التجارب وا ملمارسات البشرية امللموسة والخاصة باملواقف ،بما في ذلك تجاربنا مع التكنولوجيا .وايا كان الاتجاه الذي سيسري واجهون تحد ي تطوير هذا فيه تطوير الذكاء الاصطناعي ،فان البشر وحدهم هم م ن ي النوع الاخري من املعرفة والتعلم .وعلي البشر ان يتصد وا له .فالذكاء الاصطناعي قادر علي التع رف علي الانماط ،ولكن الحكمة لا يمكن تفويضها الي الالات."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "مسرد المصطلحات", "section_path": ["مسرد المصطلحات"], "page": 173, "content": "الابتكار املسيول :نهج يميل الي جعل الابتكار اكثر اخلاقية ومسيولية علي الصعيد املجتمعي ،وينطوي عاد ة علي تضمني الاخلاق في التصميم ومراعاة اراء اصحاب الشان ومصالحهم. الاخلاقيات الايجابية :الاخلاقيات املرتبطة بالطريقة التي ينبغي ان نعيش بها )مع ا(، وتستند الي روية للحياة الجيدة واملجتمع الجيد .وتتناقض مع الاخلاقيات السلبية ،التي تضع قيودا وتحدد ما ينبغي الا نفعله. الاخلاقيات ا ملضم نة في التصميم :نهج لاخلاقيات التكنولوجيا وعنصر اساسي في »الابتكار املسيول« الذي يهدف الي دمج الاخلاقيات في مرحلة تصميم التكنولوجيا وتطويرها .وفي بعض الاحيان ،نسميها »تضمني القيم في التصميم« .ومن املصطلحات الحساس للق يم« و»التصميم ا ملتماشي مع الاخلاق«. املشابهة لهذا املصطلح »التصميم يجب ان يعززوا انفسهم من خلال التقنيات تجاوز الانسانية :الاعتقاد بان البشر ا ملتقدمة ،وبهذه الطريقة يتجاوزون حالتهم الانسانية؛ بمعني ان الانسانية يجب ان تنتق ل الي مرحلة جديدة .وهذه ايضا حركة دولية. التحيز :التمييز ضد او لصالح افراد باعينهم او مجموعات بعينها .في سياق الاخلاقيات والسياسة ،يثار السوال حول ما اذا كان تحي ز معني ظا ملا او غري عادل. تع لم الالة :الة او برنامج يمكنه ان يتعلم تلقاييا :ليس بالطريقة التي يتع لم بها البشر، ولكن بناء علي عملية حسابية واحصايية .يمكن لخوارزميات التع لم ،من خلال تغذيتها بالبيانات ،تحديد الانماط او القواعد في البيانات واجراء توقعات للبيانات املستقبلية."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "مسرد المصطلحات", "section_path": ["مسرد المصطلحات"], "page": 174, "content": "اخلاقيات الذكاء الاصطناعي"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "مسرد المصطلحات", "section_path": ["مسرد المصطلحات"], "page": 175, "content": "التع لم العميق :شكل من اشكال »تعلم الالة« يستخدم الشبكات العصبية املكونة من عدة طبقات من »الخلايا العصبية« :وحدات معالجة بسيطة مترابطة فيما بينها وتتفاعل. التف رد التكنولوجي :الفكرة التي تقول بانه ستحني لحظة في تاريخ الانسان عندما يجلب انفجار في الذكاء الالي تغيريا جذريا في حضارتنا يجعلنا لا نفهم بعدها ما يحدث. حقبة التاثري البشري )الانثروبوسني( :الحقبة الجيولوجية الحالية املزعومة التي زادت فيها قوة البشر وتاثريهم علي الارض ونظمها البييية ،مما جعل البشر قوة جيولوجية. الذكاء الاصطناعي :الذكاء الذي تظهره او تحاكيه الوسايل التكنولوجية .غالبا ما يفترض ان معني »الذكاء« في هذا التعريف يستند الي مقاييس الذكاء البشري ،وي قصد به القدرات والسلوكيات الذكية التي يظهرها البشر .ويمكن ايضا ان يشري املصطلح الي العلم او الي التقنيات ،مثل خوارزميات التعلم. الذكاء الاصطناعي الجدير بالثقة :الذكاء الاصطناعي الذي يمكن للانسان الوثوق فيه. يمكن ان تشري شروط هذه الثقة الي مبادي اخلاقية )اخري( مثل الكرامة الانسانية واحترام حقوق الانسان ،وما الي ذلك ،و/او الي العوامل الاجتماعية والتقنية التي توثر فيما اذا كان الناس يرغبون في استخدام التكنولوجيا .استخدام مصطلح »الثقة« فيما يتعلق بالتكنولوجيا مثري للجدل. الذكاء الاصطناعي الرمزي :الذكاء الاصطناعي الذي يعتمد علي التمثيلات الرمزية للمهام املعرفية العليا ،مثل التفكري املجرد واتخاذ القرارات .ويمكن ان يستخدم شجرة اتخاذ القرار وياخذ شكل نظام خبري يتطلب مدخلات من خبراء املجال. نطاق واسع الذكاء الاصطناعي العام :الذكاء ا ملشابه لذكاء البشر ،ويمكن تطبيقه علي مشكلة او مهمة باملقارنة مع الذكاء الاصطناعي املحدود ،الذي يمكن تطبيقه علي معينة فقط .ويطلق عليه ايضا الذكاء الاصطناعي »القوي« في مقابل الذكاء الاصطناعي »الضعيف«. الذكاء الاصطناعي القابل للتفسري :الذكاء الاصطناعي الذي يمكن ان يشرح للبشر تصرفاته او قراراته او توصياته ،او يمكن ان يوفر معلومات كافية حول كيفية الوصول الي نتيجته. مسرد املصطلحات"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "مسرد المصطلحات", "section_path": ["مسرد المصطلحات"], "page": 176, "content": "الذكاء الاصطناعي املستدام :الذكاء الاصطناعي الذي يم كن ويساهم في طريقة عيش )وايضا مستدامة للبشرية ولا يدمر النظم البييية علي الارض التي يعتمد عليها البشر العديد من غري البشر(. الذكاء الفايق :الفكرة التي تقول بان الالات سوف تتفو ق علي ذكاء الانسان .ويرتبط الذكاء الفايق احيانا بفكرة »انفجار الذكاء الاصطناعي« الذي يسب به تصميم الالات الذكية لالات اكثر ذكاء. علم البيانات :علم متعدد التخصصات يستخدم الاحصاءات والخوارزميات وغريها من انماط مفيدة وذات معني من مجموعات البيانات؛ املعروفة احيانا الاساليب لاستخراج باسم »البيانات الضخمة« .في الوقت الحالي ،يستخدم تع لم الالة في هذا املضمار .وبجانب تحليل البيانات ،يهتم علم البيانات ايضا باستخراج البيانات واعدادها وتفسريها. القابلية للتفسري :القدرة علي التفسري او قابلية التفسري .في سياق الاخلاقيات ،فانه يشري الي القدرة علي الشرح للاخرين ملاذا قمت بشيء معني او ملاذا اتخذت قرا را بعينه؛ مسيولا. وهذا جزء مما يعنيه ان تكون وخصوصا املكانة ما بعد الانسانية :مجموعة من ا ملعتقدات التي تشكك في الانسانية، املحورية للانسان ،وتوسع دايرة الاهتمام الاخلاقي لتشمل غري البشر. كمرادف ملعني ان يتحلي املرء بالاخلاق ،ومن املسيولية الاخلاقية :يمكن استخدامها ثم فانها تشري الي تحقيق نتايج جيدة اخلاقيا ،والالتزام باملبادي الاخلاقية ،والتمتع بالفضيلة ،واستحقاق الثناء ،وما الي ذلك؛ حسب النظرية املعيارية ا ملفترضة .يمكن للمرء ايضا ان يتساءل عن الشروط التي بموجبها يمكن اسناد املسيولية اليه .تعد شروط اسناد املسيولية الاخلاقية هي الوكالة الاخلاقية واملعرفة .وتوكد نه ج العلاقات مسيولا امام الاخرين. ان املرء يكون دايم ا املكانة الاخلاقية :املنزلة الاخلاقية التي يتمت ع بها كيان ما؛ اي كيف ينبغي التعامل مع هذا الكيان. الوكالة الاخلاقية : القدرة علي الفعل والتفكري والح كم واتخاذ القرار الاخلاقي ، بدلا من مجرد وجود عواقب اخلاقية."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 177, "content": "ايتها املراة علي الحايط:الفصل الاول (1) See https://www.youtube.com/watch?v=D5VN56jQMWM. (2) See the case of Paul Zilly as told by Fry (2018, 71-72). More details in Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, “Machine Bias,” ProPublica, May 23, 2016, https://www.propublica.org/article/ machine-bias-risk-assessments-in-criminal-sentencing. (3) For example, in 2016 a local police zone in Belgium started using predictive policing software to predict burglaries and vehicle theft (Algorithm Watch 2019, 44). (4) BuzzFeedVideo, “You Won’t Believe What Obama Says in this Video!” https://www.youtube.com/watch?v=cQ54GDm1eL0&fbclid=IwA R1oD0AlopEZa00XHo3WNcey_qNnNqTsvHN_aZsNb0d2t9cmsDbm9oCf X8A."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 178, "content": "الذكاء الفايق والوحوش ونهاية العالم بالذكاء الاصطناعي:الفصل الثاني (1) Some talk of taming or domesticating AI, although the analogy with wild animals is problematic, if only because in contrast to the “wild”"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 179, "content": "اخلاقيات الذكاء الاصطناعي AI some imagine, animals are limited by their natural faculties and can be trained and developed only up to some point (Turner 2019). (2) It is often suggested that Mary Shelley must have been influenced by her parents, who discussed politics, philosophy, and literature, but also science, and by her partner Percy Bysshe Shelley, who was an amateur scientist especially interested in electricity."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 180, "content": "كل ما له علاقة بالبشر:الفصل الثالث (1) Dreyfus was influenced by Edmund Husserl, Martin Heidegger, and Maurice Merleau-Ponty."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 181, "content": "اهي:الفصل الرابع حقا مجرد الات؟ (1) A real-world case of this was the robot dog Spot who was kicked by its developers to test it, something that met with surprisingly empathetic responses: https://www.youtube.com/watch?v=aR5Z6AoMh6U."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 182, "content": "التكنولوجيا:الفصل الخامس (1) See https://www.humanbrainproject.eu/en/. (2) See, for example, the European Commission’s AI High Level Expert Group’s (2018) definition of AI."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 183, "content": "لا:الفصل السادس تنس )علم( البيانات (1) See http://tylervigen.com/spurious-correlations. (2) Concrete examples such as Facebook, Walmart, American Express, Hello Barbie, and BMW are drawn from Marr (2018)."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 184, "content": "لامسيولية الالات والقرارات غري ا ملبررة :الفصل الثامن (1) One could ask, however, if decisions made by AIs really count as decisions, and if so, if there is a difference in the kind of decisions we delegate or should delegate to AIs. In this sense, the problem regarding responsibility of or for AI raises the very question of what a decision is. The problem also connects with issues about delegation: we delegate decisions to machines. But what does this delegation entail in terms of responsibility? (2) Indeed, this case is more complicated since one could argue that the delegate is then still responsible for that particular task—at least to some extent—and it may not be clear how the responsibility is distributed in such cases. (3) Note that this was and is not always the case; as Turner (2019) reminds us, there are cases of animals being punished."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 185, "content": "التحيز ومعني الحياة:الفصل التاسع (1) Thanks to Bill Price for the thought experiment."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 186, "content": "السياسات املقترحة:الفصل العاشر (1) See: https://www.acrai.at/en/. (2) The resolution can be found here: http://www.europarl.europa.eu/ doceo/document/TA-8-2017-0051_EN.html?redirect#title1. (3)"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 187, "content": "https://www.scu.edu/ethics-in-technology-practice/"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 188, "content": "conceptual-frameworks/. (4) See: https://www.partnershiponai.org/. (5) See: https://www.blog.google/technology/ai/ai-principles/. (6) See: https://www.microsoft.com/en-us/ai/our-approach-to-ai. (7) See: https://www.accenture.com/t20160629T012639Z_w_/us-en/ _acnmedia/PDF-24/Accenture-Universal-Principles-Data-Ethics.pdf. اخلاقيات الذكاء الاصطناعي (8)"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 189, "content": "See: https://www.businessinsider.de/apple-ceo-tim-cook-on"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 190, "content": "-privacy-the-free-market-is-not-working-regulations-2018-11?r= US&IR=T. (9) See: https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml? bill_id=201720180SB1001. (10) See: https://www.stopkillerrobots.org/. (11) See: https://futureoflife.org/ai-principles/. (12) Consider people such as Batya Friedman and Helen Nissenbaum in the United States, and later Jeroen van den Hoven and others in the Netherlands, who have been championing the ethical design of technology for some time. (13) See: https://www.tuev-sued.de/company/press/press-archive/ tuv-sud-and-dfki-to-develop-tuv-for-artificial-intelligence."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 191, "content": "التحديات التي تواجه صانعي السياسات:الفصل الحادي عشر (1) See: https://ec.europa.eu/digital-single-market/en/european-aialliance."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "ملاحظات", "section_path": ["ملاحظات"], "page": 192, "content": "تحد ي :الفصل الثاني عشر حول الاولويات وحقبة التاثري البشري:تغري املناخ (1) See: https://hai.stanford.edu/ and https://hcai.mit.edu. (2) See: https://sustainabledevelopment.un.org/post2015/transform ingourworld. (3) See: https://www.theguardian.com/science/2018/feb/07/spaceoddity-elon-musk-spacex-car-mars-falcon-heavy. (4) See: https://cosmosmagazine.com/space/why-we-need-to-send -artists-into-space."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "قراءات إضافية", "section_path": ["قراءات إضافية"], "page": 193, "content": "Alpaydin, Ethem, 2016, Machine Learning, Cambridge, MA: MIT Press. Arendt, Hannah, 1958, The Human Condition, Chicago: Chicago University Press. Aristotle, 2002, Nichomachean Ethics, Translated by Christopher Rowe, with commentary by Sarah Broadie, Oxford: Oxford University Press. Boddington, Paula, 2017, Towards a Code of Ethics for Artificial Intelligence, Cham: Springer. Boden, Margaret A., 2016, AI: Its Nature and Future, Oxford: Oxford University Press. Bostrom, Nick. 2014, Superintelligence, Oxford: Oxford University Press. Brynjolfsson, Erik, and Andrew McAfee, 2014, The Second Machine Age, New York: W. W. Norton. Coeckelbergh, Mark, 2012, Growing Moral Relations: Critique of Moral Status Ascription, New York: Palgrave Macmillan. Crutzen, Paul J., 2006, “The ‘Anthropocene,’” In Earth System Science in the Anthropocene, edited by Eckart Ehlers and Thomas Krafft, 13–18. Cham: Springer."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "قراءات إضافية", "section_path": ["قراءات إضافية"], "page": 194, "content": "اخلاقيات الذكاء الاصطناعي Dignum, Virginia, Matteo Baldoni, Cristina Baroglio, Maruiyio Caon, Raja Chatila, Louise Dennis, Gonzalo Génova, et al. 2018, “Ethics by Design: Necessity or Curse?” Association for the Advancement of Artificial Intelligence. http://www.aies-conference.com/2018/contents/ papers/main/AIES_2018_paper_68.pdf. Dreyfus, Hubert L., 1972, What Computers Can’t Do, New York: Harper & Row. Floridi, Luciano, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, and Effy Vayena, 2018, “AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.” Minds and Machines 28, no. 4: 689–707. Frankish, Keith, and William M. Ramsey, eds. 2014. The Cambridge Handbook of Artificial Intelligence. Cambridge: Cambridge University Press. European Commission AI HLEG (High-Level Expert Group on Artificial Intelligence). 2019. “Ethics Guidelines for Trustworthy AI.” April 8, 2019. Brussels: European Commission. https://ec.europa.eu/futurium/en/ ai-alliance-consultation/guidelines#Top. Fry, Hannah. 2018. Hello World: Being Human in the Age of Algorithms. New York and London: W. W. Norton. Fuchs, Christian. 2014. Digital Labour and Karl Marx. New York: Routledge. Gunkel, David. 2012. The Machine Question. Cambridge, MA: MIT Press. Harari, Yuval Noah. 2015. Homo Deus: A Brief History of Tomorrow. London: Hervill Secker. Haraway, Donna. 1991. “A Cyborg Manifesto: Science, Technology, and Socialist-Feminism in the Late Twentieth Century.” In Simians,"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "قراءات إضافية", "section_path": ["قراءات إضافية"], "page": 195, "content": "Cyborgs and Women: The Reinvention of Nature, 149–181. New York: Routledge. IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. 2017. “Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems,” Version 2. IEEE, 2017. http://standards.Ieee.org/develop/indconn/ec/ autonomous_systems.html. Kelleher, John D. and Brendan Tierney. 2018. Data Science. Cambridge, MA: MIT Press. Nemitz, Paul Friedrich, 2018. “Constitutional Democracy and Technology in the Age of Artificial Intelligence.” Philosophical Transactions of the Royal Society A 376, no. 2133. https://doi.org/10.1098/rsta.2018 .0089. Noble, David F. 1997. The Religion of Technology. New York: Penguin Books. Reijers, Wessel, David Wright, Philip Brey, Karsten Weber, Rowena Rodrigues, Declan O’Sullivan, and Bert Gordijn. 2018. “Methods for Practising Ethics in Research and Innovation: A Literature Review, Critical Analysis and Recommendation.” Science and Engineering Ethics 24, no. 1437–1481. Shelley, Mary. 2017. Frankenstein. Annotated edition. Edited by David H. Guston, Ed Finn, and Jason Scott Robert. Cambridge, MA: MIT Press. Turkle, Sherry. 2011. Alone Together: Why We Expect More from Technology and Less from Each Other. New York: Basic Books. Wallach, Wendell, and Colin Allen. 2009. Moral Machines: Teaching Robots Right from Wrong. Oxford: Oxford University Press."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "المراجع", "section_path": ["المراجع"], "page": 196, "content": "Accessnow. 2018. “Mapping Regulatory Proposals for Artificial Intelligence in Europe.” https://www.accessnow.org/cms/assets/uploads/ /11/mapping_regulatory_proposals_for_AI_in_EU.pdf. ACRAI (Austria Council on Robotics and Artificial Intelligence). 2018. “Die Zukunft Österreichs mit Robotik und Künstlicher Intelligenz positive gestalten: White paper des Österreichischen Rats für Robotik und Künstliche Intelligenz.” “Algorithm and Blues.” 2016. Nature 537:449. AlgorithmWatch. 2019. “Automating Society: Taking Stock of Automated Decision Making in the EU.” A report by AlgorithmWatch in cooperation with Bertelsmann Stiftung. January 2019. Berlin: AW AlgorithmWatch GmbH. http://www.algorithmwatch.org/automatingsociety. Alpaydin, Ethem. 2016. Machine Learning. Cambridge, MA: MIT Press. Anderson, Michael and Susan Anderson. 2011. “General Introduction.” In Machine Ethics, edited by Michael Anderson and Susan Anderson, 1–4. Cambridge: Cambridge University Press. Arendt, Hannah. 1958. The Human Condition. Chicago: Chicago University Press."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "المراجع", "section_path": ["المراجع"], "page": 197, "content": "اخلاقيات الذكاء الاصطناعي Arkoudas, Konstantine, and Selmer Bringsjord. 2014. “Philosophical Foundations.” In The Cambridge Handbook of Artificial Intelligence, edited by Keith Frankish and William M. Ramsey. Cambridge: Cambridge University Press. Armstrong, Stuart. 2014. Smarter Than Us: The Rise of Machine Intelligence. Berkeley: Machine Intelligence Research Institute. Awad, Edmond, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-François Bonnefon, and Iyad Rahwan. 2018. “The Moral Machine Experiment.” Nature 563:59–64. Bacon, Francis. 1964. “The Refutation of Philosophies.” In The Philosophy of Francis Bacon, edited by Benjamin Farrington, 103–132. Chicago: University of Chicago Press. Boddington, Paula. 2016. “The Distinctiveness of AI Ethics, and Implications for Ethical Codes.” Paper presented at the workshop Ethics for Artificial Intelligence, July 9, 2016, IJCAI-16, New York. https://www.cs.ox.ac.uk/efai/2016/11/02/the-distinctiveness-ofai-ethics-and-implications-for-ethical-codes/. Boddington, Paula. 2017. Towards a Code of Ethics for Artificial Intelligence. Cham: Springer. Boden, Margaret A. 2016. AI: Its Nature and Future. Oxford: Oxford University Press. Borowiec, Steven. 2016. “AlphaGo Seals 4–1 Victory Over Go Grandmaster Lee Sedol.” Guardian, March 15. https://www.theguardian.com/ technology/2016/mar/15/googles-alphago-seals-4-1-victoryover-grandmaster-lee-sedol. Bostrom, Nick. 2014. Superintelligence. Oxford: Oxford University Press. Brynjolfsson, Erik, and Andrew McAfee. 2014. The Second Machine Age. New York: W. W. Norton. املراجع Bryson, Joanna. 2010. “Robots Should Be Slaves.” In Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issues, edited by Yorick Wilks, 63–74. Amsterdam: John Benjamins. Bryson, Joanna. 2018. “AI & Global Governance: No One Should Trust AI.” United Nations University Centre for Policy Research. AI & Global Governance, November 13, 2018. https://cpr.unu.edu/ai-globalgovernance-no-one-should-trust-ai.html. Bryson, Joanna, Mihailis E. Diamantis, and Thomas D. Grant. 2017. “Of, For, and By the People: The Legal Lacuna of Synthetic Persons.” Artificial Intelligence & Law 25, no. 3: 273–291. Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. 2017. “Semantics Derived Automatically from Language Corpora Contain Human-like Biases.” Science 356:183–186. Castelvecchi, Davide. 2016. “Can We Open the Black Box of AI?” Nature , no. 7623: 21–23. CDT (Centre for Democracy & Technology) 2018. “Digital Decisions.” https://cdt.org/issue/privacy-data/digital-decisions/. Coeckelbergh, Mark. 2010. “Moral Appearances: Emotions, Robots, and Human Morality.” Ethics and Information Technology 12, no. 3: 235– Coeckelbergh, Mark. 2011. “You, Robot: On the Linguistic Construction of Artificial Others.” AI & Society 26, no. 1: 61–69. Coeckelbergh, Mark. 2012. Growing Moral Relations: Critique of Moral Status Ascription. New York: Palgrave Macmillan. Coeckelbergh, Mark. 2013. Human Being @ Risk: Enhancement, Technology, and the Evaluation of Vulnerability Transformations. Cham: Springer. Coeckelbergh, Mark. 2017. New Romantic Cyborgs. Cambridge, MA: MIT Press. اخلاقيات الذكاء الاصطناعي Crawford, Kate, and Ryan Calo. 2016. “There Is a Blind Spot in AI Research.” Nature 538:311–313. Crutzen, Paul J. 2006. “The ‘Anthropocene.’” In Earth System Science in the Anthropocene edited by Eckart Ehlers and Thomas Krafft, 13–18. Cham: Springer. Darling, Kate, Palash Nandy, and Cynthia Breazeal. 2015. “Empathic Concern and the Effect of Stories in Human-Robot Interaction.” In 2015 th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 770–775. New York: IEEE. Dennett, Daniel C. 1997. “Consciousness in Human and Robot Minds. In Cognition, Computation, and Consciousness, edited by Masao Ito, Yasushi Miyashita, and Edmund T. Rolls, 17–29. New York: Oxford University Press. Digital Europe. 2018. “Recommendations on AI Policy: Towards a Sustainable and Innovation-friendly Approach.” Digitaleurope.org, November , 2018. Dignum, Virginia, Matteo Baldoni, Cristina Baroglio, Maruiyio Caon, Raja Chatila, Louise Dennis, Gonzalo Génova, et al. 2018. “Ethics by Design: Necessity or Curse?” Association for the Advancement of Artificial Intelligence. http://www.aies-conference.com/2018/contents/ papers/main/AIES_2018_paper_68.pdf. Dowd, Maureen. 2017. “Elon Musk’s Billion-Dollar Crusade to Stop the A.I. Apocalypse.” Vanity Fair, March 26, 2017. https://www.vanityfair .com/news/2017/03/elon-musk-billion-dollar-crusade-to-stopai-space-x. Dreyfus, Hubert L. 1972. What Computers Can’t Do. New York: HarperCollins. املراجع Druga, Stefania and Randi Williams. 2017. “Kids, AI Devices, and Intelligent Toys.” MIT Media Lab, June 6, 2017. https://www.media.mit.edu/ posts/kids-ai-devices/f. European Commission. 2018. “Ethics and Data Protection.” http:// ec.europa.eu/research/participants/data/ref/h2020/grants_manual/ hi/ethics/h2020_hi_ethics-data-protection_en.pdf. European Commission Directorate-General of Employment, Social Affairs and Inclusion. 2018. “Employment and Social Developments in Europe ” Luxembourg: Publications Office of the European Union. http:// ec.europa.eu/social/main.jsp?catId=738&langId=en&pubId=8110. European Commission AI HLEG (High-Level Expert Group on Artificial Intelligence). 2018. “Draft Ethics Guidelines for Trustworthy AI: Working Document for Stakeholders.” Working document, December 18, 2018. Brussels: European Commission. https://ec.europa.eu/digital-singlemarket/en/news/draft-ethics-guidelines-trustworthy-ai. European Commission AI HLEG (High-Level Expert Group on Artificial Intelligence). 2019. “Ethics Guidelines for Trustworthy AI.” April 8, 2019. Brussels: European Commission. https://ec.europa.eu/futurium/en/ ai-alliance-consultation/guidelines#Top. EGE (European Group on Ethics in Science and New Technologies). 2018. “Statement on Artificial Intelligence, Robotics and ‘Autonomous’ Systems.” Brussels: European Commission. European Parliament and the Council of the European Union. 2016. “General Data Protection Regulation (GDPR).” https://eur-lex.europa.eu/ legal-content/EN/TXT/?uri=celex%3A32016R0679. Executive Office of the President, National Science and Technology Council Committee on Technology. 2016. “Preparing for the Future of Artificial Intelligence.” Washington, DC: Office of Science and Technology Policy (OSTP). اخلاقيات الذكاء الاصطناعي Floridi, Luciano, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, and Effy Vayena. 2018. “AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.” Minds and Machines 28, no. 4: 689–707. Floridi, Luciano, and J. W. Sanders. 2004. “On the Morality of Artificial Agents.” Minds and Machines 14, no. 3: 349–379. Ford, Martin. 2015. Rise of the Robots: Technology and the Threat of a Jobless Future. New York: Basic Books. Frankish, Keith, and William M. Ramsey. 2014. “Introduction.” In The Cambridge Handbook of Artificial Intelligence, edited by Keith Frankish and William M. Ramsey, 1–14. Cambridge: Cambridge University Press. Frey, Carl Benedikt, and Michael A. Osborne. 2013. “The Future of Employment: How Susceptible Are Jobs to Computerisation?” Working paper, Oxford Martin Programme on Technology and Employment, University of Oxford. Fry, Hannah. 2018. Hello World: Being Human in the Age of Algorithms. New York: W. W. Norton. Fuchs, Christian. 2014. Digital Labour and Karl Marx. New York: Routledge. Goebel, Randy, Ajay Chander, Katharina Holzinger, Freddy Lecue, Zeynep Akata, Simone Stumpf, Peter Kieseberg, and Andreas Holzinger. 2018. “Explainable AI: The New 42?” Paper presented at the CD-MAKE 2018, Hamburg, Germany, August 2018. Gunkel, David. 2012. The Machine Question. Cambridge, MA: MIT Press. Gunkel, David. 2018. “The Other Question: Can and Should Robots Have Rights?” Ethics and Information Technology 20:87–99. املراجع Harari, Yuval Noah. 2015. Homo Deus: A Brief History of Tomorrow. London: Hervill Secker. Haraway, Donna. 1991. “A Cyborg Manifesto: Science, Technology, and Socialist-Feminism in the Late Twentieth Century.” In Simians, Cyborgs and Women: The Reinvention of Nature, 149–181. New York: Routledge. Haraway, Donna. 2015. “Anthropocene, Capitalocene, Plantationocene, Chthulucene: Making Kin.” Environmental Humanities 6:159–165. Herweijer, Celine. 2018. “8 Ways AI Can Help Save the Planet.” World Economic Forum, January 24, 2018. https://www.weforum.org/ agenda/2018/01/8-ways-ai-can-help-save-the-planet/. House of Commons. 2018. “Algorithms in Decision-Making.” Fourth Report of Session 2017-19, HC351. May 23, 2018. ICDPPC (International Conference of Data Protection and Privacy Commissioners). 2018. “Declaration on Ethics and Data Protection in Artificial Intelligence.” https://icdppc.org/wp-content/uploads/2018/10/ _ICDPPC-40th_AI-Declaration_ADOPTED.pdf. IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. 2017. “Ethically Aligned Design: A Vision for Prioritizing Human Well-Being with Autonomous and Intelligent Systems,” Version IEEE. http://standards.Ieee.org/develop/indconn/ec/autonomous_ systems.html. Ihde, Don. 1990. Technology and the Lifeworld: From Garden to Earth. Bloomington: Indiana University Press. Jansen, Philip, Stearns Broadhead, Rowena Rodrigues, David Wright, Philp Brey, Alice Fox, and Ning Wang. 2018. “State-of-the-Art Review.” Draft of the D4.1 deliverable submitted to the European Commission on April 13, 2018. A report for The SIENNA Project, an EU H2020 research and innovation program under grant agreement no. 741716. اخلاقيات الذكاء الاصطناعي Johnson, Deborah G. 2006. “Computer Systems: Moral Entities but not Moral Agents.” Ethics and Information Technology 8, no. 4: 195–204. Kant, Immanuel. 1997. Lectures on Ethics. Edited by Peter Heath and J. B. Schneewind. Translated by Peter Heath. Cambridge: Cambridge University Press. Kelleher, John D., and Brendan Tierney. 2018. Data Science. Cambridge, MA: MIT Press. Kharpal, Arjun. 2017. “Stephen Hawking Says A.I. Could Be ‘Worst Event in the History of Our Civilization.’” CNBC. November 6, 2017. https://www.cnbc.com/2017/11/06/stephen-hawking-ai-couldbe-worst-event-in-civilization.html. Kubrick, Stanley, dir. 1968. 2001: A Space Odyssey. Beverly Hills, CA: Metro-Goldwyn-Mayer. Kurzweil, Ray. 2005. The Singularity Is Near. New York: Viking. Leta Jones, Meg. 2018. “Silencing Bad Bots: Global, Legal and Political Questions for Mean Machine Communication.” Communication Law and Policy 23, no. 2: 159–195. Lin, Patrick, Keith Abney, and George Bekey. 2011. “Robot Ethics: Mapping the Issues for a Mechanized World.” Artificial Intelligence 175:942– MacIntyre, Lee C. 2018. Post-Truth. Cambridge, MA: MIT Press. Marcuse, Herbert. 1991. One-Dimensional Man. Boston: Beacon Press. Marr, Bernard. 2018. “27 Incredible Examples of AI and Machine Learning in Practice.” Forbes, April 30. https://www.forbes.com/sites/ bernardmarr/2018/04/30/27-incredible-examples-of-ai-and-ma chine-learning-in-practice/#6b37edf27502. McAfee, Andrew, and Erik Brynjolfsson. 2017. Machine, Platform, Crowd: Harnessing Our Digital Future. New York: W. W. Norton. املراجع Miller, Tim. 2018. “Explanation in Artificial Intelligence: Insights from the Social Sciences.” arXiv, August 15. https://arxiv.org/pdf/1706.07269 .pdf. Mouffe, Chantal. 2013. Agonistics: Thinking the World Politically. London: Verso. Nemitz, Paul Friedrich, 2018. “Constitutional Democracy and Technology in the Age of Artificial Intelligence.” Philosophical Transactions of the Royal Society A 376, no. 2133. https://doi.org/10.1098/rsta.2018 .0089. Noble, David F. 1997. The Religion of Technology. New York: Penguin Books. Reijers, Wessel, David Wright, Philip Brey, Karsten Weber, Rowena Rodrigues, Declan O’ Sullivan, and Bert Gordijn. 2018. “Methods for Practising Ethics in Research and Innovation: A Literature Review, Critical Analysis and Recommendation.” Science and Engineering Ethics 24, no. 1437–1481. Royal Society, the. 2018. “Portrayals and Perceptions of AI and Why They Matter.” December 11, 2018. https://royalsociety.org/topics-policy/ projects/ai-narratives/. Rushkoff, Douglas. 2018. “Survival of the Richest.” Medium, July 5. https://medium.com/s/futurehuman/survival-of-the-richest9ef6cddd0cc1. Samek, Wojciech, Thomas Wiegand, and Klaus-Robert Müller. 2017. “Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models.” https://arxiv.org/pdf/1708.08296 .pdf. Schwab, Katharine. 2018. “The Exploitation, Injustice, and Waste Powering Our AI.” Fast Company. September 18, 2018. https:// www.fastcompany.com/90237802/the-exploitation-injustice-andwaste-powering-our-ai. اخلاقيات الذكاء الاصطناعي Seseri, Rudina. 2018. “The Problem with ‘Explainable AI.’” Tech Crunch. June 14, 2018. https://techcrunch.com/2018/06/14/the-problemwith-explainable-ai/?guccounter=1. Searle, John. R. 1980. “Minds, Brains, and Programs.” Behavioral and Brain Sciences 3, no. 3: 417–457. Shanahan, Murray. 2015. The Technological Singularity. Cambridge, MA: The MIT Press. Siau, Keng, and Weiyu Wang. 2018. “Building Trust in Artificial Intelligence, Machine Learning, and Robotics.” Cutter Business Technology Journal , no. 2: 46–53. State Council of China. 2017. “New Generation Artificial Intelligence Development Plan.” Translated by Flora Sapio, Weiming Chen, and Adrian Lo."}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "المراجع", "section_path": ["المراجع"], "page": 198, "content": "https://flia.org/notice-state-council-issuing-new-generation-"}
{"pack_id": "AR-ETHICS-2023", "language": "ar", "book": "ar_ai_ethics_2023", "section_title": "المراجع", "section_path": ["المراجع"], "page": 199, "content": "artificial-intelligence-development-plan/. Stoica, Ion. 2017. “A Berkeley View of Systems Challenges for AI.” Technical Report No. UCB/EECS-2017-159. http://www2.eecs.berkeley.edu/ Pubs/TechRpts/2017/EECS-2017. Sullins, John. 2006. “When Is a Robot a Moral Agent?” International Review of Information Ethics 6: 23–30. Surur. 2017. “Microsoft Aims to Lie to Their AI to Reduce Sexist Bias.” August 25, 2017. https://mspoweruser.com/microsoft-aims-lie-aireduce-sexist-bias/. Suzuki, Yutaka, Lisa Galli, Ayaka Ikeda, Shoji Itakura, and Michiteru Kitazaki. 2015. “Measuring Empathy for Human and Robot Hand Pain Using Electroencephalography.” Scientific Reports 5, article number https://www.nature.com/articles/srep15924. Tegmark, Max. 2017. Life 3.0: Being Human in the Age of Artificial Intelligence. Allen Lane/Penguin Books. املراجع Turkle, Sherry. 2011. Alone Together: Why We Expect More from Technology and Less from Each Other. New York: Basic Books. Turner, Jacob. 2019. Robot Rules: Regulating Artificial Intelligence. Cham: Palgrave Macmillan. Université de Montréal. 2017. “Montréal Declaration Responsible AI.” https://www.montrealdeclaration-responsibleai.com/the-declara tion. Vallor, Shannon. 2016. Technology and the Virtues. New York: Oxford University Press. Vigen, Tyler. 2015. Spurious Correlations. New York: Hachette Books. Villani, Cédric. 2018. For a Meaningful Artificial Intelligence: Towards a French and European Strategy. Composition of a parliamentary mission from September 8, 2017, to March 8, 2018, and assigned by the Prime Minister of France, Èdouard Philippe. Von Schomberg, René, ed. 2011. “Towards Responsible Research and Innovation in the Information and Communication Technologies and Security Technologies Fields.” A report from the European Commission Services. Luxembourg: Publications Office of the European Union. Vu, Mai-Anh T., Tülay Adalı, Demba Ba, György Buzsáki, David Carlson, Katherine Heller, et al. 2018. “A Shared Vision for Machine Learning in Neuroscience.” Journal of Neuroscience 38, no. 7: 1601–607. Wachter, Sandra, Brent Mittelstadt, and Luciano Floridi. 2017. “Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation.” International Data Privacy Law, http://dx.doi.org/10.2139/ssrn.2903469. Wallach, Wendell and Colin Allen. 2009. Moral Machines: Teaching Robots Right from Wrong. Oxford: Oxford University Press. Weld, Daniel S. and Gagan Bansal. 2018. “The Challenge of Crafting Intelligible Intelligence.” https://arxiv.org/pdf/1803.04263.pdf. اخلاقيات الذكاء الاصطناعي Winfield, Alan F.T. and Marina Jirotka. 2017. “The Case for an Ethical Black Box.” In Towards Autonomous Robotic Systems, edited by Yang Gao, Saber Fallah, Yaochu Jin, and Constantina Lekakou (proceedings of TAROS 2017, Guildford, UK, July 2017), 262–273. Cham: Springer. Winikoff, Michael. 2018. “Towards Trusting Autonomous Systems.” In Engineering Multi-Agent Systems, edited by Amal El Fallah Seghrouchni, Alessandro Ricci, and Son Trao, 3–20. Cham: Springer. Yampolskiy, Roman V. 2013. “Artificial Intelligence Safety Engineering: Why Machine Ethics Is a Wrong Approach.” In Philosophy and Theory of Artificial Intelligence edited by Vincent C. Müller, 289–296. Cham: Springer. Yeung, Karen. 2018. “A Study of the Implications of Advanced Digital Technologies (Including AI Systems) for the Concept of Responsibility within a Human Rights Framework.” A study commissioned for the Council of Europe Committee of experts on human rights dimensions of automated data processing and different forms of artificial intelligence. MSI-AUT (2018)05. Zimmerman, Jess. 2015. “What If the Mega-Rich Just Want Rocket Ships to Escape the Earth They Destroy?” Guardian, September 16, 2015. https://www.theguardian.com/commentisfree/2015/sep/16/megarich-rocket-ships-escape-earth. Zou, James, and Londa Schiebinger. 2018. “Design AI So That It’s Fair.” Nature 559:324–326."}
